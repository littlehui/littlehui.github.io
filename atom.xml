<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Littlehui&#39;s Notes</title>
  
  <subtitle>天地那么大，世界那么辽阔。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.lilhui.com/"/>
  <updated>2022-11-23T13:54:40.278Z</updated>
  <id>https://www.lilhui.com/</id>
  
  <author>
    <name>Littlehui</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【tomcat调优系列4】Tomcat 类加载机制，和热部署</title>
    <link href="https://www.lilhui.com/2022/11/23/tomcat/tomcat_4/"/>
    <id>https://www.lilhui.com/2022/11/23/tomcat/tomcat_4/</id>
    <published>2022-11-23T06:55:17.000Z</published>
    <updated>2022-11-23T13:54:40.278Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Tomcat类加载机制"><a href="#Tomcat类加载机制" class="headerlink" title="Tomcat类加载机制"></a>Tomcat类加载机制</h2><h3 id="JVM类加载器"><a href="#JVM类加载器" class="headerlink" title="JVM类加载器"></a>JVM类加载器</h3><p>Java中有3个类加载器，并且你可以自定义加载器。</p><ul><li>BoostrapClassLoader 是启动类加载器，由C预演实现，用来加载JVM启动时所需的核心类，比如rt.jar。</li><li>ExtClassLoader是扩展类加载器，用来加载\jre\lib\ext 目录下Jar包。扩展加载器的 #getParent()返回null,实际上扩展类加载器的<br>父类加载器就是启动类加载器。</li><li>AppClassLoader是系统类加载器，用来加载ClassPath下的类。应用程序默认用它来加载类。程序可以通过#getSystemClassLoader()来获取系统类加载器。</li><li>自定义加载器，用来加载自定义路径下的类。</li></ul><h3 id="双亲委派机制"><a href="#双亲委派机制" class="headerlink" title="双亲委派机制"></a>双亲委派机制</h3><p>加载某个类时会先委派父类加载器寻找目标类，找不到再委托上层父加载器，如果所有父加载器都找不到目标类，则在自己的类加载器路径中查找，并载入目标类。</p><p><img src="https://images.lilhui.com/c9cdb1fc55bcbd323b25aa274b6f2916" alt="图片"></p><p><img src="https://images.lilhui.com/23455a00f586de4dcebe1e4dd8453b05" alt="图片"></p><p>上图：ClassLoader#loadClass加载过程</p><p>问题： 为什么要设计双亲委派机制？</p><ul><li><strong>沙箱安全机制</strong>：自己写的java.lang.String.class类不会被夹在，防止API库被篡改。</li><li><strong>避免类的重复加载</strong>：当父亲已经加载了该类，就没有必要子ClassLoader再加载一次，保证加载类的唯一性。</li></ul><h3 id="Tomcat类加载机制-1"><a href="#Tomcat类加载机制-1" class="headerlink" title="Tomcat类加载机制"></a>Tomcat类加载机制</h3><p>Tomcat作为Servlet容器，它负责加载我们的Servlet类，此外还负责加载Servlet所依赖的Jar包。并且Tomcat本身也是一个Java程序。<br>因此它需要加载自己的类和依赖的Jar包。</p><p>问题：Tomcat如何隔离Web应用的？</p><p>Tomcat 自定义了一个类加载器WebAppClassLoader，并且给每个Web应用创建一个类加载器实例，每个Context容器负责创建和维护一个<br>WebAppClassLoader加载器实例。其实现的原理就是<strong>不同的类加载器实例加载的类被认为是不同的类，即使它们的类名相同（不同类加载器<br>实例加载的类是相互隔离的）</strong>。</p><p>Tomcat的自定义类加载器WebAppClassLoader打破了双亲委派机制。它首先自己尝试加载某个类，如果找不到再代理给父类加载器，其目的是<br>优先加载Web应用自己定义的类。具体实现就是重写ClassLoader的2个方法：findClass和loadClass.</p><p>findClass步骤：</p><ol><li>在Web应用本地目录下查找要加载的类。</li><li>如果没有找到，交给父加载器去查找，它的付加载器就是上面提到的系统类加载器。AppClassLoader.</li><li>如果父加载器也没找到这个类，抛出ClassNotFound异常。</li></ol><p>loadClass有6个步骤：</p><ol><li>现在本地Cache查找该类是否加载过，也就是说Tomcat的类加载器是否已经加载过这个类。</li><li>如果Tomcat加载器没加载过这个类，再看系统类加载器是否加载过。</li><li>如果都没有，就让ExtClassLoader去加载，这一步比较关键，目的防止 Web 应用自己的类覆盖 JRE 的核心类。因为 Tomcat 需要打破双<br>亲委托机制，假如 Web 应用里自定义了一个叫 Object 的类，如果先加载这个 Object 类，就会覆盖 JRE 里面的那个 Object 类，这就<br>是为什么 Tomcat 的类加载器会优先尝试用 ExtClassLoader 去加载，因为 ExtClassLoader 会委托给 BootstrapClassLoader 去加载，BootstrapClassLoader 发现自己已经加载了 Object 类，直接返回给 Tomcat 的类加载器，这样 Tomcat 的类加载器就不会去加载 Web 应用下的 Object 类了，也就避免了覆盖 JRE 核心类的问题。</li><li>如果 ExtClassLoader 加载器加载失败，也就是说 JRE 核心类中没有这类，那么就在本地 Web 应用目录下查找并加载。</li><li>如果本地目录下没有这个类，说明不是 Web 应用自己定义的类，那么由系统类加载器去加载。这里请你注意，Web 应用是通过Class.forName调用交给系统类加载器的，因为Class.forName的默认加载器就是系统类加载器。</li><li>如果上述加载过程全部失败，抛出 ClassNotFound 异常。</li></ol><p>本地cache -&gt; ExtendClassLoader -&gt; WebAppClassLoader -&gt; AppClassLoader</p><p>所以本地可以覆盖jar包里的实现。</p><h3 id="Tomcat类加载器的层次结构"><a href="#Tomcat类加载器的层次结构" class="headerlink" title="Tomcat类加载器的层次结构"></a>Tomcat类加载器的层次结构</h3><p>Tomcat 拥有不同的自定义类加载器，以实现对各种资源库的控制。 Tomcat 主要用类加载器解决以下 4 个问题：<br>同一个 Web 服务器里，各个 Web 项目之间各自使用的 Java 类库要互相隔离。</p><ul><li>同一个 Web 服务器里，各个 Web 项目之间各自使用的 Java 类库要互相隔离。</li><li>同一个 Web 服务器里，各个 Web 项目之间可以提供共享的 Java 类库 。</li><li>为了使服务器不受 Web 项目的影响，应该使服务器的类库与应用程序的类库互相独立。</li><li>对于支持 JSP 的 Web 服务器，应该支持热插拔（ HotSwap ）功能 。  </li></ul><p>Tomcat提供了四组目录供用户存放第三方类库：</p><ul><li>放置在/common目录中：类库可被Tomcat和所有的 Web应用程序共同使用。</li><li>放置在/server目录中：类库可被Tomcat使用，对所有的Web应用程序都不可见。</li><li>放置在/shared目录中：类库可被所有的Web应用程序共同使用，但对 Tomcat自己不可见。</li><li>放置在/WebApp/WEB-INF目录中：类库仅仅可以被此Web应用程序使用，对 Tomcat和其他Web应用程序都不可见。</li></ul><p>Tomcat自定义了多个类加载器</p><ol><li>CommonClassLoader   加载 /common</li><li>CatalinaClassLoader 加载 /server/</li><li>SharedClassLoader  加载 /shared/</li><li>WebappClassLoader  加载 /WebApp/WEB-INF/</li></ol><p><img src="https://images.lilhui.com/a4bfcb6f0ae2ddbd691e12746461c7cc" alt="图片"></p><h3 id="线程上下文加载器"><a href="#线程上下文加载器" class="headerlink" title="线程上下文加载器"></a>线程上下文加载器</h3><p>在 JVM 的实现中有一条隐含的规则，默认情况下，如果一个类由类加载器 A 加载，那么这个类的依赖类也是由相同的类加载器加载。比如 Spring 作为一个 Bean 工厂，它需要创建业务类的实例，并且在创建业务类实例之前需要加载这些类。<br>思考：如果spring作为共享第三方jar包，交给SharedClassLoader加载，但是业务类在web目录下，不在SharedClassLoader的加载路径下，那spring如何加载web应用目录下的业务bean呢？</p><p>问题： 如果spring作为共享第三方jar包，交给SharedClassLoader加载，但是业务类在web目录下，不在SharedClassLoader的加载路径下，那spring如何加载web应用目录下的业务bean呢？</p><p>Tomcat为每个Web应用创建一个WebAppClassLoader加载器，并在启动Web应用的线程设置上下文加载器。这样Spring在启动时就将现成上下文加载器取出来，用来加载Bean。</p><p>线程上下文加载器是一种类加载器传递机制，因为这个类加载器保存在线程私有数据里，只要是同一个线程，一旦设置了线程上下文加载器，在线程后续执行过程中就能把这个类加载器取出来用。<br>Thread.currentThread().getContextClassLoader()</p><p>线程上下文加载器不仅仅可以用在 Tomcat 和 Spring 类加载的场景里，核心框架类需要加载具体实现类时都可以用到它，比如我们熟悉的 JDBC 就是通过上下文类加载器来加载不同的数据库驱动的</p><p>线程上下文加载器，在SPI实现上用的比较多。</p><h2 id="Tomcat热加载和热部署"><a href="#Tomcat热加载和热部署" class="headerlink" title="Tomcat热加载和热部署"></a>Tomcat热加载和热部署</h2><p>在项目开发过程中，经常要改动Java/JSP 文件，但是又不想重新启动Tomcat，有两种方式:热加载和热部署。热部署表示重新部署应⽤，它的执⾏主体是Host。 热加载表示重新加载class，它的执⾏主体是Context。<br>热加载：在server.xml -&gt; context 标签中 设置 reloadable=”true”</p><ul><li>热加载：在server.xml -&gt; context 标签中 设置 reloadable=”true”</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Context</span> <span class="attr">docBase</span>=<span class="string">"D:\mvc"</span> <span class="attr">path</span>=<span class="string">"/mvc"</span>  <span class="attr">reloadable</span>=<span class="string">"true"</span> /&gt;</span></span><br><span class="line">热部署：在server.xml -&gt; Host标签中 设置  autoDeploy="true"</span><br></pre></td></tr></table></figure><ul><li>热部署：在server.xml -&gt; Host标签中 设置  autoDeploy=”true”</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Host</span> <span class="attr">name</span>=<span class="string">"localhost"</span>  <span class="attr">appBase</span>=<span class="string">"webapps"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">unpackWARs</span>=<span class="string">"true"</span> <span class="attr">autoDeploy</span>=<span class="string">"true"</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>他们的区别</strong></p><ul><li>热加载的实现方式是 Web 容器启动一个后台线程，定期检测类文件的变化，如果有变化，就重新加载类，在这个过程中不会清空 Session ，一般用在开发环境。</li><li>热部署原理类似，也是由后台线程定时检测 Web 应用的变化，但它会重新加载整个 Web 应用。这种方式会清空 Session，比热加载更加干净、彻底，一般用在生产环境。</li></ul><p>问题： Tomcat是如何用后台线程来实现热加载和热部署的</p><h3 id="Tomcat开启后台线程执行周期性任务"><a href="#Tomcat开启后台线程执行周期性任务" class="headerlink" title="Tomcat开启后台线程执行周期性任务"></a>Tomcat开启后台线程执行周期性任务</h3><p>Tomcat 通过开启后台线程ContainerBase.ContainerBackgroundProcessor，使得各个层次的容器组件都有机会完成一些周期性任务。我们在实际工作中，往往也需要执行一些周期性的任务，比如监控程序周期性拉取系统的健康状态，就可以借鉴这种设计。<br>Tomcat9 是通过ScheduledThreadPoolExecutor来开启后台线程的，它除了具有线程池的功能，还能够执行周期性的任务。</p><p><img src="https://images.lilhui.com/0121b5252cd38720749f046807893124" alt="图片"></p><p>此后台线程会调用当前容器的 backgroundProcess 方法，以及递归调用子孙的 backgroundProcess 方法，backgroundProcess 方法会触发容器的周期性任务。</p><p><img src="https://images.lilhui.com/5c90f19905daff7d323025a58de15ebd" alt="图片"></p><p>有了 ContainerBase 中的后台线程和 backgroundProcess 方法，各种子容器和通用 组件不需要各自弄一个后台线程来处理周期性任务，这样的设计显得优雅和整洁。</p><h3 id="热加载实现原理"><a href="#热加载实现原理" class="headerlink" title="热加载实现原理"></a>热加载实现原理</h3><p>有了 ContainerBase 的周期性任务处理“框架”，作为具体容器子类，只需要实现自 己的周期性任务就行。而 Tomcat 的热加载，就是在 Context 容器中实现的。Context 容 器的 backgroundProcess 方法是这样实现的：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//  StandardContext#backgroundProcess</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//WebappLoader 周期性的检查 WEB-INF/classes 和 WEB-INF/lib 目录下的类文件</span></span><br><span class="line"><span class="comment">// 热加载</span></span><br><span class="line">Loader loader = getLoader();</span><br><span class="line"><span class="keyword">if</span> (loader != <span class="keyword">null</span>) &#123;</span><br><span class="line">    loader.backgroundProcess();        </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>WebappLoader 实现热加载的逻辑：它主要是调用了 Context 容器的 reload 方法，先stop Context容器，再start Context容器。具体的实现：<br>停止和销毁 Context 容器及其所有子容器，子容器其实就是 Wrapper，也就是说 Wrapper 里面 Servlet 实例也被销毁了。</p><ol><li>停止和销毁 Context 容器及其所有子容器，子容器其实就是 Wrapper，也就是说 Wrapper 里面 Servlet 实例也被销毁了。</li><li>停止和销毁 Context 容器关联的 Listener 和 Filter。</li><li>停止和销毁 Context 下的 Pipeline 和各种 Valve。</li><li>停止和销毁 Context 的类加载器，以及类加载器加载的类文件资源。</li><li>启动 Context 容器，在这个过程中会重新创建前面四步被销毁的资源。</li></ol><p>在这个过程中，类加载器发挥着关键作用。一个 Context 容器对应一个类加载器，类加载器在销毁的过程中会把它加载的所有类也全部销毁。Context 容器在启动过程中，会创建一个新的类加载器来加载新的类文件。</p><h3 id="Tomcat热部署原理"><a href="#Tomcat热部署原理" class="headerlink" title="Tomcat热部署原理"></a>Tomcat热部署原理</h3><p>热部署跟热加载的本质区别是，热部署会重新部署 Web 应用，原来的 Context 对象会整个被销毁掉，因此这个 Context 所关联的一切资源都会被销毁，包括 Session。<br>Host 容器并没有在 backgroundProcess 方法中实现周期性检测的任务，而是通过监听器 HostConfig 来实现的</p><p>Host 容器并没有在 backgroundProcess 方法中实现周期性检测的任务，而是通过监听器 HostConfig 来实现的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// HostConfig#lifecycleEvent</span></span><br><span class="line"><span class="comment">// 周期性任务</span></span><br><span class="line"><span class="keyword">if</span> (event.getType().equals(Lifecycle.PERIODIC_EVENT)) &#123;</span><br><span class="line">    check();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">check</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (host.getAutoDeploy()) &#123;</span><br><span class="line">        <span class="comment">// Check for resources modification to trigger redeployment</span></span><br><span class="line">        DeployedApplication[] apps = deployed.values().toArray(<span class="keyword">new</span> DeployedApplication[<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">for</span> (DeployedApplication app : apps) &#123;</span><br><span class="line">            <span class="keyword">if</span> (tryAddServiced(app.name)) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// 检查 Web 应用目录是否有变化</span></span><br><span class="line">                    checkResources(app, <span class="keyword">false</span>);</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    removeServiced(app.name);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Check for old versions of applications that can now be undeployed</span></span><br><span class="line">        <span class="keyword">if</span> (host.getUndeployOldVersions()) &#123;</span><br><span class="line">            checkUndeploy();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Hotdeploy applications</span></span><br><span class="line">        <span class="comment">//热部署</span></span><br><span class="line">        deployApps();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>HostConfig 会检查 webapps 目录下的所有 Web 应用：</p><ul><li>如果原来 Web 应用目录被删掉了，就把相应 Context 容器整个销毁掉。</li><li>是否有新的 Web 应用目录放进来了，或者有新的 WAR 包放进来了，就部署相应的 Web 应用。</li></ul><p>因此 HostConfig 做的事情都是比较“宏观”的，它不会去检查具体类文件或者资源文件是否有变化，而是检查 Web 应用目录级别的变化。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Tomcat类加载机制&quot;&gt;&lt;a href=&quot;#Tomcat类加载机制&quot; class=&quot;headerlink&quot; title=&quot;Tomcat类加载机制&quot;&gt;&lt;/a&gt;Tomcat类加载机制&lt;/h2&gt;&lt;h3 id=&quot;JVM类加载器&quot;&gt;&lt;a href=&quot;#JVM类加载器&quot; c
      
    
    </summary>
    
      <category term="tomcat" scheme="https://www.lilhui.com/categories/tomcat/"/>
    
    
      <category term="tomcat" scheme="https://www.lilhui.com/tags/tomcat/"/>
    
      <category term="类加载，热部署" scheme="https://www.lilhui.com/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD%EF%BC%8C%E7%83%AD%E9%83%A8%E7%BD%B2/"/>
    
  </entry>
  
  <entry>
    <title>【tomcat调优系列3】Tomcat底层BIO和NIO实现原理</title>
    <link href="https://www.lilhui.com/2022/11/22/tomcat/tomcat_3/"/>
    <id>https://www.lilhui.com/2022/11/22/tomcat/tomcat_3/</id>
    <published>2022-11-22T03:02:16.000Z</published>
    <updated>2022-11-23T06:55:40.261Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Tomcat-IO选择历史"><a href="#Tomcat-IO选择历史" class="headerlink" title="Tomcat IO选择历史"></a>Tomcat IO选择历史</h2><ol><li>Tomcat7时默认用的BIO,同步阻塞。可以通过配置修改为NIO</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Connector</span> <span class="attr">port</span>=<span class="string">"8080"</span> <span class="attr">protocol</span>=<span class="string">"org.apache.coyote.http11.Http11Ni oProtocol"</span> </span></span><br><span class="line"><span class="tag"><span class="attr">connectionTimeout</span>=<span class="string">"20000"</span> <span class="attr">redirectPort</span>=<span class="string">"8443"</span> /&gt;</span></span><br></pre></td></tr></table></figure><ol start="2"><li>Tomcat8.5以后默认用的是NIO.</li></ol><h2 id="阻塞与非阻塞"><a href="#阻塞与非阻塞" class="headerlink" title="阻塞与非阻塞"></a>阻塞与非阻塞</h2><p>Socket通信过程分两个部分：</p><ol><li>连接准备</li><li>拷贝内核缓存到用户缓存。<br>阻塞和非阻塞的概念是在连接准备阶段的描述。</li></ol><h2 id="Tomcat的BIO实现"><a href="#Tomcat的BIO实现" class="headerlink" title="Tomcat的BIO实现"></a>Tomcat的BIO实现</h2><ol><li>JioEndpoint的Acceptor线程负责循环阻塞接收sock连接。</li><li>每接收到一个socket连接就包装成SocketProcessor扔进线程池Executor.SocketProcessor是一个Runnable</li><li>SocketProcess负责从scoket阻塞读取数据，并且向socket中阻塞写入数据。</li></ol><p>Acceptor现成数量默认为1，可以通过acceptorThreadCount参数进行配置。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Executor</span> <span class="attr">name</span>=<span class="string">"tomcatThreadPool"</span> <span class="attr">namePrefix</span>=<span class="string">"catalina-exec-"</span> </span></span><br><span class="line"><span class="tag">        <span class="attr">maxThreads</span>=<span class="string">"150"</span> <span class="attr">minSpareThreads</span>=<span class="string">"4"</span>/&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">Connector</span> <span class="attr">port</span>=<span class="string">"8080"</span> <span class="attr">protocol</span>=<span class="string">"org.apache.coyote.http11.Http11Ni oProtocol"</span> </span></span><br><span class="line"><span class="tag">        <span class="attr">connectionTimeout</span>=<span class="string">"20000"</span> </span></span><br><span class="line"><span class="tag">           <span class="attr">redirectPort</span>=<span class="string">"8443"</span> <span class="attr">executor</span>=<span class="string">"tomcatThreadPool"</span>/&gt;</span></span><br></pre></td></tr></table></figure><p>Tomcat中每个Connector都会创建一个线程池，并且默认值：</p><ol><li>最小线程数量10</li><li>最大线程数量20</li></ol><p>使用BIO处理请求时：</p><ol><li>当请求数量比较大时，可以提高Acceptor线程数量，提高接收请求的速率。</li><li>当请求比较耗时时，可以提高线程池Executor的最大线程数量。</li></ol><p>原理图：</p><p><img src="https://images.lilhui.com/1f62e4fafb4b3b53161a55d323656dc1" alt="图片"></p><h2 id="Tomcat的NIO实现"><a href="#Tomcat的NIO实现" class="headerlink" title="Tomcat的NIO实现"></a>Tomcat的NIO实现</h2><p>NIO非阻塞接收socket连接，非阻塞从socket读取数据，非阻塞将数据写入socket中。</p><p>在Tomcat中，只有从socket读取请求行，请求头数据时是非阻塞的。在读取请求体是阻塞的，响应数据也是阻塞的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Tomcat-IO选择历史&quot;&gt;&lt;a href=&quot;#Tomcat-IO选择历史&quot; class=&quot;headerlink&quot; title=&quot;Tomcat IO选择历史&quot;&gt;&lt;/a&gt;Tomcat IO选择历史&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Tomcat7时默认用的BIO,同步阻塞
      
    
    </summary>
    
      <category term="tomcat" scheme="https://www.lilhui.com/categories/tomcat/"/>
    
    
      <category term="tomcat" scheme="https://www.lilhui.com/tags/tomcat/"/>
    
      <category term="bio" scheme="https://www.lilhui.com/tags/bio/"/>
    
      <category term="nio" scheme="https://www.lilhui.com/tags/nio/"/>
    
  </entry>
  
  <entry>
    <title>【tomcat调优系列2】Tomcat响应数据过程</title>
    <link href="https://www.lilhui.com/2022/11/18/tomcat/tomcat_2/"/>
    <id>https://www.lilhui.com/2022/11/18/tomcat/tomcat_2/</id>
    <published>2022-11-18T07:30:18.000Z</published>
    <updated>2022-11-20T02:04:38.481Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Tomcat响应数据过程"><a href="#Tomcat响应数据过程" class="headerlink" title="Tomcat响应数据过程"></a>Tomcat响应数据过程</h2><h3 id="关键部件解释"><a href="#关键部件解释" class="headerlink" title="关键部件解释"></a>关键部件解释</h3><ol><li>OutputStream： 用于response的输出流。Tomcat这里是CoyoteOutputStream</li><li>OutputBuffer: 输出流的缓冲</li><li>ByteChunk: OutputBuffer的一个对象，缓冲的，缓冲区。</li><li>ByteChunk的buff构成，大小8192.</li><li>ByteOutputChannel：ByteChunk的out。缓冲区的数据流向的渠道。其实就是socket.</li><li>realWriteBytes方法：ByteOutputChannel的方法。会把src的数据发送给对应的驱动。</li><li>org.apache.coyote.Response：发送逻辑</li></ol><h3 id="触发缓冲区标记的发送"><a href="#触发缓冲区标记的发送" class="headerlink" title="触发缓冲区标记的发送"></a>触发缓冲区标记的发送</h3><ol><li>缓冲区满的情况：ByteChunk.append -&gt; out.realWriteBytes(src,off,len)。换冲突的大小为8192 ByteChunk</li><li>缓冲区没满：调用outputStream.flush</li></ol><h3 id="ouputStream-flush的方法"><a href="#ouputStream-flush的方法" class="headerlink" title="ouputStream.flush的方法"></a>ouputStream.flush的方法</h3><ol><li>判断是否发送过响应头，没发送则发送相应头。</li><li>调用ByteChunk的flushBuffer方法，把缓冲区的数据发送出去。</li><li>发送时候是从 ByteBuffer 发送到SocketBuffer(也是ByteChunk实现的)。SocketBuffer发送给socket</li></ol><h3 id="coyoteResponse-doWrite-outputChunk"><a href="#coyoteResponse-doWrite-outputChunk" class="headerlink" title="coyoteResponse.doWrite(outputChunk)"></a>coyoteResponse.doWrite(outputChunk)</h3><ol><li>调用方法：outputBuffer.doWrite(chunk, this).OutputBuffer是InternalOutputBuffer。</li><li>该doWrite⽅法中，⾸先会判断响应头是否已经发送，如果没有发送，则会构造响应头，并发响应头发送给 socketBuffer，发送完响应头，会调⽤响应的output的activeFilters，对于不同的响应体需要使⽤不同的 发送逻辑。⽐如ChunkedOutputFilter是⽤来发送分块响应体的，IdentityOutputFilter是⽤来发送 Content-length响应体的，VoidOutputFilter不会真正的把数据发送出去。</li><li>在构造响应头时，会识别响应体应该通过什么OutputFilter来发送，如果响应中存在content-length那么 则使⽤IdentityOutputFilter来发送响应体，否则使⽤ChunkedOutputFilter，当然还有⼀些异常情况下会 使⽤VoidOutputFilter，表示不会发送响应体。</li></ol><h3 id="响应的Content-lenth什么时候确定"><a href="#响应的Content-lenth什么时候确定" class="headerlink" title="响应的Content-lenth什么时候确定"></a>响应的Content-lenth什么时候确定</h3><p>答案是：当请求在servlet中执⾏完成后，会调⽤response.finishResponse()⽅法，该⽅法会调⽤ outputBuffer.close()，该outputBuffer就是org.apache.catalina.connector.OutputBuffer，该⽅法会 判断响应体是否已发送，如果在调⽤这个close时响应头还没有发送，则表示响应体的数据在之前⼀直没有 发送过，⼀直存在了第⼀层缓冲区中，并且⼀直没有塞满该缓冲区，因为该缓冲区如果被塞满了，则会发 送响应头，所以当执⾏到close⽅法是，响应头还没发送过，那么缓冲区中的数据就是响应体全部的数据， 即，缓冲区数据的⻓度就是content-length。 反之，在调⽤close⽅法之前，就已经发送过数据了，那么响应头中就没有content-length，就会⽤ ChunkedOutputFilter来发送数据。</p><p>并且在执⾏close⽅法时，会先将响应头的数据发送给socketbuffer，然后将第⼀层缓冲区的数据通过对应 的OutputFilter发送给socketbuffer，然后调⽤OutputFilter的end⽅法，IdentityOutputFilter的end⽅ 法实现很简单，⽽ChunkedOutputFilter的end⽅法则相对做的事情更多⼀点，因为 ChunkedOutputFilter的doWrite⼀次只会发送⼀块数据，所以end要负责循环调⽤doWrite⽅法，把全部 的数据库发送完。</p><p>最后将socketbuffer中的数据发送给socket。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Tomcat响应数据过程&quot;&gt;&lt;a href=&quot;#Tomcat响应数据过程&quot; class=&quot;headerlink&quot; title=&quot;Tomcat响应数据过程&quot;&gt;&lt;/a&gt;Tomcat响应数据过程&lt;/h2&gt;&lt;h3 id=&quot;关键部件解释&quot;&gt;&lt;a href=&quot;#关键部件解释&quot;
      
    
    </summary>
    
      <category term="tomcat" scheme="https://www.lilhui.com/categories/tomcat/"/>
    
    
      <category term="tomcat" scheme="https://www.lilhui.com/tags/tomcat/"/>
    
      <category term="调优" scheme="https://www.lilhui.com/tags/%E8%B0%83%E4%BC%98/"/>
    
  </entry>
  
  <entry>
    <title>【tomcat调优系列1】Tomcat的请求过程</title>
    <link href="https://www.lilhui.com/2022/11/18/tomcat/tomcat_1/"/>
    <id>https://www.lilhui.com/2022/11/18/tomcat/tomcat_1/</id>
    <published>2022-11-18T06:57:04.000Z</published>
    <updated>2022-11-20T02:04:38.477Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Tomcat请求过程"><a href="#Tomcat请求过程" class="headerlink" title="Tomcat请求过程"></a>Tomcat请求过程</h2><h3 id="几个部件："><a href="#几个部件：" class="headerlink" title="几个部件："></a>几个部件：</h3><ol><li>Endpoint： tomcat接收socket链接的组件。</li><li>Socket：请求的通道链接</li><li>InputBuffer. InternalInputBuffer,AbstractInputBuffer：缓冲内存</li><li>Request：请求对象</li><li>MessageBytes: 请求对象的消息内容</li><li>ByteChunk：</li><li>Connection：Java层面的链接对象</li><li>Servlet：处理请求的组件</li><li>Response：请求处理后的返回</li></ol><h3 id="请求过程"><a href="#请求过程" class="headerlink" title="请求过程"></a>请求过程</h3><ul><li>请求的解析</li></ul><ol><li>Endpoint接收socket链接。</li><li>从socket中获取数据并缓存到InputBuffer。BIO是InternalInputBuffer继承自AbstractInputBuffer</li><li>从InputBuffer中解析请求。将完整的请求协议和请求体封装到Request对象。</li><li>Request中的messageByte进行标记。标记url,header,请求体等。</li><li>解析头，解析请求。</li><li>初始化请求头的一些参数：Connextion keepalive，Content-length等。包括请求体处理的InputFilter</li><li>将请求交给容器</li></ol><ul><li>请求的处理</li></ul><ol start="8"><li>容器将请求分发到具体的Servlet进行处理。</li><li>Servlet处理请求利用Response进行响应。将返回的数据写入缓冲区，调用flush或者close时，把缓冲区的数据发送给socket.</li><li>servlet处理完请求后，检查是否需要把响应数据发送给socket.</li><li>看请求体是否处理结束，是否还有剩余数据，如果有剩余数据，把这些数据处理掉。以便获取下个请求的数据。</li><li>回到第一步处理下一个请求。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Tomcat请求过程&quot;&gt;&lt;a href=&quot;#Tomcat请求过程&quot; class=&quot;headerlink&quot; title=&quot;Tomcat请求过程&quot;&gt;&lt;/a&gt;Tomcat请求过程&lt;/h2&gt;&lt;h3 id=&quot;几个部件：&quot;&gt;&lt;a href=&quot;#几个部件：&quot; class=&quot;he
      
    
    </summary>
    
      <category term="tomcat" scheme="https://www.lilhui.com/categories/tomcat/"/>
    
    
      <category term="tomcat" scheme="https://www.lilhui.com/tags/tomcat/"/>
    
      <category term="调优" scheme="https://www.lilhui.com/tags/%E8%B0%83%E4%BC%98/"/>
    
  </entry>
  
  <entry>
    <title>云原生下的Java虚拟机 GraalVM</title>
    <link href="https://www.lilhui.com/2022/10/27/java/jvm_tuning/tuning_2/"/>
    <id>https://www.lilhui.com/2022/10/27/java/jvm_tuning/tuning_2/</id>
    <published>2022-10-27T03:44:31.000Z</published>
    <updated>2022-10-27T07:08:59.961Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>java 的编译器<br>C1,C2<br>C1不进行优化，C2会进行优化。热点代码缓存,JIT等等。</p><p>C2 C++写的，太复杂，不维护，而且有bug<br>java语言一直在进步，C2没有办法维护，需要一种新的编译器来进行支持，所以有了GraalVM</p><ul><li><p>事实<br>JIT,性能优化、垃圾回收等代表的特性需要一段时间来达到最佳性能。<br>java是面向大规模、长时间的服务应而设计。</p></li><li><p>矛盾<br>  微服务时代对启动速度、达到高性能的时间提出了新的要求。</p></li></ul><h3 id="问题根源"><a href="#问题根源" class="headerlink" title="问题根源"></a>问题根源</h3><p>Java离不开虚拟机（JVM)</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p><strong>革命派：</strong> 直接而干掉Java和Java生态。（Golang的诞生）<br><strong>保守派：</strong> 保留原有主流Java生态和技术资产，朝着微服务、云原生环境靠拢（GraalVM)</p><h2 id="GraalVM的技术"><a href="#GraalVM的技术" class="headerlink" title="GraalVM的技术"></a>GraalVM的技术</h2><p><strong>AOT技术：</strong> ahead of time</p><p>编译成native代码花费时间太大，这部分时间无法节省，所以引入AOT，减少这部分时间。</p><h3 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h3><ul><li>C++<br>  微软的Stackless模式单台1000万个链接。<br>  腾讯微信团队：libco</li><li>Java<br>  JVM（Loom:fibers轻量级用户线程）<br>  基于JNI<br>  操控字节码</li></ul><h2 id="GraalVM介绍"><a href="#GraalVM介绍" class="headerlink" title="GraalVM介绍"></a>GraalVM介绍</h2><p>C2编译器比较缓和，GraalVM比较激进</p><p><img src="https://images.lilhui.com/a0c5bf2ee63b97dcd762ee4843e6a734" alt="图片"></p><p>JVMCI: JVM compile interface</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;java 的编译器&lt;br&gt;C1,C2&lt;br&gt;C1不进行优化，C2会进行优化。热点代码缓存,JIT等等。&lt;/p&gt;
&lt;p&gt;C2 C++写的，太复
      
    
    </summary>
    
      <category term="java" scheme="https://www.lilhui.com/categories/java/"/>
    
    
      <category term="GraalVM" scheme="https://www.lilhui.com/tags/GraalVM/"/>
    
  </entry>
  
  <entry>
    <title>JVM调优系列1:ZGC详解</title>
    <link href="https://www.lilhui.com/2022/10/26/java/jvm_tuning/tuning_1/"/>
    <id>https://www.lilhui.com/2022/10/26/java/jvm_tuning/tuning_1/</id>
    <published>2022-10-26T07:49:32.000Z</published>
    <updated>2022-10-27T02:38:19.283Z</updated>
    
    <content type="html"><![CDATA[<ul><li>逃逸分析</li><li>标量替换</li><li><p>栈上分配</p></li><li><p>锁消除</p></li><li>锁粗化</li></ul><h2 id="JIT"><a href="#JIT" class="headerlink" title="JIT"></a>JIT</h2><p>JVM 语言无关性<br>字节码执行</p><pre><code>- 解释执行- 即时编译 JIT</code></pre><p>JIT是编译成本地字节码。非java字节码，是机器直接运行的本地编码，可能是汇编等。</p><p><img src="https://images.lilhui.com/7e6500afac4a1919f2d8d780657aa187" alt="图片"></p><h3 id="编译器"><a href="#编译器" class="headerlink" title="编译器"></a>编译器</h3><p>C1 class -&gt; 本地编码（不做优化）<br>C2 性能优化</p><ul><li>热点探测技术<ul><li>方法内联<br>热点探测技术<br>方法体大小限制</li><li>栈上分配</li></ul></li></ul><p>C2比较难维护，Java 10 以后开发了新的Graal（java写的）</p><ul><li>分层编译</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;逃逸分析&lt;/li&gt;
&lt;li&gt;标量替换&lt;/li&gt;
&lt;li&gt;&lt;p&gt;栈上分配&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;锁消除&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;锁粗化&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;JIT&quot;&gt;&lt;a href=&quot;#JIT&quot; class=&quot;headerlink
      
    
    </summary>
    
      <category term="java" scheme="https://www.lilhui.com/categories/java/"/>
    
      <category term="jvm" scheme="https://www.lilhui.com/categories/java/jvm/"/>
    
    
      <category term="调优" scheme="https://www.lilhui.com/tags/%E8%B0%83%E4%BC%98/"/>
    
      <category term="jvm" scheme="https://www.lilhui.com/tags/jvm/"/>
    
      <category term="ZGC" scheme="https://www.lilhui.com/tags/ZGC/"/>
    
  </entry>
  
  <entry>
    <title>【深入理解Spring系列4】BeanDefinition</title>
    <link href="https://www.lilhui.com/2022/07/12/java/spring/spring_deep_4/"/>
    <id>https://www.lilhui.com/2022/07/12/java/spring/spring_deep_4/</id>
    <published>2022-07-12T07:31:17.000Z</published>
    <updated>2022-07-12T07:43:09.243Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h2><p>Spring Bean的 四种装配模式外，还有一种自动策略。</p><p>当只有一个 构造方法，并且构造方法里有参数。<br>会进行 aurowireConstructor(beanName, mdb, ctors, args)</p><ul><li>spring扫描不能直接new的方法</li></ul><p>@DependsOn</p><p>@Prototype 执行的时候new</p><p>所以需要先解析验证。</p><p>scan-parse（会变成BeaDefinition）-validate(info)-new(开始spring的生命周期)</p><p>可以这么理解：</p><p>beanDefinition之于Spring<br>相当于class之于java对象</p><ul><li>常量（BeanDefinition)<br>-<br>SCOPE_SINGLETON</li></ul><p>ROLE_APPLICATION</p><p>setParentName</p><p>//自动装配候选对象 ，被装配<br>setAutowireCandidate<br>//候选对象最高级<br>setPrimary</p><p>BeanDefinition所有属性都能找到与之匹配的 xml配置。</p><p>ac.getBean(XXX);是从DefaultSingletonBeanRegistry.singletonObjects.get(XXX)</p><ul><li>abstractApplicationContext</li></ul><p>abstractApplicationContext.refresh()</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//这里初始化对象。还未装配</span><br><span class="line">finishBeanFactoryInitialization(beanFactory);</span><br><span class="line"></span><br><span class="line">//这里装配。</span><br><span class="line">finishRefresh()</span><br></pre></td></tr></table></figure><ol><li>扫描</li><li>parse</li><li>validate</li><li>life  遍历map得到BeanDefinition实例化。</li></ol><h2 id="BeanDefinition"><a href="#BeanDefinition" class="headerlink" title="BeanDefinition"></a>BeanDefinition</h2><p>各方法说明：</p><p>setPrimary:<br>多个接口实现的时候，自动注入候选的时候排第一。</p><ul><li>关键父类<br>AbstractBeanDefinition</li></ul><p>ChildBeanDefinition,RootBeanDefinition Spring 2.5的时候用</p><p>GenericBeanDefinition<br>现在常用。</p><p>xml 配置里的<bean></bean>描述的就是 beanDefinition的属性。<br>spring容器会进行扫描。扫描后会根据bendefinition里描述的进行实例化。</p><p>abstract = true 必须要有 beanClass</p><ul><li>RootBeanDefinition</li></ul><p>减少不同 bean配置多种相同相同属性值的 工作量 abstract=true</p><p>parent = ‘xxx’</p><p>spring 2.5之前有这种写法。后面更方便了用扫描，用标签。</p><p>问题：RootBeanDefinition也有 setParentName()，为什么要多一个ChildBeanDefinition ?</p><p>RootBeanDefinition一般作为父出现，或者一般BD出现。但是不作为子BD出现。<br>为什么要这样规定？为什么设置Root的Parent要抛出异常？</p><p>合并BeanDefinition？</p><ul><li>AnnotatedBeanDefinitionReader</li></ul><p>作用：解析@Configuration 这标签会去扫描</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public AnnotationConfigApplicationContext() &#123;</span><br><span class="line">this.reader = new AnnotatedBeanDefinitionReader(this);</span><br><span class="line">this.scanner = new ClassPathBeanDefinitionScanner(this);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>beanReader = AnnotatedBeanDefinitionReader(this);<br>把 配置的AppConfig 变成 BeanDefinition</p><p>其他的 要完成扫描的时候去new 其他BD.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">this.reader = new AnnotatedBeanDefinitionReader(this);  这么写是为了后面能通过 context.register.registBean(标签) 来扩展自定义标签。</span><br></pre></td></tr></table></figure></p><p>注意这里是为了扩展，spring启动的时候并不是用这个scaner去扫描。<br>实际上用的是,在BeanDefinitionRegistry这个后置处理器。</p><p>ConfigutationClassPostProcessor.postProcessBanDefinitionRegistry(registry)</p><p>-&gt;<br>这里找到 registry里初始化的BeanDefinition，进行parse<br>ConfigurationClassParser.parse(Set<beandefinitionholder> candidates)<br>这个方法里会判断 参数是否实现了 AnnotatedBeanDefinition</beandefinitionholder></p><p>bd instanceof AnnotatedBeanDefinition</p><p>-</p><p>ConfigurationClassParser.processConfigurationClass</p><p>//这段很有意思，扫描结束后会将sourceClass设置为null。说明所有的BeanDefinition都扫描出来了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">do &#123;</span><br><span class="line">sourceClass = doProcessConfigurationClass(configClass, sourceClass);</span><br><span class="line">&#125;</span><br><span class="line">while (sourceClass != null);</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">protected final SourceClass doProcessConfigurationClass(ConfigurationClass configClass, SourceClass sourceClass)</span><br></pre></td></tr></table></figure><p>doProcessConfigurationClass<br>这里是实现。<br>实际识别了@Component  @ComponentScan @ImportSource 等标签。</p><p>然后在<br>ComponentScanAnnotationParser<br>类里的<br>public Set<beandefinitionholder> parse(AnnotationAttributes componentScan, final String declaringClass)</beandefinitionholder></p><p>进行实际的扫描，先new 出了<br>ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(this.registry,</p><p>再判断各种includerFilter excluderFilter<br>最后根据 标签配置的 包路径进行文件扫描。<br>从而扫描出Beandefinition 放到BeanDeinitionMap</p><p>小总结：<br>Beandefinition决定了spring 中Bean的各种特征。<br>class-beandefinition-springbean。<br>通过beandefinition spring定义了一套 spring bean的属性特征。</p><p>GenericBeanDefinition追加了setBeanClass</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前情提要&quot;&gt;&lt;a href=&quot;#前情提要&quot; class=&quot;headerlink&quot; title=&quot;前情提要&quot;&gt;&lt;/a&gt;前情提要&lt;/h2&gt;&lt;p&gt;Spring Bean的 四种装配模式外，还有一种自动策略。&lt;/p&gt;
&lt;p&gt;当只有一个 构造方法，并且构造方法里有参数。&lt;b
      
    
    </summary>
    
      <category term="spring" scheme="https://www.lilhui.com/categories/spring/"/>
    
    
      <category term="bean" scheme="https://www.lilhui.com/tags/bean/"/>
    
  </entry>
  
  <entry>
    <title>【rabbitMq学习1】MQ的基本概念</title>
    <link href="https://www.lilhui.com/2022/07/11/mq/rabbitmq_core_1/"/>
    <id>https://www.lilhui.com/2022/07/11/mq/rabbitmq_core_1/</id>
    <published>2022-07-11T07:00:32.000Z</published>
    <updated>2022-07-11T07:03:49.781Z</updated>
    
    <content type="html"><![CDATA[<p>##MQ的基本概念</p><p>MQ全称 Message Queue(消息队列)，是在消息的传输过程中保存消息的容器。多用于分布式系统之间进行通信。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;##MQ的基本概念&lt;/p&gt;
&lt;p&gt;MQ全称 Message Queue(消息队列)，是在消息的传输过程中保存消息的容器。多用于分布式系统之间进行通信。&lt;/p&gt;

      
    
    </summary>
    
      <category term="mq" scheme="https://www.lilhui.com/categories/mq/"/>
    
    
      <category term="rabbitMq" scheme="https://www.lilhui.com/tags/rabbitMq/"/>
    
  </entry>
  
  <entry>
    <title>【Redis学习7】开发规范和性能优化</title>
    <link href="https://www.lilhui.com/2022/07/06/redis/redis_core_7/"/>
    <id>https://www.lilhui.com/2022/07/06/redis/redis_core_7/</id>
    <published>2022-07-06T08:58:52.000Z</published>
    <updated>2022-07-06T09:24:34.085Z</updated>
    
    <content type="html"><![CDATA[<h2 id="键值设计"><a href="#键值设计" class="headerlink" title="键值设计"></a>键值设计</h2><h3 id="key名设计"><a href="#key名设计" class="headerlink" title="key名设计"></a>key名设计</h3><p>(1)【建议】: 可读性和可管理性<br>以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trade:order:<span class="number">1</span></span><br></pre></td></tr></table></figure><p>(2)【建议】：简洁性<br>保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">user:&#123;uid&#125;:friends:messages:&#123;mid&#125; 简化为 u:&#123;uid&#125;:fr:m:&#123;mid&#125;</span><br></pre></td></tr></table></figure><p>(3)【强制】：不要包含特殊字符<br>反例：包含空格、换行、单双引号以及其他转义字符</p><h3 id="value设计"><a href="#value设计" class="headerlink" title="value设计"></a>value设计</h3><p>(1)【强制】：拒绝bigkey(防止网卡流量、慢查询)<br>在Redis中，一个字符串最大512MB，一个二级数据结构（例如hash、list、set、zset）可以存储大约40亿个(2^32-1)个元素，但实际中如果下面两种情况，我就会认为它是bigkey。</p><ul><li>字符串类型：它的big体现在单个value值很大，一般认为超过10KB就是bigkey。</li><li>非字符串类型：哈希、列表、集合、有序集合，它们的big体现在元素个数太多。</li></ul><p>一般来说，string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。<br>反例：一个包含200万个元素的list。</p><p>非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞）</p><h3 id="bigkey的危害"><a href="#bigkey的危害" class="headerlink" title="bigkey的危害"></a>bigkey的危害</h3><ol><li>导致网络堵塞</li><li>导致redis阻塞<br>bigkey也就意味着每次获取要产生的网络流量较大，假设一个bigkey为1MB，客户端每秒访问量为1000，那么每秒产生1000MB的流量，对于普通的千兆网卡(按照字节算是128MB/s)的服务器来说简直是灭顶之灾，而且一般服务器会采用单机多实例的方式来部署，也就是说一个bigkey可能会对其他实例也造成影响，其后果不堪设想。</li><li>过期删除<br>有个bigkey，它安分守己（只执行简单的命令，例如hget、lpop、zscore等），但它设置了过期时间，当它过期后，会被删除，如果没有使用Redis 4.0的过期异步删除(lazyfree-lazy-expire yes)，就会存在阻塞Redis的可能性。</li></ol><h3 id="bigkey的产生"><a href="#bigkey的产生" class="headerlink" title="bigkey的产生"></a>bigkey的产生</h3><p>一般来说，bigkey的产生都是由于程序设计不当，或者对于数据规模预料不清楚造成的，来看几个例子：<br>(1) 社交类：粉丝列表，如果某些明星或者大v不精心设计下，必是bigkey。<br>(2) 统计类：例如按天存储某项功能或者网站的用户集合，除非没几个人用，否则必是bigkey。<br>(3) 缓存类：将数据从数据库load出来序列化放到Redis里，这个方式非常常用，但有两个地方需要注意，第一，是不是有必要把所有字段都缓存；第二，有没有相关关联的数据，有的同学为了图方便把相关数据都存一个key下，产生bigkey。</p><h3 id="如何优化bigkey"><a href="#如何优化bigkey" class="headerlink" title="如何优化bigkey"></a>如何优化bigkey</h3><ol><li>拆<br>big list： list1、list2、…listN<br>big hash：可以讲数据分段存储，比如一个大的key，假设存了1百万的用户数据，可以拆分成200个key，每个key下面存放5000个用户数据</li><li>如果bigkey不可避免，也要思考一下要不要每次把所有元素都取出来(例如有时候仅仅需要hmget，而不是hgetall)，删除也是一样，尽量使用优雅的方式来处理。</li></ol><p>(2)【推荐】：选择适合的数据类型。<br>例如：实体类型(要合理控制和使用数据结构，但也要注意节省内存和性能之间的平衡)<br>反例：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set user:<span class="number">1</span>:name tom</span><br><span class="line">set user:<span class="number">1</span>:age <span class="number">19</span></span><br><span class="line">set user:<span class="number">1</span>:favor football</span><br></pre></td></tr></table></figure></p><p>正例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hmset user:<span class="number">1</span> name tom age <span class="number">19</span> favor football</span><br></pre></td></tr></table></figure><p>3.【推荐】：控制key的生命周期，redis不是垃圾桶。<br>建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)。</p><h2 id="命令使用"><a href="#命令使用" class="headerlink" title="命令使用"></a>命令使用</h2><p>1.【推荐】 O(N)命令关注N的数量<br>例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。</p><p>2.【推荐】：禁用命令<br>禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。</p><p>3.【推荐】合理使用select<br>redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。</p><p>4.【推荐】使用批量操作提高效率<br>原生命令：例如mget、mset。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原生命令：例如mget、mset。</span><br><span class="line">非原生命令：可以使用pipeline提高效率。</span><br></pre></td></tr></table></figure><p>但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。<br>注意两者不同：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 原生命令是原子操作，pipeline是非原子操作。</span><br><span class="line">2. pipeline可以打包不同的命令，原生命令做不到</span><br><span class="line">3. pipeline需要客户端和服务端同时支持。</span><br></pre></td></tr></table></figure><p>5.【建议】Redis事务功能较弱，不建议过多使用，可以用lua替代</p><h2 id="客户端使用"><a href="#客户端使用" class="headerlink" title="客户端使用"></a>客户端使用</h2><p>1.【推荐】<br>避免多个应用使用一个Redis实例<br>正例：不相干的业务拆分，公共数据做服务化。</p><p>2.【推荐】<br>使用带有连接池的数据库，可以有效控制连接，同时提高效率，标准使用方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">JedisPoolConfig jedisPoolConfig = <span class="keyword">new</span> JedisPoolConfig();</span><br><span class="line">jedisPoolConfig.setMaxTotal(<span class="number">5</span>);</span><br><span class="line">jedisPoolConfig.setMaxIdle(<span class="number">2</span>);</span><br><span class="line">jedisPoolConfig.setTestOnBorrow(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">JedisPool jedisPool = <span class="keyword">new</span> JedisPool(jedisPoolConfig, <span class="string">"192.168.0.60"</span>, <span class="number">6379</span>, <span class="number">3000</span>, <span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line">Jedis jedis = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    jedis = jedisPool.getResource();</span><br><span class="line">    <span class="comment">//具体的命令</span></span><br><span class="line">    jedis.executeCommand()</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    logger.error(<span class="string">"op key &#123;&#125; error: "</span> + e.getMessage(), key, e);</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="comment">//注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。</span></span><br><span class="line">    <span class="keyword">if</span> (jedis != <span class="keyword">null</span>) </span><br><span class="line">        jedis.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>连接池参数含义：</p><p><img src="https://images.lilhui.com/b944f308e024d4748649b8989b92e793" alt="图片"></p><h2 id="优化建议"><a href="#优化建议" class="headerlink" title="优化建议"></a>优化建议</h2><p>1）maxTotal：最大连接数，早期的版本叫maxActive<br>实际上这个是一个很难回答的问题，考虑的因素比较多：</p><p>业务希望Redis并发量<br>客户端执行命令时间<br>Redis资源：例如 nodes(例如应用个数) * maxTotal 是不能超过redis的最大连接数maxclients。<br>资源开销：例如虽然希望控制空闲连接(连接池此刻可马上使用的连接)，但是不希望因为连接池的频繁释放创建连接造成不必靠开销。</p><p>以一个例子说明，假设:<br>一次命令时间（borrow|return resource + Jedis执行命令(含网络) ）的平均耗时约为1ms，一个连接的QPS大约是1000<br>业务期望的QPS是50000<br>那么理论上需要的资源池大小是50000 / 1000 = 50个。但事实上这是个理论值，还要考虑到要比理论值预留一些资源，通常来讲maxTotal可以比理论值大一些。</p><p>但这个值不是越大越好，一方面连接太多占用客户端和服务端资源，另一方面对于Redis这种高QPS的服务器，一个大命令的阻塞即使设置再大资源池仍然会无济于事。</p><p>2）maxIdle和minIdle</p><p>maxIdle实际上才是业务需要的最大连接数，maxTotal是为了给出余量，所以maxIdle不要设置过小，否则会有new Jedis(新连接)开销。<br>连接池的最佳性能是maxTotal = maxIdle，这样就避免连接池伸缩带来的性能干扰。但是如果并发量不大或者maxTotal设置过高，会导致不必要的连接资源浪费。一般推荐maxIdle可以设置为按上面的业务期望QPS计算出来的理论连接数，maxTotal可以再放大一倍。</p><p>minIdle（最小空闲连接数），与其说是最小空闲连接数，不如说是”至少需要保持的空闲连接数”，在使用连接的过程中，如果连接数超过了minIdle，那么继续建立连接，如果超过了maxIdle，当超过的连接执行完业务后会慢慢被移出连接池释放掉。<br>如果系统启动完马上就会有很多的请求过来，那么可以给redis连接池做预热，比如快速的创建一些redis连接，执行简单命令，类似ping()，快速的将连接池里的空闲连接提升到minIdle的数量。</p><p>连接池预热示例代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Jedis&gt; minIdleJedisList = <span class="keyword">new</span> ArrayList&lt;Jedis&gt;(jedisPoolConfig.getMinIdle());</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; jedisPoolConfig.getMinIdle(); i++) &#123;</span><br><span class="line">    Jedis jedis = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        jedis = pool.getResource();</span><br><span class="line">        minIdleJedisList.add(jedis);</span><br><span class="line">        jedis.ping();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        logger.error(e.getMessage(), e);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">//注意，这里不能马上close将连接还回连接池，否则最后连接池里只会建立1个连接。。</span></span><br><span class="line">        <span class="comment">//jedis.close();</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//统一将预热的连接还回连接池</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; jedisPoolConfig.getMinIdle(); i++) &#123;</span><br><span class="line">    Jedis jedis = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        jedis = minIdleJedisList.get(i);</span><br><span class="line">        <span class="comment">//将连接归还回连接池</span></span><br><span class="line">        jedis.close();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        logger.error(e.getMessage(), e);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>总之，要根据实际系统的QPS和调用redis客户端的规模整体评估每个节点所使用的连接池大小。</p><p>3.【建议】<br>高并发下建议客户端添加熔断功能(例如sentinel、hystrix)</p><p>4.【推荐】<br>设置合理的密码，如有必要可以使用SSL加密访问</p><p>5.【建议】<br>Redis对于过期键有三种清除策略：</p><ol><li>被动删除：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key</li><li>主动删除：由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期(默认每100ms)主动淘汰一批已过期的key，这里的一批只是部分过期key，所以可能会出现部分key已经过期但还没有被清理掉的情况，导致内存并没有被释放</li><li>当前已用内存超过maxmemory限定时，触发主动清理策略</li></ol><p>主动清理策略在Redis 4.0 之前一共实现了 6 种内存淘汰策略，在 4.0 之后，又增加了 2 种策略，总共8种：<br>a) 针对设置了过期时间的key做处理：</p><ol><li>volatile-ttl：在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。</li><li>volatile-random：就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。</li><li>volatile-lru：会使用 LRU 算法筛选设置了过期时间的键值对删除。</li><li>volatile-lfu：会使用 LFU 算法筛选设置了过期时间的键值对删除。</li></ol><p>b) 针对所有的key做处理：</p><ol><li>allkeys-random：从所有键值对中随机选择并删除数据。</li><li>allkeys-lru：使用 LRU 算法在所有数据中进行筛选删除。</li><li>allkeys-lfu：使用 LFU 算法在所有数据中进行筛选删除。</li></ol><p>c) 不处理：<br>noeviction：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息”(error) OOM command not allowed when used memory”，此时Redis只响应读操作。</p><p><strong>LRU 算法（Least Recently Used，最近最少使用）</strong><br>淘汰很久没被访问过的数据，以最近一次访问时间作为参考。</p><p><strong>LFU 算法（Least Frequently Used，最不经常使用）</strong><br>淘汰最近一段时间被访问次数最少的数据，以次数作为参考。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;键值设计&quot;&gt;&lt;a href=&quot;#键值设计&quot; class=&quot;headerlink&quot; title=&quot;键值设计&quot;&gt;&lt;/a&gt;键值设计&lt;/h2&gt;&lt;h3 id=&quot;key名设计&quot;&gt;&lt;a href=&quot;#key名设计&quot; class=&quot;headerlink&quot; title=&quot;key名设
      
    
    </summary>
    
      <category term="redis" scheme="https://www.lilhui.com/categories/redis/"/>
    
    
      <category term="性能优化" scheme="https://www.lilhui.com/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    
      <category term="redis" scheme="https://www.lilhui.com/tags/redis/"/>
    
      <category term="开发规范" scheme="https://www.lilhui.com/tags/%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/"/>
    
  </entry>
  
  <entry>
    <title>【Redis学习5】redis缓存设计和性能优化</title>
    <link href="https://www.lilhui.com/2022/07/06/redis/redis_core_6/"/>
    <id>https://www.lilhui.com/2022/07/06/redis/redis_core_6/</id>
    <published>2022-07-06T08:38:47.000Z</published>
    <updated>2022-07-06T09:00:16.633Z</updated>
    
    <content type="html"><![CDATA[<h2 id="缓存设计"><a href="#缓存设计" class="headerlink" title="缓存设计"></a>缓存设计</h2><p><img src="https://images.lilhui.com/de63da81ef636030b90e77bf4d25c9d7" alt="图片"></p><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>缓存穿透是指查询一个根本不存在的数据， 缓存层和存储层都不会命中， 通常出于容错的考虑， 如果从存储层查不到数据则不写入缓存层。<br>缓存穿透将导致不存在的数据每次请求都要到存储层去查询， 失去了缓存保护后端存储的意义。</p><p>造成缓存穿透的基本原因有两个：<br>第一， 自身业务代码或者数据出现问题。<br>第二， 一些恶意攻击、 爬虫等造成大量空命中。<br><strong>缓存穿透问题解决方案：</strong></p><h3 id="缓存空对象"><a href="#缓存空对象" class="headerlink" title="缓存空对象"></a>缓存空对象</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">String <span class="title">get</span><span class="params">(String key)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 从缓存中获取数据</span></span><br><span class="line">    String cacheValue = cache.get(key);</span><br><span class="line">    <span class="comment">// 缓存为空</span></span><br><span class="line">    <span class="keyword">if</span> (StringUtils.isBlank(cacheValue)) &#123;</span><br><span class="line">        <span class="comment">// 从存储中获取</span></span><br><span class="line">        String storageValue = storage.get(key);</span><br><span class="line">        cache.set(key, storageValue);</span><br><span class="line">        <span class="comment">// 如果存储数据为空， 需要设置一个过期时间(300秒)</span></span><br><span class="line">        <span class="keyword">if</span> (storageValue == <span class="keyword">null</span>) &#123;</span><br><span class="line">            cache.expire(key, <span class="number">60</span> * <span class="number">5</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> storageValue;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 缓存非空</span></span><br><span class="line">        <span class="keyword">return</span> cacheValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h3><p>对于恶意攻击，向服务器请求大量不存在的数据造成的缓存穿透，还可以用布隆过滤器先做一次过滤，对于不存在的数据布隆过滤器一般都能够过滤掉，不让请求再往后端发送。当布隆过滤器说某个值存在时，这个值可能不存在；当它说不存在时，那就肯定不存在。</p><p><img src="https://images.lilhui.com/2316311cd8e0ce72dcf850ddb6520014" alt="图片"></p><p>布隆过滤器就是一个大型的位数组和几个不一样的无偏 hash 函数。所谓无偏就是能够把元素的 hash 值算得比较均匀。<br>向布隆过滤器中添加 key 时，会使用多个 hash 函数对 key 进行 hash 算得一个整数索引值然后对位数组长度进行取模运算得到一个位置，每个 hash 函数都会算得一个不同的位置。再把位数组的这几个位置都置为 1 就完成了 add 操作。</p><p>向布隆过滤器询问 key 是否存在时，跟 add 一样，也会把 hash 的几个位置都算出来，看看位数组中这几个位置是否都为 1，只要有一个位为 0，那么说明布隆过滤器中这个key 不存在。如果都是 1，这并不能说明这个 key 就一定存在，只是极有可能存在，因为这些位被置为 1 可能是因为其它的 key 存在所致。如果这个位数组长度比较大，存在概率就会很大，如果这个位数组长度比较小，存在概率就会降低。</p><p>这种方法适用于数据命中不高、 数据相对固定、 实时性低（通常是数据集较大） 的应用场景， 代码维护较为复杂， 但是缓存空间占用很少。<br>可以用redisson实现布隆过滤器，引入依赖：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">   &lt;groupId&gt;org.redisson&lt;/groupId&gt;</span><br><span class="line">   &lt;artifactId&gt;redisson&lt;/artifactId&gt;</span><br><span class="line">   &lt;version&gt;3.6.5&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>示例伪代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.redisson;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.redisson.Redisson;</span><br><span class="line"><span class="keyword">import</span> org.redisson.api.RBloomFilter;</span><br><span class="line"><span class="keyword">import</span> org.redisson.api.RedissonClient;</span><br><span class="line"><span class="keyword">import</span> org.redisson.config.Config;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedissonBloomFilter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Config config = <span class="keyword">new</span> Config();</span><br><span class="line">        config.useSingleServer().setAddress(<span class="string">"redis://localhost:6379"</span>);</span><br><span class="line">        <span class="comment">//构造Redisson</span></span><br><span class="line">        RedissonClient redisson = Redisson.create(config);</span><br><span class="line"></span><br><span class="line">        RBloomFilter&lt;String&gt; bloomFilter = redisson.getBloomFilter(<span class="string">"nameList"</span>);</span><br><span class="line">        <span class="comment">//初始化布隆过滤器：预计元素为100000000L,误差率为3%,根据这两个参数会计算出底层的bit数组大小</span></span><br><span class="line">        bloomFilter.tryInit(<span class="number">100000000L</span>,<span class="number">0.03</span>);</span><br><span class="line">        <span class="comment">//将zhuge插入到布隆过滤器中</span></span><br><span class="line">        bloomFilter.add(<span class="string">"zhuge"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//判断下面号码是否在布隆过滤器中</span></span><br><span class="line">        System.out.println(bloomFilter.contains(<span class="string">"guojia"</span>));<span class="comment">//false</span></span><br><span class="line">        System.out.println(bloomFilter.contains(<span class="string">"baiqi"</span>));<span class="comment">//false</span></span><br><span class="line">        System.out.println(bloomFilter.contains(<span class="string">"zhuge"</span>));<span class="comment">//true</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用布隆过滤器需要把所有数据提前放入布隆过滤器，并且在增加数据时也要往布隆过滤器里放，布隆过滤器缓存过滤伪代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//初始化布隆过滤器</span></span><br><span class="line">RBloomFilter&lt;String&gt; bloomFilter = redisson.getBloomFilter(<span class="string">"nameList"</span>);</span><br><span class="line"><span class="comment">//初始化布隆过滤器：预计元素为100000000L,误差率为3%</span></span><br><span class="line">        bloomFilter.tryInit(<span class="number">100000000L</span>,<span class="number">0.03</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//把所有数据存入布隆过滤器</span></span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">()</span></span>&#123;</span><br><span class="line">            <span class="keyword">for</span> (String key: keys) &#123;</span><br><span class="line">                bloomFilter.put(key);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function">String <span class="title">get</span><span class="params">(String key)</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 从布隆过滤器这一级缓存判断下key是否存在</span></span><br><span class="line">            Boolean exist = bloomFilter.contains(key);</span><br><span class="line">            <span class="keyword">if</span>(!exist)&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="string">""</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 从缓存中获取数据</span></span><br><span class="line">            String cacheValue = cache.get(key);</span><br><span class="line">            <span class="comment">// 缓存为空</span></span><br><span class="line">            <span class="keyword">if</span> (StringUtils.isBlank(cacheValue)) &#123;</span><br><span class="line">                <span class="comment">// 从存储中获取</span></span><br><span class="line">                String storageValue = storage.get(key);</span><br><span class="line">                cache.set(key, storageValue);</span><br><span class="line">                <span class="comment">// 如果存储数据为空， 需要设置一个过期时间(300秒)</span></span><br><span class="line">                <span class="keyword">if</span> (storageValue == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    cache.expire(key, <span class="number">60</span> * <span class="number">5</span>);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> storageValue;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 缓存非空</span></span><br><span class="line">                <span class="keyword">return</span> cacheValue;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>注意：布隆过滤器不能删除数据，如果要删除得重新初始化数据。</p><h2 id="缓存失效（击穿）"><a href="#缓存失效（击穿）" class="headerlink" title="缓存失效（击穿）"></a>缓存失效（击穿）</h2><p>由于大批量缓存在同一时间失效可能导致大量请求同时穿透缓存直达数据库，可能会造成数据库瞬间压力过大甚至挂掉，对于这种情况我们在批量增加缓存时最好将这一批数据的缓存过期时间设置为一个时间段内的不同时间。<br>示例伪代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">String <span class="title">get</span><span class="params">(String key)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 从缓存中获取数据</span></span><br><span class="line">    String cacheValue = cache.get(key);</span><br><span class="line">    <span class="comment">// 缓存为空</span></span><br><span class="line">    <span class="keyword">if</span> (StringUtils.isBlank(cacheValue)) &#123;</span><br><span class="line">        <span class="comment">// 从存储中获取</span></span><br><span class="line">        String storageValue = storage.get(key);</span><br><span class="line">        cache.set(key, storageValue);</span><br><span class="line">        <span class="comment">//设置一个过期时间(300到600之间的一个随机数)</span></span><br><span class="line">        <span class="keyword">int</span> expireTime = <span class="keyword">new</span> Random().nextInt(<span class="number">300</span>)  + <span class="number">300</span>;</span><br><span class="line">        <span class="keyword">if</span> (storageValue == <span class="keyword">null</span>) &#123;</span><br><span class="line">            cache.expire(key, expireTime);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> storageValue;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 缓存非空</span></span><br><span class="line">        <span class="keyword">return</span> cacheValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><p>缓存雪崩指的是缓存层支撑不住或宕掉后， 流量会像奔逃的野牛一样， 打向后端存储层。<br>由于缓存层承载着大量请求， 有效地保护了存储层， 但是如果缓存层由于某些原因不能提供服务(比如超大并发过来，缓存层支撑不住，或者由于缓存设计不好，类似大量请求访问bigkey，导致缓存能支撑的并发急剧下降)， 于是大量请求都会打到存储层， 存储层的调用量会暴增， 造成存储层也会级联宕机的情况。<br>预防和解决缓存雪崩问题， 可以从以下三个方面进行着手。<br>1） 保证缓存层服务高可用性，比如使用Redis Sentinel或Redis Cluster。<br>2） 依赖隔离组件为后端限流熔断并降级。比如使用Sentinel或Hystrix限流降级组件。<br>比如服务降级，我们可以针对不同的数据采取不同的处理方式。当业务应用访问的是非核心数据（例如电商商品属性，用户信息等）时，暂时停止从缓存中查询这些数据，而是直接返回预定义的默认降级信息、空值或是错误提示信息；当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。<br>3） 提前演练。 在项目上线前， 演练缓存层宕掉后， 应用以及后端的负载情况以及可能出现的问题， 在此基础上做一些预案设定。</p><h3 id="热点缓存key重建优化"><a href="#热点缓存key重建优化" class="headerlink" title="热点缓存key重建优化"></a>热点缓存key重建优化</h3><p>开发人员使用“缓存+过期时间”的策略既可以加速数据读写， 又保证数据的定期更新， 这种模式基本能够满足绝大部分需求。 但是有两个问题如果同时出现， 可能就会对应用造成致命的危害：<br>当前key是一个热点key（例如一个热门的娱乐新闻），并发量非常大。<br>重建缓存不能在短时间完成， 可能是一个复杂计算， 例如复杂的SQL、 多次IO、 多个依赖等。<br>在缓存失效的瞬间， 有大量线程来重建缓存， 造成后端负载加大， 甚至可能会让应用崩溃。<br>要解决这个问题主要就是要避免大量线程同时重建缓存。<br>我们可以利用互斥锁来解决，此方法只允许一个线程重建缓存， 其他线程等待重建缓存的线程执行完， 重新从缓存获取数据即可。<br>示例伪代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">String <span class="title">get</span><span class="params">(String key)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 从Redis中获取数据</span></span><br><span class="line">    String value = redis.get(key);</span><br><span class="line">    <span class="comment">// 如果value为空， 则开始重构缓存</span></span><br><span class="line">    <span class="keyword">if</span> (value == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 只允许一个线程重建缓存， 使用nx， 并设置过期时间ex</span></span><br><span class="line">        String mutexKey = <span class="string">"mutext:key:"</span> + key;</span><br><span class="line">        <span class="keyword">if</span> (redis.set(mutexKey, <span class="string">"1"</span>, <span class="string">"ex 180"</span>, <span class="string">"nx"</span>)) &#123;</span><br><span class="line">             <span class="comment">// 从数据源获取数据</span></span><br><span class="line">            value = db.get(key);</span><br><span class="line">            <span class="comment">// 回写Redis， 并设置过期时间</span></span><br><span class="line">            redis.setex(key, timeout, value);</span><br><span class="line">            <span class="comment">// 删除key_mutex</span></span><br><span class="line">            redis.delete(mutexKey);</span><br><span class="line">        &#125;<span class="comment">// 其他线程休息50毫秒后重试</span></span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">50</span>);</span><br><span class="line">            get(key);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="缓存与数据库双写不一致"><a href="#缓存与数据库双写不一致" class="headerlink" title="缓存与数据库双写不一致"></a>缓存与数据库双写不一致</h2><p>在大并发下，同时操作数据库与缓存会存在数据不一致性问题<br>1、双写不一致情况<br><img src="https://images.lilhui.com/12a83025928c7558cd7aa2eb80cd414f" alt="图片"></p><ol start="2"><li>读写不一致<br><img src="https://images.lilhui.com/448141939bf5b6a53088e0332c577d0b" alt="图片"></li></ol><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>1、对于并发几率很小的数据(如个人维度的订单数据、用户数据等)，这种几乎不用考虑这个问题，很少会发生缓存不一致，可以给缓存数据加上过期时间，每隔一段时间触发读的主动更新即可。<br>2、就算并发很高，如果业务上能容忍短时间的缓存数据不一致(如商品名称，商品分类菜单等)，缓存加上过期时间依然可以解决大部分业务对于缓存的要求。<br>3、如果不能容忍缓存数据不一致，可以通过加分布式读写锁保证并发读写或写写的时候按顺序排好队，读读的时候相当于无锁。<br>4、也可以用阿里开源的canal通过监听数据库的binlog日志及时的去修改缓存，但是引入了新的中间件，增加了系统的复杂度。</p><p><img src="https://images.lilhui.com/f101e7c0009f26cadfcb012a0b6ab022" alt="图片"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上我们针对的都是读多写少的情况加入缓存提高性能，如果写多读多的情况又不能容忍缓存数据不一致，那就没必要加缓存了，可以直接操作数据库。当然，如果数据库抗不住压力，还可以把缓存作为数据读写的主存储，异步将数据同步到数据库，数据库只是作为数据的备份。<br>放入缓存的数据应该是对实时性、一致性要求不是很高的数据。切记不要为了用缓存，同时又要保证绝对的一致性做大量的过度设计和控制，增加系统复杂性！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;缓存设计&quot;&gt;&lt;a href=&quot;#缓存设计&quot; class=&quot;headerlink&quot; title=&quot;缓存设计&quot;&gt;&lt;/a&gt;缓存设计&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://images.lilhui.com/de63da81ef636030b90e77bf4d
      
    
    </summary>
    
      <category term="redis" scheme="https://www.lilhui.com/categories/redis/"/>
    
    
      <category term="性能优化" scheme="https://www.lilhui.com/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    
      <category term="redis" scheme="https://www.lilhui.com/tags/redis/"/>
    
      <category term="缓存设计" scheme="https://www.lilhui.com/tags/%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>【Redis学习5】redis新版本特性</title>
    <link href="https://www.lilhui.com/2022/07/06/redis/redis_core_5/"/>
    <id>https://www.lilhui.com/2022/07/06/redis/redis_core_5/</id>
    <published>2022-07-06T08:38:00.000Z</published>
    <updated>2022-07-06T08:39:02.457Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="redis" scheme="https://www.lilhui.com/categories/redis/"/>
    
    
      <category term="redis，新特性" scheme="https://www.lilhui.com/tags/redis%EF%BC%8C%E6%96%B0%E7%89%B9%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>【Redis学习4】redis底层核心设计原理</title>
    <link href="https://www.lilhui.com/2022/07/06/redis/redis_core_4/"/>
    <id>https://www.lilhui.com/2022/07/06/redis/redis_core_4/</id>
    <published>2022-07-06T08:26:45.000Z</published>
    <updated>2022-11-20T02:27:24.199Z</updated>
    
    <content type="html"><![CDATA[<h2 id="SDS"><a href="#SDS" class="headerlink" title="SDS"></a>SDS</h2><p>simple dynamic string<br>redis 3.2以前<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sdshdr</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> len; <span class="comment">//32 bit 0-2 32次方-1</span></span><br><span class="line">    <span class="keyword">int</span> <span class="built_in">free</span>;</span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">char</span> *sds</span><br></pre></td></tr></table></figure></p><p>redis3.2以后</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">char</span> *sds;</span><br><span class="line">sdshdr5</span><br><span class="line">sdshdr8</span><br><span class="line">sdshdr16</span><br><span class="line">sdshdr32</span><br><span class="line">sdshdr64</span><br></pre></td></tr></table></figure><p>对sdshdr做了优化和细分;<br>内存对齐：<br><img src="https://images.lilhui.com/054ba99b9267ed34e17460afff4d24bf" alt="图片"></p><h3 id="key类型"><a href="#key类型" class="headerlink" title="key类型"></a>key类型</h3><p>string</p><h3 id="值类型"><a href="#值类型" class="headerlink" title="值类型"></a>值类型</h3><p>string,hash,set, sorted set,list</p><ul><li>K-V: 是一个dict数据类型。<br>海量数据的存储：</li></ul><ol><li>数组: O(1)</li><li>链表: O(N)</li><li>树： long(N)</li></ol><p>arr[4]<br>hash(key) -&gt; 自然数%4 。变成索引。</p><p>hash(k1) % 4 = 0<br>hash(k2) % 4 = 1<br>hash(k3) % 4 = 1</p><p>arr[0] -&gt; (k1, v1,next -&gt; null)<br>arr[1,2] -&gt; (k3, v3, next -&gt; k2) (k2, v2, next -&gt; null)</p><p>当数组容量很大时，hash碰撞加剧。数据结构由数组变成了链表，时间复杂度从O(1)退化成<br>O(N) 此时需要进行扩容。</p><p>k2,k3碰撞了怎么办？</p><ol><li>开放地址法。</li><li>链表法</li><li>头插法（redis使用的方式）</li></ol><p>redisDB的设计<br>redis总共16个Db 索引从0-15<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">redisDb</span> &#123;</span></span><br><span class="line">    dict *dict;</span><br><span class="line">    dict *expires;</span><br><span class="line">    dict *blocking_keys;</span><br><span class="line">    dict *watched_keys;</span><br><span class="line">    <span class="keyword">int</span> id;</span><br><span class="line">    <span class="keyword">long</span> <span class="keyword">long</span> avg_ttl;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> expires_cursor;</span><br><span class="line">    <span class="built_in">list</span> *defrag_later;</span><br><span class="line">&#125; redisDb;</span><br><span class="line"></span><br><span class="line">_typedef <span class="class"><span class="keyword">struct</span> <span class="title">dict</span> &#123;</span>_</span><br><span class="line">    dictType *type;</span><br><span class="line">    <span class="keyword">void</span> *privdata;</span><br><span class="line">    dictht ht[<span class="number">2</span>];<span class="comment">//ht : hashTable的缩小</span></span><br><span class="line">    <span class="keyword">long</span> rehashidx;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> iterators;</span><br><span class="line">&#125; dict;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictType</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint64_t</span> (*hashFunction)(<span class="keyword">const</span> <span class="keyword">void</span> *key);</span><br><span class="line">    <span class="keyword">void</span> *(*keyDup)(<span class="keyword">void</span> *privdata, <span class="keyword">const</span> <span class="keyword">void</span> *key);</span><br><span class="line">    <span class="keyword">void</span> *(*valDup)(<span class="keyword">void</span> *privdate, <span class="keyword">const</span> <span class="keyword">void</span> *obj);</span><br><span class="line">    <span class="keyword">int</span> (*keyCompare)(<span class="keyword">void</span> *privdata, <span class="keyword">const</span> <span class="keyword">void</span> *key1, <span class="keyword">const</span> <span class="keyword">void</span> *key2);</span><br><span class="line">    <span class="keyword">void</span> (*keyDestructor)(<span class="keyword">void</span> *privdata, <span class="keyword">void</span> *key);</span><br><span class="line">    <span class="keyword">void</span> (*valDestructor)(<span class="keyword">void</span> *privdata, <span class="keyword">void</span> *obj);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictht</span> &#123;</span></span><br><span class="line">    dictEntry **table;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> size; <span class="comment">// hashtable 容量</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> sizemask; <span class="comment">//size - 1</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> used; <span class="comment">//hashtable元素个数 used/size = 1</span></span><br><span class="line">&#125; dictht;</span><br><span class="line"><span class="comment">//redis值类型对象封装 string,list,set,hash, zset</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">redisObject</span> &#123;</span></span><br><span class="line">    <span class="comment">//约束能够对redis key进行的操作 lpush，get什么的</span></span><br><span class="line">    unsiged type:<span class="number">4</span>;  <span class="comment">// 4bit,string hash</span></span><br><span class="line">    <span class="comment">//object encoding key 支持。对应的值在redis底层用的编码形式</span></span><br><span class="line">    <span class="keyword">unsigned</span> encoding:<span class="number">4</span>; <span class="comment">// 4bit</span></span><br><span class="line">    unsigined lru:LRU_BITS;</span><br><span class="line">    <span class="comment">//管理内存，引用计数法！这里表示引用的数量。0的时候可以进行回收。</span></span><br><span class="line">    <span class="keyword">int</span> refcount;  <span class="comment">//4 byte</span></span><br><span class="line">    <span class="comment">//指向数据的地址</span></span><br><span class="line">    <span class="keyword">void</span> *ptr;      <span class="comment">//8byte</span></span><br><span class="line">&#125; robj;</span><br></pre></td></tr></table></figure></p><p>扩容方法 。原有容量 *2.<br>rehash迁移方式：1. 渐进式迁移。2. 定时迁移。</p><p>set xxx // set是对 string操作。所以 type xxx也是string<br>lpush xxx // lpush 操作 type xxx 是list</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;SDS&quot;&gt;&lt;a href=&quot;#SDS&quot; class=&quot;headerlink&quot; title=&quot;SDS&quot;&gt;&lt;/a&gt;SDS&lt;/h2&gt;&lt;p&gt;simple dynamic string&lt;br&gt;redis 3.2以前&lt;br&gt;&lt;figure class=&quot;highlight c
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>【Redis学习3】redis集群和高可用</title>
    <link href="https://www.lilhui.com/2022/07/02/redis/redis_core_3/"/>
    <id>https://www.lilhui.com/2022/07/02/redis/redis_core_3/</id>
    <published>2022-07-02T03:26:40.000Z</published>
    <updated>2022-07-04T10:32:13.722Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis集群方案"><a href="#Redis集群方案" class="headerlink" title="Redis集群方案"></a>Redis集群方案</h2><p><strong>哨兵模式</strong></p><p><img src="https://images.lilhui.com/8b76471ec50ed03137bfb7b2ee9dfc17" alt="图片"></p><p>在redis3.0以前的版本需要实现集群一般是借助于哨兵sentinel工具来监控master节点的状态，如果master异常，则会做主从切换，将某一台slave作为master,<br>哨兵的配置略微复杂，并且性能和高可用等方面表现一般，特别在主从切换的瞬间存在访问瞬断的情况，而且哨兵模式只有一个主节点对外进行服务，没法支持很高的<br>并发，而且单个节点内存也不宜设置的过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率。</p><p><strong>高可用集群</strong></p><p><img src="https://images.lilhui.com/525b5676ac10f2dc5ed4be83bfb45a23" alt="图片"></p><p>redis集群是一个由<strong>多个主从节点群组组成的分布式服务器群</strong>，它具有<strong>复制、高可用和分片</strong>特性。redis集群不需要sentinel哨兵也能完成节点移除和故障<br>转移工鞥呢。需要将每个节点设置成集群模式，这种集群模式没有中心节点，可水平扩展，根据官方文档称：可以线性扩展到上万个节点（官方推荐不超过1000）。<br>redis集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单。</p><h2 id="Redis高可用集群搭建"><a href="#Redis高可用集群搭建" class="headerlink" title="Redis高可用集群搭建"></a>Redis高可用集群搭建</h2><p>redis集群至少三个master节点，我们这里搭建三个master节点，并且给每个master再搭建一个slave节点，总共6个redis节点，这里用三台机器部署6个实例。<br>每台机器一主一从，搭建步骤如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">第一步：在第一台机器的/usr/local下创建文件夹redis-cluster，然后在其下面分别创建2个文件夾如下</span><br><span class="line">（1）mkdir -p /usr/local/redis-cluster</span><br><span class="line">（2）mkdir 8001 8004</span><br><span class="line"></span><br><span class="line">第一步：把之前的redis.conf配置文件copy到8001下，修改如下内容：</span><br><span class="line">（1）daemonize yes</span><br><span class="line">（2）port 8001（分别对每个机器的端口号进行设置）</span><br><span class="line">（3）pidfile /var/run/redis_8001.pid  # 把pid进程号写入pidfile配置的文件</span><br><span class="line">（4）dir /usr/local/redis-cluster/8001/（指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据）</span><br><span class="line">（5）cluster-enabled yes（启动集群模式）</span><br><span class="line">（6）cluster-config-file nodes-8001.conf（集群节点信息文件，这里800x最好和port对应上）</span><br><span class="line">（7）cluster-node-timeout 10000</span><br><span class="line"><span class="meta"> (8)#</span><span class="bash"> <span class="built_in">bind</span> 127.0.0.1（<span class="built_in">bind</span>绑定的是自己机器网卡的ip，如果有多块网卡可以配多个ip，代表允许客户端通过机器的哪些网卡ip去访问，内网一般可以不配置<span class="built_in">bind</span>，注释掉即可）</span></span><br><span class="line"> (9)protected-mode  no   （关闭保护模式）</span><br><span class="line"> (10)appendonly yes</span><br><span class="line">如果要设置密码需要增加如下配置：</span><br><span class="line"> (11)requirepass littlehui     (设置redis访问密码)</span><br><span class="line"> (12)masterauth littlehui      (设置集群节点间访问密码，跟上面一致)</span><br><span class="line"></span><br><span class="line">第三步：把修改后的配置文件，copy到8004，修改第2、3、4、6项里的端口号，可以用批量替换：</span><br><span class="line">:%s/源字符串/目的字符串/g </span><br><span class="line"></span><br><span class="line">第四步：另外两台机器也需要做上面几步操作，第二台机器用8002和8005，第三台机器用8003和8006</span><br><span class="line"></span><br><span class="line">第五步：分别启动6个redis实例，然后检查是否启动成功</span><br><span class="line">（1）/usr/local/redis-5.0.3/src/redis-server /usr/local/redis-cluster/800*/redis.conf</span><br><span class="line">（2）ps -ef | grep redis 查看是否启动成功</span><br><span class="line">    </span><br><span class="line">第六步：用redis-cli创建整个redis集群(redis5以前的版本集群是依靠ruby脚本redis-trib.rb实现)</span><br><span class="line"><span class="meta">#</span><span class="bash"> 下面命令里的1代表为每个创建的主服务器节点创建一个从服务器节点</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 执行这条命令需要确认三台机器之间的redis实例要能相互访问，可以先简单把所有机器防火墙关掉，如果不关闭防火墙则需要打开redis服务端口和集群节点gossip通信端口16379(默认是在redis端口号上加1W)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 关闭防火墙</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> systemctl stop firewalld <span class="comment"># 临时关闭防火墙</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> systemctl <span class="built_in">disable</span> firewalld <span class="comment"># 禁止开机启动</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 注意：下面这条创建集群的命令大家不要直接复制，里面的空格编码可能有问题导致创建集群不成功</span></span><br><span class="line">（1）/usr/local/redis-5.0.3/src/redis-cli -a littlehui --cluster create --cluster-replicas 1 192.168.0.61:8001 192.168.0.62:8002 192.168.0.63:8003 192.168.0.61:8004 192.168.0.62:8005 192.168.0.63:8006 </span><br><span class="line"></span><br><span class="line">第七步：验证集群：</span><br><span class="line">（1）连接任意一个客户端即可：./redis-cli -c -h -p (-a访问服务端密码，-c表示集群模式，指定ip地址和端口号）</span><br><span class="line">    如：/usr/local/redis-5.0.3/src/redis-cli -a littlehui -c -h 192.168.0.61 -p 800*</span><br><span class="line">（2）进行验证： cluster info（查看集群信息）、cluster nodes（查看节点列表）</span><br><span class="line">（3）进行数据操作验证</span><br><span class="line">（4）关闭集群则需要逐个进行关闭，使用命令：</span><br><span class="line">/usr/local/redis-5.0.3/src/redis-cli -a littlehui -c -h 192.168.0.60 -p 800* shutdown</span><br></pre></td></tr></table></figure><h2 id="Java操作redis集群"><a href="#Java操作redis集群" class="headerlink" title="Java操作redis集群"></a>Java操作redis集群</h2><p>借助redis的java客户端jedis可以操作以上集群，引用jedis坐标</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;redis.clients&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;jedis&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.9.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>Java编写访问redis集群代码:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JedisClusterTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        JedisPoolConfig config = <span class="keyword">new</span> JedisPoolConfig();</span><br><span class="line">        config.setMaxTotal(<span class="number">20</span>);</span><br><span class="line">        config.setMaxIdle(<span class="number">10</span>);</span><br><span class="line">        config.setMinIdle(<span class="number">5</span>);</span><br><span class="line"></span><br><span class="line">        Set&lt;HostAndPort&gt; jedisClusterNode = <span class="keyword">new</span> HashSet&lt;HostAndPort&gt;();</span><br><span class="line">        jedisClusterNode.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.0.61"</span>, <span class="number">8001</span>));</span><br><span class="line">        jedisClusterNode.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.0.62"</span>, <span class="number">8002</span>));</span><br><span class="line">        jedisClusterNode.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.0.63"</span>, <span class="number">8003</span>));</span><br><span class="line">        jedisClusterNode.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.0.61"</span>, <span class="number">8004</span>));</span><br><span class="line">        jedisClusterNode.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.0.62"</span>, <span class="number">8005</span>));</span><br><span class="line">        jedisClusterNode.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.0.63"</span>, <span class="number">8006</span>));</span><br><span class="line"></span><br><span class="line">        JedisCluster jedisCluster = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//connectionTimeout：指的是连接一个url的连接等待时间</span></span><br><span class="line">            <span class="comment">//soTimeout：指的是连接上一个url，获取response的返回等待时间</span></span><br><span class="line">            jedisCluster = <span class="keyword">new</span> JedisCluster(jedisClusterNode, <span class="number">6000</span>, <span class="number">5000</span>, <span class="number">10</span>, <span class="string">"littlehui"</span>, config);</span><br><span class="line">            System.out.println(jedisCluster.set(<span class="string">"cluster"</span>, <span class="string">"littlehui"</span>));</span><br><span class="line">            System.out.println(jedisCluster.get(<span class="string">"cluster"</span>));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (jedisCluster != <span class="keyword">null</span>)</span><br><span class="line">                jedisCluster.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">运行效果如下：</span><br><span class="line">OK</span><br><span class="line">littlehui</span><br></pre></td></tr></table></figure><p>集群Spring boot整合redis连接代码示例：redis-sentinel-cluster</p><ol><li>引入依赖：</li></ol><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">   &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">   &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;</span><br><span class="line">   &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>springboot项目核心配置：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">server:</span><br><span class="line">  port: <span class="number">8080</span></span><br><span class="line"></span><br><span class="line">spring:</span><br><span class="line">  redis:</span><br><span class="line">    database: <span class="number">0</span></span><br><span class="line">    timeout: <span class="number">3000</span></span><br><span class="line">    password: littlehui</span><br><span class="line">    cluster:</span><br><span class="line">      nodes: <span class="number">192.168</span><span class="number">.0</span><span class="number">.61</span>:<span class="number">8001</span>,<span class="number">192.168</span><span class="number">.0</span><span class="number">.62</span>:<span class="number">8002</span>,<span class="number">192.168</span><span class="number">.0</span><span class="number">.63</span>:<span class="number">8003</span>,<span class="number">192.168</span><span class="number">.0</span><span class="number">.61</span>:<span class="number">8004</span>,<span class="number">192.168</span><span class="number">.0</span><span class="number">.62</span>:<span class="number">8005</span>,<span class="number">192.168</span><span class="number">.0</span><span class="number">.63</span>:<span class="number">8006</span></span><br><span class="line">   lettuce:</span><br><span class="line">      pool:</span><br><span class="line">        max-idle: <span class="number">50</span></span><br><span class="line">        min-idle: <span class="number">10</span></span><br><span class="line">        max-active: <span class="number">100</span></span><br><span class="line">        max-wait: <span class="number">1000</span></span><br></pre></td></tr></table></figure><p>访问代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IndexController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(IndexController<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> StringRedisTemplate stringRedisTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping</span>(<span class="string">"/test_cluster"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCluster</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">       stringRedisTemplate.opsForValue().set(<span class="string">"littlehui"</span>, <span class="string">"666"</span>);</span><br><span class="line">       System.out.println(stringRedisTemplate.opsForValue().get(<span class="string">"littlehui"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Redis集群原理分析"><a href="#Redis集群原理分析" class="headerlink" title="Redis集群原理分析"></a>Redis集群原理分析</h2><p>Redis Cluster将所有数据划分为16384个slot(槽位)，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中。</p><p>当Redis Cluster的客户端来连接集群时，它会得到一份集群的槽位配置信息，并将其缓存在客户端本地。这样当客户端要查找某个key时，可以直接定位到目标<br>节点。同时因为槽位的信息可能会存在客户端与服务器不一致的情况。还需要纠正机制来实现槽位信息的校验调整。</p><h3 id="槽位定位"><a href="#槽位定位" class="headerlink" title="槽位定位"></a>槽位定位</h3><p>Cluster默认会对key值使用crc16算法进行hash得到一个整数值，然后用这个整数值对16384进行取摸到具体槽位。</p><p>HASH_SLOT = CRC16(key) mod 16384</p><h3 id="跳转重定位"><a href="#跳转重定位" class="headerlink" title="跳转重定位"></a>跳转重定位</h3><p>当客户端向一个错误的节点发出了指令，该节点会发现指令的key所在的槽位并不归自己管理，这时它会向客户端发送一个特殊的跳转指令携带目标操作的节点地址，<br>告诉客户端去链接这个节点去获取数据。客户端接收到指令后除了跳转到正确的节点上去操作，还会同步更新纠正本地的槽位映射表缓存，后续所有key将使用新的<br>槽位映射表。</p><p><img src="https://images.lilhui.com/1dc5c7bb99d6ffcc06c834ee4ae9ebf6" alt="图片"></p><h3 id="Redis集群节点间的通信机制"><a href="#Redis集群节点间的通信机制" class="headerlink" title="Redis集群节点间的通信机制"></a>Redis集群节点间的通信机制</h3><p>redis cluster 节点间采用gossip协议进行通信</p><p>维护集群的元数据（集群节点信息，主从节点，节点数量，各节点共享的数据等）有两种方式:几种式和gossip</p><h4 id="集中式"><a href="#集中式" class="headerlink" title="集中式"></a>集中式</h4><p>优点在于元数据的更新和读取，时效性非常好，一单元数据出现变更立即更新到集中式的存储中，其他节点读取的时候立即感知到；不足在于所有的元数据更新压力<br>集中在一个地方，可能导致元数据的存储压力。很多中间件都会借助zookeeper集中式存储元数据。</p><h4 id="gossip"><a href="#gossip" class="headerlink" title="gossip"></a>gossip</h4><p><img src="https://images.lilhui.com/be3e04e29fca2d867970bc9caced10c7" alt="图片"></p><p>gossip协议包含多种消息，包括ping，pong，meet，fail等等。<br>meet：某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信；</p><p><strong>meet</strong>:某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信；<br><strong>ping</strong>:每个节点都会频繁给其他节点发送ping,其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据（类似自己感知到的集群节点增加<br>和移除hash slot信息等）；<br><strong>pong</strong>:对ping和meet消息的返回，包含自己的状态和其他信息，也可以用于信息广播和更新；<br><strong>fail</strong>:某个节点判断另一个节点fail之后，就发送fail给其他节点，通知其他节点，指定的节点宕机了。</p><h4 id="gossip通信的1000端口"><a href="#gossip通信的1000端口" class="headerlink" title="gossip通信的1000端口"></a>gossip通信的1000端口</h4><p>每个节点都有一个专门用于节点间gossip通信的端口，就是自己提供的服务端口+10000，比如7001，那么用于节点通信的就是17001端口。每个节点间隔一段时间<br>就会往另外几个节点发送ping消息，同时其他节点接收到ping消息之后返回pong信息。</p><h4 id="网络抖动"><a href="#网络抖动" class="headerlink" title="网络抖动"></a>网络抖动</h4><p>真实世界的机房网络往往并不是风平浪静的，他们经常会发生各种各样的小问题。比如网络抖动。突然之间部分链接变得不可访问，然后很快又恢复正常。</p><p>为解决这种问题，Redis cluster提供了一种选项cluster-node-timeout,表示当某个节点持续timeout的时间失联时，才可以认定该节点出现故障，需要进行<br>主从切换。如果没有这个选项，网络抖动会导致主从频繁切换（数据的重新复制）。</p><h3 id="Redis集群选举原理分析"><a href="#Redis集群选举原理分析" class="headerlink" title="Redis集群选举原理分析"></a>Redis集群选举原理分析</h3><p>当slave发现自己的master变为FAIL状态时，进行failover,以期成为新的master。由于挂掉的master可能会有多个slave,从而存在多个slave竞争成为master<br>节点的过程，过程如下：</p><ol><li>slave发现自己的master变成fail</li><li>将自己记录的集群currentEpoch加1， 并广播failover_auth_request信息</li><li>其他节点接收到该信息，只有master响应，判断请求的合法性，并发送failover_auth_ack，对每一个epoch只发送一次ack.</li><li>尝试failover的slave搜集master返回的failover_auth_ack</li><li>slave收到过半数master的ack后变成新的master(所以为什么至少要三个主节点，如果只有2个其中一个挂了，只剩一个节点是不能选举成功的)</li><li>slave广播pong消息通知其他集群节点</li></ol><p>从节点并不是在主节点已进入fail状态就马上尝试发生选举，而是有一定延迟，一定的延迟保证我们等待fail状态在集群中传播，slave如果立即选举，其他master<br>获取尚未意识到fail状态，可能会拒绝投票。</p><ul><li>延迟计算公式</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> DELAY = <span class="number">500</span>ms + random(<span class="number">0</span> ~ <span class="number">500</span>ms) + SLAVE_RANK * <span class="number">1000</span>ms</span><br></pre></td></tr></table></figure><p>SLAVE_RANK表示此slave已经从master复制数据的总量的rank。Rank越小代表已复制的数据越新。这种方式下，持有最新数据的slave将会首先发起选举（理论上）。</p><h2 id="集群的一些问题"><a href="#集群的一些问题" class="headerlink" title="集群的一些问题"></a>集群的一些问题</h2><h3 id="集群脑裂数据丢失问题"><a href="#集群脑裂数据丢失问题" class="headerlink" title="集群脑裂数据丢失问题"></a>集群脑裂数据丢失问题</h3><p>redis集群没有过半机制会有脑裂问题，网络分区导致脑裂后。多个主节点对外提供写服务，一旦网络分区恢复，会将其中一个主节点变为从节点，这时会有大量数据丢失。</p><p>规避方法可以在redis配置里加上参数（这种方法不可能百分百避免数据丢失，参考集群leader选举机制）</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">min-replicas-to-write <span class="number">1</span>  <span class="comment">//写数据成功最少同步的slave数量，这个数量可以模仿大于半数机制配置，比如集群总共三个节点可以配置1，加上leader就是2，超过了半数</span></span><br><span class="line">注意：这个配置在一定程度上会影响集群的可用性，比如slave要是少于<span class="number">1</span>个，这个集群就算leader正常也不能提供服务了，需要具体场景权衡选择。</span><br></pre></td></tr></table></figure><p><strong>注意</strong>：这个配置在一定程度上可能影响集群的可用性，比如slave少于1个，这个集群就算leader正常也不能提供服务，需要具体场景权衡。</p><h3 id="集群是否完整才能对外提供服务"><a href="#集群是否完整才能对外提供服务" class="headerlink" title="集群是否完整才能对外提供服务"></a>集群是否完整才能对外提供服务</h3><p>当redis.conf的配置cluster-require-full-coverage为no时，表示当负责一个插槽的主库下线且没有响应的从库进行故障恢复时，集群仍然可用，如果yes则集群不可用。</p><h3 id="Redis集群为什么至少需要三个master节点，并且推荐节点数量为奇数"><a href="#Redis集群为什么至少需要三个master节点，并且推荐节点数量为奇数" class="headerlink" title="Redis集群为什么至少需要三个master节点，并且推荐节点数量为奇数"></a>Redis集群为什么至少需要三个master节点，并且推荐节点数量为奇数</h3><p>因为新master的选举需要大于半数的集群master节点同意才能选举成功。如果只有2个master节点，其中一个挂了，是达不到选举新master的条件的。</p><p>奇数个master节点可以在满足选举该条件的基础上节省一个节点，比如三个master节点和四个master节点的集群相比，大家如果都挂了一个master节点都能选举新的<br>master节点，如果都挂了2个master节点都没法选举新的master节点，所以奇数的master节点更多的是从节省机器资源角度考虑的。</p><h2 id="Redis集群对批量操作命令的支持"><a href="#Redis集群对批量操作命令的支持" class="headerlink" title="Redis集群对批量操作命令的支持"></a>Redis集群对批量操作命令的支持</h2><p>对于类似mset,mget这样的多个key原生批量操作命令，redis集群只支持所有key落在同一个slot的情况，如果有多个key一定要用mset命令在redis集群上操作，<br>则可以在key的前面加上{xx},这样参数数据分片hash计算的只会是大括号里的值，遮掩功能确保不同的key能落到同一个slot里。示例如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mset &#123;user1&#125;:<span class="number">1</span>:name littlehui &#123;user1&#125;:<span class="number">1</span>:age <span class="number">18</span></span><br></pre></td></tr></table></figure></p><p>假设name和age计算的hash slot值不一样，但是这条命令在集群下执行，redis只会用大括号里的 user1 做hash slot计算，所以算出来的slot值肯定相同，最后都能落在同一slot。</p><h2 id="哨兵leader选举流程"><a href="#哨兵leader选举流程" class="headerlink" title="哨兵leader选举流程"></a>哨兵leader选举流程</h2><p>当一个master服务器被某sentinel视为下线状态后，该sentinel会与其他sentinel协商选出sentinel的leader进行故障转移工作。每个发现master服务器进入下线的sentinel都可以要求其他sentinel选自己为sentinel的leader，选举是先到先得。同时每个sentinel每次选举都会自增配置纪元(选举周期)，每个纪元中只会选择一个sentinel的leader。如果所有超过一半的sentinel选举某sentinel作为leader。之后该sentinel进行故障转移操作，从存活的slave中选举出新的master，这个选举过程跟集群的master选举很类似。<br>哨兵集群只有一个哨兵节点，redis的主从也能正常运行以及选举master，如果master挂了，那唯一的那个哨兵节点就是哨兵leader了，可以正常选举新master。</p><p>哨兵集群只有一个哨兵节点，redis的主从也能正常运行以及选举master，如果master挂了，那唯一的那个哨兵节点就是哨兵leader了，可以正常选举新master。<br>不过为了高可用一般都推荐至少部署三个哨兵节点。为什么推荐奇数个哨兵节点原理跟集群奇数个master节点类似。</p><h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><h3 id="分布式锁实现场景"><a href="#分布式锁实现场景" class="headerlink" title="分布式锁实现场景"></a>分布式锁实现场景</h3><p>互联网秒杀，抢优惠券，接口幂等性校验</p><h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><ul><li>setnx</li><li>原子加</li></ul><p><img src="https://images.lilhui.com/390ed2a0d1575105c79a366ecd64e6f6" alt="图片"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Redis集群方案&quot;&gt;&lt;a href=&quot;#Redis集群方案&quot; class=&quot;headerlink&quot; title=&quot;Redis集群方案&quot;&gt;&lt;/a&gt;Redis集群方案&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;哨兵模式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;htt
      
    
    </summary>
    
      <category term="redis" scheme="https://www.lilhui.com/categories/redis/"/>
    
    
      <category term="redis" scheme="https://www.lilhui.com/tags/redis/"/>
    
      <category term="sentinel" scheme="https://www.lilhui.com/tags/sentinel/"/>
    
      <category term="cluster" scheme="https://www.lilhui.com/tags/cluster/"/>
    
  </entry>
  
  <entry>
    <title>【Redis学习2】redis持久化，主从，哨兵架构</title>
    <link href="https://www.lilhui.com/2022/06/29/redis/redis_core_2/"/>
    <id>https://www.lilhui.com/2022/06/29/redis/redis_core_2/</id>
    <published>2022-06-29T07:35:00.000Z</published>
    <updated>2022-06-30T16:31:02.594Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis持久化"><a href="#Redis持久化" class="headerlink" title="Redis持久化"></a>Redis持久化</h2><h3 id="RDB快照（snapshot"><a href="#RDB快照（snapshot" class="headerlink" title="RDB快照（snapshot)"></a>RDB快照（snapshot)</h3><p>在默认情况下， Redis 将内存数据库快照保存在名字为 dump.rdb 的二进制文件中。 你可以对 Redis 进行设置， 让它在“ N 秒内数据集至少有 M 个改动”<br>这一条件被满足时， 自动保存一次 数据集。 比如说， 以下设置会让 Redis 在满足“ 60 秒内有至少有 1000 个键被改动”这一条件时， 自动保存一次 数据<br>集： # save 60 1000 //关闭RDB只需要将所有的save保存策略注释掉即可</p><p>还可以手动执行命令生成RDB快照，进入redis客户端执行命令save或bgsave可以生成dump.rdb文件， 每次命令执行都会将所有redis内存快照到一个新的rdb<br>文件里，并覆盖原有rdb快照文件。</p><p><strong>bgsave的写时复制(COW)机制</strong><br>Redis 借助操作系统提供的写时复制技术（Copy-On-Write, COW），在生成快照的同时，依然可以正常 处理写命令。简单来说，bgsave 子进程是由主线程<br>fork 生成的，可以共享主线程的所有内存数据。 bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。此时，如果主线程对这些 数<br>据也都是读操作，那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据，那 么，这块数据就会被复制一份，生成该数据的副本。然后，<br>bgsave 子进程会把这个副本数据写入 RDB 文 件，而在这个过程中，主线程仍然可以直接修改原来的数据。</p><p><strong>save与bgsave对比</strong></p><table><thead><tr><th>命令</th><th>save</th><th>bgsave</th></tr></thead><tbody><tr><td>IO类型</td><td>同步</td><td>异步</td></tr><tr><td>是否阻塞redis其他命令</td><td>是</td><td>否（在生成子进程执行调用fork函数时会有短期阻塞）</td></tr><tr><td>复杂度</td><td>O(n)</td><td>O(n)</td></tr><tr><td>有点</td><td>不会消耗额外内存</td><td>不阻塞客户端命令</td></tr><tr><td>缺点</td><td>阻塞客户端命令</td><td>需要fork子进程，消耗内存</td></tr></tbody></table><p>配置自动生成rdb文件后台使用的是bgsave方式。</p><ul><li>AOF (append-only file)</li></ul><p>快照功能并不是非常耐久(durable)：如果redis因为某些原因造成故障停机，那么服务器将丢失最近写入、且未保存到快照的那些数据。从1.1版开始<br>Redis增加了一种完全耐久的持久化方式：AOF持久化，将修改的每一条指令记录进文件appendonly.aof中（先写入os cache,每隔一段时间fsync到<br>磁盘）<br>比如执行命令 “set littlehui 666” ，aof记录如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3 </span></span><br><span class="line">set </span><br><span class="line"><span class="meta">$</span><span class="bash">5 </span></span><br><span class="line">littlehui</span><br><span class="line"><span class="meta">$</span><span class="bash">3 </span></span><br><span class="line">666</span><br></pre></td></tr></table></figure><p>这种是resp协议格式数据，星号后面的数字代表命令有多少个参数。$号后面的数字代表这个参数有几个字符。<br>PS:如果执行带过期的set命令，aof文件记录的并不是原始命令。而是记录这个key的过期时间戳。</p><p>比如执行 “set littlehui 888 ex 1000” aof记录如下<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">*3 </span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">6</span></span><br><span class="line">littlehui</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">888</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">9</span></span><br><span class="line">PEXPIREAT </span><br><span class="line"><span class="meta">$</span><span class="bash">6</span></span><br><span class="line">tuling</span><br><span class="line"><span class="meta">$</span><span class="bash">13</span></span><br><span class="line">1604249786301</span><br></pre></td></tr></table></figure></p><p>AOF功能开启：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendonly yes</span><br></pre></td></tr></table></figure></p><p>redis重启时，程序通过执行AOF的命令来进行重加数据集。<br>通过配置修改fsync到磁盘的频次。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">appendfsync always：每次有新命令追加到 AOF 文件时就执行一次 fsync ，非常慢，也非常安全。</span><br><span class="line">appendfsync everysec：每秒 fsync 一次，足够快，并且在故障时只会丢失 1 秒钟的数据。</span><br><span class="line">appendfsync no：从不 fsync ，将数据交给操作系统来处理。更快，也更不安全的选择。</span><br></pre></td></tr></table></figure></p><p>以上配置为推荐值，可以兼顾速度和安全性。</p><ul><li>AOF重写<br>AOF文件里可能有太多没用指令，所以AOF会定期根据内存的新数据生成aof文件。<br>例如：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt;incr readcount</span><br><span class="line">（Integer）1</span><br><span class="line">127.0.0.1:6379&gt;incr readcount</span><br><span class="line">（Integer）2</span><br></pre></td></tr></table></figure></li></ul><p>重写后AOF变成<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">2</span></span><br><span class="line">readcount</span><br><span class="line"><span class="meta">$</span><span class="bash">1</span></span><br><span class="line">2</span><br></pre></td></tr></table></figure></p><p><strong>自动重写频率</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> auto‐aof‐rewrite‐min‐size 64mb //aof文件至少要达到64M才会自动重写，文件太小恢复速度本来就 很快，重写的意义不大 </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> auto‐aof‐rewrite‐percentage 100 //aof文件自上一次重写后文件大小增长了100%则再次触发重写</span></span><br></pre></td></tr></table></figure></p><table><thead><tr><th>命令</th><th>RDB</th><th>AOF</th></tr></thead><tbody><tr><td>启动优先级</td><td>低</td><td>高</td></tr><tr><td>体积</td><td>小</td><td>大</td></tr><tr><td>恢复速度</td><td>快</td><td>慢</td></tr><tr><td>数据安全性</td><td>容易丢数据</td><td>根据策略决定</td></tr></tbody></table><p>生产环境可以都启用，redis启动时如果既有rdb文件又有aof文件则优先选择aof文件恢复数据，因为aof 一般来说数据更全一点。</p><h3 id="Redis-4-0混合持久化"><a href="#Redis-4-0混合持久化" class="headerlink" title="Redis 4.0混合持久化"></a>Redis 4.0混合持久化</h3><p>重启 Redis 时，我们很少使用 RDB来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重 放，但是重放 AOF 日志性能相对 RDB来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很 长的时间。 Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。 通过如下配置可以开启混合持久化(必须先开启aof)：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aof-use-rdb-preamble yes</span><br></pre></td></tr></table></figure><p>如果开启了混合持久化，AOF在重写时，不再是单纯将内存数据转换为RESP命令写入AOF文件，而是将 重写这一刻之前的内存做RDB快照处理，并且将RDB快照内容和增量的AOF修改内存数据的命令存在一 起，都写入新的AOF文件，新的文件一开始不叫appendonly.aof，等到重写完新的AOF文件才会进行改 名，覆盖原有的AOF文件，完成新旧两个AOF文件的替换。 于是在 Redis 重启的时候，可以先加载 RDB 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，因此重启效率大幅得到提升。</p><p>混合持久化AOF文件结构</p><p><img src="https://images.lilhui.com/0042927170653d7df11736fd7cbdad67" alt="图片"></p><ul><li>Redis数据备份策略</li></ul><ol><li>写crontab定时调度脚本，每小时都copy一份rdb或aof备份到一个目录中去，仅仅保留最近48小时的备份。</li><li>每天都保留一份当日的数据备份到一个目录中去，可以保留最近1个月的备份。</li><li>每次copy留备份的时候，都把太旧的备份给删了。</li><li>每天晚上将当前机器上的备份复制一份到其他机器上，以防机器损坏。</li></ol><h3 id="主从架构"><a href="#主从架构" class="headerlink" title="主从架构"></a>主从架构</h3><p><img src="https://images.lilhui.com/bbc61a741bf58968a1eb3d42ae25f2d1" alt="图片"></p><p><strong> redis主从架构搭建，配置从节点步骤 </strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">1、复制一份redis.conf文件</span><br><span class="line">2、将相关配置修改为：</span><br><span class="line">port 6380</span><br><span class="line">pidfile /var/run/redis_6380.pid #把pid进程号写入pidfile配置的文件</span><br><span class="line">logfile "6380.log"</span><br><span class="line">dif /usr/local/redis-5.0.3/data/6380 #指定数据存放目录</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 需要注释掉<span class="built_in">bind</span> </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">bind</span> 127.0.0.1（<span class="built_in">bind</span>绑定的是自己机器网卡的ip，如果有多块网卡可以配多个ip，代表允许客户端通 过机器的哪些网卡ip去访问，内网一般可以不配置<span class="built_in">bind</span>，注释掉即可） </span></span><br><span class="line">3、配置主从复制</span><br><span class="line">replicaof 192.168.0.60 6379 # 从本机6379的redis实例复制数据，Redis 5.0之前使用slaveof</span><br><span class="line">replica‐read‐only yes # 配置从节点只读 </span><br><span class="line">4、启动从节点 16 redis‐server redis.conf 1718 5、连接从节点  </span><br><span class="line">redis‐cli ‐p 6380 2021 6、测试在6379实例上写数据，6380实例是否能及时同步新修改数据 </span><br><span class="line">7、可以自己再配置一个6381的从节点</span><br></pre></td></tr></table></figure><h2 id="Redis主从工作原理"><a href="#Redis主从工作原理" class="headerlink" title="Redis主从工作原理"></a>Redis主从工作原理</h2><p>如果你为master配置了一个slave,不管这个slave是否是第一次连上Master，都会发送一个PSYNC命令给master请求复制数据。<br>master收到PSYNC命令后，会再后台进行数据持久化通过bgsave生成最新的rdb快照文件，持久化期间，master会继续接收客户端<br>的请求，它会把这些可能修改数据集的请求缓存在内存中。当持久化进行完毕后，master会把这份rdb文件数据集发送给slave,slave<br>会把接收到的数据进行持久化生成rdb,然后加载到内存中。最后master再将之前缓存在内存中的命令发送给slave.</p><p>当master与slave之间的链接由于某些原因而断开时，slave能够自动重连Master,如果master收到了多个slave并发链接请求，它<br>只会进行一次持久化，而不是一个连接一次，然后再把这一份持久化的数据发送给多个并发连接的slave.</p><ul><li>主从复制（全量复制）流程图</li></ul><p><img src="https://images.lilhui.com/ff66d9de5d9dc974140a149f433647f4" alt="图片"></p><ul><li>数据部分复制</li></ul><p>当master和slave断开重连后，一般会对整个数据进行复制。但从redis2.8版开始，redis改用可以支持部分数据复制的命令PSYNC<br>去master同步数据，slave和master能够在网络连接断开重连后进行部分数据复制（断点续传）</p><p>master会再其内存中创建一个复制数据用的缓存队列，缓存最近一段时间的数据，master和它所有的slave都维护了复制数据下表offset<br>和master的进程ID,因此，当网络连接断开后，slave会请求master offset太久，已经补在master的缓存队列里了。那么将会进行一次<br>全量数据的复制。</p><ul><li>主从断点续传流程图</li></ul><p><img src="https://images.lilhui.com/af577bd4dd5d5aaffcc48b4ad76d3dd7" alt="图片"></p><p>如果有很多从节点，为了环节主从复制风暴（多个节点同时复制主节点导致主节点压力过大可以做一下架构，让部分从节点与从节点同步数据。</p><p><img src="https://images.lilhui.com/84e0a901a219fdb01f0d6172d46f80d4" alt="图片"></p><h2 id="Redis管道与Lua脚本"><a href="#Redis管道与Lua脚本" class="headerlink" title="Redis管道与Lua脚本"></a>Redis管道与Lua脚本</h2><h3 id="管道（pipeline"><a href="#管道（pipeline" class="headerlink" title="管道（pipeline)"></a>管道（pipeline)</h3><p>客户端可以一次性发送多个请求而不用等待服务器的响应，待所有命令都发送完后再一次性读取服务的响应，这样可以极大的降低多条命令执行的网络传输开销，管道执行多条命令的网络开销实际上只相当于一次命令执行的网络开销。需要注意到是用pipeline方式打包命令发送，redis必须在处理完所有命令前先缓存起所有命令的处理结果。打包的命令越多，缓存消耗内存也越多。所以并不是打包的命令越多越好。<br>pipeline中发送的每个command都会被server立即执行，如果执行失败，将会在此后的响应中得到信<br>息；也就是pipeline并不是表达“所有command都一起成功”的语义，管道中前面命令失败，后面命令不会有影响，继续执行。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Pipeline pl = jedis.pipelined();</span><br><span class="line">for (int i=0; i&lt;10; i++) &#123;</span><br><span class="line">  pl.incr("pipelineKey");</span><br><span class="line">  pl.set("littlehui" + i, "666")</span><br><span class="line">&#125;</span><br><span class="line">List&lt;Object&gt; results = pl.syncAndReturnAll();</span><br><span class="line">System.out.println(results)</span><br></pre></td></tr></table></figure><h3 id="Redis-Lua脚本"><a href="#Redis-Lua脚本" class="headerlink" title="Redis Lua脚本"></a>Redis Lua脚本</h3><hr><p>Redis在2.6推出了脚本功能，允许开发者使用Lua语言编写脚本传到Redis中执行。使用脚本的好处如下:<br>1、<strong>减少网络开销</strong>：本来5次网络请求的操作，可以用一个请求完成，原先5次请求的逻辑放在redis服务器上完成。使用脚本，减少了网络往返时延。这点跟管道类似。<br>2、<strong>原子操作</strong>：Redis会将整个脚本作为一个整体执行，中间不会被其他命令插入。管道不是原子的，不过redis的批量操作命令(类似mset)是原子的。<br>3、<strong>替代redis的事务功能</strong>：redis自带的事务功能很鸡肋，而redis的lua脚本几乎实现了常规的事务功能，官方推荐如果要使用redis的事务功能可以用redis lua替代。</p><p>官网文档上有这样一段话：</p><hr><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A Redis script is transactional by definition, so everything you can do with a Redis t ransaction, you can also do with a script,</span><br><span class="line">and usually the script will be both simpler and faster.</span><br></pre></td></tr></table></figure><p>从Redis2.6.0版本开始，通过内置的Lua解释器，可以使用EVAL命令对Lua脚本进行求值。EVAL命令的格式如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EVAL script numkeys key [key ...] arg [arg ...]</span><br></pre></td></tr></table></figure><p>script参数是一段Lua脚本程序，它会被运行在Redis服务器上下文中，这段脚本不必(也不应该)定义为一个Lua函数。numkeys参数用于指定键名参数的个数。键名参数 key [key …] 从EVAL的第三个参数开始算起，表示在脚本中所用到的那些Redis键(key)，这些键名参数可以在 Lua中通过全局变量KEYS数组，用1 为基址的形式访问( KEYS[1] ， KEYS[2] ，以此类推)。<br>在命令的最后，那些不是键名参数的附加参数 arg [arg …] ，可以在Lua中通过全局变量ARGV数组访问，访问的形式和KEYS变量类似( ARGV[1] 、 ARGV[2] ，诸如此类)。例如</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; eval "return &#123;KEYS[1],KEYS[2],ARGV[1],ARGV[2]&#125;" 2 key1 key2 first seco nd</span><br><span class="line">1) "key1"</span><br><span class="line">2) "key2"</span><br><span class="line">3) "key3"</span><br><span class="line">4) "key4"</span><br></pre></td></tr></table></figure><p>其中 “return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}” 是被求值的Lua脚本，数字2指定了键名参数的数量， key1和key2是键名参数，分别使用 KEYS[1] 和 KEYS[2] 访问，而最后的 first 和 second 则是附加参数，可以通过 ARGV[1] 和 ARGV[2] 访问它们。<br>在 Lua 脚本中，可以使用redis.call()函数来执行Redis命令<br>Jedis调用示例详见上面jedis连接示例：</p><p><img src="https://images.lilhui.com/559aa96f28fdd3cb8e1371f9974d69f6" alt="图片"></p><p><strong>注意，不要在Lua脚本中出现死循环和耗时的运算，否则redis会阻塞，将不接受其他的命令， 所以使用时要注意不能出现死循环、耗时的运算。redis是单进程、单线程执行脚本。管道不会阻塞redis。</strong></p><h2 id="Redis哨兵高可用架构"><a href="#Redis哨兵高可用架构" class="headerlink" title="Redis哨兵高可用架构"></a>Redis哨兵高可用架构</h2><p><img src="https://images.lilhui.com/8d7487de106d52e9bdb8f25e9bb9862b" alt="图片"></p><p>sentinel哨兵是特殊的redis服务，不提供读写服务，主要用来监控redis实例节点。<br>哨兵架构下client端第一次从哨兵找出redis的主节点，后续就直接访问redis的主节点，不会每次都通过<br>sentinel代理访问redis的主节点，当redis的主节点发生变化，哨兵会第一时间感知到，并且将新的redis 主节点通知给client端(这里面redis的client端一般都实现了订阅功能，订阅sentinel发布的节点变动消息)</p><h3 id="Redis-哨兵搭建步骤"><a href="#Redis-哨兵搭建步骤" class="headerlink" title="Redis 哨兵搭建步骤"></a>Redis 哨兵搭建步骤</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">1、复制一份sentinel.conf文件</span><br><span class="line">cp sentinel.conf sentinel‐26379.conf  </span><br><span class="line">2、将相关配置修改为如下值： </span><br><span class="line">port 26379 </span><br><span class="line">daemonize yes </span><br><span class="line">pidfile "/var/run/redis‐sentinel‐26379.pid" </span><br><span class="line">logfile "26379.log" </span><br><span class="line">dir "/usr/local/redis‐5.0.3/data" </span><br><span class="line"><span class="meta">#</span><span class="bash"> sentinel monitor &lt;master‐redis‐name&gt; &lt;master‐redis‐ip&gt; &lt;master‐redis‐port&gt; &lt;quorum&gt; </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> quorum是一个数字，指明当有多少个sentinel认为一个master失效时(值一般为：sentinel总数/2 + 1)，master才算真正失效</span></span><br><span class="line"></span><br><span class="line">sentinel monitor mymaster 192.168.0.60 6379 2 # mymaster这个名字随便取，客户端访问时会用 到</span><br><span class="line">3、启动sentinel哨兵实例 </span><br><span class="line">src/redis‐sentinel sentinel‐26379.conf </span><br><span class="line">4、查看sentinel的info信息 </span><br><span class="line">src/redis‐cli ‐p 26379 19 127.0.0.1:26379&gt;info </span><br><span class="line">可以看到Sentinel的info里已经识别出了redis的主从 </span><br><span class="line">5、可以自己再配置两个sentinel，端口26380和26381，注意上述配置文件里的对应数字都要修改</span><br></pre></td></tr></table></figure><p>sentinel集群都启动完毕后，会将哨兵集群的元数据信息写入所有sentinel的配置文件里去(追加在文件的 最下面)，我们查看下如下配置文件sentinel-26379.conf，如下所示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sentinel known‐replica mymaster 192.168.0.60 6380 #代表redis主节点的从节点信息 </span><br><span class="line">sentinel known‐replica mymaster 192.168.0.60 6381 #代表redis主节点的从节点信息 </span><br><span class="line">sentinel known‐sentinel mymaster 192.168.0.60 26380 52d0a5d70c1f90475b4fc03b6ce7c3c569 35760f #代表感知到的其它哨兵节点 </span><br><span class="line">sentinel known‐sentinel mymaster 192.168.0.60 26381 e9f530d3882f8043f76ebb8e1686438ba8 bd5ca6 #代表感知到的其它哨兵节点</span><br></pre></td></tr></table></figure><p>当redis主节点如果挂了，哨兵集群会重新选举出新的redis主节点，同时会修改所有sentinel节点配置文件 的集群元数据信息，比如6379的redis如果挂了，假设选举出的新主节点是6380，则sentinel文件里的集 群元数据信息会变成如下所示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sentinel known‐replica mymaster 192.168.0.60 6379 #代表主节点的从节点信息 </span><br><span class="line">sentinel known‐replica mymaster 192.168.0.60 6381 #代表主节点的从节点信息 </span><br><span class="line">sentinel known‐sentinel mymaster 192.168.0.60 26380 52d0a5d70c1f90475b4fc03b6ce7c3c569 35760f #代表感知到的其它哨兵节点 </span><br><span class="line">sentinel known‐sentinel mymaster 192.168.0.60 26381 e9f530d3882f8043f76ebb8e1686438ba8 bd5ca6 #代表感知到的其它哨兵节点</span><br></pre></td></tr></table></figure><p>同时还会修改sentinel文件里之前配置的mymaster对应的6379端口，改为6380<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentinel monitor mymaster 192.168.0.60 6380 2</span><br></pre></td></tr></table></figure></p><p>当6379的redis实例再次启动时，哨兵集群根据集群元数据信息就可以将6379端口的redis节点作为从节点 加入集群。</p><p>哨兵的Jedis连接代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JedisSentinelTest</span> </span>&#123; </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123; </span><br><span class="line">        JedisPoolConfig config = <span class="keyword">new</span> JedisPoolConfig(); </span><br><span class="line">        config.setMaxTotal(<span class="number">20</span>); </span><br><span class="line">        config.setMaxIdle(<span class="number">10</span>); </span><br><span class="line">        config.setMinIdle(<span class="number">5</span>); </span><br><span class="line">        String masterName = <span class="string">"mymaster"</span>; </span><br><span class="line">        Set&lt;String&gt; sentinels = <span class="keyword">new</span> HashSet&lt;String&gt;();</span><br><span class="line">        sentinels.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.0.60"</span>,<span class="number">26379</span>).toString()); </span><br><span class="line">        sentinels.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.0.60"</span>,<span class="number">26380</span>).toString()); </span><br><span class="line">        sentinels.add(<span class="keyword">new</span> HostAndPort(<span class="string">"192.168.0.60"</span>,<span class="number">26381</span>).toString());</span><br><span class="line">        <span class="comment">//JedisSentinelPool其实本质跟JedisPool类似，都是与redis主节点建立的连接池 </span></span><br><span class="line">        <span class="comment">// JedisSentinelPool并不是说与sentinel建立的连接池，而是通过sentinel发现redis主节点并与其 建立连接</span></span><br><span class="line">        JedisSentinelPool jedisSentinelPool = <span class="keyword">new</span> JedisSentinelPool(masterName, sentinels, co nfig, <span class="number">3000</span>, <span class="keyword">null</span>); </span><br><span class="line">        Jedis jedis = <span class="keyword">null</span>; </span><br><span class="line">        <span class="keyword">try</span> &#123; </span><br><span class="line">            jedis = jedisSentinelPool.getResource(); </span><br><span class="line">            System.out.println(jedis.set(<span class="string">"sentinel"</span>, <span class="string">"littlehui"</span>)); </span><br><span class="line">            System.out.println(jedis.get(<span class="string">"sentinel"</span>)); </span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123; </span><br><span class="line">            e.printStackTrace(); </span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123; </span><br><span class="line">            <span class="comment">//注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。 </span></span><br><span class="line">            <span class="keyword">if</span> (jedis != <span class="keyword">null</span>) </span><br><span class="line">                jedis.close(); </span><br><span class="line">        &#125; </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>哨兵的Spring Boot整合Redis连接代码见示例项目：redis-sentinel-cluster</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt; </span><br><span class="line">&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; </span><br><span class="line">&lt;artifactId&gt;spring‐boot‐starter‐data‐redis&lt;/artifactId&gt; </span><br><span class="line">&lt;/dependency&gt; </span><br><span class="line">&lt;dependency&gt; </span><br><span class="line">&lt;groupId&gt;org.apache.commons&lt;/groupId&gt; </span><br><span class="line">&lt;artifactId&gt;commons‐pool2&lt;/artifactId&gt; </span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>springboot项目核心配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">server: </span><br><span class="line">        port: 8080 </span><br><span class="line">        spring: </span><br><span class="line">            redis: </span><br><span class="line">                database: 0</span><br><span class="line">                timeout: 3000 </span><br><span class="line">                sentinel: #哨兵模式 </span><br><span class="line">                    master: mymaster #主服务器所在集群名称 </span><br><span class="line">                    nodes: 192.168.0.60:26379,192.168.0.60:26380,192.168.0.60:26381 </span><br><span class="line">            lettuce:</span><br><span class="line">                pool: </span><br><span class="line">                  max‐idle: 50 </span><br><span class="line">                  min‐idle: 10 </span><br><span class="line">                  max‐active: 100 </span><br><span class="line">                  max‐wait: 1000</span><br></pre></td></tr></table></figure><h3 id="StringRedisTemplate与RedisTemplate详解"><a href="#StringRedisTemplate与RedisTemplate详解" class="headerlink" title="StringRedisTemplate与RedisTemplate详解"></a>StringRedisTemplate与RedisTemplate详解</h3><p>spring 封装了 RedisTemplate 对象来进行对redis的各种操作，它支持所有的 redis 原生的 api。在 RedisTemplate中提供了几个常用的接口方法的使用，分别是:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">private ValueOperations&lt;K, V&gt; valueOps; </span><br><span class="line">private HashOperations&lt;K, V&gt; hashOps; </span><br><span class="line">private ListOperations&lt;K, V&gt; listOps; </span><br><span class="line">private SetOperations&lt;K, V&gt; setOps;</span><br><span class="line">private ZSetOperations&lt;K, V&gt; zSetOps;</span><br></pre></td></tr></table></figure><p>RedisTemplate中定义了对5种数据结构操作</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">redisTemplate.opsForValue();//操作字符串 </span><br><span class="line">redisTemplate.opsForHash();//操作hash </span><br><span class="line">redisTemplate.opsForList();//操作list </span><br><span class="line">redisTemplate.opsForSet();//操作set </span><br><span class="line">redisTemplate.opsForZSet();//操作有序set</span><br></pre></td></tr></table></figure><p>StringRedisTemplate继承自RedisTemplate，也一样拥有上面这些操作。 StringRedisTemplate默认采用的是String的序列化策略，保存的key和value都是采用此策略序列化保存 的。RedisTemplate默认采用的是JDK的序列化策略，保存的key和value都是采用此策略序列化保存的。</p><p>Redis客户端命令对应的RedisTemplate中的方法列表：</p><p><img src="https://images.lilhui.com/701b9d3fc1a6eacf37468e93d36f10e0" alt="图片"></p><p><img src="https://images.lilhui.com/74100f8edf5b02b2f9bc229dd567da87" alt="图片"></p><p><img src="https://images.lilhui.com/1ec7a56abb3e06364c49830ce29a8988" alt="图片"></p><p><img src="https://images.lilhui.com/d14be88c07fe271ca86af964e71ca178" alt="图片"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Redis持久化&quot;&gt;&lt;a href=&quot;#Redis持久化&quot; class=&quot;headerlink&quot; title=&quot;Redis持久化&quot;&gt;&lt;/a&gt;Redis持久化&lt;/h2&gt;&lt;h3 id=&quot;RDB快照（snapshot&quot;&gt;&lt;a href=&quot;#RDB快照（snapshot&quot;
      
    
    </summary>
    
      <category term="redis" scheme="https://www.lilhui.com/categories/redis/"/>
    
    
      <category term="redis，哨兵" scheme="https://www.lilhui.com/tags/redis%EF%BC%8C%E5%93%A8%E5%85%B5/"/>
    
  </entry>
  
  <entry>
    <title>【Redis学习1】核心数据结构与高性能原理</title>
    <link href="https://www.lilhui.com/2022/06/29/redis/redis_core_1/"/>
    <id>https://www.lilhui.com/2022/06/29/redis/redis_core_1/</id>
    <published>2022-06-29T07:14:58.000Z</published>
    <updated>2022-06-29T08:11:36.172Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis-单线程为什么还能这么快？"><a href="#Redis-单线程为什么还能这么快？" class="headerlink" title="Redis 单线程为什么还能这么快？"></a>Redis 单线程为什么还能这么快？</h2><p>因为它所有的数据都在内存中，所有的运算都是内存级别的运算，而且单线程避免了多线程的切换性 能损耗问题。正因为 Redis 是单线程，所以要小心使用<br>Redis 指令，对于那些耗时的指令(比如 keys)，一定要谨慎使用，一不小心就可能会导致 Redis 卡顿。</p><h2 id="Redis单线程如何处理那么多的并发客户端链接？"><a href="#Redis单线程如何处理那么多的并发客户端链接？" class="headerlink" title="Redis单线程如何处理那么多的并发客户端链接？"></a>Redis单线程如何处理那么多的并发客户端链接？</h2><p>Redis的<strong>IO多路复用</strong>：redis利用epoll来实现IO多路复用，将连接信息和事件放到队列中，依次放到 文件事件分派器，事件分派器将事件分发给事件处理器。</p><p><img src="https://images.lilhui.com/3d76aa01f1678c619f175331f40e982d" alt="图片"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看redis支持的最大连接数，在redis.conf文件中可修改<span class="comment"># maxclients 10000 </span></span></span><br><span class="line">        127.0.0.1:6379&gt; CONFIG GET maxclients </span><br><span class="line">        ##1) "maxclients" 4 </span><br><span class="line">        ##2) "10000"</span><br></pre></td></tr></table></figure><h2 id="一些高级命令"><a href="#一些高级命令" class="headerlink" title="一些高级命令"></a>一些高级命令</h2><p>keys: 全量遍历，用来列出所有满足特定正则字符串规则的key.性能比较差。避免使用。<br>scan: 渐进式遍历。SCAN cursor [MATCH pattern] [COUNT count]</p><p>scan 参数提供了三个参数，第一个是 cursor 整数值(hash桶的索引值)，第二个是 key 的正则模式， 第三个是一次遍历的key的数量(参考值，底层遍历的数量不一定)，并不是符合条件的结果数量。第 一次遍历时，cursor 值为 0，然后将返回结果中第一个整数值作为下一次遍历的 cursor。一直遍历 到返回的 cursor 值为 0 时结束。<br>注意：但是scan并非完美无瑕， 如果在scan的过程中如果有键的变化（增加、 删除、 修改） ，那 么遍历效果可能会碰到如下问题： 新增的键可能没有遍历到， 遍历出了重复的键等情况， 也就是说 scan并不能保证完整的遍历出来所有的键， 这些是我们在开发时需要考虑的。</p><p>Info：查看redis服务运行信息，分为 9 大块，每个块都有非常多的参数，这 9 个块分别是:</p><p>Server 服务器运行的环境参数<br>Clients 客户端相关信息<br>Memory 服务器运行内存统计数据<br>Persistence 持久化信息<br>Stats 通用统计数据<br>Replication 主从复制相关信息<br>CPU CPU 使用情况<br>Cluster 集群信息<br>KeySpace 键值对统计数量信息</p><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p><img src="https://images.lilhui.com/5a5b50442717feb7d0a23dd21b64d570" alt="图片"></p><h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">字符串常用操作</span><br><span class="line">SET  key  value //存入字符串键值对</span><br><span class="line">MSET  key  value [key value ...] //批量存储字符串键值对</span><br><span class="line">SETNX  key  value //存入一个不存在的字符串键值对</span><br><span class="line">GET  key //获取一个字符串键值</span><br><span class="line">MGET  key  [key ...] //批量获取字符串键值</span><br><span class="line">DEL  key  [key ...] //删除一个键</span><br><span class="line">EXPIRE  key  seconds //设置一个键的过期时间(秒)</span><br><span class="line"></span><br><span class="line">原子加减</span><br><span class="line">INCR  key //将key中储存的数字值加1</span><br><span class="line">DECR  key //将key中储存的数字值减1</span><br><span class="line">INCRBY  key  increment //将key所储存的值加上increment</span><br><span class="line">DECRBY  key  decrement //将key所储存的值减去decrement</span><br><span class="line"></span><br><span class="line">计数器</span><br><span class="line">INCR article:readcount:&#123;文章id&#125;</span><br><span class="line">GET article:readcount:&#123;文章id&#125; </span><br><span class="line"></span><br><span class="line">Web集群session共享</span><br><span class="line">spring session + redis实现session共享</span><br><span class="line"></span><br><span class="line">分布式系统全局序列号</span><br><span class="line">INCRBY  orderId  1000</span><br></pre></td></tr></table></figure><h3 id="Hash结构"><a href="#Hash结构" class="headerlink" title="Hash结构"></a>Hash结构</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Hash常用操作</span><br><span class="line">HSET  key  field  value //存储一个哈希表key的键值</span><br><span class="line">HSETNX  key  field  value //存储一个不存在的哈希表key的键值</span><br><span class="line">HMSET  key  field  value [field value ...] //在一个哈希表key中存储多个键值对</span><br><span class="line">HGET  key  field //获取哈希表key对应的field键值</span><br><span class="line">HMGET  key  field  [field ...] //批量获取哈希表key中多个field键值</span><br><span class="line">HDEL  key  field  [field ...] //删除哈希表key中的field键值</span><br><span class="line">HLEN  key//返回哈希表key中field的数量</span><br><span class="line">HGETALL key//返回哈希表key中所有的键值</span><br><span class="line"></span><br><span class="line">HINCRBY  key  field  increment //为哈希表key中field键的值加上增量increment</span><br><span class="line"></span><br><span class="line">对象缓存</span><br><span class="line">HMSET  user  &#123;userId&#125;:name  zhuge  &#123;userId&#125;:balance  1888</span><br><span class="line">HMSET  user  1:name  zhuge  1:balance  1888</span><br><span class="line">HMGET  user  1:name  1:balance</span><br></pre></td></tr></table></figure><p><img src="https://images.lilhui.com/8ea1cfd959c1da3d3febafbff977c492" alt="图片"><br>表内容<br><img src="https://images.lilhui.com/50e1a804785e735f677e9844230bb37d" alt="图片"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">电商购物车</span><br><span class="line">1）以用户id为key</span><br><span class="line">2）商品id为field</span><br><span class="line">3）商品数量为value</span><br><span class="line"></span><br><span class="line">购物车操作</span><br><span class="line">添加商品hset cart:1001 10088 1</span><br><span class="line">增加数量hincrby cart:1001 10088 1</span><br><span class="line">商品总数hlen cart:1001</span><br><span class="line">删除商品hdel cart:1001 10088</span><br><span class="line">获取购物车所有商品hgetall cart:1001</span><br></pre></td></tr></table></figure><ul><li>hash结构的优点<br>优点<br>1）同类数据归类整合储存，方便数据管理<br>2）相比string操作消耗内存与cpu更小<br>3）相比string储存更节省空间</li><li>hash结构的缺点<br>缺点<br>过期功能不能使用在field上，只能用在key上<br>Redis集群架构下不适合大规模使用</li></ul><h3 id="List结构"><a href="#List结构" class="headerlink" title="List结构"></a>List结构</h3><p><img src="https://images.lilhui.com/ff9c0592b6fc90f5b541809cbd3cb90c" alt="图片"></p><ul><li><p>常用操作</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">List常用操作</span><br><span class="line">LPUSH  key  value [value ...] //将一个或多个值value插入到key列表的表头(最左边)</span><br><span class="line">RPUSH  key  value [value ...] //将一个或多个值value插入到key列表的表尾(最右边)</span><br><span class="line">LPOP  key//移除并返回key列表的头元素</span><br><span class="line">RPOP  key//移除并返回key列表的尾元素</span><br><span class="line">LRANGE  key  start  stop//返回列表key中指定区间内的元素，区间以偏移量start和stop指定</span><br><span class="line"></span><br><span class="line">BLPOP  key  [key ...]  timeout//从key列表表头弹出一个元素，若列表中没有元素，阻塞等待timeout秒,如果timeout=0,一直阻塞等待</span><br><span class="line">BRPOP  key  [key ...]  timeout //从key列表表尾弹出一个元素，若列表中没有元素，阻塞等待timeout秒,如果timeout=0,一直阻塞等待</span><br></pre></td></tr></table></figure></li><li><p>应用场景</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">常用数据结构</span><br><span class="line">Stack(栈) = LPUSH + LPOP</span><br><span class="line">Queue(队列）= LPUSH + RPOP</span><br><span class="line">Blocking MQ(阻塞队列）= LPUSH + BRPOP</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://images.lilhui.com/ff9c0592b6fc90f5b541809cbd3cb90c" alt="图片"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">微博消息和微信公号消息</span><br><span class="line">诸葛老师关注了MacTalk，备胎说车等大V</span><br><span class="line">1）MacTalk发微博，消息ID为10018</span><br><span class="line">LPUSH  msg:&#123;诸葛老师-ID&#125;  10018</span><br><span class="line">2）备胎说车发微博，消息ID为10086</span><br><span class="line">LPUSH  msg:&#123;诸葛老师-ID&#125; 10086</span><br><span class="line">3）查看最新微博消息</span><br><span class="line">LRANGE  msg:&#123;诸葛老师-ID&#125;  0  4</span><br></pre></td></tr></table></figure><p><img src="https://images.lilhui.com/62e6f348f1bde713939375c504320454" alt="图片"></p><h3 id="Set结构"><a href="#Set结构" class="headerlink" title="Set结构"></a>Set结构</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Set常用操作</span><br><span class="line">SADD  key  member  [member ...]//往集合key中存入元素，元素存在则忽略，</span><br><span class="line">若key不存在则新建</span><br><span class="line">SREM  key  member  [member ...]//从集合key中删除元素</span><br><span class="line">SMEMBERS  key//获取集合key中所有元素</span><br><span class="line">SCARD  key//获取集合key的元素个数</span><br><span class="line">SISMEMBER  key  member//判断member元素是否存在于集合key中</span><br><span class="line">SRANDMEMBER  key  [count]//从集合key中选出count个元素，元素不从key中删除</span><br><span class="line">SPOP  key  [count]//从集合key中选出count个元素，元素从key中删除</span><br><span class="line"></span><br><span class="line">Set运算操作</span><br><span class="line">SINTER  key  [key ...] //交集运算</span><br><span class="line">SINTERSTORE  destination  key  [key ..]//将交集结果存入新集合destination中</span><br><span class="line">SUNION  key  [key ..] //并集运算</span><br><span class="line">SUNIONSTORE  destination  key  [key ...]//将并集结果存入新集合destination中</span><br><span class="line">SDIFF  key  [key ...] //差集运算</span><br><span class="line">SDIFFSTORE  destination  key  [key ...]//将差集结果存入新集合destination中</span><br><span class="line"></span><br><span class="line">微信抽奖小程序</span><br><span class="line">1）点击参与抽奖加入集合</span><br><span class="line">SADD key &#123;userlD&#125;</span><br><span class="line">2）查看参与抽奖所有用户</span><br><span class="line">SMEMBERS key  </span><br><span class="line">3）抽取count名中奖者</span><br><span class="line">SRANDMEMBER key [count] / SPOP key [count]</span><br></pre></td></tr></table></figure><p><img src="https://images.lilhui.com/a73277f489af351a18afef12a4a309ad" alt="图片"></p><ul><li>应用场景</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">微信微博点赞，收藏，标签</span><br><span class="line">1) 点赞</span><br><span class="line">SADD  like:&#123;消息ID&#125;  &#123;用户ID&#125;</span><br><span class="line">2) 取消点赞</span><br><span class="line">SREM like:&#123;消息ID&#125;  &#123;用户ID&#125;</span><br><span class="line">3) 检查用户是否点过赞</span><br><span class="line">SISMEMBER  like:&#123;消息ID&#125;  &#123;用户ID&#125;</span><br><span class="line">4) 获取点赞的用户列表</span><br><span class="line">SMEMBERS like:&#123;消息ID&#125;</span><br><span class="line">5) 获取点赞用户数 </span><br><span class="line">SCARD like:&#123;消息ID&#125;</span><br></pre></td></tr></table></figure><p><img src="https://images.lilhui.com/a9e7bcdfdb7f96bf0f13595f44c40792" alt="图片"></p><ul><li>集合操作<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SINTER set1 set2 set3  &#123; c &#125;</span><br><span class="line">SUNION set1 set2 set3  &#123; a,b,c,d,e &#125;</span><br><span class="line">SDIFF set1 set2 set3  &#123; a &#125;</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://images.lilhui.com/a32160b24d2b4685bad068eb3afd1ca2" alt="图片"></p><ul><li>集合操作实现微博关注模型</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">集合操作实现微博微信关注模型</span><br><span class="line">1) 诸葛老师关注的人: </span><br><span class="line"><span class="meta">zhugeSet-&gt;</span><span class="bash"> &#123;guojia, xushu&#125;</span></span><br><span class="line">2) 杨过老师关注的人:</span><br><span class="line"><span class="meta"> yangguoSet--&gt;</span><span class="bash"> &#123;zhuge, baiqi, guojia, xushu&#125;</span></span><br><span class="line">3) 郭嘉老师关注的人: </span><br><span class="line"><span class="meta">guojiaSet-&gt;</span><span class="bash"> &#123;zhuge, yangguo, baiqi, xushu, xunyu)</span></span><br><span class="line">4) 我和杨过老师共同关注: </span><br><span class="line">SINTER zhugeSet yangguoSet--&gt; &#123;guojia, xushu&#125;</span><br><span class="line">5) 我关注的人也关注他(杨过老师): </span><br><span class="line">SISMEMBER guojiaSet yangguo </span><br><span class="line">SISMEMBER xushuSet yangguo</span><br><span class="line">6) 我可能认识的人: </span><br><span class="line">SDIFF yangguoSet zhugeSet-&gt;(zhuge, baiqi&#125;</span><br></pre></td></tr></table></figure><p><img src="https://images.lilhui.com/a389d879e58447147e4ce1ddcab47473" alt="图片"></p><p><img src="https://images.lilhui.com/31491901442e1895639eab5095e5eee6" alt="图片"></p><ul><li>集合操作实现电商商品筛选</li></ul><p><img src="https://images.lilhui.com/3783a4643c2467640defa05085821cd7" alt="图片"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">SADD  brand:huawei  P40</span><br><span class="line">SADD  brand:xiaomi  mi-10</span><br><span class="line">SADD  brand:iPhone iphone12</span><br><span class="line">SADD os:android  P40  mi-10</span><br><span class="line">SADD cpu:brand:intel  P40  mi-10</span><br><span class="line">SADD ram:8G  P40  mi-10  iphone12</span><br><span class="line"></span><br><span class="line">SINTER  os:android  cpu:brand:intel  ram:8G   &#123;P40，mi-10&#125;</span><br></pre></td></tr></table></figure><h3 id="Zset有序集合结构"><a href="#Zset有序集合结构" class="headerlink" title="Zset有序集合结构"></a>Zset有序集合结构</h3><p><img src="https://images.lilhui.com/f693785556dbdb72de891f82df20830d" alt="图片"></p><ul><li><p>ZSet常用操作</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ZSet常用操作</span><br><span class="line">ZADD key score member [[score member]…]//往有序集合key中加入带分值元素</span><br><span class="line">ZREM key member [member …]//从有序集合key中删除元素</span><br><span class="line">ZSCORE key member //返回有序集合key中元素member的分值</span><br><span class="line">ZINCRBY key increment member//为有序集合key中元素member的分值加上increment </span><br><span class="line">ZCARD key//返回有序集合key中元素个数</span><br><span class="line">ZRANGE key start stop [WITHSCORES]//正序获取有序集合key从start下标到stop下标的元素</span><br><span class="line">ZREVRANGE key start stop [WITHSCORES]//倒序获取有序集合key从start下标到stop下标的元素</span><br></pre></td></tr></table></figure></li><li><p>ZSet集合操作</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ZUNIONSTORE destkey numkeys key [key ...] //并集计算</span><br><span class="line">ZINTERSTORE destkey numkeys key [key …]//交集计算</span><br></pre></td></tr></table></figure></li><li><p>应用场景</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Zset集合操作实现排行榜</span><br><span class="line">1）点击新闻</span><br><span class="line">ZINCRBY  hotNews:20190819  1  守护香港</span><br><span class="line">2）展示当日排行前十</span><br><span class="line">ZREVRANGE  hotNews:20190819  0  9  WITHSCORES </span><br><span class="line">3）七日搜索榜单计算</span><br><span class="line">ZUNIONSTORE  hotNews:20190813-20190819  7 </span><br><span class="line">hotNews:20190813  hotNews:20190814... hotNews:20190819</span><br><span class="line">4）展示七日排行前十</span><br><span class="line">ZREVRANGE hotNews:20190813-20190819  0  9  WITHSCORES</span><br></pre></td></tr></table></figure><p><img src="https://images.lilhui.com/5c41f408bd96434d668b17cb147b8603" alt="图片"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Redis-单线程为什么还能这么快？&quot;&gt;&lt;a href=&quot;#Redis-单线程为什么还能这么快？&quot; class=&quot;headerlink&quot; title=&quot;Redis 单线程为什么还能这么快？&quot;&gt;&lt;/a&gt;Redis 单线程为什么还能这么快？&lt;/h2&gt;&lt;p&gt;因为它所有的
      
    
    </summary>
    
      <category term="redis" scheme="https://www.lilhui.com/categories/redis/"/>
    
    
      <category term="redis" scheme="https://www.lilhui.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>【深入理解Spring系列2】动态代理</title>
    <link href="https://www.lilhui.com/2022/04/28/java/spring/spring_deep_3/"/>
    <id>https://www.lilhui.com/2022/04/28/java/spring/spring_deep_3/</id>
    <published>2022-04-28T06:11:53.000Z</published>
    <updated>2022-04-28T06:19:58.855Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Spring-动态代理"><a href="#Spring-动态代理" class="headerlink" title="Spring 动态代理"></a>Spring 动态代理</h2><p>以mybatis-spring为例子讲下Spring的动态代理过程。<br>mybatis官网：<a href="https://mybatis.org/mybatis-3/zh" target="_blank" rel="noopener">https://mybatis.org/mybatis-3/zh</a></p><ul><li>动态代理的关键</li></ul><ol><li>新建</li></ol><p>JDK的动态代理。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy);</span><br></pre></td></tr></table></figure><p>mapperProxy实现了InvocationHanlder<br>mapperInterface是这个new出来的类接口。接口与实现是分开的。<br>mybatis的关键点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;T&gt;(sqlSession, mapperInterface, methodCache);</span><br></pre></td></tr></table></figure><p>sqlSession在这里传入 MapperProxy<br>MapperProxy又调用MapperMethod<br>Mybatis Mapper具体的代理方法的实现在这里<br>MybatisMapperRegistry.addMapper(Class)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MybatisMapperAnnotationBuilder parser = new MybatisMapperAnnotationBuilder(config, type);</span><br></pre></td></tr></table></figure><p>MybatisMapperAnnotationBuilder</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">@SuppressWarnings(&quot;unchecked&quot;)</span><br><span class="line">public void parse() &#123;</span><br><span class="line">    String resource = type.toString();</span><br><span class="line">    if (!configuration.isResourceLoaded(resource)) &#123;</span><br><span class="line">        loadXmlResource();</span><br><span class="line">        configuration.addLoadedResource(resource);</span><br><span class="line">        assistant.setCurrentNamespace(type.getName());</span><br><span class="line">        parseCache();</span><br><span class="line">        parseCacheRef();</span><br><span class="line">        Method[] methods = type.getMethods();</span><br><span class="line">        // TODO 注入 CURD 动态 SQL (应该在注解之前注入)</span><br><span class="line">        if (GlobalConfigUtils.getSuperMapperClass(configuration).isAssignableFrom(type)) &#123;</span><br><span class="line">            GlobalConfigUtils.getSqlInjector(configuration).inspectInject(assistant, type);</span><br><span class="line">        &#125;</span><br><span class="line">        for (Method method : methods) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                // issue #237</span><br><span class="line">                if (!method.isBridge()) &#123;</span><br><span class="line">                    parseStatement(method);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; catch (IncompleteElementException e) &#123;</span><br><span class="line">                /*</span><br><span class="line">                 * 使用 MybatisMethodResolver 而不是 MethodResolver</span><br><span class="line">                 */</span><br><span class="line">                configuration.addIncompleteMethod(new MybatisMethodResolver(this, method));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    parsePendingMethods();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>mybatis两种：</p><ul><li><p>初始化</p></li><li><p>执行过程</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Spring-动态代理&quot;&gt;&lt;a href=&quot;#Spring-动态代理&quot; class=&quot;headerlink&quot; title=&quot;Spring 动态代理&quot;&gt;&lt;/a&gt;Spring 动态代理&lt;/h2&gt;&lt;p&gt;以mybatis-spring为例子讲下Spring的动态代理过程。
      
    
    </summary>
    
      <category term="spring" scheme="https://www.lilhui.com/categories/spring/"/>
    
    
      <category term="动态代理" scheme="https://www.lilhui.com/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>【Dubbo源码系列6】Duboo 服务调用源码解析</title>
    <link href="https://www.lilhui.com/2022/03/03/java/dubbo/dubbo_6/"/>
    <id>https://www.lilhui.com/2022/03/03/java/dubbo/dubbo_6/</id>
    <published>2022-03-03T10:49:42.000Z</published>
    <updated>2022-03-07T03:52:10.265Z</updated>
    
    <content type="html"><![CDATA[<h2 id="服务消费端执行逻辑"><a href="#服务消费端执行逻辑" class="headerlink" title="服务消费端执行逻辑"></a>服务消费端执行逻辑</h2><ol><li>nvoker.invoke(new RpcInvocation(method, args))：Mock逻辑</li><li>AbstractClusterInvoker.invoke(invocation)：把RpcContext中设置的Attachments添加到invocation对象上，调用路由链从服务目录上筛选出适合的服务Invoker，获得服务均衡策略loadbalance</li><li>FailoverClusterInvoker.doInvoke(invocation, invokers, loadbalance)：根据负载均衡策略选出一个invoker，然后执行</li><li>InvokerWrapper.invoke(invocation)：没做什么事情</li><li>CallbackRegistrationInvoker.invoke(invocation)：开始执行Filter链，执行完得到结果后，会获取ListenableFilter中的listener，执行listener的onResponse方法</li><li>ConsumerContextFilter.invoke(invocation)：设置RpcContext中LocalAddress、RemoteAddress、RemoteApplicationName参数</li><li>FutureFilter.invoke(invocation)：</li><li>MonitorFilter.invoke(invocation)：方法的执行次数+1</li><li>ListenerInvokerWrapper.invoke(invocation)：没做什么事情</li><li>AsyncToSyncInvoker.invoke(invocation)：异步转同步，会先用下层Invoker去异步执行，然后阻塞Integer.MAX_VALUE时间，直到拿到了结果</li><li>AbstractInvoker.invoke(invocation)：主要调用DubboInvoker的doInvoke方法，如果doInvoker方法出现了异常，会进行包装，包装成AsyncRpcResult</li><li>DubboInvoker.doInvoke(invocation)：从clients轮询出一个client进行数据发送，如果配置了不关心结果，则调用ReferenceCountExchangeClient的send方法，否则调用ReferenceCountExchangeClient的request方法</li><li>ReferenceCountExchangeClient.request(Object request, int timeout)：没做什么事情</li><li>HeaderExchangeClient.request(Object request, int timeout)：没做什么事情</li><li>HeaderExchangeChannel.request(Object request, int timeout)：构造一个Request对象，并且会构造一个DefaultFuture对象来阻塞timeout的时间来等待结果，在构造DefaultFuture对象时，会把DefaultFuture对象和req的id存入FUTURES中，FUTURES是一个Map，当HeaderExchangeHandler接收到结果时，会从这个Map中根据id获取到DefaultFuture对象，然后返回Response。</li><li>AbstractPeer.send(Object message)：从url中获取send参数，默认为false</li><li>AbstractClient.send(Object message, boolean sent)：没做什么</li><li>NettyChannel.send(Object message, boolean sent)：调用NioSocketChannel的writeAndFlush发送数据，然后判断send如果是true，那么则阻塞url中指定的timeout时间，因为如果send是false，在HeaderExchangeChannel中会阻塞timeout时间</li><li>NioSocketChannel.writeAndFlush(Object msg)：最底层的Netty非阻塞式的发送数据</li></ol><h2 id="总结流程"><a href="#总结流程" class="headerlink" title="总结流程"></a>总结流程</h2><ol><li>最外层是Mock逻辑，调用前，调用后进行Mock</li><li>从服务目录中，根据当前调用的方法和路由链，筛选出部分服务Invoker（DubboInvoker）</li><li>对服务Invoker进行负载均衡，选出一个服务Invoker</li><li>执行Filter链</li><li>AsyncToSyncInvoker完成异步转同步，因为DubboInvoker的执行是异步非阻塞的，所以如果是同步调用，则会在此处阻塞，知道拿到响应结果</li><li>DubboInvoker开始异步非阻塞的调用</li><li>HeaderExchangeChannel中会阻塞timeout的时间来等待结果，该timeout就是用户在消费端所配置的timeout</li></ol><h2 id="服务提供端执行逻辑"><a href="#服务提供端执行逻辑" class="headerlink" title="服务提供端执行逻辑"></a>服务提供端执行逻辑</h2><ol><li>NettyServerHandler：接收数据</li><li>MultiMessageHandler：判断接收到的数据是否是MultiMessage，如果是则获取MultiMessage中的单个Message，传递给HeartbeatHandler进行处理</li><li>HeartbeatHandler：判断是不是心跳消息，如果是不是则把Message传递给AllChannelHandler</li><li>AllChannelHandler：把接收到的Message封装为一个ChannelEventRunnable对象，扔给线程池进行处理</li><li>ChannelEventRunnable：在ChannelEventRunnable的run方法中会调用DecodeHandler处理Message</li><li>DecodeHandler：按Dubbo协议的数据格式，解析当前请求的path，versio，方法，方法参数等等，然后把解析好了的请求交给HeaderExchangeHandler</li><li>HeaderExchangeHandler：处理Request数据，首先构造一个Response对象，然后调用ExchangeHandlerAdapter得到一个CompletionStage future，然后给future通过whenComplete绑定一个回调函数，当future执行完了之后，就可以从回调函数中得到ExchangeHandlerAdapter的执行结果，并把执行结果设置给Response对象，通过channel发送出去。</li><li>ExchangeHandlerAdapter：从本机已经导出的Exporter中根据当前Request所对应的服务key，去寻找Exporter对象，从Exporter中得到Invoker，然后执行invoke方法，此Invoker为ProtocolFilterWrapper$CallbackRegistrationInvoker</li><li>ProtocolFilterWrapper$CallbackRegistrationInvoker：负责执行过滤器链，并且在执行完了之后回调每个过滤器的onResponse或onError方法</li><li>EchoFilter：判断当前请求是不是一个回升测试，如果是，则不继续执行过滤器链了（服务实现者Invoker也不会调用了）</li><li>ClassLoaderFilter：设置当前线程的classloader为当前要执行的服务接口所对应的classloader</li><li>GenericFilter：把泛化调用发送过来的信息包装为RpcInvocation对象</li><li>ContextFilter：设置RpcContext.getContext()的参数</li><li>TraceFilter：先执行下一个invoker的invoke方法，调用成功后录调用信息</li><li>TimeoutFilter：调用时没有特别处理，只是记录了一下当前时间，当整个filter链都执行完了之后回调TimeoutFilter的onResponse方法时，会判断本次调用是否超过了timeout</li><li>MonitorFilter：记录当前服务的执行次数</li><li>ExceptionFilter：调用时没有特别处理，在回调onResponse方法时，对不同的异常进行处理，详解Dubbo的异常处理</li><li>DelegateProviderMetaDataInvoker：过滤器链结束，调用下一个Invoker</li><li>AbstractProxyInvoker：在服务导出时，根据服务接口，服务实现类对象生成的，它的invoke方法就会执行服务实现类对象的方法，得到结果</li></ol><h2 id="Dubbo的异常处理"><a href="#Dubbo的异常处理" class="headerlink" title="Dubbo的异常处理"></a>Dubbo的异常处理</h2><p>当服务消费者在调用一个服务时，服务提供者在执行服务逻辑时可能会出现异常，对于Dubbo来说，服务消费者需要在消费端抛出这个异常，那么这个功能是怎么做到的呢？<br>服务提供者在执行服务时，如果出现了异常，那么框架会把异常捕获，捕获异常的逻辑在AbstractProxyInvoker中，捕获到异常后，会把异常信息包装为正常的AppResponse对象，只是AppResponse的value属性没有值，exception属性有值。<br>此后，服务提供者会把这个AppResponse对象发送给服务消费端，服务消费端是在InvokerInvocationHandler中调用AppResponse的recreate方法重新得到一个结果，在recreate方法中会去失败AppResponse对象是否正常，也就是是否存在exception信息，如果存在，则直接throw这个exception，从而做到服务执行时出现的异常，在服务消费端抛出。<br>那么这里存在一个问题，如果服务提供者抛出的异常类，在服务消费者这边不存在，那么服务消费者也就抛不出这个异常了，那么dubbo是怎么处理的呢？<br>这里就涉及到了ExceptionFilter，它是服务提供者端的一个过滤器，它主要是在服务提供者执行完服务后会去识别异常：</p><ol><li>如果是需要开发人员捕获的异常，那么忽略，直接把这个异常返回给消费者</li><li>如果在当前所执行的方法签名上有声明，那么忽略，直接把这个异常返回给消费者</li><li>如果抛出的异常不需要开发人员捕获，或者方法上没有申明，那么服务端或记录一个error日志</li><li>异常类和接口类在同一jar包里，那么忽略，直接把这个异常返回给消费者</li><li>如果异常类是JDK自带的异常，那么忽略，直接把这个异常返回给消费者</li><li>如果异常类是Dubbo自带的异常，那么忽略，直接把这个异常返回给消费者</li><li>否则，把异常信息包装成RuntimeException，并覆盖AppResponse对象中的exception属性</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;服务消费端执行逻辑&quot;&gt;&lt;a href=&quot;#服务消费端执行逻辑&quot; class=&quot;headerlink&quot; title=&quot;服务消费端执行逻辑&quot;&gt;&lt;/a&gt;服务消费端执行逻辑&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;nvoker.invoke(new RpcInvocation(meth
      
    
    </summary>
    
      <category term="dubbo" scheme="https://www.lilhui.com/categories/dubbo/"/>
    
    
      <category term="服务调用" scheme="https://www.lilhui.com/tags/%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>Druid连接池 communications link failure问题</title>
    <link href="https://www.lilhui.com/2022/03/03/java/midware/druid_1/"/>
    <id>https://www.lilhui.com/2022/03/03/java/midware/druid_1/</id>
    <published>2022-03-03T01:46:31.000Z</published>
    <updated>2022-03-08T08:30:35.843Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>项目基于Spring boot 链接数据库用的Druid连接池1.1.16版。通过nginx代理连接数据库。数据库配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">show VARIABLES like &apos;%timeout%&apos;</span><br><span class="line">        interactive_timeout 1000</span><br><span class="line">        wait_timeout 1000</span><br></pre></td></tr></table></figure></p><p>物理链接空闲1000秒后会进行回收。<br>druid连接池配置:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">timeBetweenEvictionRunsMillis: 10000</span><br><span class="line">minEvictableIdleTimeMillis: 30000</span><br><span class="line">maxEvictableIdleTimeMillis: 84000</span><br></pre></td></tr></table></figure></p><p>每隔10秒回进行判断空闲时间大于30秒的，或者总存活时间大于84秒的，是否需要回收。按照道理不会有问题，但是执行后会发现druid后台的逻辑链接打开次数<br>大于逻辑链接关闭次数。两者之差，正好等于物理连接打开次数-物理链接关闭次数-1。（-1是因为配置的最小链接数量）。通过后台日志查看到会报</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Communications link failure\n\nThe last packet successfully received from the server was 3 milliseconds ago. The last packet sent successfully to the server was 4 milliseconds ago.; nested exception is com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failure\n\nThe last packet successfully received from the server was 3 milliseconds ago. The last packet sent successfully to the server was 4 milliseconds ago.</span><br></pre></td></tr></table></figure><p>看着很难受，也影响使用。</p><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>druid通过MySqlValidConnectionChecker类进行链接健康检查。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span>   <span class="title">MySqlValidConnectionChecker</span></span>&#123;</span><br><span class="line">    <span class="comment">//其他方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configFromProperties</span><span class="params">(Properties properties)</span> </span>&#123;</span><br><span class="line">        String property = properties.getProperty(<span class="string">"druid.mysql.usePingMethod"</span>);</span><br><span class="line">        <span class="keyword">if</span> (<span class="string">"true"</span>.equals(property)) &#123;</span><br><span class="line">            setUsePingMethod(<span class="keyword">true</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">"false"</span>.equals(property)) &#123;</span><br><span class="line">            setUsePingMethod(<span class="keyword">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isValidConnection</span><span class="params">(Connection conn, String validateQuery, <span class="keyword">int</span> validationQueryTimeout)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (conn.isClosed()) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (usePingMethod) &#123;</span><br><span class="line">            <span class="keyword">if</span> (conn <span class="keyword">instanceof</span> DruidPooledConnection) &#123;</span><br><span class="line">                conn = ((DruidPooledConnection) conn).getConnection();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (conn <span class="keyword">instanceof</span> ConnectionProxy) &#123;</span><br><span class="line">                conn = ((ConnectionProxy) conn).getRawObject();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (clazz.isAssignableFrom(conn.getClass())) &#123;</span><br><span class="line">                <span class="keyword">if</span> (validationQueryTimeout &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                    validationQueryTimeout = DEFAULT_VALIDATION_QUERY_TIMEOUT;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    ping.invoke(conn, <span class="keyword">true</span>, validationQueryTimeout * <span class="number">1000</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InvocationTargetException e) &#123;</span><br><span class="line">                    Throwable cause = e.getCause();</span><br><span class="line">                    <span class="keyword">if</span> (cause <span class="keyword">instanceof</span> SQLException) &#123;</span><br><span class="line">                        <span class="keyword">throw</span> (SQLException) cause;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">throw</span> e;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        String query = validateQuery;</span><br><span class="line">        <span class="keyword">if</span> (validateQuery == <span class="keyword">null</span> || validateQuery.isEmpty()) &#123;</span><br><span class="line">            query = DEFAULT_VALIDATION_QUERY;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Statement stmt = <span class="keyword">null</span>;</span><br><span class="line">        ResultSet rs = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            stmt = conn.createStatement();</span><br><span class="line">            <span class="keyword">if</span> (validationQueryTimeout &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                stmt.setQueryTimeout(validationQueryTimeout);</span><br><span class="line">            &#125;</span><br><span class="line">            rs = stmt.executeQuery(query);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            JdbcUtils.close(rs);</span><br><span class="line">            JdbcUtils.close(stmt);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//其他方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>检查链接是否存活。默认是用的internalPing方法。这个方法会一直返回true 当达到mysql的wait_timeout后。数据库将物理链接关闭，druid端还认为可用。<br>这就有问题了。</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>使用validationQuery进行检查。<br>配置方法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1. 增加yml配置</span><br><span class="line">validationQuery: select &apos;x&apos;</span><br><span class="line">2.  启动时参数带上</span><br><span class="line">    -Ddruid.mysql.usePingMethod=false</span><br><span class="line">    或者在druid配置类上加入：</span><br><span class="line">    @PostConstruct</span><br><span class="line">    public void setProperties()&#123;</span><br><span class="line">        System.setProperty(&quot;druid.mysql.usePingMethod&quot;,&quot;false&quot;);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;项目基于Spring boot 链接数据库用的Druid连接池1.1.16版。通过nginx代理连接数据库。数据库配置&lt;br&gt;&lt;figure
      
    
    </summary>
    
      <category term="druid" scheme="https://www.lilhui.com/categories/druid/"/>
    
    
      <category term="druid" scheme="https://www.lilhui.com/tags/druid/"/>
    
  </entry>
  
  <entry>
    <title>【Dubbo源码系列5】Duboo 服务引入</title>
    <link href="https://www.lilhui.com/2022/02/18/java/dubbo/dubbo_5/"/>
    <id>https://www.lilhui.com/2022/02/18/java/dubbo/dubbo_5/</id>
    <published>2022-02-18T06:39:10.000Z</published>
    <updated>2022-03-07T03:57:02.915Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Dubbo服务引入源码分析"><a href="#Dubbo服务引入源码分析" class="headerlink" title="Dubbo服务引入源码分析"></a>Dubbo服务引入源码分析</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><ol><li>服务引入原理解析</li><li>路由链源码解析</li><li>服务静态目录与动态目录源码解析</li><li>服务引入源码解析</li></ol><h3 id="服务引入原理"><a href="#服务引入原理" class="headerlink" title="服务引入原理"></a>服务引入原理</h3><p>当Spring启动过程中，会去给@Reference注解标注了的属性去进行赋值，赋值的对象为ReferenceBean中get()方法所返回的对象，这个对象是一个代理对象。<br>对于ReferenceBean，它表示应用想要引入的服务的信息，在执行get()时会做如下几步：</p><ol><li>调用checkAndUpdateSubConfigs()，检查和更新参数，和服务提供者类似，把ReferenceBean里的属性的值更新为优先级最高的参数值</li><li>调用init()去生成代理对象ref，get()方法会返回这个ref</li><li>在生成代理对象ref之前，先把消费者所引入服务设置的参数添加到一个map中，等会根据这个map中的参数去从注册中心查找服务</li><li>把消费者配置的所有注册中心获取出来<br>a. 如果只有一个注册中心，那么直接调用Protocol的refer(interfaceClass, urls.get(0));得到一个Invoker对象<br>b. 如果有多个注册中心，则遍历每个注册中心，分别调用Protocol的refer(interfaceClass, url);得到一个Invoker对象添加到invokers中，然后把invokers调用CLUSTER.join(new StaticDirectory(u, invokers));封装所有invokers得到一个invoker，</li><li>把最终得到的invoker对象调用PROXY_FACTORY.getProxy(invoker);得到一个代理对象，并返回，这个代理对象就是ref</li><li>总结：上文的Invoker对象，表示服务执行者，从注册中心refer下来的是一个服务执行者，合并invokers后得到的invoker也是一个服务执行者（抽象范围更大了）</li></ol><p>接下来，来看Protorol.refer(interfaceClass, url)方法是怎么生成一个Invoker的</p><ol><li>首先interfaceClass表示要引入的服务接口，url是注册中心的url（registry://），该url中有一个refer参数，参数值为当前所要引入服务的参数</li><li>调用doRefer(cluster, registry, type, url)</li><li>在doRefer方法中会生成一个RegistryDirectory</li><li>然后获取新版本中的路由器链，并添加到RegistryDirectory中去</li><li>RegistryDirectory监听几个目录（注意，完成监听器的订阅绑定后，会自动触发一次去获取这些目录上的当前数据）<br>a. 当前所引入的服务的动态配置目录：/dubbo/config/dubbo/org.apache.dubbo.demo.DemoService:1.1.1:g1.configurators<br>b. 当前所引入的服务的提供者目录：/dubbo/org.apache.dubbo.demo.DemoService/providers<br>c. 当前所引入的服务的老版本动态配置目录：/dubbo/org.apache.dubbo.demo.DemoService/configurators<br>d. 当前所引入的服务的老版本路由器目录：/dubbo/org.apache.dubbo.demo.DemoService/routers</li><li>调用cluster.join(directory)得到一个invoker</li><li>返回invoker（如果消费者引入了多个group中的服务，那么这里返回的是new MergeableClusterInvoker<t>(directory);，否则返回的是new FailoverClusterInvoker<t>(directory);）</t></t></li><li>但是，上面返回的两个Invoker都会被MockClusterInvoker包装，所以最终返回的是MockClusterInvoker。</li></ol><ol><li>获取服务提供者列表</li><li>Mock</li><li>路由 M–&gt;N</li><li>负载均衡 N—&gt;1</li><li>集群容错</li><li>构造NettyClient</li><li>发送数据</li></ol><h2 id="服务引入"><a href="#服务引入" class="headerlink" title="服务引入"></a>服务引入</h2><ol><li>构造Invoker</li><li>DemoService 服务目录。当前服务的提供者列表 List<invoker> 实际上是 List<dubboinvoker><ol><li>构造一个服务目录的时候要到注册中心查看</li><li>多少个提供者 List<invoker>就多少个 List<dubboinvoker></dubboinvoker></invoker></li><li>监听 当前服务对应的节点</li><li>路由 TagRouter–&gt;AppRouter–&gt;ServiceRouter<br>本质上是构造一个代理对象。代理对象最重要的是Invoker</li></ol></dubboinvoker></invoker></li></ol><p>代理对象逻辑</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">代理对象.a() &#123;</span><br><span class="line">    invoker.invoke(Invocation)</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><ul><li>代理对象<br>  Invoker invoker 有这个就行了。</li><li>Invoker<br>MockClusterInvoker.invoke()<br>  FailoverClusterInvoker.invoke()<pre><code>DubboInvoker.invoke()</code></pre></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Dubbo服务引入源码分析&quot;&gt;&lt;a href=&quot;#Dubbo服务引入源码分析&quot; class=&quot;headerlink&quot; title=&quot;Dubbo服务引入源码分析&quot;&gt;&lt;/a&gt;Dubbo服务引入源码分析&lt;/h2&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; cla
      
    
    </summary>
    
      <category term="dubbo" scheme="https://www.lilhui.com/categories/dubbo/"/>
    
    
      <category term="服务引入" scheme="https://www.lilhui.com/tags/%E6%9C%8D%E5%8A%A1%E5%BC%95%E5%85%A5/"/>
    
  </entry>
  
  <entry>
    <title>【Dubbo源码系列4】Duboo 服务导出</title>
    <link href="https://www.lilhui.com/2022/02/18/java/dubbo/dubbo_4/"/>
    <id>https://www.lilhui.com/2022/02/18/java/dubbo/dubbo_4/</id>
    <published>2022-02-18T06:38:07.000Z</published>
    <updated>2022-03-03T08:54:59.219Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Dubbo服务导出源码解析"><a href="#Dubbo服务导出源码解析" class="headerlink" title="Dubbo服务导出源码解析"></a>Dubbo服务导出源码解析</h2><p>服务导出流程 </p><ol><li>读取配置(端口，协议，loadbalance，注册中心)</li><li>启动netty,tomcat</li><li>服务注册 -&gt; 服务信息 -&gt; 注册中心</li><li>服务提供者，监听动态配置</li></ol><ol start="2"><li>服务注册<br>围绕URL + SPI</li></ol><p>export -&gt; doRegister<br>构造URL剔除冗余 信息，调用注册中心的接口保存到注册中心。</p><p>注册中心URL-&gt;服务URL-&gt;简化-&gt;注册</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Dubbo服务导出源码解析&quot;&gt;&lt;a href=&quot;#Dubbo服务导出源码解析&quot; class=&quot;headerlink&quot; title=&quot;Dubbo服务导出源码解析&quot;&gt;&lt;/a&gt;Dubbo服务导出源码解析&lt;/h2&gt;&lt;p&gt;服务导出流程 &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;读取配置(
      
    
    </summary>
    
      <category term="dubbo" scheme="https://www.lilhui.com/categories/dubbo/"/>
    
    
      <category term="服务导出" scheme="https://www.lilhui.com/tags/%E6%9C%8D%E5%8A%A1%E5%AF%BC%E5%87%BA/"/>
    
  </entry>
  
</feed>
