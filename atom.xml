<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Littlehui&#39;s Notes</title>
  
  <subtitle>天地那么大，世界那么辽阔。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.lilhui.com/"/>
  <updated>2022-12-05T10:07:27.497Z</updated>
  <id>https://www.lilhui.com/</id>
  
  <author>
    <name>Littlehui</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>学习工作方法总结</title>
    <link href="https://www.lilhui.com/2022/12/05/article/worker/learn_tool/"/>
    <id>https://www.lilhui.com/2022/12/05/article/worker/learn_tool/</id>
    <published>2022-12-05T08:12:08.000Z</published>
    <updated>2022-12-05T10:07:27.497Z</updated>
    
    <content type="html"><![CDATA[<h2 id="规划-工作计划"><a href="#规划-工作计划" class="headerlink" title="规划/工作计划"></a>规划/工作计划</h2><h3 id="OKR"><a href="#OKR" class="headerlink" title="OKR"></a>OKR</h3><p>合理地设定目标和分解关键成果来弥补KPI的缺陷。</p><p>更注重聚焦和逻辑</p><p>事前-事中-事后</p><h3 id="步骤-事前"><a href="#步骤-事前" class="headerlink" title="步骤-事前"></a>步骤-事前</h3><ol><li><p>聚焦业务目标（O)/对齐业务OKR(自上而下传导)</p><ul><li>聚焦重要的事情，真去形成合力和突破。</li><li>OKR规划最难的部分<ul><li>环境和处理的信息不稳定性。</li><li>不同人，制定的规划标准不同。</li></ul></li><li>探索，基类</li></ul></li><li><p>分解关键结果（KR)/补充专业OKR</p><ul><li>每个目标 2-5 个KR,收尾结果后，综合多个KPI评判是否达到目标。</li></ul></li></ol><h3 id="执行-事中"><a href="#执行-事中" class="headerlink" title="执行-事中"></a>执行-事中</h3><h4 id="多个备选方案"><a href="#多个备选方案" class="headerlink" title="多个备选方案"></a>多个备选方案</h4><ul><li>制定多个备选方案，系统地分析事情相关的方面，避免思维狭隘。</li><li><p>多执行几个方案（3-5），选择最优的。</p><ul><li>预研：设计多个方案</li><li>讨论：进行方案评审</li><li>决策：选择最终的执行方案</li></ul></li></ul><h4 id="PDCA-执行推进"><a href="#PDCA-执行推进" class="headerlink" title="PDCA 执行推进"></a>PDCA 执行推进</h4><p>plan - do - check - act</p><p>计划 - 执行 - 检查 - 行动</p><blockquote><p>遇到问题如何推进</p></blockquote><p>检查是否有长期问题，如果有长期问题，需要定一个中期或者长期计划。</p><p>解决好问题后，汇总，再把下一步的行动，做汇报。让领导做选择题~</p><p>我知道每个阶段要做什么，让领导知道我每个阶段要做什么。如果出了问题，我也知道要怎么做。</p><p>各个阶段的人，各个阶段的协作方，都知道做什么。</p><ul><li>四个环节</li></ul><ol><li>计划：确定具体任务，阶段目标，时间节点和具体负责人。<ol><li>处理紧急的事情，长短结合，有限解决事情，再配合长期根除。</li><li>需要但不紧急的事情，拆分成多个小项目。</li></ol></li><li><p>执行：按照计划落地的具体活动</p><ol><li>及时同步信息。</li></ol></li><li><p>检查：对照计划来检查结果。</p><ol><li>明确哪些符合预期，哪些不达到预期，哪些超出预期以及存在什么问题。</li></ol></li><li>行动：基于检查结果，总结明确下一步措施。<ol><li>做好总结汇报</li><li>每次挑3个以内的改进点落实到下一步措施。</li></ol></li></ol><h3 id="分析根本原因"><a href="#分析根本原因" class="headerlink" title="分析根本原因"></a>分析根本原因</h3><ol><li>通过五个为什么来深挖问题本质<br>下一个问题是对上一个问题的进一步深入。<br>问题数量不是关键，关键是找到根本原因才是关键。</li></ol><p>明确问题本身。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>要展示出来自己做的东西，而且做的很好。不能闷声做事。做事让人看不到，是白做。要懂得总结，汇报。</p><h3 id="金字塔汇报"><a href="#金字塔汇报" class="headerlink" title="金字塔汇报"></a>金字塔汇报</h3><ol><li>军训四个原则来汇总汇报成果。从而更容易获得更高级别人员的认可。</li><li>标准的回报内容包括 总体结论，具体分析，关键事项，总结改进。</li></ol><blockquote><p>总体结论</p></blockquote><p>全局改过整体工作情况，得出关键性结论，结果一目了然</p><blockquote><p>具体分析</p></blockquote><p>进一步阐述和分析结论，提供具体数据佐证。</p><p>逻辑自洽，有理有据。</p><blockquote><p>关键事项</p></blockquote><p>介绍工作，项目关键效果。</p><ol><li>不用金字塔原理</li><li>全局大图:展示整体情况</li><li>演进路径：展示个体情况。</li><li>时间轴：展示过程</li></ol><blockquote><p>总结改进</p></blockquote><p>总结经验教训和后续措施，措施也有理有据，有迹可循，3-5条。</p><blockquote><p>金字塔原理</p></blockquote><p>核心思想是任何事情都可以归纳出一个中心思想，中心思想可以有三至七个论点支持，每个论点可以由三至七个论据支持。</p><h2 id="业务能力提升"><a href="#业务能力提升" class="headerlink" title="业务能力提升"></a>业务能力提升</h2><blockquote><p>缺少业务能力</p></blockquote><ol><li>讨论需求，产品的需求不合理，实现代价很高，无法发现，知道设计升值编码阶段才发现，自己累，效果不好。出力不讨好。</li><li>处理线上故障，被动接受别人的分析和推断容易背锅~</li><li>不熟悉业务，无法承当整体需求分析和方案设计任务，导致个人能力得不到锻炼，失去晋升机会。</li></ol><blockquote><p>摆脱上线既再见，提升业务能力</p></blockquote><ol><li>无论是前端，客户端还是服务端的技术人员，最好都花点时间，通过业务缓来了解业务的整个流程。</li><li>环式学习</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;规划-工作计划&quot;&gt;&lt;a href=&quot;#规划-工作计划&quot; class=&quot;headerlink&quot; title=&quot;规划/工作计划&quot;&gt;&lt;/a&gt;规划/工作计划&lt;/h2&gt;&lt;h3 id=&quot;OKR&quot;&gt;&lt;a href=&quot;#OKR&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
      <category term="learn" scheme="https://www.lilhui.com/categories/learn/"/>
    
    
      <category term="work" scheme="https://www.lilhui.com/tags/work/"/>
    
      <category term="method" scheme="https://www.lilhui.com/tags/method/"/>
    
  </entry>
  
  <entry>
    <title>海量数据查询和存储</title>
    <link href="https://www.lilhui.com/2022/12/02/java/distributed/big_data/"/>
    <id>https://www.lilhui.com/2022/12/02/java/distributed/big_data/</id>
    <published>2022-12-02T09:19:55.000Z</published>
    <updated>2022-12-05T05:42:40.457Z</updated>
    
    <content type="html"><![CDATA[<h2 id="存储选型"><a href="#存储选型" class="headerlink" title="存储选型"></a>存储选型</h2><p>存储系统的选择，决定了系统的性能上限。</p><p>Mysql: 1000W以内</p><h2 id="如何技术选型"><a href="#如何技术选型" class="headerlink" title="如何技术选型"></a>如何技术选型</h2><p>技术选型不能脱离业务，业务决定技术选型。</p><ul><li>业务系统类型<br>在线业务系统OLTP,分析系统OLAP</li></ul><h3 id="选型步骤"><a href="#选型步骤" class="headerlink" title="选型步骤"></a>选型步骤</h3><ol><li><p>评估规模<br>评估规模，一般估两年以后的量。实际的量，跟老板的期望会有折扣。</p></li><li><p>数据库选择<br>如果数据数量在千万（1GB)：mysql首选。 </p></li></ol><p>数量亿级（1TB): 数据进行分库分表，分片等。<br>只能事先对数据进行聚合计算，然后再聚合后的数据进行查询，这种情况放在HDFS。</p><h3 id="成本考虑"><a href="#成本考虑" class="headerlink" title="成本考虑"></a>成本考虑</h3><p>比如购买Oracle服务。市场MySQL人更容易找到，成本就会更低。尽量选择普遍的技术。学习成本高低,是否有坑。</p><h2 id="如何存储埋点之类的海量数据"><a href="#如何存储埋点之类的海量数据" class="headerlink" title="如何存储埋点之类的海量数据"></a>如何存储埋点之类的海量数据</h2><p>这种数据写的量巨大，先进入队列。kafka,rocketMq。</p><h2 id="分析类系统如何选择存储"><a href="#分析类系统如何选择存储" class="headerlink" title="分析类系统如何选择存储"></a>分析类系统如何选择存储</h2><p>分析类存储的需求有四点</p><ol><li>分析的数据量，会比业务数据量高几个数量级。需要存储系统能够保存海量数据。</li><li>还要能在海量数据上进行聚合，如果要快速请求返回，分析和查询操作。GB,TB,PB级别的海量数据，这种业务在毫秒级响应是不可能的。</li><li>大多数情况下数据都是异步写入</li></ol><p>关键点，还是根据业务决定技术。查询- 选择存储系统和数据结构。</p><h3 id="京东的仓库"><a href="#京东的仓库" class="headerlink" title="京东的仓库"></a>京东的仓库</h3><p>运营过程产生的物流数据。智能补货系统要用，运力调度的系统要用。每个系统使用的方式不同。<br>京东智能补货，需求仓库间补货的最短路径。</p><p><strong>分析</strong>  </p><p>补货系统:地域性，通过地域分片数据，先查询距离近的分片在汇总成区域物流数据。得到最优的发货点。</p><h2 id="商品系统需要保存哪些数据"><a href="#商品系统需要保存哪些数据" class="headerlink" title="商品系统需要保存哪些数据"></a>商品系统需要保存哪些数据</h2><p>商品详情页保存哪些信息？<br>基本信息：标题，副标题，原价，价格，促销价<br>详细信息：商品参数，商品介绍，图片视频<br>其他信息：促销信息，推荐商品，评论，评价，配送信息，店铺信息</p><p>商品详情页：静态化。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;存储选型&quot;&gt;&lt;a href=&quot;#存储选型&quot; class=&quot;headerlink&quot; title=&quot;存储选型&quot;&gt;&lt;/a&gt;存储选型&lt;/h2&gt;&lt;p&gt;存储系统的选择，决定了系统的性能上限。&lt;/p&gt;
&lt;p&gt;Mysql: 1000W以内&lt;/p&gt;
&lt;h2 id=&quot;如何技术选型&quot;&gt;
      
    
    </summary>
    
      <category term="concurrent" scheme="https://www.lilhui.com/categories/concurrent/"/>
    
    
      <category term="bigdata" scheme="https://www.lilhui.com/tags/bigdata/"/>
    
  </entry>
  
  <entry>
    <title>RocksDB详解</title>
    <link href="https://www.lilhui.com/2022/12/02/java/distributed/rocksDB/"/>
    <id>https://www.lilhui.com/2022/12/02/java/distributed/rocksDB/</id>
    <published>2022-12-02T06:39:04.000Z</published>
    <updated>2022-12-05T05:47:28.296Z</updated>
    
    <content type="html"><![CDATA[<h2 id="RocksDB-详解"><a href="#RocksDB-详解" class="headerlink" title="RocksDB 详解"></a>RocksDB 详解</h2><blockquote><p>性能好，支持事务。</p></blockquote><p>秒杀库存扣减中使用了缓存 + Write-Ahead Logging 技术。</p><p>事务随机读写。Redo日志是追加文件顺序读写，性能差异有30-40倍。</p><p>事务的实现上，MySQL使用的是WAL机制来的。所有的修改都先被写到日志中，然后再被应用到系统重。包括<br>redo,undo.</p><p>RocksDB是Facebook开源的高性能，持久化的KV存储引擎，最初是Facebook数据库工程师团队基于 Google LevelDB开发。<br>一般很少使用到RocksDB保存数据。</p><p>越来越多的新生代数据库都选择RocksDB作为他们的存储引擎。比如：CockroachDB(蟑螂)一个开源，可伸缩，跨地域复制且<br>兼容事务的ACID特性的分布式数据库，思路来源于Google的全球性分布式数据库Spanner，其理念是将数据分布在多数据中心的<br>多台服务上。</p><p>YugabyteDB，Tidb 作为CockroachDB的竞争产品，底层也是RocksDB.</p><p>MyRocks使用RocksDB给MySQL做引擎，目的是取代现有的InnoDB存储引擎。MySQL的请兄弟MariaDB已经接纳了MyRocks作为<br>它的存储引擎。</p><p>实时计算引擎Flink,其State就是一个KV存储，它用的也是RocksDB</p><p>MongoDB，Cassandra,Hbase都在开发基于RocksDB的引擎。</p><p>原因是 RocksDB性能高，并且支持事务。</p><blockquote><p>随机读写能达到: 18w-19w qps<br>覆盖操作能达到：9w tps<br>多读单鞋：10w qps</p></blockquote><p>所以用RocksDB实现 Write-Ahead Logging</p><h3 id="RocksDB为什么这么快呢"><a href="#RocksDB为什么这么快呢" class="headerlink" title="RocksDB为什么这么快呢"></a>RocksDB为什么这么快呢</h3><p>内存+磁盘IO,读写性能主要取决于他的存储结构。MySql B+树,Oracle B*,RocksDB LSM-tree</p><h4 id="LSM-Tree"><a href="#LSM-Tree" class="headerlink" title="LSM-Tree"></a>LSM-Tree</h4><p>保证顺序写入的前提下，还能保证很好的查询性能。<br>WAL,跳表和一个分层的有序表（sorted String table,SSTable).LSM-Tree专门为key-value设计的<br>存储系统，以牺牲部分读性能为代价提高写入性能。通常适合于写多读上的场景。</p><p>LSM-Tree 描述图如下 </p><p><img src="https://images.lilhui.com/28ee3b34af9b86ce6288179da1edd623" alt="图片"></p><p>在SSD搞并行下，扩展LevelDB以显示利用SSD的多通道，优化并发I/O请求的调度和调度策略，将常规SSD<br>上运行LevelDB的吞吐量再提高4倍。</p><p>Log写入是使用的WAL机制，顺序写。</p><p>MemTable，跳表（类似红黑树)</p><p>c端过来写MemTable和log后就可以返回了。MemTable 32M,写满后会Dump成ImultableMemTable（不可变）<br>如果write继续，会重新创建一个MemTable.</p><blockquote><p>问题：写入磁盘，部分有序全局无序。</p></blockquote><p>解决方案：Level0,Level1，会进行合并。</p><p>SSTable分层，越热的数据越靠上。对热数据比较友好。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;RocksDB-详解&quot;&gt;&lt;a href=&quot;#RocksDB-详解&quot; class=&quot;headerlink&quot; title=&quot;RocksDB 详解&quot;&gt;&lt;/a&gt;RocksDB 详解&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;性能好，支持事务。&lt;/p&gt;
&lt;/blockquot
      
    
    </summary>
    
      <category term="concurrent" scheme="https://www.lilhui.com/categories/concurrent/"/>
    
    
      <category term="rocksDB" scheme="https://www.lilhui.com/tags/rocksDB/"/>
    
  </entry>
  
  <entry>
    <title>多数据源项目下dubbo调用，获取的数据源不正确</title>
    <link href="https://www.lilhui.com/2022/12/01/bugfix/bugfix_0/"/>
    <id>https://www.lilhui.com/2022/12/01/bugfix/bugfix_0/</id>
    <published>2022-12-01T06:51:37.000Z</published>
    <updated>2022-12-05T06:53:16.581Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>每天定时任务会跑一次下个月的表是否存在，然后进行建表。dubbo调用。在线程上配置了 datasource选取规则。</p><p>初始化的时候会判断是否有建下个月的表，这个操作需要通过schema.xxx操作。但是shardingsphere不支持schema.xxx操作。所以我们创建了两个数据源，shardingDatasource和dataSource</p><p>1：如果 schema.xxx操作的话用 dataSource。<br>2：非schema.xxx操作的 用shardingDataSource。</p><p>在线程执行的时候通过ThreadLocal变量缓存dataSource。但是忘记cleanThreadLocal值了。<br>在短连接的时候是正常的，在长链接的调用下会有以下错误逻辑发生比如dubbo调用下的异常：</p><p>1：如果某次执行 获取了一个 dubboThread1，这个线程执行 先获取了未分表的数据源。并缓存了，如果没有清除数据源，下次拿到的还是这个数据源。</p><p>2：dubbo 协议的provider-consumer 链接是1：1，所以执行一次后，这个链接并没有被销毁，某个下单请求获取到了 这个dubboThread1，由于这个线程链接已经在1 操作中获取到了未分表的数据源 dataSource。就在母表上进行了业务操作。创建订单成功，但是订单所在的表示错误的。</p><p>3：回调来的请求操作是另外一个节点进行处理，获取到的是 dubboThread2 这个dubboThread2 未获取到数据源，所以按照上面的规则进行初始化数据源并缓存 得到shardingDatasource。根据订单号选择的是订单号归属的分表，此时无法找到这个订单。所以报错。</p><h2 id="bug修复"><a href="#bug修复" class="headerlink" title="bug修复"></a>bug修复</h2><p>在定时任务结束后清理dataSource类型缓存。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;每天定时任务会跑一次下个月的表是否存在，然后进行建表。dubbo调用。在线程上配置了 datasource选取规则。&lt;/p&gt;
&lt;p&gt;初始化的
      
    
    </summary>
    
      <category term="bug" scheme="https://www.lilhui.com/categories/bug/"/>
    
    
      <category term="dubbo" scheme="https://www.lilhui.com/tags/dubbo/"/>
    
      <category term="bug" scheme="https://www.lilhui.com/tags/bug/"/>
    
  </entry>
  
  <entry>
    <title>Spring boot gateway 网关压测时配置异常，导致服务返回405</title>
    <link href="https://www.lilhui.com/2022/12/01/bugfix/bugfix_1/"/>
    <id>https://www.lilhui.com/2022/12/01/bugfix/bugfix_1/</id>
    <published>2022-12-01T06:47:11.000Z</published>
    <updated>2022-12-05T05:48:02.246Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>网关选用的是Spring-boot-gateway，网关配置使用nacos持久化。</p><h2 id="Spring的网关源码分析"><a href="#Spring的网关源码分析" class="headerlink" title="Spring的网关源码分析"></a>Spring的网关源码分析</h2><p>通过网关的源码分析，StripPrefixGatewayFilterFactory 通过parts值来截断请求的前缀。正常的是1，在执行过程中被刷新成了5。导致截断请求错误。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   <span class="keyword">if</span> (<span class="keyword">this</span>.running.compareAndSet(<span class="keyword">false</span>, <span class="keyword">true</span>)) &#123;</span><br><span class="line">     # 30s 触发一次定时任务</span><br><span class="line">      <span class="keyword">this</span>.watchFuture = <span class="keyword">this</span>.taskScheduler.scheduleWithFixedDelay(</span><br><span class="line">            <span class="keyword">this</span>::nacosServicesWatch, <span class="keyword">this</span>.properties.getWatchDelay());</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nacosServicesWatch</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   <span class="comment">// 此处nacos 啥都没干, 就强制发送一个更新命令, 正常情况需要判断 service 是否存在更新</span></span><br><span class="line">   <span class="comment">// 因此此处可以作为修复bug的触发点</span></span><br><span class="line">   <span class="comment">// nacos doesn't support watch now , publish an event every 30 seconds.</span></span><br><span class="line">   <span class="keyword">this</span>.publisher.publishEvent(</span><br><span class="line">         <span class="keyword">new</span> HeartbeatEvent(<span class="keyword">this</span>, nacosWatchIndex.getAndIncrement()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="路由配置刷新机制"><a href="#路由配置刷新机制" class="headerlink" title="路由配置刷新机制"></a>路由配置刷新机制</h2><p>Spring gateway 启动后会缓存路由配置，并且，每隔30秒会从缓存刷新配置到具体的路由执行类。<br>在刷新路由配置的方法里加入了监控日志：<br>RouteDefinitionRouteLocator.loadGatewayFilters</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">ConfigurationUtils.bind(configuration, properties,</span><br><span class="line">      factory.shortcutFieldPrefix(), definition.getName(), validator);</span><br><span class="line"></span><br><span class="line">if (configuration instanceof StripPrefixGatewayFilterFactory.Config) &#123;</span><br><span class="line">   StripPrefixGatewayFilterFactory.Config stripConfig = (StripPrefixGatewayFilterFactory.Config)configuration;</span><br><span class="line">   if (stripConfig.getParts() &gt; 2) &#123;</span><br><span class="line">      String errorMessage = &quot;parts 异常：&quot; +  stripConfig.getParts()</span><br><span class="line">            + &quot;definition:&quot; + definition</span><br><span class="line">            + &quot;properties:&quot; + properties</span><br><span class="line">            + &quot;id:&quot; + id;</span><br><span class="line">      log.error(errorMessage, new RuntimeException(errorMessage));</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>properties 是个Map，存放的是待刷新的part值，configuration 是被刷新的配置类，有一个属性 int parts。通过网关通过ConfigurationUtils.bind 来注入 configuration中的parts值。<br>以上代码修改后的异常日志：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">2022-07-15 13:46:38,233 - parts 异常：5definition:FilterDefinition&#123;name=&apos;StripPrefix&apos;, args=&#123;parts=1&#125;&#125;properties:&#123;parts=1&#125;id:pay-api-web</span><br><span class="line">java.lang.RuntimeException: parts 异常：5definition:FilterDefinition&#123;name=&apos;StripPrefix&apos;, args=&#123;parts=1&#125;&#125;properties:&#123;parts=1&#125;id:pay-api-web</span><br><span class="line">at org.springframework.cloud.gateway.route.RouteDefinitionRouteLocator.loadGatewayFilters(RouteDefinitionRouteLocator.java:183)</span><br><span class="line">at org.springframework.cloud.gateway.route.RouteDefinitionRouteLocator.getFilters(RouteDefinitionRouteLocator.java:212)</span><br><span class="line">at org.springframework.cloud.gateway.route.RouteDefinitionRouteLocator.convertToRoute(RouteDefinitionRouteLocator.java:143)</span><br><span class="line">at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:100)</span><br><span class="line">at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:664)</span><br></pre></td></tr></table></figure><p>可以看到在绑定后的 值是5. 但是properties里的是 {parts=1}。 说明bug发生在</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ConfigurationUtils.bind(configuration, properties,</span><br><span class="line">      factory.shortcutFieldPrefix(), definition.getName(), validator);</span><br></pre></td></tr></table></figure><p>这一行ConfigurationUtils.bind 调用的是Spring 底层JavaBeanBinder的bind方法<br>进一步分析JavaBeanBinder.bind</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">private &lt;T&gt; boolean bind(BeanSupplier&lt;T&gt; beanSupplier, BeanPropertyBinder propertyBinder, BeanProperty property) &#123;</span><br><span class="line">   String propertyName = property.getName();</span><br><span class="line">   ResolvableType type = property.getType();</span><br><span class="line">   Supplier&lt;Object&gt; value = property.getValue(beanSupplier);</span><br><span class="line">   Annotation[] annotations = property.getAnnotations();</span><br><span class="line">   //这行在设置后返回bound=5。有错！</span><br><span class="line">   Object bound = propertyBinder.bindProperty(propertyName,</span><br><span class="line">         Bindable.of(type).withSuppliedValue(value).withAnnotations(annotations));</span><br><span class="line">   if (bound == null) &#123;</span><br><span class="line">      return false;</span><br><span class="line">   &#125;</span><br><span class="line">   if (property.isSettable()) &#123;</span><br><span class="line">      property.setValue(beanSupplier, bound);</span><br><span class="line">   &#125;</span><br><span class="line">   else if (value == null || !bound.equals(value.get())) &#123;</span><br><span class="line">      throw new IllegalStateException(&quot;No setter found for property: &quot; + property.getName());</span><br><span class="line">   &#125;</span><br><span class="line">   return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Object bound = propertyBinder.bindProperty(propertyName,</span><br><span class="line">         Bindable.of(type).withSuppliedValue(value).withAnnotations(annotations));</span><br></pre></td></tr></table></figure><p>JavaBeanBinder 是spring boot底层bean属性处理类。</p><h2 id="bind过程分析"><a href="#bind过程分析" class="headerlink" title="bind过程分析"></a>bind过程分析</h2><p>propertyBinder.bindProperty的后续调用链路<br>-&gt;Binder.bind<br>-&gt;BindConverter.cover<br>-&gt;TypeConverterSupport.convertIfNecessary<br>-&gt;TypeConverterSupport.doConvertValue<br>-&gt;TypeConverterSupport.doConvertTextValue</p><p>doConvertTextValue方法有两行代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">editor.setAsText(newTextValue);</span><br><span class="line">return editor.getValue();</span><br></pre></td></tr></table></figure><p>editor是通过PropertyEditorRegistrySupport.createDefaultEditors()初始化，一个类型一个对象。在执行的时候通过propertyEditorRegistry.getDefaultEditor(requiredType)获取。 如果requiredType相同，获取的就是同一个对象。<br>所以当有2次调用获取的editor相同，就可能有并发问题。时序如下：<br>A：editor.setAsText(1)<br>B：editor.setAsText(5)<br>A: return editor.getValue();<br>此时A获取到的就是5。与期望的值不同。造成执行错误。</p><h2 id="错误分析总结"><a href="#错误分析总结" class="headerlink" title="错误分析总结"></a>错误分析总结</h2><ol><li>spring cloud gateway和nacos30秒一次心跳，每次心跳会从内存中刷新路由规则到执行对象。<br>刷新过程调用的是ConfigurationUtils.bind方法，此方法依赖的PropertyEditor。对象对于每个类型是单例的，如果同时有2个相同类型的值进行bind，可能产生并发问题。</li><li>压测时gateway的负载高。RouteDefinitionRouteLocator.getRoutes()方法并发调用RouteDefinitionRouteLocator.loadGatewayFilters。</li><li>RouteDefinitionRouteLocator.loadGatewayFilters依赖的方法ConfigurationUtils.bind有并发问题 导致路由配置错乱。</li></ol><h2 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h2><p>重现方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.google.common.collect.Lists;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang3.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.junit.Before;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"><span class="keyword">import</span> org.junit.runner.RunWith;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.BeansException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.BeanFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.BeanFactoryAware;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.filter.FilterDefinition;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.filter.GatewayFilter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.filter.OrderedGatewayFilter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.filter.factory.GatewayFilterFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.filter.factory.StripPrefixGatewayFilterFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.filter.factory.StripPrefixGatewayFilterFactory.Config;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.support.ConfigurationUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.support.HasRouteId;</span><br><span class="line"><span class="keyword">import</span> org.springframework.core.Ordered;</span><br><span class="line"><span class="keyword">import</span> org.springframework.expression.spel.standard.SpelExpressionParser;</span><br><span class="line"><span class="keyword">import</span> org.springframework.test.context.ActiveProfiles;</span><br><span class="line"><span class="keyword">import</span> org.springframework.test.context.junit4.SpringRunner;</span><br><span class="line"><span class="keyword">import</span> org.springframework.validation.Validator;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> littlehui</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span> TODO</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2022/7/18 22:45</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@RunWith</span>(SpringRunner<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">@<span class="title">SpringBootTest</span>()</span></span><br><span class="line">@ActiveProfiles("local")</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RouteDefinitionRouteLocatorTest</span>   <span class="keyword">implements</span> <span class="title">BeanFactoryAware</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">   Logger logger = LoggerFactory.getLogger(RouteDefinitionRouteLocatorTest<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Autowired</span></span><br><span class="line">   <span class="keyword">private</span> Validator validator;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> SpelExpressionParser parser = <span class="keyword">new</span> SpelExpressionParser();</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span> BeanFactory beanFactory;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Autowired</span></span><br><span class="line">   <span class="keyword">private</span> List&lt;GatewayFilterFactory&gt; gatewayFilterFactoryList;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, GatewayFilterFactory&gt; gatewayFilterFactories = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">concurrentTest</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * assume we have below gateway route config</span></span><br><span class="line"><span class="comment">       *</span></span><br><span class="line"><span class="comment">       - id: r1</span></span><br><span class="line"><span class="comment">       uri: lb://service1</span></span><br><span class="line"><span class="comment">       predicates:</span></span><br><span class="line"><span class="comment">       - Path=/gateway/auth/**</span></span><br><span class="line"><span class="comment">       filters:</span></span><br><span class="line"><span class="comment">       - StripPrefix=1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">       - id: r2</span></span><br><span class="line"><span class="comment">       uri: lb://service2</span></span><br><span class="line"><span class="comment">       predicates:</span></span><br><span class="line"><span class="comment">       - Path=/gateway/api/business/**</span></span><br><span class="line"><span class="comment">       filters:</span></span><br><span class="line"><span class="comment">       - StripPrefix=2</span></span><br><span class="line"><span class="comment">       * then we can construct the  FilterDefinition to mock this config</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line"></span><br><span class="line">      FilterDefinition f1 = <span class="keyword">new</span> FilterDefinition();</span><br><span class="line">      f1.setName(<span class="string">"StripPrefix"</span>);</span><br><span class="line">      f1.setArgs(<span class="keyword">new</span> HashMap&lt;&gt;());</span><br><span class="line">      f1.getArgs().put(<span class="string">"_genkey_0"</span>, <span class="string">"1"</span>);</span><br><span class="line"></span><br><span class="line">      FilterDefinition f2 = <span class="keyword">new</span> FilterDefinition();</span><br><span class="line">      f2.setName(<span class="string">"Retry"</span>);</span><br><span class="line">      f2.setArgs(<span class="keyword">new</span> HashMap&lt;&gt;());</span><br><span class="line">      f2.getArgs().put(<span class="string">"retries"</span>, <span class="string">"5"</span>);</span><br><span class="line"></span><br><span class="line">      Thread t1 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">         <span class="meta">@Override</span></span><br><span class="line">         <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (!Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">               loadGatewayFilters(<span class="string">"r1"</span>, Lists.newArrayList(f1));</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;, <span class="string">"prefix1"</span>);</span><br><span class="line"></span><br><span class="line">      Thread t2 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">         <span class="meta">@Override</span></span><br><span class="line">         <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (!Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">               loadGatewayFilters(<span class="string">"r2"</span>, Lists.newArrayList(f2));</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;, <span class="string">"prefix2"</span>);</span><br><span class="line"></span><br><span class="line">      Thread t22 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">         <span class="meta">@Override</span></span><br><span class="line">         <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (!Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">               loadGatewayFilters(<span class="string">"r2"</span>, Lists.newArrayList(f2));</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;, <span class="string">"prefix2"</span>);</span><br><span class="line"></span><br><span class="line">      Thread t11 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">         <span class="meta">@Override</span></span><br><span class="line">         <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (!Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">               loadGatewayFilters(<span class="string">"r1"</span>, Lists.newArrayList(f1));</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;, <span class="string">"prefix1"</span>);</span><br><span class="line"></span><br><span class="line">      t1.start();</span><br><span class="line">      t2.start();</span><br><span class="line">      t11.start();</span><br><span class="line">      t22.start();</span><br><span class="line"></span><br><span class="line">      <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">         <span class="keyword">if</span> (t1.isInterrupted() || t11.isInterrupted() || t2.isInterrupted() || t22.isInterrupted()) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="function">List&lt;GatewayFilter&gt; <span class="title">loadGatewayFilters</span><span class="params">(String id,</span></span></span><br><span class="line"><span class="function"><span class="params">                                          List&lt;FilterDefinition&gt; filterDefinitions)</span> </span>&#123;</span><br><span class="line">      ArrayList&lt;GatewayFilter&gt; ordered = <span class="keyword">new</span> ArrayList&lt;&gt;(filterDefinitions.size());</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; filterDefinitions.size(); i++) &#123;</span><br><span class="line">         FilterDefinition definition = filterDefinitions.get(i);</span><br><span class="line">         GatewayFilterFactory factory = <span class="keyword">this</span>.gatewayFilterFactories</span><br><span class="line">                 .get(definition.getName());</span><br><span class="line">         <span class="keyword">if</span> (factory == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</span><br><span class="line">                    <span class="string">"Unable to find GatewayFilterFactory with name "</span></span><br><span class="line">                            + definition.getName());</span><br><span class="line">         &#125;</span><br><span class="line">         Map&lt;String, String&gt; args = definition.getArgs();</span><br><span class="line">         <span class="keyword">if</span> (logger.isDebugEnabled()) &#123;</span><br><span class="line">            logger.debug(<span class="string">"RouteDefinition "</span> + id + <span class="string">" applying filter "</span> + args + <span class="string">" to "</span></span><br><span class="line">                    + definition.getName());</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         Map&lt;String, Object&gt; properties = factory.shortcutType().normalize(args,</span><br><span class="line">                 factory, <span class="keyword">this</span>.parser, <span class="keyword">this</span>.beanFactory);</span><br><span class="line"></span><br><span class="line">         Object configuration = factory.newConfig();</span><br><span class="line"></span><br><span class="line"><span class="comment">/*          //加锁解决</span></span><br><span class="line"><span class="comment">            synchronized (this) &#123;</span></span><br><span class="line"><span class="comment">                ConfigurationUtils.bind(configuration, properties,</span></span><br><span class="line"><span class="comment">                        factory.shortcutFieldPrefix(), definition.getName(), validator);</span></span><br><span class="line"><span class="comment">            &#125;*/</span></span><br><span class="line"></span><br><span class="line">         ConfigurationUtils.bind(configuration, properties,</span><br><span class="line">                 factory.shortcutFieldPrefix(), definition.getName(), validator);</span><br><span class="line">         <span class="comment">// some filters require routeId</span></span><br><span class="line">         <span class="comment">// <span class="doctag">TODO:</span> is there a better place to apply this?</span></span><br><span class="line">         <span class="keyword">if</span> (configuration <span class="keyword">instanceof</span> HasRouteId) &#123;</span><br><span class="line">            HasRouteId hasRouteId = (HasRouteId) configuration;</span><br><span class="line">            hasRouteId.setRouteId(id);</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         GatewayFilter gatewayFilter = factory.apply(configuration);</span><br><span class="line"></span><br><span class="line">         <span class="comment">//asset statement start</span></span><br><span class="line">         <span class="keyword">if</span> (configuration <span class="keyword">instanceof</span> StripPrefixGatewayFilterFactory.Config) &#123;</span><br><span class="line">            <span class="keyword">int</span> parts = ((Config) configuration).getParts();</span><br><span class="line">            <span class="keyword">if</span> (StringUtils.equals(<span class="string">"r1"</span>, id) &amp;&amp; !StringUtils.equals(<span class="string">"1"</span>, String.valueOf(parts))) &#123;</span><br><span class="line">               logger.error(<span class="string">"for router id r1,expect parts is 1,but actual is &#123;&#125;"</span>, parts);</span><br><span class="line">               Thread.currentThread().interrupt();</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (StringUtils.equals(<span class="string">"r2"</span>, id) &amp;&amp; !StringUtils</span><br><span class="line">                    .equals(<span class="string">"5"</span>, String.valueOf(parts))) &#123;</span><br><span class="line">               logger.error(<span class="string">"for router id r2,expect parts is 2,but actual is &#123;&#125;"</span>, parts);</span><br><span class="line">               Thread.currentThread().interrupt();</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">//asset statement end</span></span><br><span class="line"></span><br><span class="line">         <span class="keyword">if</span> (gatewayFilter <span class="keyword">instanceof</span> Ordered) &#123;</span><br><span class="line">            ordered.add(gatewayFilter);</span><br><span class="line">         &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            ordered.add(<span class="keyword">new</span> OrderedGatewayFilter(gatewayFilter, i + <span class="number">1</span>));</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> ordered;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setBeanFactory</span><span class="params">(BeanFactory beanFactory)</span> <span class="keyword">throws</span> BeansException </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.beanFactory = beanFactory;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Before</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      gatewayFilterFactoryList.forEach(</span><br><span class="line">              factory -&gt; <span class="keyword">this</span>.gatewayFilterFactories.put(factory.name(), factory));</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;网关选用的是Spring-boot-gateway，网关配置使用nacos持久化。&lt;/p&gt;
&lt;h2 id=&quot;Spring的网关源码分析&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="bug" scheme="https://www.lilhui.com/categories/bug/"/>
    
    
      <category term="gateway" scheme="https://www.lilhui.com/tags/gateway/"/>
    
  </entry>
  
  <entry>
    <title>电商项目数据高可用架构设计</title>
    <link href="https://www.lilhui.com/2022/12/01/java/practice/trade_1/"/>
    <id>https://www.lilhui.com/2022/12/01/java/practice/trade_1/</id>
    <published>2022-12-01T06:37:30.000Z</published>
    <updated>2022-12-01T06:38:59.569Z</updated>
    
    <content type="html"><![CDATA[<h2 id="缓存数据库一致"><a href="#缓存数据库一致" class="headerlink" title="缓存数据库一致"></a>缓存数据库一致</h2><p>Canal : 基于Binlog的同步中间件。</p><p>Canal伪装成Mysql的从节点。收到Binlog 解析变更的binlog。</p><p>Canal Server - 接收Mysql 日志流。<br>Canal Client - 处理解析后的操作。可以在业务进行实现。</p><p>Canal也可以推送到Mq,kafka等。</p><p>RabbitMq不支持。Rocket可以支持。</p><h2 id="Mysql检查"><a href="#Mysql检查" class="headerlink" title="Mysql检查"></a>Mysql检查</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">show VARIABLES like %bin_log%</span><br><span class="line">show VARIABLES like %binlog_format%</span><br><span class="line">show VARIABLES like %server_id%</span><br></pre></td></tr></table></figure><ul><li>修改：</li></ul><p>my.conf</p><h2 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h2><p>创建canal用户，用来复制Mysql权限。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> mysql.user;</span><br></pre></td></tr></table></figure><h2 id="canal配置文件"><a href="#canal配置文件" class="headerlink" title="canal配置文件"></a>canal配置文件</h2><p>几个关键配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">//支持的表，支持正则表达黑丝</span><br><span class="line">canal.instance.filter.regex =</span><br><span class="line">canal.destination =</span><br></pre></td></tr></table></figure><ul><li>启动canal server</li><li>启动canal client</li></ul><h2 id="Binlog"><a href="#Binlog" class="headerlink" title="Binlog"></a>Binlog</h2><h3 id="Binlog的格式"><a href="#Binlog的格式" class="headerlink" title="Binlog的格式"></a>Binlog的格式</h3><ol><li>Row:幂等操作，所以canal选择这种。</li><li>Sql:可以幂等也可能非幂等。</li><li>Mix</li></ol><p>Canal 适用 Row格式Mysql Binlog</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;缓存数据库一致&quot;&gt;&lt;a href=&quot;#缓存数据库一致&quot; class=&quot;headerlink&quot; title=&quot;缓存数据库一致&quot;&gt;&lt;/a&gt;缓存数据库一致&lt;/h2&gt;&lt;p&gt;Canal : 基于Binlog的同步中间件。&lt;/p&gt;
&lt;p&gt;Canal伪装成Mysql的从节点。收
      
    
    </summary>
    
      <category term="practice" scheme="https://www.lilhui.com/categories/practice/"/>
    
    
      <category term="电商，数据高可用" scheme="https://www.lilhui.com/tags/%E7%94%B5%E5%95%86%EF%BC%8C%E6%95%B0%E6%8D%AE%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>大型网站的高并发读写总结</title>
    <link href="https://www.lilhui.com/2022/12/01/java/distributed/concurrent_read_write/"/>
    <id>https://www.lilhui.com/2022/12/01/java/distributed/concurrent_read_write/</id>
    <published>2022-12-01T06:22:20.000Z</published>
    <updated>2022-12-05T05:45:10.782Z</updated>
    
    <content type="html"><![CDATA[<h2 id="高并发的读写场景解析"><a href="#高并发的读写场景解析" class="headerlink" title="高并发的读写场景解析"></a>高并发的读写场景解析</h2><p>不管什么系统，都是做读和写。</p><h3 id="侧重”高并发读”的系统"><a href="#侧重”高并发读”的系统" class="headerlink" title="侧重”高并发读”的系统"></a>侧重”高并发读”的系统</h3><p>存储引擎 ES,solr等<br>终端用户-搜索（读）-&gt; 搜索引擎 &lt;-发布（写）- 内容生产者</p><ol><li>数量级的差别：终端用户成千上百万个。生产者是公司内部产生，数量级不会太高。</li><li>响应时间。读的响应时间要求在毫秒级。</li></ol><h3 id="侧重”高并发写”的系统"><a href="#侧重”高并发写”的系统" class="headerlink" title="侧重”高并发写”的系统"></a>侧重”高并发写”的系统</h3><p>广告位竞拍，扣费类的。如baidu的业务模式，抖音的广告投放扣费等。</p><ol><li>按照浏览次数，点击收费。需要写的实时性。C端每次浏览点击都要进行主账号上的扣减。</li></ol><h3 id="同时有-“高并发读”-和-“高并发写”"><a href="#同时有-“高并发读”-和-“高并发写”" class="headerlink" title="同时有 “高并发读” 和 “高并发写”"></a>同时有 “高并发读” 和 “高并发写”</h3><ol><li>电商的库存系统和秒杀系统</li><li>支付系统，微信红包</li><li>IM,微博朋友圈</li></ol><p>不同场景面面对的高并发压力不同，应对高并发读和高并发写的策略是不同的。</p><h2 id="高并发读常见解决策略"><a href="#高并发读常见解决策略" class="headerlink" title="高并发读常见解决策略"></a>高并发读常见解决策略</h2><h3 id="本地缓存或集中式缓存"><a href="#本地缓存或集中式缓存" class="headerlink" title="本地缓存或集中式缓存"></a>本地缓存或集中式缓存</h3><p>本地Map缓存<br>Redis缓存</p><ul><li>集中式缓存需要避免的问题</li></ul><ol><li>缓存高可用</li><li>缓存穿透</li><li>缓存击穿</li><li>大量热key过期</li></ol><h3 id="读副本"><a href="#读副本" class="headerlink" title="读副本"></a>读副本</h3><p>Mysql Master/Slave 增加一堆Slave（网易的Mysql用法）几百台Mysql slave树。</p><h3 id="CND-静态文件加速，动静分离"><a href="#CND-静态文件加速，动静分离" class="headerlink" title="CND/静态文件加速，动静分离"></a>CND/静态文件加速，动静分离</h3><ol><li>静态内容，数据不变。html,js,css,图片等，是静态，分发到CDN</li><li>动态内容，用户的信息，实时查询的数据，这些放在服务器进行处理。</li></ol><h3 id="并发读"><a href="#并发读" class="headerlink" title="并发读"></a>并发读</h3><h3 id="异步RPC"><a href="#异步RPC" class="headerlink" title="异步RPC"></a>异步RPC</h3><p>串行读 -&gt; 并发读</p><ol><li>在链路上的请求 并发执行。</li><li>冗余请求 Jeaf Dean 写的 The Tail at scale。肠胃耗时优化的经验。<br>案例：一个用户的请求需要100台服务器联合处理，每个服务器有1%的概率发生调用延迟（1秒延迟)。那么C端用户来说，响应时间<br>大于1秒的概率是63%<br>怎么算出来的呢？如果用户请求响应时间小于1s那么 100台服务器响应时间都小于1s。这个概念是100个99%相乘。<br>所以是 1- 0.99 100次方。 问题就很严重。</li></ol><p>此问题的解决方法：冗余请求。客户端同时向多台服务器发送请求，哪个返回快就用哪个，其他的丢弃。这种方法系统的调用量会翻倍。<br>调整一下：如果客户端在一定时间内没有收到服务端的响应，则马上给另一台或者多台发送同样的请求。客户端等待第一个响应到达之后，立即终止其他请求的处理<br>“一定时间” 定义为 ： 内部服务95%请求的响应时间。这种方法称之为 “对冲请求”。</p><p>测试数据：采用这种方法，可以仅用2%的额外请求将系统99.9%的请求响应时间从1800ms降低到74ms.</p><p>牛逼的 The Tail at Scale</p><p>另一个方法：<br>捆绑请求。 上游对下游服务器进行探测，找负载低的。在请求的时候顺便探测。</p><p>核心：用更多的机器来减少延迟，扛起高并发读</p><h3 id="重写轻读"><a href="#重写轻读" class="headerlink" title="重写轻读"></a>重写轻读</h3><h4 id="微博-feeds流的实现"><a href="#微博-feeds流的实现" class="headerlink" title="微博 feeds流的实现"></a>微博 feeds流的实现</h4><p>Feeds流 关注的n个人的微博进行排序成一个列表。有变更，冗余保存起来。<br>为每个人增加一个Feeds流，叫做收件箱。</p><p>将复杂的读逻辑，通过重写的方式，进行了简化。  </p><p>实现的方案：<br>Redis list 缓存。并对list大小进行限制。并且持久化，分库分表。根据业务进行设置分片键。</p><p>以上解决了读的高并发，又引来一个问题：假设一个用户的粉丝很多，每个粉丝的邮箱都复制一份，计算<br>和延迟会很大。比如某个明星有粉丝8000万，如果复制8000万份，对系统来说是个沉重的负担。</p><p>解决方法：回到最初的思路，在读的时候进行实时聚合。用’拉’的方式进行获取。</p><p>将粉丝用户分组，份成在线和不在线。只推送在线的粉丝。系统维护一个全局的，在线列表</p><p>对于读的一端一个用户关注的人当中。有的人是推给他的。有的人需要他去拉的，需要把两者聚合起来，再按时间排序，然后分页显示，这就是’推拉结合’。</p><h3 id="多表的关联查询：宽表于搜索引擎"><a href="#多表的关联查询：宽表于搜索引擎" class="headerlink" title="多表的关联查询：宽表于搜索引擎"></a>多表的关联查询：宽表于搜索引擎</h3><p>多表关联到情况下，通过加Slave解决。这种方法在没有分库的情况下可以实现。</p><p>如果已经分库了，那需要多个查询进行聚合，无法使用原声的Join功能。只能从程序中分别从两个库读取，再做聚合。</p><p>存在一个问题：如果需要把聚合出来的数据按某个维度进行排序分页，这个维度是临时计算出来的维度，而不是数据库本来就有的维度。</p><p>由于无法使用数据库的排序和分页功能，也无法再内存中通过实时计算来实现排序、分页此时如何处理？</p><p>采用类似微博重写轻读的思路：提前把关联数据计算好，存在一个地方，读的时候直接去读聚合好的数据，而不是读的时候去做join.</p><p>具体的操作：准备一张宽表，把关联表的数据算好后保存在宽表里。依据实际情况，定时计算，也可能任何一张原始表发生变化时进行宽表数据的计算。</p><p>也可以使用ES类的搜索引擎来实现：把多个表的join结果做成一个个的文档，放在搜索引擎里。可以林火实现排序和分页查询。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>读写分离Command Query Responsiblility Spareation<br>分别为读和写设计不同的数据结构。在C端，当同时面临读和写的高并发压力时，把系统分成读和写两个视角来设计，各自设计适合搞并发和读写的数据结构或模型。</p><p>缓存其实是读写分离的一个简化，或者是说特例，写业务DB和读缓存用了基本一样的数据结构。</p><h2 id="高并发写常见解决策略"><a href="#高并发写常见解决策略" class="headerlink" title="高并发写常见解决策略"></a>高并发写常见解决策略</h2><h3 id="数据分片"><a href="#数据分片" class="headerlink" title="数据分片"></a>数据分片</h3><p>数据分片后利用多台机器的资源进行分发写操作。</p><p>MySQL: 分库分表<br>Redis: Redis Cluster集群<br>ES: 分布式索引 sharder<br>10亿个网页或商品分成n份，建成n个小的索引。一个查询请求来了，并行地在n各索引上查询。</p><h3 id="异步化"><a href="#异步化" class="headerlink" title="异步化"></a>异步化</h3><p>异步化，无处不在。  </p><p>发送请求立即响应返回。客户端轮询或者其他方式进行获取结果。<br>客户端发起一个Http请求，不等结果，立即发送2，3个。数据库的事务提交Write-aheadLog 。</p><h4 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h4><ul><li>电商系统的拆单功能  </li><li>短信验证码或者登录</li><li>写内存 + Write-Ahead 日志。</li></ul><p>MySQL为了提高磁盘IO性能，使用了 Write-Ahead日志。也就是RedoLog。<br>高并发扣减MySQL中的账户余额，或者电商系统中扣减库存，直接在数据库中口，数据库可能扛不住。<br>可以在Redis中先扣，然后同时落地一条日志（日志可以在一个高可靠的消息中间件或数据库中插入一条条日志）。<br>当Redis宕机，把所有的日志重放完毕，再用数据库中的数据初始化Redis的数据。</p><h3 id="批量写"><a href="#批量写" class="headerlink" title="批量写"></a>批量写</h3><blockquote><p>广告计费的合并扣费</p></blockquote><p>假设有10个用户，对于1个广澳，每个用户点了1次，就意味着同1个广告的主账号要扣10次钱，每次扣1块（假设点击1次扣1次）如果改成<br>合并扣费，就是1次扣10块钱。</p><p>扣费模块一次性从持久化消息队列中取多条消息，对多条消息按照广告的主账号进行分类然后进行扣费。</p><blockquote><p>MySQL的小事务合并机制</p></blockquote><p>MySQL内核会自动合并小事务进行批量的事务操作。<br>Canal里 进行更新的时候，进行合并事务执行。</p><h3 id="侧重-‘高并发写’-的系统"><a href="#侧重-‘高并发写’-的系统" class="headerlink" title="侧重 ‘高并发写’ 的系统"></a>侧重 ‘高并发写’ 的系统</h3><blockquote><p>扣费系统:</p></blockquote><h2 id="商城秒杀中RocketDB数据详解"><a href="#商城秒杀中RocketDB数据详解" class="headerlink" title="商城秒杀中RocketDB数据详解"></a>商城秒杀中RocketDB数据详解</h2><p>异步下单 Redis挂了，但是单没有正常发出去。这时候哪里去找单呢？<br>引入写内存+ write ahead日志。将日志写到RocketDB</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;高并发的读写场景解析&quot;&gt;&lt;a href=&quot;#高并发的读写场景解析&quot; class=&quot;headerlink&quot; title=&quot;高并发的读写场景解析&quot;&gt;&lt;/a&gt;高并发的读写场景解析&lt;/h2&gt;&lt;p&gt;不管什么系统，都是做读和写。&lt;/p&gt;
&lt;h3 id=&quot;侧重”高并发读”的系统
      
    
    </summary>
    
      <category term="concurrent" scheme="https://www.lilhui.com/categories/concurrent/"/>
    
    
      <category term="高并发" scheme="https://www.lilhui.com/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>【秒杀系统4】订单链路兜底方案，限流和熔断降级</title>
    <link href="https://www.lilhui.com/2022/11/30/java/distributed/seckill_4/"/>
    <id>https://www.lilhui.com/2022/11/30/java/distributed/seckill_4/</id>
    <published>2022-11-30T02:54:26.000Z</published>
    <updated>2022-12-05T05:52:22.716Z</updated>
    
    <content type="html"><![CDATA[<h2 id="高并发场景下实现系统稳定运行"><a href="#高并发场景下实现系统稳定运行" class="headerlink" title="高并发场景下实现系统稳定运行"></a>高并发场景下实现系统稳定运行</h2><h2 id="微服务网关常见限流方案"><a href="#微服务网关常见限流方案" class="headerlink" title="微服务网关常见限流方案"></a>微服务网关常见限流方案</h2><p>客户端限流</p><p>服务端限流</p><p>网关限流</p><p>应用层限流</p><h3 id="微服务网关限流"><a href="#微服务网关限流" class="headerlink" title="微服务网关限流"></a>微服务网关限流</h3><p>详情页入口流量保护，黑订单，限制一个IP访问频率。</p><h4 id="基于Redis-Lua的脚本限流"><a href="#基于Redis-Lua的脚本限流" class="headerlink" title="基于Redis + Lua的脚本限流"></a>基于Redis + Lua的脚本限流</h4><p>RequestRateLimiter过滤工厂。算法：令牌桶。</p><p>初始化令牌数量。每次请求过来获取一个令牌，请求完成后，令牌返回桶。</p><h4 id="网关整合-Sentinel-Route-amp-API维度限流"><a href="#网关整合-Sentinel-Route-amp-API维度限流" class="headerlink" title="网关整合 Sentinel Route &amp; API维度限流"></a>网关整合 Sentinel Route &amp; API维度限流</h4><p>主要功能：<br>根据API流控，根据热点参数进行流控。</p><p>流控规则配置在Sentinel后台，分发到网关各节点。网关加入Sentinel jar包。<br>在接受请求时候，通过SlotChain记录并计算流控的结果。</p><h2 id="Sentinel-生产环境引入"><a href="#Sentinel-生产环境引入" class="headerlink" title="Sentinel 生产环境引入"></a>Sentinel 生产环境引入</h2><ul><li>2个维度</li></ul><ol><li>API维度。api流控。</li><li>Route维度。整个为服务进行流控</li></ol><ul><li>持久化<br>改造Senitnel支持Nacos持久化。规则从nacos分发到微服务网关。</li></ul><h2 id="下单引入Sentinel熔断"><a href="#下单引入Sentinel熔断" class="headerlink" title="下单引入Sentinel熔断"></a>下单引入Sentinel熔断</h2><ol><li>秒杀确认页，配置排队等待。匀速器设置。</li><li>热点参数限流。进行流控。<ol><li>商品ID进行流控。</li><li>用户ID为参数，针对一段时间频繁访问的用户ID进行限制。</li></ol></li></ol><p>PS:<br>热点参数规则需要使用@SentinalResource(“resourceName”)进行注解。<br>参数必须是7中基本数据类型才行。</p><h2 id="电商系统自适应保护方案"><a href="#电商系统自适应保护方案" class="headerlink" title="电商系统自适应保护方案"></a>电商系统自适应保护方案</h2><h3 id="降级"><a href="#降级" class="headerlink" title="降级"></a>降级</h3><p>系统容量达到一定程度时，限制或者关闭系统的某些非核心功能。把有限的资源保留给核心业务。<br>降级方案例子：</p><ol><li>当秒杀流量达到5w/s时，把成交记录的获取从展示20条降级到只展示5条。从20 到5，通过开关来配置实现。<br>降级的核心目标是，牺牲次要的功能和用户体验来保证核心业务流程的稳定。不得已为之的举措。例如：在双11时如果优惠券<br>系统扛不住，可能会临时降级商品详情的优惠券信息展示。把有限的资源用在保障交易系统正确展示优惠信息上。既保证用户<br>整整下单时的价格是正确的。</li></ol><h4 id="服务降级的策略"><a href="#服务降级的策略" class="headerlink" title="服务降级的策略"></a>服务降级的策略</h4><p><img src="https://images.lilhui.com/b2c1ecaebba2d0509d9f167867db4b98" alt="图片"></p><h3 id="熔断"><a href="#熔断" class="headerlink" title="熔断"></a>熔断</h3><p>对返回失败的借口，或者借口请求返回慢的。进行降级熔断。直接返回。不请求到后端服务。降低服务端的压力。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;高并发场景下实现系统稳定运行&quot;&gt;&lt;a href=&quot;#高并发场景下实现系统稳定运行&quot; class=&quot;headerlink&quot; title=&quot;高并发场景下实现系统稳定运行&quot;&gt;&lt;/a&gt;高并发场景下实现系统稳定运行&lt;/h2&gt;&lt;h2 id=&quot;微服务网关常见限流方案&quot;&gt;&lt;a h
      
    
    </summary>
    
      <category term="seckill" scheme="https://www.lilhui.com/categories/seckill/"/>
    
    
      <category term="限流，熔断" scheme="https://www.lilhui.com/tags/%E9%99%90%E6%B5%81%EF%BC%8C%E7%86%94%E6%96%AD/"/>
    
  </entry>
  
  <entry>
    <title>【秒杀系统3】优化订单交易全链路优化</title>
    <link href="https://www.lilhui.com/2022/11/30/java/distributed/seckill_3/"/>
    <id>https://www.lilhui.com/2022/11/30/java/distributed/seckill_3/</id>
    <published>2022-11-30T02:04:17.000Z</published>
    <updated>2022-12-05T05:49:10.813Z</updated>
    
    <content type="html"><![CDATA[<h2 id="下单定时检查的优化"><a href="#下单定时检查的优化" class="headerlink" title="下单定时检查的优化"></a>下单定时检查的优化</h2><p>RocketMq事务消息</p><h2 id="Redis扣减库存优化"><a href="#Redis扣减库存优化" class="headerlink" title="Redis扣减库存优化"></a>Redis扣减库存优化</h2><blockquote><p>分布式锁，存在锁竞争，一个商品对应一个锁。几百个商品同时秒杀，Redis压力巨大。</p></blockquote><p><strong>优化方案：</strong> 分布式锁变成本地锁。秒杀服务开始前，由配置中心给每个应用服务实例下发<br>一个库存数胡亮。然后每次下单，每个服务器只管自己的库存数量。与其他应用服务器完全不进行<br>库存同步。在各自的内存里扣减库存，然后定时批量扣减Redis里面的总库存。这样就不会有超卖的问题。减少了网络消耗，性能得到提升。</p><p><strong>引入的问题：</strong> 库存扣减不均衡。少卖了。这种情况是可以接受的。解决的方案有：返场。因为有的下单不支付<br>这些也是要加入到库存。</p><p>技术都是工具，工具的组合才是解决方法之道！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;下单定时检查的优化&quot;&gt;&lt;a href=&quot;#下单定时检查的优化&quot; class=&quot;headerlink&quot; title=&quot;下单定时检查的优化&quot;&gt;&lt;/a&gt;下单定时检查的优化&lt;/h2&gt;&lt;p&gt;RocketMq事务消息&lt;/p&gt;
&lt;h2 id=&quot;Redis扣减库存优化&quot;&gt;&lt;a h
      
    
    </summary>
    
      <category term="seckill" scheme="https://www.lilhui.com/categories/seckill/"/>
    
    
      <category term="全链路" scheme="https://www.lilhui.com/tags/%E5%85%A8%E9%93%BE%E8%B7%AF/"/>
    
  </entry>
  
  <entry>
    <title>【秒杀系统2】设计与实现下</title>
    <link href="https://www.lilhui.com/2022/11/29/java/distributed/seckill_2/"/>
    <id>https://www.lilhui.com/2022/11/29/java/distributed/seckill_2/</id>
    <published>2022-11-29T06:56:26.000Z</published>
    <updated>2022-12-01T08:15:06.076Z</updated>
    
    <content type="html"><![CDATA[<h2 id="秒杀前的流量控制"><a href="#秒杀前的流量控制" class="headerlink" title="秒杀前的流量控制"></a>秒杀前的流量控制</h2><h3 id="预约"><a href="#预约" class="headerlink" title="预约"></a>预约</h3><p>开放预约获得资格后才能参与秒杀。<br>    预约也有高并发所以需要一些设计：</p><ol><li>预约管理后台。</li><li>预约短信和消息提醒。</li><li>面向终端的雨夜核心微服务，提供给用户预约和取消资格能力。</li><li>详情页在展示时获取预约信息的能力，比如商品是否预约，当前预约人数等等。</li><li>秒杀下单时检查预约资格的能力。</li><li>核心在两个维度：<ol><li>预约活动和用户预约关系。所以需要2张表。预约活动表信息表，记录预约活动本身。预约活动开始和结束时间，<br>预约活动对应的秒杀信息，预约商品信息等。另一张表 用户预约关系表，用户的ID,预约的活动ID，预约商品等。</li></ol></li></ol><h3 id="预约系统优化"><a href="#预约系统优化" class="headerlink" title="预约系统优化"></a>预约系统优化</h3><p>用户预约关系表量非常大。方法：</p><ol><li>分库分表。用户预约关系表，写热点。</li><li>前置缓存。预约活动信息，读热点。</li></ol><p>计算预约量：</p><ol><li>用redis记录。</li><li>本地缓存累加，批量写入redis。</li></ol><h2 id="秒杀中流量控制-削峰"><a href="#秒杀中流量控制-削峰" class="headerlink" title="秒杀中流量控制-削峰"></a>秒杀中流量控制-削峰</h2><h3 id="削峰"><a href="#削峰" class="headerlink" title="削峰"></a>削峰</h3><p>无损削峰：限流技术是有损。<br>有损削峰：验证码，问答题，以及一部消息队列。</p><p>加验证码的作用：本来需要0.1秒完成的操作，拉长到10秒或者更长时间。拉长了时间<br>降低的最高的峰值。</p><h3 id="流量削峰"><a href="#流量削峰" class="headerlink" title="流量削峰"></a>流量削峰</h3><p>异步下单：<br>引入消息队列：kafka,RocketMQ,RabbitMQ</p><p>异步支付和订单不一致如何解决？</p><p>订单支付页，定时检查秒杀订单是否已经生成！WebSocket 等等。下单查库问题不大，比访问量第很多。</p><h3 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h3><h2 id="秒杀中的流量控制-限流"><a href="#秒杀中的流量控制-限流" class="headerlink" title="秒杀中的流量控制-限流"></a>秒杀中的流量控制-限流</h2><p>自我保护的直接手段，整个链路都可以进行限流：逐级限流、分层过滤。</p><p>常用算法：令牌桶和漏铜。</p><p><img src="https://images.lilhui.com/2b1147408ad1ebece871df0d32ae979b" alt="图片"></p><h3 id="nginx限流"><a href="#nginx限流" class="headerlink" title="nginx限流"></a>nginx限流</h3><p>HttpLimitZone,HttpLimitRequest<br>HttpLimitZone: 用来限制一个客户端的并发连接数。<br>HttpLimitRequest: 通过漏桶算法进行限制用户的链接频率。</p><p><img src="https://images.lilhui.com/b957e25c0046c74e56476b84ba3d032b" alt="图片"></p><p>limit_req_zone: 指令名称，关键字，只能在http块中使用。<br>$binary_remote_addr Nginx内置绑定变量，比如$remote_port是指客户端端口号。<br>zone=one：规则名称zai limit_req_zone申明过。<br>burst=2: 制定最大突然请求数，超过这个数目的请求会被延迟。<br>nodelay: 突发请求大于burst时候，立即返回503.不排队了。<br>rate:每秒允许通过的请求，每个IP。<br>zone=one:10m :1M可以支持 16000个链接。 10M就是160000个会话链接。</p><h3 id="线程池限流"><a href="#线程池限流" class="headerlink" title="线程池限流"></a>线程池限流</h3><p>Java，Tomcat原生线程池，配置最大连接数，请求处理队列长度以及拒绝策略来达到限流的目的。</p><h3 id="API限流"><a href="#API限流" class="headerlink" title="API限流"></a>API限流</h3><p>线程池限流是一种并发限流。并发恒定的情况下，处理速度越快。QPS越高。</p><p>大部分情况是根据QPS来限流。可以使用Google的RateLimiter开源包。基于令牌桶的算法实现。</p><p>开源的组件Sentinel整合了流量控制、流量整型、流量路由、熔断升级、系统自适应。</p><h3 id="自定义限流"><a href="#自定义限流" class="headerlink" title="自定义限流"></a>自定义限流</h3><p>订单的重复下单问题。订单结算也的时候进行判断（生成ID服务）。下单的时候用这个订单来校验下单是否重复。<br>如果高并发回拖慢秒杀的速度，所以需要进行改造：</p><ol><li>OrderId预生成，放在队列里。缓存在本地。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">OrderIdList = <span class="keyword">new</span> ConcurrentLinkedQueue();</span><br><span class="line">OrderItemList = <span class="keyword">new</span> ConcurrentLinkedQueue();</span><br></pre></td></tr></table></figure></li></ol><p>100毫秒产生200个订单号。所以1秒内只能有2000个订单过来。类似令牌桶限流。更精细的可以控制某个商品的发放速度。</p><ol start="2"><li>商品库存分发到本地。</li></ol><h2 id="限购、秒杀的库存与降级、热点"><a href="#限购、秒杀的库存与降级、热点" class="headerlink" title="限购、秒杀的库存与降级、热点"></a>限购、秒杀的库存与降级、热点</h2><p>重点问题：</p><ol><li>库存超卖，库存扣减的热点。</li></ol><p>在库存服务里解决。</p><h3 id="限购"><a href="#限购" class="headerlink" title="限购"></a>限购</h3><p>全部流量不能直接打到库存服务。需要有个系统来承接大流量没并且脂肪商品库存和匹配的请求到库存服务。限购就是这样的角色。<br>限购之于库存，就像秒杀之于下单。欠着都是后者的滤网和保护伞。</p><p>限购： 做商品的限制购买。因为参加秒杀活动的商品都是爆品、稀缺品，所以为了让更多的用户参与进来，并让有限的投放量汇集<br>更多的人，所以往往会对商品的售卖做限制，一般限制的维度包括两个方面。</p><p><strong>商品维度限购</strong>：每次参加秒杀的活动商品投放量。针对不同地区投放。</p><p><strong>个人维度限购</strong>：校验个人是否能购买数量。</p><h3 id="库存扣减"><a href="#库存扣减" class="headerlink" title="库存扣减"></a>库存扣减</h3><p>如何不超卖 -&gt; 查询用户库存。</p><p>库存扣减必须实现原子性和一致性，如何实现呢？<br>两个操作</p><h4 id="利用乐观锁"><a href="#利用乐观锁" class="headerlink" title="利用乐观锁"></a>利用乐观锁</h4><ol><li><p>查询库存。<br>乐观锁 version 每次扣减的时候带上这个版本号比如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> stock,<span class="keyword">version</span> <span class="keyword">from</span> product <span class="keyword">where</span> <span class="keyword">id</span> = ? ;</span><br></pre></td></tr></table></figure></li><li><p>扣减库存</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">update</span> product <span class="keyword">set</span> stock = stock - ?,<span class="keyword">version</span> = <span class="keyword">version</span> + <span class="number">1</span> <span class="keyword">where</span> <span class="keyword">id</span> = ? <span class="keyword">and</span> <span class="keyword">version</span> = ?</span><br></pre></td></tr></table></figure></li></ol><h4 id="利用数据库特性"><a href="#利用数据库特性" class="headerlink" title="利用数据库特性"></a>利用数据库特性</h4><p><strong>数据库方案：</strong> 行锁。查询和扣减放在一个事务，for update。事务结束后进行释放锁。<br><strong>通过SQL语句</strong>: where条件，保证库存不会被溅到0以下。</p><h4 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h4><p>redis分布式锁可以实现。<br>弊端：需要超时机制。但是有超时机制，又占用时间，与高并发的秒杀系统是相悖的。不建议使用。</p><h4 id="高并发扣减"><a href="#高并发扣减" class="headerlink" title="高并发扣减"></a>高并发扣减</h4><p>流量洪峰来临时，TP99指标变差，CPU升高，IO等待边长。系统变得不稳定。需要对非核心服务进行降级，减轻<br>系统负担，这种降级一般是有损的。属于 ‘弃卒保帅’</p><p>秒杀的核心问题是解决单个商品搞并发读和写的问题。是典型的热点数据问题。我们需要响应的机制，避免热点数据打垮<br>系统。</p><p>Redis库存扣减。宁可少卖，不可超卖。</p><p>如何实现：</p><ol><li>对缓存进行扣减。<br>redis lua eval原子脚本：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">local c_s = redis.call(&apos;get&apos;, KEYS[1])</span><br><span class="line">if (not c_s or  tonumber(c_s) &lt; tonumber(KEYS[2]) then</span><br><span class="line">    return 0</span><br><span class="line">end</span><br><span class="line">redis.call(&apos;decrby&apos;,KEYS[1],KEYS[2])</span><br></pre></td></tr></table></figure></li></ol><p>下单失败需要还原数量。</p><p>问题：Redis挂了怎么办?<br>快速持久化扣减记录，采用WAL机制实现。保存到本地RockDB数据库。</p><h4 id="降级"><a href="#降级" class="headerlink" title="降级"></a>降级</h4><ul><li>写服务降级</li></ul><p>Redis高并发扣减就是一种写降级</p><ul><li>读服务降级</li></ul><p>在不影响正常购买的流程中。将一些无关紧要的信息隐藏。完成读降级。<br>例子：</p><p>问题：双11时登录后，切换几分钟后需要重新登陆。平时并不用重新登陆。</p><p>登录信息缓存失效时间减少。腾出缓存资源。<br><strong>牢记：</strong>微服务资深所依赖的外服中间件或者系统跟本身可用性无关。</p><h2 id="秒杀的防刷，风控，容灾"><a href="#秒杀的防刷，风控，容灾" class="headerlink" title="秒杀的防刷，风控，容灾"></a>秒杀的防刷，风控，容灾</h2><h3 id="防刷"><a href="#防刷" class="headerlink" title="防刷"></a>防刷</h3><p>秒杀商品有限，防止黄牛<br>有效流量： 6：1：3</p><p>6： 黄牛用户<br>1： 错误用户<br>3： 正常请求  </p><p>防刷方法有：</p><ol><li>Nginx限流机制。限制IP高频访问。</li><li>Token机制，用来做鉴权。防止直接访问下单接口。在订单详情页时候获取Token，在下单时候带上原Token并再产生一个Token,每个环节进行校验。保证用户的操作是连续的。<br> 例子：在header_filter_by_lua_block 返回 的header里增加流程Token</li></ol><h3 id="风控"><a href="#风控" class="headerlink" title="风控"></a>风控</h3><p>如果已经有风控系统，可以拿到黑名单列表。进行封闭。</p><h3 id="容灾"><a href="#容灾" class="headerlink" title="容灾"></a>容灾</h3><p>防天灾，机房容灾。</p><p>异地双活：跨城市备份。有物理时延比较难实现。（招行实现）<br>同城双活：同城双活，物理距离比价近，延迟低。同城机房，同事承担部分流量。主机房承担写，部分读，备份机房部分读。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;秒杀前的流量控制&quot;&gt;&lt;a href=&quot;#秒杀前的流量控制&quot; class=&quot;headerlink&quot; title=&quot;秒杀前的流量控制&quot;&gt;&lt;/a&gt;秒杀前的流量控制&lt;/h2&gt;&lt;h3 id=&quot;预约&quot;&gt;&lt;a href=&quot;#预约&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
      <category term="seckill" scheme="https://www.lilhui.com/categories/seckill/"/>
    
    
      <category term="秒杀" scheme="https://www.lilhui.com/tags/%E7%A7%92%E6%9D%80/"/>
    
  </entry>
  
  <entry>
    <title>【秒杀系统1】设计与实现上</title>
    <link href="https://www.lilhui.com/2022/11/29/java/distributed/seckill_1/"/>
    <id>https://www.lilhui.com/2022/11/29/java/distributed/seckill_1/</id>
    <published>2022-11-29T01:58:14.000Z</published>
    <updated>2022-11-30T02:06:34.801Z</updated>
    
    <content type="html"><![CDATA[<h2 id="业务分析-系统挑战"><a href="#业务分析-系统挑战" class="headerlink" title="业务分析 系统挑战"></a>业务分析 系统挑战</h2><ol><li>瞬时流量</li><li>库存有限</li><li>持续时间短</li><li>预约，限购</li><li>涉及 商品详情页，订单结算，支付</li></ol><h2 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h2><ol><li>瞬时流量带来的服务端压力，造成单个请求增加。打挂服务器，用户体验不佳。</li><li>库存有限。造成多卖，超卖。</li><li>刷子流量，黄牛抢单，刷订单。黑产！道高一尺魔高一丈。</li></ol><h2 id="通用秒杀架构"><a href="#通用秒杀架构" class="headerlink" title="通用秒杀架构"></a>通用秒杀架构</h2><h3 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h3><p><strong><em>解决大流量问题</em></strong></p><ul><li>Http请求路径</li></ul><p>用户 -&gt; DNS -&gt; NGINX -&gt; Web服务 -&gt; RPC调用</p><p>解决流量问题，就是在链路上的个个节点进行优化。</p><p>NGINX：负载均衡，反向代理，静态资源服务器。流量过滤，限流。<br>Web服务：集群，业务聚合。<br>RPC调用：数据库，缓存等基础服务。</p><h3 id="NGINX"><a href="#NGINX" class="headerlink" title="NGINX"></a>NGINX</h3><p>流量筛选，缓存接口（openretry)</p><p>引入Openrestry 处理商品展示页面相关接口。</p><p>Nginx启动后，产生Master进程。Master生成多个Worker进程，处理相关请求。<br>Worker进程数可以配置。一般跟CPU数量保持一致。或者CPU跟Worker进行绑定，减少上下文切换，提升性能。</p><p>OpenRestry将LuaJIT的虚拟机嵌入到Nginx的管理进程和Worker进程。性能上OpenRestry接近或者超过C的模块，开发效率高。</p><p>Nginx将Http请求分成多个阶段，一个Http请求分给多个模块进行处理。每个模块专注一个独立简单的功能处理。</p><p>9个模块：</p><p>OpenRestry在Http处理阶段基础上分别在Rewrite/Access阶段、Content阶段、Log阶段注册了自己的Handler，加上系统初始阶段<br>Master的两个阶段，共11 个阶段为Lua脚本提供了介入的能力。</p><p>init_by_lua：进程加载Nginx配置文件时运行，一般用于注册全局变量，或者预加载Lua模块。<br>init_worker_by_lua：每个worker进程启动时执行，通常用于定时拉取配置数据或则进行后端服务的健康检查。<br>set_by_lua：变量初始化。<br>rewrite_by_lua：可以实现复杂的转发，重定向逻辑。<br>access_by_lua：准入，接口权限等情况集中处理。<br>content_by_lua：内容处理器，接收请求处理并输出响应。<br>header_filter_by_lua：响应头部或者Cookie处理。<br>body_filter_by_lua： 对响应数据进行过滤，如截断或者替换。<br>log_by_lua:会话完成后，本地异步完成日志记录。  </p><h3 id="商城中的OpenRestry"><a href="#商城中的OpenRestry" class="headerlink" title="商城中的OpenRestry"></a>商城中的OpenRestry</h3><ol><li>负载均衡</li><li>网关</li><li>反向代理</li></ol><h4 id="详情页静态化"><a href="#详情页静态化" class="headerlink" title="详情页静态化"></a>详情页静态化</h4><p><strong>页面</strong>：商品详情页静态化。比商城页面静态化更彻底的静态化。  </p><p>秒杀的商品是独立提报的。秒杀商品详情页的模板是类似的。抽出相同部分，通过freemark生成静态页面，缓存到ftp服务器。通过nginx直接访问。<br>具体做法：  </p><ol><li>准备提报脚本，自动化处理 生成html静态文件。推送到nginx服务端。</li><li>秒杀管理后台，开启秒杀开关，选取商品进行商详面静态化。</li><li>sftp 上传到nginx服务器。</li><li>访问链接和具体页面进行映射。通过RestyTemplate</li><li>OpenRestry二次模板化。活动详情的渲染等。通过RestyTemplate</li></ol><h4 id="库存获取"><a href="#库存获取" class="headerlink" title="库存获取"></a>库存获取</h4><p><strong>库存</strong>：库存直接从redis进行获取。不用通过后端服务。</p><ol><li>OpenResty直接访问Redis获取库存。resty.redis开源模块。</li><li>Nginx 和 Redis从服务器放在一起，避免链路层和传输层的开销。完全避免网络开销需要用到Unix Domain Socket变成进程间通信 IPC！</li></ol><p>Unix Domain Socket: 进程间通讯。</p><h2 id="秒杀隔离设计"><a href="#秒杀隔离设计" class="headerlink" title="秒杀隔离设计"></a>秒杀隔离设计</h2><p>隔离策略,秒杀商品和普通商品隔离。</p><h3 id="如何隔离"><a href="#如何隔离" class="headerlink" title="如何隔离"></a>如何隔离</h3><ol><li>业务上的隔离</li><li>系统隔离。流量大的系统进行隔离（订单，支付,库存)</li><li>数据的隔离</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;业务分析-系统挑战&quot;&gt;&lt;a href=&quot;#业务分析-系统挑战&quot; class=&quot;headerlink&quot; title=&quot;业务分析 系统挑战&quot;&gt;&lt;/a&gt;业务分析 系统挑战&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;瞬时流量&lt;/li&gt;
&lt;li&gt;库存有限&lt;/li&gt;
&lt;li&gt;持续时间短&lt;/l
      
    
    </summary>
    
      <category term="seckill" scheme="https://www.lilhui.com/categories/seckill/"/>
    
    
      <category term="秒杀" scheme="https://www.lilhui.com/tags/%E7%A7%92%E6%9D%80/"/>
    
  </entry>
  
  <entry>
    <title>【tomcat调优系列4】Tomcat 类加载机制，和热部署</title>
    <link href="https://www.lilhui.com/2022/11/23/tomcat/tomcat_4/"/>
    <id>https://www.lilhui.com/2022/11/23/tomcat/tomcat_4/</id>
    <published>2022-11-23T06:55:17.000Z</published>
    <updated>2022-11-23T13:54:40.278Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Tomcat类加载机制"><a href="#Tomcat类加载机制" class="headerlink" title="Tomcat类加载机制"></a>Tomcat类加载机制</h2><h3 id="JVM类加载器"><a href="#JVM类加载器" class="headerlink" title="JVM类加载器"></a>JVM类加载器</h3><p>Java中有3个类加载器，并且你可以自定义加载器。</p><ul><li>BoostrapClassLoader 是启动类加载器，由C预演实现，用来加载JVM启动时所需的核心类，比如rt.jar。</li><li>ExtClassLoader是扩展类加载器，用来加载\jre\lib\ext 目录下Jar包。扩展加载器的 #getParent()返回null,实际上扩展类加载器的<br>父类加载器就是启动类加载器。</li><li>AppClassLoader是系统类加载器，用来加载ClassPath下的类。应用程序默认用它来加载类。程序可以通过#getSystemClassLoader()来获取系统类加载器。</li><li>自定义加载器，用来加载自定义路径下的类。</li></ul><h3 id="双亲委派机制"><a href="#双亲委派机制" class="headerlink" title="双亲委派机制"></a>双亲委派机制</h3><p>加载某个类时会先委派父类加载器寻找目标类，找不到再委托上层父加载器，如果所有父加载器都找不到目标类，则在自己的类加载器路径中查找，并载入目标类。</p><p><img src="https://images.lilhui.com/c9cdb1fc55bcbd323b25aa274b6f2916" alt="图片"></p><p><img src="https://images.lilhui.com/23455a00f586de4dcebe1e4dd8453b05" alt="图片"></p><p>上图：ClassLoader#loadClass加载过程</p><p>问题： 为什么要设计双亲委派机制？</p><ul><li><strong>沙箱安全机制</strong>：自己写的java.lang.String.class类不会被夹在，防止API库被篡改。</li><li><strong>避免类的重复加载</strong>：当父亲已经加载了该类，就没有必要子ClassLoader再加载一次，保证加载类的唯一性。</li></ul><h3 id="Tomcat类加载机制-1"><a href="#Tomcat类加载机制-1" class="headerlink" title="Tomcat类加载机制"></a>Tomcat类加载机制</h3><p>Tomcat作为Servlet容器，它负责加载我们的Servlet类，此外还负责加载Servlet所依赖的Jar包。并且Tomcat本身也是一个Java程序。<br>因此它需要加载自己的类和依赖的Jar包。</p><p>问题：Tomcat如何隔离Web应用的？</p><p>Tomcat 自定义了一个类加载器WebAppClassLoader，并且给每个Web应用创建一个类加载器实例，每个Context容器负责创建和维护一个<br>WebAppClassLoader加载器实例。其实现的原理就是<strong>不同的类加载器实例加载的类被认为是不同的类，即使它们的类名相同（不同类加载器<br>实例加载的类是相互隔离的）</strong>。</p><p>Tomcat的自定义类加载器WebAppClassLoader打破了双亲委派机制。它首先自己尝试加载某个类，如果找不到再代理给父类加载器，其目的是<br>优先加载Web应用自己定义的类。具体实现就是重写ClassLoader的2个方法：findClass和loadClass.</p><p>findClass步骤：</p><ol><li>在Web应用本地目录下查找要加载的类。</li><li>如果没有找到，交给父加载器去查找，它的付加载器就是上面提到的系统类加载器。AppClassLoader.</li><li>如果父加载器也没找到这个类，抛出ClassNotFound异常。</li></ol><p>loadClass有6个步骤：</p><ol><li>现在本地Cache查找该类是否加载过，也就是说Tomcat的类加载器是否已经加载过这个类。</li><li>如果Tomcat加载器没加载过这个类，再看系统类加载器是否加载过。</li><li>如果都没有，就让ExtClassLoader去加载，这一步比较关键，目的防止 Web 应用自己的类覆盖 JRE 的核心类。因为 Tomcat 需要打破双<br>亲委托机制，假如 Web 应用里自定义了一个叫 Object 的类，如果先加载这个 Object 类，就会覆盖 JRE 里面的那个 Object 类，这就<br>是为什么 Tomcat 的类加载器会优先尝试用 ExtClassLoader 去加载，因为 ExtClassLoader 会委托给 BootstrapClassLoader 去加载，BootstrapClassLoader 发现自己已经加载了 Object 类，直接返回给 Tomcat 的类加载器，这样 Tomcat 的类加载器就不会去加载 Web 应用下的 Object 类了，也就避免了覆盖 JRE 核心类的问题。</li><li>如果 ExtClassLoader 加载器加载失败，也就是说 JRE 核心类中没有这类，那么就在本地 Web 应用目录下查找并加载。</li><li>如果本地目录下没有这个类，说明不是 Web 应用自己定义的类，那么由系统类加载器去加载。这里请你注意，Web 应用是通过Class.forName调用交给系统类加载器的，因为Class.forName的默认加载器就是系统类加载器。</li><li>如果上述加载过程全部失败，抛出 ClassNotFound 异常。</li></ol><p>本地cache -&gt; ExtendClassLoader -&gt; WebAppClassLoader -&gt; AppClassLoader</p><p>所以本地可以覆盖jar包里的实现。</p><h3 id="Tomcat类加载器的层次结构"><a href="#Tomcat类加载器的层次结构" class="headerlink" title="Tomcat类加载器的层次结构"></a>Tomcat类加载器的层次结构</h3><p>Tomcat 拥有不同的自定义类加载器，以实现对各种资源库的控制。 Tomcat 主要用类加载器解决以下 4 个问题：<br>同一个 Web 服务器里，各个 Web 项目之间各自使用的 Java 类库要互相隔离。</p><ul><li>同一个 Web 服务器里，各个 Web 项目之间各自使用的 Java 类库要互相隔离。</li><li>同一个 Web 服务器里，各个 Web 项目之间可以提供共享的 Java 类库 。</li><li>为了使服务器不受 Web 项目的影响，应该使服务器的类库与应用程序的类库互相独立。</li><li>对于支持 JSP 的 Web 服务器，应该支持热插拔（ HotSwap ）功能 。  </li></ul><p>Tomcat提供了四组目录供用户存放第三方类库：</p><ul><li>放置在/common目录中：类库可被Tomcat和所有的 Web应用程序共同使用。</li><li>放置在/server目录中：类库可被Tomcat使用，对所有的Web应用程序都不可见。</li><li>放置在/shared目录中：类库可被所有的Web应用程序共同使用，但对 Tomcat自己不可见。</li><li>放置在/WebApp/WEB-INF目录中：类库仅仅可以被此Web应用程序使用，对 Tomcat和其他Web应用程序都不可见。</li></ul><p>Tomcat自定义了多个类加载器</p><ol><li>CommonClassLoader   加载 /common</li><li>CatalinaClassLoader 加载 /server/</li><li>SharedClassLoader  加载 /shared/</li><li>WebappClassLoader  加载 /WebApp/WEB-INF/</li></ol><p><img src="https://images.lilhui.com/a4bfcb6f0ae2ddbd691e12746461c7cc" alt="图片"></p><h3 id="线程上下文加载器"><a href="#线程上下文加载器" class="headerlink" title="线程上下文加载器"></a>线程上下文加载器</h3><p>在 JVM 的实现中有一条隐含的规则，默认情况下，如果一个类由类加载器 A 加载，那么这个类的依赖类也是由相同的类加载器加载。比如 Spring 作为一个 Bean 工厂，它需要创建业务类的实例，并且在创建业务类实例之前需要加载这些类。<br>思考：如果spring作为共享第三方jar包，交给SharedClassLoader加载，但是业务类在web目录下，不在SharedClassLoader的加载路径下，那spring如何加载web应用目录下的业务bean呢？</p><p>问题： 如果spring作为共享第三方jar包，交给SharedClassLoader加载，但是业务类在web目录下，不在SharedClassLoader的加载路径下，那spring如何加载web应用目录下的业务bean呢？</p><p>Tomcat为每个Web应用创建一个WebAppClassLoader加载器，并在启动Web应用的线程设置上下文加载器。这样Spring在启动时就将现成上下文加载器取出来，用来加载Bean。</p><p>线程上下文加载器是一种类加载器传递机制，因为这个类加载器保存在线程私有数据里，只要是同一个线程，一旦设置了线程上下文加载器，在线程后续执行过程中就能把这个类加载器取出来用。<br>Thread.currentThread().getContextClassLoader()</p><p>线程上下文加载器不仅仅可以用在 Tomcat 和 Spring 类加载的场景里，核心框架类需要加载具体实现类时都可以用到它，比如我们熟悉的 JDBC 就是通过上下文类加载器来加载不同的数据库驱动的</p><p>线程上下文加载器，在SPI实现上用的比较多。</p><h2 id="Tomcat热加载和热部署"><a href="#Tomcat热加载和热部署" class="headerlink" title="Tomcat热加载和热部署"></a>Tomcat热加载和热部署</h2><p>在项目开发过程中，经常要改动Java/JSP 文件，但是又不想重新启动Tomcat，有两种方式:热加载和热部署。热部署表示重新部署应⽤，它的执⾏主体是Host。 热加载表示重新加载class，它的执⾏主体是Context。<br>热加载：在server.xml -&gt; context 标签中 设置 reloadable=”true”</p><ul><li>热加载：在server.xml -&gt; context 标签中 设置 reloadable=”true”</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Context</span> <span class="attr">docBase</span>=<span class="string">"D:\mvc"</span> <span class="attr">path</span>=<span class="string">"/mvc"</span>  <span class="attr">reloadable</span>=<span class="string">"true"</span> /&gt;</span></span><br><span class="line">热部署：在server.xml -&gt; Host标签中 设置  autoDeploy="true"</span><br></pre></td></tr></table></figure><ul><li>热部署：在server.xml -&gt; Host标签中 设置  autoDeploy=”true”</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Host</span> <span class="attr">name</span>=<span class="string">"localhost"</span>  <span class="attr">appBase</span>=<span class="string">"webapps"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">unpackWARs</span>=<span class="string">"true"</span> <span class="attr">autoDeploy</span>=<span class="string">"true"</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>他们的区别</strong></p><ul><li>热加载的实现方式是 Web 容器启动一个后台线程，定期检测类文件的变化，如果有变化，就重新加载类，在这个过程中不会清空 Session ，一般用在开发环境。</li><li>热部署原理类似，也是由后台线程定时检测 Web 应用的变化，但它会重新加载整个 Web 应用。这种方式会清空 Session，比热加载更加干净、彻底，一般用在生产环境。</li></ul><p>问题： Tomcat是如何用后台线程来实现热加载和热部署的</p><h3 id="Tomcat开启后台线程执行周期性任务"><a href="#Tomcat开启后台线程执行周期性任务" class="headerlink" title="Tomcat开启后台线程执行周期性任务"></a>Tomcat开启后台线程执行周期性任务</h3><p>Tomcat 通过开启后台线程ContainerBase.ContainerBackgroundProcessor，使得各个层次的容器组件都有机会完成一些周期性任务。我们在实际工作中，往往也需要执行一些周期性的任务，比如监控程序周期性拉取系统的健康状态，就可以借鉴这种设计。<br>Tomcat9 是通过ScheduledThreadPoolExecutor来开启后台线程的，它除了具有线程池的功能，还能够执行周期性的任务。</p><p><img src="https://images.lilhui.com/0121b5252cd38720749f046807893124" alt="图片"></p><p>此后台线程会调用当前容器的 backgroundProcess 方法，以及递归调用子孙的 backgroundProcess 方法，backgroundProcess 方法会触发容器的周期性任务。</p><p><img src="https://images.lilhui.com/5c90f19905daff7d323025a58de15ebd" alt="图片"></p><p>有了 ContainerBase 中的后台线程和 backgroundProcess 方法，各种子容器和通用 组件不需要各自弄一个后台线程来处理周期性任务，这样的设计显得优雅和整洁。</p><h3 id="热加载实现原理"><a href="#热加载实现原理" class="headerlink" title="热加载实现原理"></a>热加载实现原理</h3><p>有了 ContainerBase 的周期性任务处理“框架”，作为具体容器子类，只需要实现自 己的周期性任务就行。而 Tomcat 的热加载，就是在 Context 容器中实现的。Context 容 器的 backgroundProcess 方法是这样实现的：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//  StandardContext#backgroundProcess</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//WebappLoader 周期性的检查 WEB-INF/classes 和 WEB-INF/lib 目录下的类文件</span></span><br><span class="line"><span class="comment">// 热加载</span></span><br><span class="line">Loader loader = getLoader();</span><br><span class="line"><span class="keyword">if</span> (loader != <span class="keyword">null</span>) &#123;</span><br><span class="line">    loader.backgroundProcess();        </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>WebappLoader 实现热加载的逻辑：它主要是调用了 Context 容器的 reload 方法，先stop Context容器，再start Context容器。具体的实现：<br>停止和销毁 Context 容器及其所有子容器，子容器其实就是 Wrapper，也就是说 Wrapper 里面 Servlet 实例也被销毁了。</p><ol><li>停止和销毁 Context 容器及其所有子容器，子容器其实就是 Wrapper，也就是说 Wrapper 里面 Servlet 实例也被销毁了。</li><li>停止和销毁 Context 容器关联的 Listener 和 Filter。</li><li>停止和销毁 Context 下的 Pipeline 和各种 Valve。</li><li>停止和销毁 Context 的类加载器，以及类加载器加载的类文件资源。</li><li>启动 Context 容器，在这个过程中会重新创建前面四步被销毁的资源。</li></ol><p>在这个过程中，类加载器发挥着关键作用。一个 Context 容器对应一个类加载器，类加载器在销毁的过程中会把它加载的所有类也全部销毁。Context 容器在启动过程中，会创建一个新的类加载器来加载新的类文件。</p><h3 id="Tomcat热部署原理"><a href="#Tomcat热部署原理" class="headerlink" title="Tomcat热部署原理"></a>Tomcat热部署原理</h3><p>热部署跟热加载的本质区别是，热部署会重新部署 Web 应用，原来的 Context 对象会整个被销毁掉，因此这个 Context 所关联的一切资源都会被销毁，包括 Session。<br>Host 容器并没有在 backgroundProcess 方法中实现周期性检测的任务，而是通过监听器 HostConfig 来实现的</p><p>Host 容器并没有在 backgroundProcess 方法中实现周期性检测的任务，而是通过监听器 HostConfig 来实现的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// HostConfig#lifecycleEvent</span></span><br><span class="line"><span class="comment">// 周期性任务</span></span><br><span class="line"><span class="keyword">if</span> (event.getType().equals(Lifecycle.PERIODIC_EVENT)) &#123;</span><br><span class="line">    check();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">check</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (host.getAutoDeploy()) &#123;</span><br><span class="line">        <span class="comment">// Check for resources modification to trigger redeployment</span></span><br><span class="line">        DeployedApplication[] apps = deployed.values().toArray(<span class="keyword">new</span> DeployedApplication[<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">for</span> (DeployedApplication app : apps) &#123;</span><br><span class="line">            <span class="keyword">if</span> (tryAddServiced(app.name)) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// 检查 Web 应用目录是否有变化</span></span><br><span class="line">                    checkResources(app, <span class="keyword">false</span>);</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    removeServiced(app.name);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Check for old versions of applications that can now be undeployed</span></span><br><span class="line">        <span class="keyword">if</span> (host.getUndeployOldVersions()) &#123;</span><br><span class="line">            checkUndeploy();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Hotdeploy applications</span></span><br><span class="line">        <span class="comment">//热部署</span></span><br><span class="line">        deployApps();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>HostConfig 会检查 webapps 目录下的所有 Web 应用：</p><ul><li>如果原来 Web 应用目录被删掉了，就把相应 Context 容器整个销毁掉。</li><li>是否有新的 Web 应用目录放进来了，或者有新的 WAR 包放进来了，就部署相应的 Web 应用。</li></ul><p>因此 HostConfig 做的事情都是比较“宏观”的，它不会去检查具体类文件或者资源文件是否有变化，而是检查 Web 应用目录级别的变化。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Tomcat类加载机制&quot;&gt;&lt;a href=&quot;#Tomcat类加载机制&quot; class=&quot;headerlink&quot; title=&quot;Tomcat类加载机制&quot;&gt;&lt;/a&gt;Tomcat类加载机制&lt;/h2&gt;&lt;h3 id=&quot;JVM类加载器&quot;&gt;&lt;a href=&quot;#JVM类加载器&quot; c
      
    
    </summary>
    
      <category term="tomcat" scheme="https://www.lilhui.com/categories/tomcat/"/>
    
    
      <category term="tomcat" scheme="https://www.lilhui.com/tags/tomcat/"/>
    
      <category term="类加载，热部署" scheme="https://www.lilhui.com/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD%EF%BC%8C%E7%83%AD%E9%83%A8%E7%BD%B2/"/>
    
  </entry>
  
  <entry>
    <title>【tomcat调优系列3】Tomcat底层BIO和NIO实现原理</title>
    <link href="https://www.lilhui.com/2022/11/22/tomcat/tomcat_3/"/>
    <id>https://www.lilhui.com/2022/11/22/tomcat/tomcat_3/</id>
    <published>2022-11-22T03:02:16.000Z</published>
    <updated>2022-11-23T06:55:40.261Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Tomcat-IO选择历史"><a href="#Tomcat-IO选择历史" class="headerlink" title="Tomcat IO选择历史"></a>Tomcat IO选择历史</h2><ol><li>Tomcat7时默认用的BIO,同步阻塞。可以通过配置修改为NIO</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Connector</span> <span class="attr">port</span>=<span class="string">"8080"</span> <span class="attr">protocol</span>=<span class="string">"org.apache.coyote.http11.Http11Ni oProtocol"</span> </span></span><br><span class="line"><span class="tag"><span class="attr">connectionTimeout</span>=<span class="string">"20000"</span> <span class="attr">redirectPort</span>=<span class="string">"8443"</span> /&gt;</span></span><br></pre></td></tr></table></figure><ol start="2"><li>Tomcat8.5以后默认用的是NIO.</li></ol><h2 id="阻塞与非阻塞"><a href="#阻塞与非阻塞" class="headerlink" title="阻塞与非阻塞"></a>阻塞与非阻塞</h2><p>Socket通信过程分两个部分：</p><ol><li>连接准备</li><li>拷贝内核缓存到用户缓存。<br>阻塞和非阻塞的概念是在连接准备阶段的描述。</li></ol><h2 id="Tomcat的BIO实现"><a href="#Tomcat的BIO实现" class="headerlink" title="Tomcat的BIO实现"></a>Tomcat的BIO实现</h2><ol><li>JioEndpoint的Acceptor线程负责循环阻塞接收sock连接。</li><li>每接收到一个socket连接就包装成SocketProcessor扔进线程池Executor.SocketProcessor是一个Runnable</li><li>SocketProcess负责从scoket阻塞读取数据，并且向socket中阻塞写入数据。</li></ol><p>Acceptor现成数量默认为1，可以通过acceptorThreadCount参数进行配置。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Executor</span> <span class="attr">name</span>=<span class="string">"tomcatThreadPool"</span> <span class="attr">namePrefix</span>=<span class="string">"catalina-exec-"</span> </span></span><br><span class="line"><span class="tag">        <span class="attr">maxThreads</span>=<span class="string">"150"</span> <span class="attr">minSpareThreads</span>=<span class="string">"4"</span>/&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">Connector</span> <span class="attr">port</span>=<span class="string">"8080"</span> <span class="attr">protocol</span>=<span class="string">"org.apache.coyote.http11.Http11Ni oProtocol"</span> </span></span><br><span class="line"><span class="tag">        <span class="attr">connectionTimeout</span>=<span class="string">"20000"</span> </span></span><br><span class="line"><span class="tag">           <span class="attr">redirectPort</span>=<span class="string">"8443"</span> <span class="attr">executor</span>=<span class="string">"tomcatThreadPool"</span>/&gt;</span></span><br></pre></td></tr></table></figure><p>Tomcat中每个Connector都会创建一个线程池，并且默认值：</p><ol><li>最小线程数量10</li><li>最大线程数量20</li></ol><p>使用BIO处理请求时：</p><ol><li>当请求数量比较大时，可以提高Acceptor线程数量，提高接收请求的速率。</li><li>当请求比较耗时时，可以提高线程池Executor的最大线程数量。</li></ol><p>原理图：</p><p><img src="https://images.lilhui.com/1f62e4fafb4b3b53161a55d323656dc1" alt="图片"></p><h2 id="Tomcat的NIO实现"><a href="#Tomcat的NIO实现" class="headerlink" title="Tomcat的NIO实现"></a>Tomcat的NIO实现</h2><p>NIO非阻塞接收socket连接，非阻塞从socket读取数据，非阻塞将数据写入socket中。</p><p>在Tomcat中，只有从socket读取请求行，请求头数据时是非阻塞的。在读取请求体是阻塞的，响应数据也是阻塞的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Tomcat-IO选择历史&quot;&gt;&lt;a href=&quot;#Tomcat-IO选择历史&quot; class=&quot;headerlink&quot; title=&quot;Tomcat IO选择历史&quot;&gt;&lt;/a&gt;Tomcat IO选择历史&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Tomcat7时默认用的BIO,同步阻塞
      
    
    </summary>
    
      <category term="tomcat" scheme="https://www.lilhui.com/categories/tomcat/"/>
    
    
      <category term="tomcat" scheme="https://www.lilhui.com/tags/tomcat/"/>
    
      <category term="bio" scheme="https://www.lilhui.com/tags/bio/"/>
    
      <category term="nio" scheme="https://www.lilhui.com/tags/nio/"/>
    
  </entry>
  
  <entry>
    <title>【tomcat调优系列2】Tomcat响应数据过程</title>
    <link href="https://www.lilhui.com/2022/11/18/tomcat/tomcat_2/"/>
    <id>https://www.lilhui.com/2022/11/18/tomcat/tomcat_2/</id>
    <published>2022-11-18T07:30:18.000Z</published>
    <updated>2022-11-20T02:04:38.481Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Tomcat响应数据过程"><a href="#Tomcat响应数据过程" class="headerlink" title="Tomcat响应数据过程"></a>Tomcat响应数据过程</h2><h3 id="关键部件解释"><a href="#关键部件解释" class="headerlink" title="关键部件解释"></a>关键部件解释</h3><ol><li>OutputStream： 用于response的输出流。Tomcat这里是CoyoteOutputStream</li><li>OutputBuffer: 输出流的缓冲</li><li>ByteChunk: OutputBuffer的一个对象，缓冲的，缓冲区。</li><li>ByteChunk的buff构成，大小8192.</li><li>ByteOutputChannel：ByteChunk的out。缓冲区的数据流向的渠道。其实就是socket.</li><li>realWriteBytes方法：ByteOutputChannel的方法。会把src的数据发送给对应的驱动。</li><li>org.apache.coyote.Response：发送逻辑</li></ol><h3 id="触发缓冲区标记的发送"><a href="#触发缓冲区标记的发送" class="headerlink" title="触发缓冲区标记的发送"></a>触发缓冲区标记的发送</h3><ol><li>缓冲区满的情况：ByteChunk.append -&gt; out.realWriteBytes(src,off,len)。换冲突的大小为8192 ByteChunk</li><li>缓冲区没满：调用outputStream.flush</li></ol><h3 id="ouputStream-flush的方法"><a href="#ouputStream-flush的方法" class="headerlink" title="ouputStream.flush的方法"></a>ouputStream.flush的方法</h3><ol><li>判断是否发送过响应头，没发送则发送相应头。</li><li>调用ByteChunk的flushBuffer方法，把缓冲区的数据发送出去。</li><li>发送时候是从 ByteBuffer 发送到SocketBuffer(也是ByteChunk实现的)。SocketBuffer发送给socket</li></ol><h3 id="coyoteResponse-doWrite-outputChunk"><a href="#coyoteResponse-doWrite-outputChunk" class="headerlink" title="coyoteResponse.doWrite(outputChunk)"></a>coyoteResponse.doWrite(outputChunk)</h3><ol><li>调用方法：outputBuffer.doWrite(chunk, this).OutputBuffer是InternalOutputBuffer。</li><li>该doWrite⽅法中，⾸先会判断响应头是否已经发送，如果没有发送，则会构造响应头，并发响应头发送给 socketBuffer，发送完响应头，会调⽤响应的output的activeFilters，对于不同的响应体需要使⽤不同的 发送逻辑。⽐如ChunkedOutputFilter是⽤来发送分块响应体的，IdentityOutputFilter是⽤来发送 Content-length响应体的，VoidOutputFilter不会真正的把数据发送出去。</li><li>在构造响应头时，会识别响应体应该通过什么OutputFilter来发送，如果响应中存在content-length那么 则使⽤IdentityOutputFilter来发送响应体，否则使⽤ChunkedOutputFilter，当然还有⼀些异常情况下会 使⽤VoidOutputFilter，表示不会发送响应体。</li></ol><h3 id="响应的Content-lenth什么时候确定"><a href="#响应的Content-lenth什么时候确定" class="headerlink" title="响应的Content-lenth什么时候确定"></a>响应的Content-lenth什么时候确定</h3><p>答案是：当请求在servlet中执⾏完成后，会调⽤response.finishResponse()⽅法，该⽅法会调⽤ outputBuffer.close()，该outputBuffer就是org.apache.catalina.connector.OutputBuffer，该⽅法会 判断响应体是否已发送，如果在调⽤这个close时响应头还没有发送，则表示响应体的数据在之前⼀直没有 发送过，⼀直存在了第⼀层缓冲区中，并且⼀直没有塞满该缓冲区，因为该缓冲区如果被塞满了，则会发 送响应头，所以当执⾏到close⽅法是，响应头还没发送过，那么缓冲区中的数据就是响应体全部的数据， 即，缓冲区数据的⻓度就是content-length。 反之，在调⽤close⽅法之前，就已经发送过数据了，那么响应头中就没有content-length，就会⽤ ChunkedOutputFilter来发送数据。</p><p>并且在执⾏close⽅法时，会先将响应头的数据发送给socketbuffer，然后将第⼀层缓冲区的数据通过对应 的OutputFilter发送给socketbuffer，然后调⽤OutputFilter的end⽅法，IdentityOutputFilter的end⽅ 法实现很简单，⽽ChunkedOutputFilter的end⽅法则相对做的事情更多⼀点，因为 ChunkedOutputFilter的doWrite⼀次只会发送⼀块数据，所以end要负责循环调⽤doWrite⽅法，把全部 的数据库发送完。</p><p>最后将socketbuffer中的数据发送给socket。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Tomcat响应数据过程&quot;&gt;&lt;a href=&quot;#Tomcat响应数据过程&quot; class=&quot;headerlink&quot; title=&quot;Tomcat响应数据过程&quot;&gt;&lt;/a&gt;Tomcat响应数据过程&lt;/h2&gt;&lt;h3 id=&quot;关键部件解释&quot;&gt;&lt;a href=&quot;#关键部件解释&quot;
      
    
    </summary>
    
      <category term="tomcat" scheme="https://www.lilhui.com/categories/tomcat/"/>
    
    
      <category term="tomcat" scheme="https://www.lilhui.com/tags/tomcat/"/>
    
      <category term="调优" scheme="https://www.lilhui.com/tags/%E8%B0%83%E4%BC%98/"/>
    
  </entry>
  
  <entry>
    <title>【tomcat调优系列1】Tomcat的请求过程</title>
    <link href="https://www.lilhui.com/2022/11/18/tomcat/tomcat_1/"/>
    <id>https://www.lilhui.com/2022/11/18/tomcat/tomcat_1/</id>
    <published>2022-11-18T06:57:04.000Z</published>
    <updated>2022-11-20T02:04:38.477Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Tomcat请求过程"><a href="#Tomcat请求过程" class="headerlink" title="Tomcat请求过程"></a>Tomcat请求过程</h2><h3 id="几个部件："><a href="#几个部件：" class="headerlink" title="几个部件："></a>几个部件：</h3><ol><li>Endpoint： tomcat接收socket链接的组件。</li><li>Socket：请求的通道链接</li><li>InputBuffer. InternalInputBuffer,AbstractInputBuffer：缓冲内存</li><li>Request：请求对象</li><li>MessageBytes: 请求对象的消息内容</li><li>ByteChunk：</li><li>Connection：Java层面的链接对象</li><li>Servlet：处理请求的组件</li><li>Response：请求处理后的返回</li></ol><h3 id="请求过程"><a href="#请求过程" class="headerlink" title="请求过程"></a>请求过程</h3><ul><li>请求的解析</li></ul><ol><li>Endpoint接收socket链接。</li><li>从socket中获取数据并缓存到InputBuffer。BIO是InternalInputBuffer继承自AbstractInputBuffer</li><li>从InputBuffer中解析请求。将完整的请求协议和请求体封装到Request对象。</li><li>Request中的messageByte进行标记。标记url,header,请求体等。</li><li>解析头，解析请求。</li><li>初始化请求头的一些参数：Connextion keepalive，Content-length等。包括请求体处理的InputFilter</li><li>将请求交给容器</li></ol><ul><li>请求的处理</li></ul><ol start="8"><li>容器将请求分发到具体的Servlet进行处理。</li><li>Servlet处理请求利用Response进行响应。将返回的数据写入缓冲区，调用flush或者close时，把缓冲区的数据发送给socket.</li><li>servlet处理完请求后，检查是否需要把响应数据发送给socket.</li><li>看请求体是否处理结束，是否还有剩余数据，如果有剩余数据，把这些数据处理掉。以便获取下个请求的数据。</li><li>回到第一步处理下一个请求。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Tomcat请求过程&quot;&gt;&lt;a href=&quot;#Tomcat请求过程&quot; class=&quot;headerlink&quot; title=&quot;Tomcat请求过程&quot;&gt;&lt;/a&gt;Tomcat请求过程&lt;/h2&gt;&lt;h3 id=&quot;几个部件：&quot;&gt;&lt;a href=&quot;#几个部件：&quot; class=&quot;he
      
    
    </summary>
    
      <category term="tomcat" scheme="https://www.lilhui.com/categories/tomcat/"/>
    
    
      <category term="tomcat" scheme="https://www.lilhui.com/tags/tomcat/"/>
    
      <category term="调优" scheme="https://www.lilhui.com/tags/%E8%B0%83%E4%BC%98/"/>
    
  </entry>
  
  <entry>
    <title>云原生下的Java虚拟机 GraalVM</title>
    <link href="https://www.lilhui.com/2022/10/27/java/jvm_tuning/tuning_2/"/>
    <id>https://www.lilhui.com/2022/10/27/java/jvm_tuning/tuning_2/</id>
    <published>2022-10-27T03:44:31.000Z</published>
    <updated>2022-10-27T07:08:59.961Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>java 的编译器<br>C1,C2<br>C1不进行优化，C2会进行优化。热点代码缓存,JIT等等。</p><p>C2 C++写的，太复杂，不维护，而且有bug<br>java语言一直在进步，C2没有办法维护，需要一种新的编译器来进行支持，所以有了GraalVM</p><ul><li><p>事实<br>JIT,性能优化、垃圾回收等代表的特性需要一段时间来达到最佳性能。<br>java是面向大规模、长时间的服务应而设计。</p></li><li><p>矛盾<br>  微服务时代对启动速度、达到高性能的时间提出了新的要求。</p></li></ul><h3 id="问题根源"><a href="#问题根源" class="headerlink" title="问题根源"></a>问题根源</h3><p>Java离不开虚拟机（JVM)</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p><strong>革命派：</strong> 直接而干掉Java和Java生态。（Golang的诞生）<br><strong>保守派：</strong> 保留原有主流Java生态和技术资产，朝着微服务、云原生环境靠拢（GraalVM)</p><h2 id="GraalVM的技术"><a href="#GraalVM的技术" class="headerlink" title="GraalVM的技术"></a>GraalVM的技术</h2><p><strong>AOT技术：</strong> ahead of time</p><p>编译成native代码花费时间太大，这部分时间无法节省，所以引入AOT，减少这部分时间。</p><h3 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h3><ul><li>C++<br>  微软的Stackless模式单台1000万个链接。<br>  腾讯微信团队：libco</li><li>Java<br>  JVM（Loom:fibers轻量级用户线程）<br>  基于JNI<br>  操控字节码</li></ul><h2 id="GraalVM介绍"><a href="#GraalVM介绍" class="headerlink" title="GraalVM介绍"></a>GraalVM介绍</h2><p>C2编译器比较缓和，GraalVM比较激进</p><p><img src="https://images.lilhui.com/a0c5bf2ee63b97dcd762ee4843e6a734" alt="图片"></p><p>JVMCI: JVM compile interface</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;java 的编译器&lt;br&gt;C1,C2&lt;br&gt;C1不进行优化，C2会进行优化。热点代码缓存,JIT等等。&lt;/p&gt;
&lt;p&gt;C2 C++写的，太复
      
    
    </summary>
    
      <category term="java" scheme="https://www.lilhui.com/categories/java/"/>
    
    
      <category term="GraalVM" scheme="https://www.lilhui.com/tags/GraalVM/"/>
    
  </entry>
  
  <entry>
    <title>JVM调优系列1:ZGC详解</title>
    <link href="https://www.lilhui.com/2022/10/26/java/jvm_tuning/tuning_1/"/>
    <id>https://www.lilhui.com/2022/10/26/java/jvm_tuning/tuning_1/</id>
    <published>2022-10-26T07:49:32.000Z</published>
    <updated>2022-10-27T02:38:19.283Z</updated>
    
    <content type="html"><![CDATA[<ul><li>逃逸分析</li><li>标量替换</li><li><p>栈上分配</p></li><li><p>锁消除</p></li><li>锁粗化</li></ul><h2 id="JIT"><a href="#JIT" class="headerlink" title="JIT"></a>JIT</h2><p>JVM 语言无关性<br>字节码执行</p><pre><code>- 解释执行- 即时编译 JIT</code></pre><p>JIT是编译成本地字节码。非java字节码，是机器直接运行的本地编码，可能是汇编等。</p><p><img src="https://images.lilhui.com/7e6500afac4a1919f2d8d780657aa187" alt="图片"></p><h3 id="编译器"><a href="#编译器" class="headerlink" title="编译器"></a>编译器</h3><p>C1 class -&gt; 本地编码（不做优化）<br>C2 性能优化</p><ul><li>热点探测技术<ul><li>方法内联<br>热点探测技术<br>方法体大小限制</li><li>栈上分配</li></ul></li></ul><p>C2比较难维护，Java 10 以后开发了新的Graal（java写的）</p><ul><li>分层编译</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;逃逸分析&lt;/li&gt;
&lt;li&gt;标量替换&lt;/li&gt;
&lt;li&gt;&lt;p&gt;栈上分配&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;锁消除&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;锁粗化&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;JIT&quot;&gt;&lt;a href=&quot;#JIT&quot; class=&quot;headerlink
      
    
    </summary>
    
      <category term="java" scheme="https://www.lilhui.com/categories/java/"/>
    
      <category term="jvm" scheme="https://www.lilhui.com/categories/java/jvm/"/>
    
    
      <category term="调优" scheme="https://www.lilhui.com/tags/%E8%B0%83%E4%BC%98/"/>
    
      <category term="jvm" scheme="https://www.lilhui.com/tags/jvm/"/>
    
      <category term="ZGC" scheme="https://www.lilhui.com/tags/ZGC/"/>
    
  </entry>
  
  <entry>
    <title>【深入理解Spring系列4】BeanDefinition</title>
    <link href="https://www.lilhui.com/2022/07/12/java/spring/spring_deep_4/"/>
    <id>https://www.lilhui.com/2022/07/12/java/spring/spring_deep_4/</id>
    <published>2022-07-12T07:31:17.000Z</published>
    <updated>2022-07-12T07:43:09.243Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h2><p>Spring Bean的 四种装配模式外，还有一种自动策略。</p><p>当只有一个 构造方法，并且构造方法里有参数。<br>会进行 aurowireConstructor(beanName, mdb, ctors, args)</p><ul><li>spring扫描不能直接new的方法</li></ul><p>@DependsOn</p><p>@Prototype 执行的时候new</p><p>所以需要先解析验证。</p><p>scan-parse（会变成BeaDefinition）-validate(info)-new(开始spring的生命周期)</p><p>可以这么理解：</p><p>beanDefinition之于Spring<br>相当于class之于java对象</p><ul><li>常量（BeanDefinition)<br>-<br>SCOPE_SINGLETON</li></ul><p>ROLE_APPLICATION</p><p>setParentName</p><p>//自动装配候选对象 ，被装配<br>setAutowireCandidate<br>//候选对象最高级<br>setPrimary</p><p>BeanDefinition所有属性都能找到与之匹配的 xml配置。</p><p>ac.getBean(XXX);是从DefaultSingletonBeanRegistry.singletonObjects.get(XXX)</p><ul><li>abstractApplicationContext</li></ul><p>abstractApplicationContext.refresh()</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//这里初始化对象。还未装配</span><br><span class="line">finishBeanFactoryInitialization(beanFactory);</span><br><span class="line"></span><br><span class="line">//这里装配。</span><br><span class="line">finishRefresh()</span><br></pre></td></tr></table></figure><ol><li>扫描</li><li>parse</li><li>validate</li><li>life  遍历map得到BeanDefinition实例化。</li></ol><h2 id="BeanDefinition"><a href="#BeanDefinition" class="headerlink" title="BeanDefinition"></a>BeanDefinition</h2><p>各方法说明：</p><p>setPrimary:<br>多个接口实现的时候，自动注入候选的时候排第一。</p><ul><li>关键父类<br>AbstractBeanDefinition</li></ul><p>ChildBeanDefinition,RootBeanDefinition Spring 2.5的时候用</p><p>GenericBeanDefinition<br>现在常用。</p><p>xml 配置里的<bean></bean>描述的就是 beanDefinition的属性。<br>spring容器会进行扫描。扫描后会根据bendefinition里描述的进行实例化。</p><p>abstract = true 必须要有 beanClass</p><ul><li>RootBeanDefinition</li></ul><p>减少不同 bean配置多种相同相同属性值的 工作量 abstract=true</p><p>parent = ‘xxx’</p><p>spring 2.5之前有这种写法。后面更方便了用扫描，用标签。</p><p>问题：RootBeanDefinition也有 setParentName()，为什么要多一个ChildBeanDefinition ?</p><p>RootBeanDefinition一般作为父出现，或者一般BD出现。但是不作为子BD出现。<br>为什么要这样规定？为什么设置Root的Parent要抛出异常？</p><p>合并BeanDefinition？</p><ul><li>AnnotatedBeanDefinitionReader</li></ul><p>作用：解析@Configuration 这标签会去扫描</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public AnnotationConfigApplicationContext() &#123;</span><br><span class="line">this.reader = new AnnotatedBeanDefinitionReader(this);</span><br><span class="line">this.scanner = new ClassPathBeanDefinitionScanner(this);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>beanReader = AnnotatedBeanDefinitionReader(this);<br>把 配置的AppConfig 变成 BeanDefinition</p><p>其他的 要完成扫描的时候去new 其他BD.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">this.reader = new AnnotatedBeanDefinitionReader(this);  这么写是为了后面能通过 context.register.registBean(标签) 来扩展自定义标签。</span><br></pre></td></tr></table></figure></p><p>注意这里是为了扩展，spring启动的时候并不是用这个scaner去扫描。<br>实际上用的是,在BeanDefinitionRegistry这个后置处理器。</p><p>ConfigutationClassPostProcessor.postProcessBanDefinitionRegistry(registry)</p><p>-&gt;<br>这里找到 registry里初始化的BeanDefinition，进行parse<br>ConfigurationClassParser.parse(Set<beandefinitionholder> candidates)<br>这个方法里会判断 参数是否实现了 AnnotatedBeanDefinition</beandefinitionholder></p><p>bd instanceof AnnotatedBeanDefinition</p><p>-</p><p>ConfigurationClassParser.processConfigurationClass</p><p>//这段很有意思，扫描结束后会将sourceClass设置为null。说明所有的BeanDefinition都扫描出来了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">do &#123;</span><br><span class="line">sourceClass = doProcessConfigurationClass(configClass, sourceClass);</span><br><span class="line">&#125;</span><br><span class="line">while (sourceClass != null);</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">protected final SourceClass doProcessConfigurationClass(ConfigurationClass configClass, SourceClass sourceClass)</span><br></pre></td></tr></table></figure><p>doProcessConfigurationClass<br>这里是实现。<br>实际识别了@Component  @ComponentScan @ImportSource 等标签。</p><p>然后在<br>ComponentScanAnnotationParser<br>类里的<br>public Set<beandefinitionholder> parse(AnnotationAttributes componentScan, final String declaringClass)</beandefinitionholder></p><p>进行实际的扫描，先new 出了<br>ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(this.registry,</p><p>再判断各种includerFilter excluderFilter<br>最后根据 标签配置的 包路径进行文件扫描。<br>从而扫描出Beandefinition 放到BeanDeinitionMap</p><p>小总结：<br>Beandefinition决定了spring 中Bean的各种特征。<br>class-beandefinition-springbean。<br>通过beandefinition spring定义了一套 spring bean的属性特征。</p><p>GenericBeanDefinition追加了setBeanClass</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前情提要&quot;&gt;&lt;a href=&quot;#前情提要&quot; class=&quot;headerlink&quot; title=&quot;前情提要&quot;&gt;&lt;/a&gt;前情提要&lt;/h2&gt;&lt;p&gt;Spring Bean的 四种装配模式外，还有一种自动策略。&lt;/p&gt;
&lt;p&gt;当只有一个 构造方法，并且构造方法里有参数。&lt;b
      
    
    </summary>
    
      <category term="spring" scheme="https://www.lilhui.com/categories/spring/"/>
    
    
      <category term="bean" scheme="https://www.lilhui.com/tags/bean/"/>
    
  </entry>
  
  <entry>
    <title>【rabbitMq学习1】MQ的基本概念</title>
    <link href="https://www.lilhui.com/2022/07/11/mq/rabbitmq_core_1/"/>
    <id>https://www.lilhui.com/2022/07/11/mq/rabbitmq_core_1/</id>
    <published>2022-07-11T07:00:32.000Z</published>
    <updated>2022-07-11T07:03:49.781Z</updated>
    
    <content type="html"><![CDATA[<p>##MQ的基本概念</p><p>MQ全称 Message Queue(消息队列)，是在消息的传输过程中保存消息的容器。多用于分布式系统之间进行通信。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;##MQ的基本概念&lt;/p&gt;
&lt;p&gt;MQ全称 Message Queue(消息队列)，是在消息的传输过程中保存消息的容器。多用于分布式系统之间进行通信。&lt;/p&gt;

      
    
    </summary>
    
      <category term="mq" scheme="https://www.lilhui.com/categories/mq/"/>
    
    
      <category term="rabbitMq" scheme="https://www.lilhui.com/tags/rabbitMq/"/>
    
  </entry>
  
  <entry>
    <title>【Redis学习7】开发规范和性能优化</title>
    <link href="https://www.lilhui.com/2022/07/06/redis/redis_core_7/"/>
    <id>https://www.lilhui.com/2022/07/06/redis/redis_core_7/</id>
    <published>2022-07-06T08:58:52.000Z</published>
    <updated>2022-07-06T09:24:34.085Z</updated>
    
    <content type="html"><![CDATA[<h2 id="键值设计"><a href="#键值设计" class="headerlink" title="键值设计"></a>键值设计</h2><h3 id="key名设计"><a href="#key名设计" class="headerlink" title="key名设计"></a>key名设计</h3><p>(1)【建议】: 可读性和可管理性<br>以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trade:order:<span class="number">1</span></span><br></pre></td></tr></table></figure><p>(2)【建议】：简洁性<br>保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">user:&#123;uid&#125;:friends:messages:&#123;mid&#125; 简化为 u:&#123;uid&#125;:fr:m:&#123;mid&#125;</span><br></pre></td></tr></table></figure><p>(3)【强制】：不要包含特殊字符<br>反例：包含空格、换行、单双引号以及其他转义字符</p><h3 id="value设计"><a href="#value设计" class="headerlink" title="value设计"></a>value设计</h3><p>(1)【强制】：拒绝bigkey(防止网卡流量、慢查询)<br>在Redis中，一个字符串最大512MB，一个二级数据结构（例如hash、list、set、zset）可以存储大约40亿个(2^32-1)个元素，但实际中如果下面两种情况，我就会认为它是bigkey。</p><ul><li>字符串类型：它的big体现在单个value值很大，一般认为超过10KB就是bigkey。</li><li>非字符串类型：哈希、列表、集合、有序集合，它们的big体现在元素个数太多。</li></ul><p>一般来说，string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。<br>反例：一个包含200万个元素的list。</p><p>非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞）</p><h3 id="bigkey的危害"><a href="#bigkey的危害" class="headerlink" title="bigkey的危害"></a>bigkey的危害</h3><ol><li>导致网络堵塞</li><li>导致redis阻塞<br>bigkey也就意味着每次获取要产生的网络流量较大，假设一个bigkey为1MB，客户端每秒访问量为1000，那么每秒产生1000MB的流量，对于普通的千兆网卡(按照字节算是128MB/s)的服务器来说简直是灭顶之灾，而且一般服务器会采用单机多实例的方式来部署，也就是说一个bigkey可能会对其他实例也造成影响，其后果不堪设想。</li><li>过期删除<br>有个bigkey，它安分守己（只执行简单的命令，例如hget、lpop、zscore等），但它设置了过期时间，当它过期后，会被删除，如果没有使用Redis 4.0的过期异步删除(lazyfree-lazy-expire yes)，就会存在阻塞Redis的可能性。</li></ol><h3 id="bigkey的产生"><a href="#bigkey的产生" class="headerlink" title="bigkey的产生"></a>bigkey的产生</h3><p>一般来说，bigkey的产生都是由于程序设计不当，或者对于数据规模预料不清楚造成的，来看几个例子：<br>(1) 社交类：粉丝列表，如果某些明星或者大v不精心设计下，必是bigkey。<br>(2) 统计类：例如按天存储某项功能或者网站的用户集合，除非没几个人用，否则必是bigkey。<br>(3) 缓存类：将数据从数据库load出来序列化放到Redis里，这个方式非常常用，但有两个地方需要注意，第一，是不是有必要把所有字段都缓存；第二，有没有相关关联的数据，有的同学为了图方便把相关数据都存一个key下，产生bigkey。</p><h3 id="如何优化bigkey"><a href="#如何优化bigkey" class="headerlink" title="如何优化bigkey"></a>如何优化bigkey</h3><ol><li>拆<br>big list： list1、list2、…listN<br>big hash：可以讲数据分段存储，比如一个大的key，假设存了1百万的用户数据，可以拆分成200个key，每个key下面存放5000个用户数据</li><li>如果bigkey不可避免，也要思考一下要不要每次把所有元素都取出来(例如有时候仅仅需要hmget，而不是hgetall)，删除也是一样，尽量使用优雅的方式来处理。</li></ol><p>(2)【推荐】：选择适合的数据类型。<br>例如：实体类型(要合理控制和使用数据结构，但也要注意节省内存和性能之间的平衡)<br>反例：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set user:<span class="number">1</span>:name tom</span><br><span class="line">set user:<span class="number">1</span>:age <span class="number">19</span></span><br><span class="line">set user:<span class="number">1</span>:favor football</span><br></pre></td></tr></table></figure></p><p>正例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hmset user:<span class="number">1</span> name tom age <span class="number">19</span> favor football</span><br></pre></td></tr></table></figure><p>3.【推荐】：控制key的生命周期，redis不是垃圾桶。<br>建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)。</p><h2 id="命令使用"><a href="#命令使用" class="headerlink" title="命令使用"></a>命令使用</h2><p>1.【推荐】 O(N)命令关注N的数量<br>例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。</p><p>2.【推荐】：禁用命令<br>禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。</p><p>3.【推荐】合理使用select<br>redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。</p><p>4.【推荐】使用批量操作提高效率<br>原生命令：例如mget、mset。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原生命令：例如mget、mset。</span><br><span class="line">非原生命令：可以使用pipeline提高效率。</span><br></pre></td></tr></table></figure><p>但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。<br>注意两者不同：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 原生命令是原子操作，pipeline是非原子操作。</span><br><span class="line">2. pipeline可以打包不同的命令，原生命令做不到</span><br><span class="line">3. pipeline需要客户端和服务端同时支持。</span><br></pre></td></tr></table></figure><p>5.【建议】Redis事务功能较弱，不建议过多使用，可以用lua替代</p><h2 id="客户端使用"><a href="#客户端使用" class="headerlink" title="客户端使用"></a>客户端使用</h2><p>1.【推荐】<br>避免多个应用使用一个Redis实例<br>正例：不相干的业务拆分，公共数据做服务化。</p><p>2.【推荐】<br>使用带有连接池的数据库，可以有效控制连接，同时提高效率，标准使用方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">JedisPoolConfig jedisPoolConfig = <span class="keyword">new</span> JedisPoolConfig();</span><br><span class="line">jedisPoolConfig.setMaxTotal(<span class="number">5</span>);</span><br><span class="line">jedisPoolConfig.setMaxIdle(<span class="number">2</span>);</span><br><span class="line">jedisPoolConfig.setTestOnBorrow(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">JedisPool jedisPool = <span class="keyword">new</span> JedisPool(jedisPoolConfig, <span class="string">"192.168.0.60"</span>, <span class="number">6379</span>, <span class="number">3000</span>, <span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line">Jedis jedis = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    jedis = jedisPool.getResource();</span><br><span class="line">    <span class="comment">//具体的命令</span></span><br><span class="line">    jedis.executeCommand()</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    logger.error(<span class="string">"op key &#123;&#125; error: "</span> + e.getMessage(), key, e);</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="comment">//注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。</span></span><br><span class="line">    <span class="keyword">if</span> (jedis != <span class="keyword">null</span>) </span><br><span class="line">        jedis.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>连接池参数含义：</p><p><img src="https://images.lilhui.com/b944f308e024d4748649b8989b92e793" alt="图片"></p><h2 id="优化建议"><a href="#优化建议" class="headerlink" title="优化建议"></a>优化建议</h2><p>1）maxTotal：最大连接数，早期的版本叫maxActive<br>实际上这个是一个很难回答的问题，考虑的因素比较多：</p><p>业务希望Redis并发量<br>客户端执行命令时间<br>Redis资源：例如 nodes(例如应用个数) * maxTotal 是不能超过redis的最大连接数maxclients。<br>资源开销：例如虽然希望控制空闲连接(连接池此刻可马上使用的连接)，但是不希望因为连接池的频繁释放创建连接造成不必靠开销。</p><p>以一个例子说明，假设:<br>一次命令时间（borrow|return resource + Jedis执行命令(含网络) ）的平均耗时约为1ms，一个连接的QPS大约是1000<br>业务期望的QPS是50000<br>那么理论上需要的资源池大小是50000 / 1000 = 50个。但事实上这是个理论值，还要考虑到要比理论值预留一些资源，通常来讲maxTotal可以比理论值大一些。</p><p>但这个值不是越大越好，一方面连接太多占用客户端和服务端资源，另一方面对于Redis这种高QPS的服务器，一个大命令的阻塞即使设置再大资源池仍然会无济于事。</p><p>2）maxIdle和minIdle</p><p>maxIdle实际上才是业务需要的最大连接数，maxTotal是为了给出余量，所以maxIdle不要设置过小，否则会有new Jedis(新连接)开销。<br>连接池的最佳性能是maxTotal = maxIdle，这样就避免连接池伸缩带来的性能干扰。但是如果并发量不大或者maxTotal设置过高，会导致不必要的连接资源浪费。一般推荐maxIdle可以设置为按上面的业务期望QPS计算出来的理论连接数，maxTotal可以再放大一倍。</p><p>minIdle（最小空闲连接数），与其说是最小空闲连接数，不如说是”至少需要保持的空闲连接数”，在使用连接的过程中，如果连接数超过了minIdle，那么继续建立连接，如果超过了maxIdle，当超过的连接执行完业务后会慢慢被移出连接池释放掉。<br>如果系统启动完马上就会有很多的请求过来，那么可以给redis连接池做预热，比如快速的创建一些redis连接，执行简单命令，类似ping()，快速的将连接池里的空闲连接提升到minIdle的数量。</p><p>连接池预热示例代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Jedis&gt; minIdleJedisList = <span class="keyword">new</span> ArrayList&lt;Jedis&gt;(jedisPoolConfig.getMinIdle());</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; jedisPoolConfig.getMinIdle(); i++) &#123;</span><br><span class="line">    Jedis jedis = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        jedis = pool.getResource();</span><br><span class="line">        minIdleJedisList.add(jedis);</span><br><span class="line">        jedis.ping();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        logger.error(e.getMessage(), e);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">//注意，这里不能马上close将连接还回连接池，否则最后连接池里只会建立1个连接。。</span></span><br><span class="line">        <span class="comment">//jedis.close();</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//统一将预热的连接还回连接池</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; jedisPoolConfig.getMinIdle(); i++) &#123;</span><br><span class="line">    Jedis jedis = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        jedis = minIdleJedisList.get(i);</span><br><span class="line">        <span class="comment">//将连接归还回连接池</span></span><br><span class="line">        jedis.close();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        logger.error(e.getMessage(), e);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>总之，要根据实际系统的QPS和调用redis客户端的规模整体评估每个节点所使用的连接池大小。</p><p>3.【建议】<br>高并发下建议客户端添加熔断功能(例如sentinel、hystrix)</p><p>4.【推荐】<br>设置合理的密码，如有必要可以使用SSL加密访问</p><p>5.【建议】<br>Redis对于过期键有三种清除策略：</p><ol><li>被动删除：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key</li><li>主动删除：由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期(默认每100ms)主动淘汰一批已过期的key，这里的一批只是部分过期key，所以可能会出现部分key已经过期但还没有被清理掉的情况，导致内存并没有被释放</li><li>当前已用内存超过maxmemory限定时，触发主动清理策略</li></ol><p>主动清理策略在Redis 4.0 之前一共实现了 6 种内存淘汰策略，在 4.0 之后，又增加了 2 种策略，总共8种：<br>a) 针对设置了过期时间的key做处理：</p><ol><li>volatile-ttl：在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。</li><li>volatile-random：就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。</li><li>volatile-lru：会使用 LRU 算法筛选设置了过期时间的键值对删除。</li><li>volatile-lfu：会使用 LFU 算法筛选设置了过期时间的键值对删除。</li></ol><p>b) 针对所有的key做处理：</p><ol><li>allkeys-random：从所有键值对中随机选择并删除数据。</li><li>allkeys-lru：使用 LRU 算法在所有数据中进行筛选删除。</li><li>allkeys-lfu：使用 LFU 算法在所有数据中进行筛选删除。</li></ol><p>c) 不处理：<br>noeviction：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息”(error) OOM command not allowed when used memory”，此时Redis只响应读操作。</p><p><strong>LRU 算法（Least Recently Used，最近最少使用）</strong><br>淘汰很久没被访问过的数据，以最近一次访问时间作为参考。</p><p><strong>LFU 算法（Least Frequently Used，最不经常使用）</strong><br>淘汰最近一段时间被访问次数最少的数据，以次数作为参考。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;键值设计&quot;&gt;&lt;a href=&quot;#键值设计&quot; class=&quot;headerlink&quot; title=&quot;键值设计&quot;&gt;&lt;/a&gt;键值设计&lt;/h2&gt;&lt;h3 id=&quot;key名设计&quot;&gt;&lt;a href=&quot;#key名设计&quot; class=&quot;headerlink&quot; title=&quot;key名设
      
    
    </summary>
    
      <category term="redis" scheme="https://www.lilhui.com/categories/redis/"/>
    
    
      <category term="性能优化" scheme="https://www.lilhui.com/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    
      <category term="redis" scheme="https://www.lilhui.com/tags/redis/"/>
    
      <category term="开发规范" scheme="https://www.lilhui.com/tags/%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/"/>
    
  </entry>
  
</feed>
