<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Littlehui&#39;s Notes</title>
  
  <subtitle>天地那么大，世界那么辽阔。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.lilhui.com/"/>
  <updated>2022-12-09T08:03:47.981Z</updated>
  <id>https://www.lilhui.com/</id>
  
  <author>
    <name>Littlehui</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>The Tail At Scale 论文总结</title>
    <link href="https://www.lilhui.com/2022/12/09/paper/paper_1/"/>
    <id>https://www.lilhui.com/2022/12/09/paper/paper_1/</id>
    <published>2022-12-09T07:55:48.000Z</published>
    <updated>2022-12-09T08:03:47.981Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-问题"><a href="#1-问题" class="headerlink" title="1. 问题"></a>1. 问题</h1><p>这是Google大神Jeff Dean在2013年的时候发表的一篇文章，主要是为分布式系统中一个复杂而重要的问题提供了一整套的解决方案，这个问题就是：</p><p><strong>当用户的请求依赖大规模分布式系统来协作完成时，如何保证请求的响应时间？</strong></p><h1 id="2-为什么"><a href="#2-为什么" class="headerlink" title="2. 为什么"></a>2. 为什么</h1><p>首先，为什么要保证用户请求的响应时间？因为对于某些使用场景来说，只有当响应时间控制在百毫秒以内，用户才能感觉到系统是流畅的，例如Google的搜索框会随着用户的输入不断地提示用户可能之后输入的内容，试想如果这个提示需要一秒的时间才能出现？那用户体验是会大打折扣的。</p><p>其次，什么是大规模分布式系统？</p><p>举例来说，当用户打开亚马逊购物网站的一个商品信息页时，可能需要从底层数百个子服务来获取信息，而这些子服务还有它们依赖的更基础的服务，这意味着一个用户的请求可能需要数千台服务器协同工作才能完成。</p><p>在这样的集群规模下，即使有极少数机器请求响应时间较长，也有很大的概率导致用户请求的响应时间变长，如下图所示：</p><p><img src="https://images.lilhui.com/7e5a78403c311fc037788368428d92b2" alt="图片"></p><blockquote><p>当用户请求需要100台服务器来协同完成时，假设只有 1% 的调用延迟较大，那用户请求受影响导致响应时间较长的概率为0.63（1 - 0.99 <strong> 100）<br>当用户的请求需要2000台服务器来协同完成时，假设只有 0.01% 的调用延迟较大，那用户请求受影响导致响应时间较长的概率为0.18（1 - 0.9999 </strong> 2000），相当于每5个用户就有一个体验不佳</p></blockquote><p>在实际生产环境中，有多种原因导致服务调用的响应时间变长，如：</p><ol><li>在一台机器上可能同时部署了多个服务，这些服务可能会对于如CPU，内存，网络等多种资源进行竞争，导致某个服务的响应时间变长；</li><li>某些后台运行的线程（假设每个小时运行一次），可能会在运行时占用一些系统资源（如磁盘IO）导致这台机器上的服务响应时间变长；</li><li>在分布式环境下， 当多个服务对共享资源（如分布式文件系统等）产生竞争时，也会导致服务的响应时间变长；</li><li>其他的原因还包括请求排队、垃圾回收、日志压缩等；</li></ol><p>Jeff Dean的想法是，既然可以在不可靠的服务器上实现可靠的分布式存储系统，那利用同样的想法，我们也可以在响应时间有突刺的服务器集群上实现响应时间快速且一致的分布式集群，他把这样的系统叫做Tail-Tolerant。</p><h1 id="3-怎么做"><a href="#3-怎么做" class="headerlink" title="3. 怎么做"></a>3. 怎么做</h1><h2 id="3-1-单个模块的响应时间"><a href="#3-1-单个模块的响应时间" class="headerlink" title="3.1 单个模块的响应时间"></a>3.1 单个模块的响应时间</h2><p>这一部分讨论的是如何实现一个模块对外的每一次响应的时间是快速一致的，这部分不是本文的重点，因此简单带过。</p><p>作者列举了一些基本的方法，如：</p><ol><li>不要在底层设置太长的任务队列，而由上层基于任务的优先级进行动态的下发。例如Google的集群文件系统，在磁盘的IO队列上只有维护一个很短的队列，当应用层有优先级更高的任务的时候，可以及时将这些任务下发，以保证这些高优先级任务的快速响应；</li><li>将需要长时间运行的任务拆成多个短时间运行的任务。这个跟上面做法的逻辑一样，就是为了防止一个任务长时间占用系统资源而导致其他任务响应时间变长；</li><li>控制好定时任务和后台运行的任务。具体做法有，将后台的大任务拆分成一系列的小任务，在后台任务运行的时候首先确认系统的负载，如果负载太高，则延迟运行后台任务等。</li></ol><p>尽管我们可以通过各种做法让一个模块的响应时间变得更快更均匀，然而由于大规模分布式系统的复杂性，实际上根本无法做到完全消除单个模块的响应时间出现突刺，因此接下来讨论在更大的层面如何解决这个问题。</p><h2 id="3-2-服务间调用控制"><a href="#3-2-服务间调用控制" class="headerlink" title="3.2. 服务间调用控制"></a>3.2. 服务间调用控制</h2><p>这一部分讨论在一个服务调用另一个服务时，可以通过什么技巧来解决响应时间出现突刺的问题。</p><p>首先，分布式系统为了解决数据可靠性的问题，通常将数据复制到多台服务器上，同时为了实现服务的高可用，又会有多个服务器提供同样的功能，防止部分服务器出现故障。</p><p>为了解决响应时间出现突刺，调用者需要将请求“同时”发送给多台服务器，并在收到最快的响应之后，马上终止其他服务器的处理（或将其他服务器返回的结果直接丢弃）。采用这种方法，可以大大降低某个调用出现突刺的情况，因为所有的服务器都出现突刺的概率会大大降低。同时我们也可以看到，这样会让整个系统的请求数量翻两倍或三倍。</p><p>因此，论文给出的做法是：</p><ol><li>客户端首先发送一个请求给服务端，并等待服务端返回的响应；</li><li>如果客户端在一定的时间内没有收到服务端的响应，则马上发送同样的请求到另一台（或多台）服务器；</li><li>客户端等待第一个响应到达之后，终止其他请求的处理；</li></ol><p>上面“一定的时间”定义为：95%的请求的响应时间。</p><p>Google的测试数据表明，采用这种方法，可以仅用2%的额外请求，将系统99.9%的请求的响应时间从1800ms降低到74ms：</p><blockquote><p>For example, in a Google benchmark that reads the values for 1,000 keys stored in a BigTable table distributed across 100 different servers, sending a hedging request after a 10ms delay reduces the 99.9th-percentile latency for retrieving all 1,000 values from 1,800ms to 74ms while sending just 2% more requests.</p></blockquote><p>以上这种做法被称为 Hedged Request，下面介绍另一种解决问题的办法，称为 Tied Request。</p><p>分布式系统中存在一种情况，即请求排队，特别地，可能出现请求的排队时间比处理时间更长的情况。</p><p>当一个上游系统向下游系统分发请求时，一个比较合理的做法是将请求分发给任务队列较短，负载较轻的服务器。</p><p>Google推荐的做法是，上游系统同时发送两个一样的请求给下游多个服务器，当下游服务器处理完成后，通知其他服务器不用再处理该请求。为了防止由于任务队列为空而导致的所有服务器同时处理任务的情况，上游系统需要在发给下游多个系统的时候引入一个延迟，该延迟时间要足够第一个系统处理完任务并通知其他系统。</p><blockquote><p>此处有一个重要的思考：为什么上游系统不再发送请求给下游时首先进行探测，查看各个下游服务器的任务队列长度，然后再将请求发送给任务队列最短的服务呢？</p><p>原因有三：</p><ol><li>探测和发送请求之间有一段时间间隔，即在探测之后再发送请求时，各个服务器的负载已经发生了变化</li><li>如果很多客户端同时发现某个服务器负载较低，则可能同时将请求发给该服务器，导致该服务器瞬间过热</li><li>仅通过队列长度来估计处理时间未必准确，即任务队列端不一定真的负载低</li></ol></blockquote><p>以上两个技巧不仅仅可以用于简单的数据查询服务，例如基于Reed-Solomon编码的存储系统，第一个请求可以去某台服务器上查询数据，如果在一定时间内数据未查到，则可以向其他服务器发起数据重建的任务并得到期望的数据。</p><h2 id="3-3-架构上的权衡"><a href="#3-3-架构上的权衡" class="headerlink" title="3.3. 架构上的权衡"></a>3.3. 架构上的权衡</h2><p>这一部分提出了一些在系统设计层面，为了解决长尾响应时间做的权衡：</p><ol><li>更细粒度的Partition：为了解决系统负载不均衡，Google会将任务拆解成比机器数量多很多的Partition，这样，即使任务的复杂程度不同，机器的处理能力不同会导致各个机器的负载不均衡，这种不均衡也会大大降低。这就会带来系统的响应时间的一致性；<br>举例，如果一个系统有5台机器，将ABCDE 5个任务分给这5台机器来做，如果A任务很复杂，那分到A的机器处理时间就会变得很长。然而，如果将ABCDE 这5个任务继续拆分，变成 A1 - A10, B1-B10, …, D1-D10，再将这些任务分配到5台机器上去，那各台机器的负载就会平均很多（除非A1-A10全部分配到同一台机器上）</li><li>对于热点的数据进行复制：如果某个新闻事件导致某个数据的访问量激增，则可以将该数据复制更多份，来降低这个热点数据的访问响应时间</li><li>将响应时间长的服务器暂时屏蔽：上游系统要实时监控所有下游服务器的响应时间，如果某台服务器的响应时间明显超过其他，则可以暂时将该服务器屏蔽（不再向这台服务器上发送请求），以提高整个系统的响应速度</li><li>某些情况不用追求完美：例如对于网页搜索服务，如果底层的某些系统出现故障，上层未必要等所有的响应全都返回，而是等待一段时间后，基于已经获得的数据为用户进行展示即可：good enough is better than high latency</li></ol><h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h1><p>这篇文章的要点总结完成，给我们的收获就是如果基于不确定的系统来实现确定的服务，本文的核心思想是</p><p>“A simple way to curb latency variability is to issue the same request to multiple replicas and use the results from whichever replica responds first.”</p><p>这个方法看似简单，然而在真正落地时还是会有很多的细节需要去权衡，大家可以通过读论文来学习Google是如何对各个细节进行权衡的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-问题&quot;&gt;&lt;a href=&quot;#1-问题&quot; class=&quot;headerlink&quot; title=&quot;1. 问题&quot;&gt;&lt;/a&gt;1. 问题&lt;/h1&gt;&lt;p&gt;这是Google大神Jeff Dean在2013年的时候发表的一篇文章，主要是为分布式系统中一个复杂而重要的问题提供了一
      
    
    </summary>
    
      <category term="paper" scheme="https://www.lilhui.com/categories/paper/"/>
    
    
      <category term="scale" scheme="https://www.lilhui.com/tags/scale/"/>
    
      <category term="tail" scheme="https://www.lilhui.com/tags/tail/"/>
    
  </entry>
  
  <entry>
    <title>【Mysql深入理解系列9】Mysql高可用</title>
    <link href="https://www.lilhui.com/2022/12/07/mysql/mysql_deep_9/"/>
    <id>https://www.lilhui.com/2022/12/07/mysql/mysql_deep_9/</id>
    <published>2022-12-07T08:41:47.000Z</published>
    <updated>2022-12-07T09:25:46.454Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、MySQL高可用集群介绍"><a href="#一、MySQL高可用集群介绍" class="headerlink" title="一、MySQL高可用集群介绍"></a>一、MySQL高可用集群介绍</h1><h2 id="1、数据库主从架构与分库分表"><a href="#1、数据库主从架构与分库分表" class="headerlink" title="1、数据库主从架构与分库分表"></a>1、数据库主从架构与分库分表</h2><p>随着现在互联网的应用越来越大，数据库会频繁的成为整个应用的性能瓶颈。而我们经常使用的MySQL数据库，也会不断面临数据量太大、数据访问太频繁、数据读写速度太快等一系列的问题。所以，我们需要设计复杂的应用架构来保护孱弱的数据库，例如添加Redis缓存，增加MQ进行流量削峰等等。但是，数据库本身如果不能得到提升，这就相当于是水桶理论中的最短板。</p><p>而要提升数据库的性能，一种思路，当然是对数据库本身进行优化，例如对MySQL进行优化配置，或者干脆换成ClickHouse这一类的针对大数据的产品。另一方面就是跟微服务架构的思路一样，从单体架构升级到集群架构，这样才能真正全方位解放数据库的性能瓶颈。而我们后续要学习的分库分表就是一种非常常见的数据库集群架构管理方案。</p><p>但是就像微服务架构并不是简单的将服务从单机升级为就能一样，分库分表也并不只是字面意义上的将数据分到多个库或者多个表这么简单，他也是基于数据库产品的一系列分布式解决方案。在不同的应用场景下，针对不同的数据库产品，分库分表也有不同的落地方式。而我们后续，会以最为常见的MySQL数据库以及ShardingSphere框架来了解分库分表要如何进行。</p><h2 id="2、MySQL主从同步原理"><a href="#2、MySQL主从同步原理" class="headerlink" title="2、MySQL主从同步原理"></a>2、MySQL主从同步原理</h2><p>既然要解决MySQL数据库的分布式集群化问题，那就不能不先了解MySQL自身提供的主从同步原理。这是构建MySQL集群的基础，也是后续进行分库分表的基础，更是MySQL进行生产环境部署的基础。</p><p>其实数据库的主从同步，就是为了要保证多个数据库之间的数据保持一致。最简单的方式就是使用数据库的导入导出工具，定时将主库的数据导出，再导入到从库当中。这是一种很常见，也很简单易行的数据库集群方式。也有很多的工具帮助我们来做这些事情。但是这种方式进行数据同步的实时性比较差。</p><p>而如果要保证数据能够实时同步，对于MySQL，通常就要用到他自身提供的一套通过Binlog日志在多个MySQL服务之间进行同步的集群方案。基于这种集群方案，一方面可以提高数据的安全性，另外也可以以此为基础，提供读写分离、故障转移等其他高级的功能。</p><p><img src="https://images.lilhui.com/06521780b407e1c83cf87e94633d3da6" alt="图片"></p><p>即在主库上打开Binlog日志，记录对数据的每一步操作。然后在从库上打开RelayLog日志，用来记录跟主库一样的Binlog日志，并将RelayLog中的操作日志在自己数据库中进行重演。这样就能够更加实时的保证主库与从库的数据一致。</p><blockquote><p>MySQL的Binlog默认是不打开的。</p></blockquote><p>他的实现过程是在从库上启动一系列IO线程，负责与主库建立TCP连接，请求主库在写入Binlog日志时，也往从库传输一份。这时，主库上会有一个IO Dump线程，负责将Binlog日志通过这些TCP连接传输给从库的IO线程。而从库为了保证日志接收的稳定性，并不会立即重演Binlog数据操作，而是先将接收到的Binlog日志写入到自己的RelayLog日志当中。然后再异步的重演RelayLog中的数据操作。</p><p>MySQL的BinLog日志能够比较实时的记录主库上的所有日志操作，因此他也被很多其他工具用来实时监控MySQL的数据变化。例如Canal框架，可以模拟一个slave节点，同步MySQL的Binlog，然后将具体的数据操作按照定制的逻辑进行转发。例如转发到Redis实现缓存一致，转发到Kafka实现数据实时流转等。而ClickHouse也支持将自己模拟成一个MySQL的从节点，接收MySQL的Binlog日志，实时同步MySQL的数据。<code>这个功能目前还在实验阶段。</code></p><h1 id="二、动手搭建MySQL主从集群"><a href="#二、动手搭建MySQL主从集群" class="headerlink" title="二、动手搭建MySQL主从集群"></a>二、动手搭建MySQL主从集群</h1><h2 id="1、基础环境搭建"><a href="#1、基础环境搭建" class="headerlink" title="1、基础环境搭建"></a>1、基础环境搭建</h2><p>以下实验准备两台服务器，来搭建一个MySQL的主从集群。均安装CentOS7操作系统。 192.168.232.128将作为MySQL主节点，192.168.232.129将作为MySQL的从节点。</p><p>然后在两台服务器上均安装MySQL服务，MySQL版本采用mysql-8.0.20版本。</p><h2 id="2、安装MySQL服务"><a href="#2、安装MySQL服务" class="headerlink" title="2、安装MySQL服务"></a>2、安装MySQL服务</h2><p>这里强调下，我们下面的示例是带大家在Linux上搭建MySQL服务。但是在Linux上安装MySQL经常会遇到各种各样的环境问题，这些环境问题大都只能通过百度加经验的方式来解决。大家根据自己的实际情况，如果在Linux上搭建MySQL有困难的话，可以改为用Windows来安装MySQL。Windows上安装MySQL会简单很多，并且也不影响我们后续ShardingSphere的学习。</p><h3 id="1》初始化MySQL"><a href="#1》初始化MySQL" class="headerlink" title="1》初始化MySQL"></a>1》初始化MySQL</h3><p>MySQL的安装有很多种方式，具体可以参考官网手册：<a href="https://dev.mysql.com/doc/refman/8.0/en/binary-installation.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/8.0/en/binary-installation.html</a></p><p>我们这里采用对系统环境依赖最低，出问题的可能性最小的tar包方式来安装。</p><p>上传mysql压缩包到worker2机器的root用户工作目录/root下，然后按照下面的指令，解压安装mysql</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">groupadd mysql</span><br><span class="line">useradd -r -g mysql -s /bin/false mysql  #这里是创建一个mysql用户用于承载mysql服务，但是不需要登录权限。</span><br><span class="line">tar -zxvf mysql-8.0.20-el7-x86_64.tar.gz #解压</span><br><span class="line">ln -s mysql-8.0.20-el7-x86_64 mysql #建立软链接</span><br><span class="line">cd mysql</span><br><span class="line">mkdir mysql-files</span><br><span class="line">chown mysql:mysql mysql-files</span><br><span class="line">chmod 750 mysql-files</span><br><span class="line">bin/mysqld --initialize --user=mysql #初始化mysql数据文件 注意点1</span><br><span class="line">bin/mysql_ssl_rsa_setup</span><br><span class="line">bin/mysqld_safe --user=mysql </span><br><span class="line"></span><br><span class="line">cp support-files/mysql.server /etc/init.d/mysql.server</span><br></pre></td></tr></table></figure><blockquote><p> <strong>注意点：</strong></p><p> 1、初始化过程中会初始化一些mysql的数据文件，经常会出现一些文件或者文件夹权限不足的问题。如果有文件权限不足的问题，需要根据他的报错信息，创建对应的文件或者文件夹，并配置对应的文件权限。</p><p> 2、初始化过程如果正常完成，日志中会打印出一个root用户的默认密码。这个密码需要记录下来。</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;  2020-12-10T06:05:28.948043Z 6 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: P6kigsT6Lg&gt;=</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><h3 id="2》启动mysql"><a href="#2》启动mysql" class="headerlink" title="2》启动mysql"></a>2》启动mysql</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/mysqld --user=mysql</span><br></pre></td></tr></table></figure><blockquote><p> <strong>注意点：</strong></p><p> 1、这个启动过程会独占当前命令行窗口，如果要后台执行可以在后面添加一个 &amp;。但是一般第一次启动mysql服务时，经常会出现一些错误，所以建议用独占窗口的模式跟踪下日志。</p><p> Linux上安装软件经常会出现各种各样的环境问题，很难全部概括。大部分的问题，需要查百度，根据别人的经验来修改。如果安装有困难的同学，可以改为在Windows上安装MySQL，整个过程会简单很多，不会影响后续ShardingSpehre的学习。</p></blockquote><p>3、连接MySQL</p><p>MySQL服务启动完成后，默认是只能从本机登录，远程是无法访问的。所以需要用root用户登录下，配置远程访问的权限。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /root/mysql</span><br><span class="line">bin/mysql -uroot -p #然后用之前记录的默认密码登录</span><br></pre></td></tr></table></figure><blockquote><p> <strong>注意点：</strong></p><p> 1、如果有同学遇到  <strong>ERROR 2002 (HY000): Can’t connect to local MySQL server through socket ‘/tmp/mysql.sock’ (2)</strong>  这个报错信息，可以参照下面的配置，修改下/etc/my.cnf配置文件，来配置下socket连接文件的地址。主要是下面client部分。</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&gt;  [mysqld]</span><br><span class="line">&gt;  datadir=/var/lib/mysql</span><br><span class="line">&gt;  socket=/var/lib/mysql/mysql.sock</span><br><span class="line">&gt;  user=mysql</span><br><span class="line">&gt;  # Disabling symbolic-links is recommended to prevent assorted security risks</span><br><span class="line">&gt;  symbolic-links=0</span><br><span class="line">&gt;  # Settings user and group are ignored when systemd is used.</span><br><span class="line">&gt;  # If you need to run mysqld under a different user or group,</span><br><span class="line">&gt;  # customize your systemd unit file for mariadb according to the</span><br><span class="line">&gt;  # instructions in http://fedoraproject.org/wiki/Systemd</span><br><span class="line">&gt;  </span><br><span class="line">&gt;  [mysqld_safe]</span><br><span class="line">&gt;  log-error=/var/log/mariadb/mariadb.log</span><br><span class="line">&gt;  pid-file=/var/run/mariadb/mariadb.pid</span><br><span class="line">&gt;  </span><br><span class="line">&gt;  #</span><br><span class="line">&gt;  # include all files from the config directory</span><br><span class="line">&gt;  #</span><br><span class="line">&gt;  !includedir /etc/my.cnf.d</span><br><span class="line">&gt;  </span><br><span class="line">&gt;  [client]</span><br><span class="line">&gt;  port=3306</span><br><span class="line">&gt;  socket=/var/lib/mysql/mysql.sock</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>登录进去后，需要配置远程登录权限：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">user</span> <span class="string">'root'</span>@<span class="string">'localhost'</span> <span class="keyword">identified</span> <span class="keyword">by</span> <span class="string">'123456'</span>; <span class="comment">#修改root用户的密码</span></span><br><span class="line"><span class="keyword">use</span> mysql;</span><br><span class="line"><span class="keyword">update</span> <span class="keyword">user</span> <span class="keyword">set</span> host=<span class="string">'%'</span> <span class="keyword">where</span> <span class="keyword">user</span>=<span class="string">'root'</span>;</span><br><span class="line"><span class="keyword">flush</span> <span class="keyword">privileges</span>;</span><br></pre></td></tr></table></figure><p>这样，Linux机器上的MySQL服务就搭建完成了。可以使用navicat等连接工具远程访问MySQL服务了。</p><blockquote><p>然后如果有同学安装MySQL确实有问题的话，推荐大家可以使用宝塔面板。<a href="https://www.bt.cn/" target="_blank" rel="noopener">https://www.bt.cn/</a> 。使用这个工具可以图形化安装以及管理MySQL，非常方便。</p><p>另外，对于熟悉Docker和K8s的同学，可以用这些虚拟化的方式来搭建，也非常简单高效。</p></blockquote><p>这里需要注意下的是，搭建主从集群的多个服务，有两个必要的条件。</p><p>1、MySQL版本必须一致。</p><p>2、集群中各个服务器的时间需要同步。</p><h2 id="3、搭建主从集群"><a href="#3、搭建主从集群" class="headerlink" title="3、搭建主从集群"></a>3、搭建主从集群</h2><p>接下来在这两个MySQL服务基础上，搭建一个主从集群。</p><h3 id="1》配置master主服务"><a href="#1》配置master主服务" class="headerlink" title="1》配置master主服务"></a>1》配置master主服务</h3><p>首先，配置主节点的mysql配置文件： /etc/my.cnf(没有的话就手动创建一个)</p><p>这一步需要对master进行配置，主要是需要打开binlog日志，以及指定severId。我们打开MySQL主服务的my.cnf文件，在文件中一行server-id以及一个关闭域名解析的配置。然后重启服务。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[mysqld]</span></span><br><span class="line"><span class="attr">server-id</span>=<span class="number">47</span></span><br><span class="line"><span class="comment">#开启binlog</span></span><br><span class="line"><span class="attr">log_bin</span>=master-bin</span><br><span class="line"><span class="attr">log_bin-index</span>=master-bin.index</span><br><span class="line">skip-name-resolve</span><br><span class="line"><span class="comment"># 设置连接端口</span></span><br><span class="line"><span class="attr">port</span>=<span class="number">3306</span></span><br><span class="line"><span class="comment"># 设置mysql的安装目录</span></span><br><span class="line"><span class="attr">basedir</span>=/usr/local/mysql</span><br><span class="line"><span class="comment"># 设置mysql数据库的数据的存放目录</span></span><br><span class="line"><span class="attr">datadir</span>=/usr/local/mysql/mysql-files</span><br><span class="line"><span class="comment"># 允许最大连接数</span></span><br><span class="line"><span class="attr">max_connections</span>=<span class="number">200</span></span><br><span class="line"><span class="comment"># 允许连接失败的次数。</span></span><br><span class="line"><span class="attr">max_connect_errors</span>=<span class="number">10</span></span><br><span class="line"><span class="comment"># 服务端使用的字符集默认为UTF8</span></span><br><span class="line"><span class="attr">character-set-server</span>=utf8</span><br><span class="line"><span class="comment"># 创建新表时将使用的默认存储引擎</span></span><br><span class="line"><span class="attr">default-storage-engine</span>=INNODB</span><br><span class="line"><span class="comment"># 默认使用“mysql_native_password”插件认证</span></span><br><span class="line"><span class="comment">#mysql_native_password</span></span><br><span class="line"><span class="attr">default_authentication_plugin</span>=mysql_native_password</span><br></pre></td></tr></table></figure><blockquote><p>配置说明：主要需要修改的是以下几个属性：</p><p>server-id：服务节点的唯一标识。需要给集群中的每个服务分配一个单独的ID。</p><p>log_bin：打开Binlog日志记录，并指定文件名。</p><p>log_bin-index：Binlog日志文件</p></blockquote><p>重启MySQL服务， <code>service mysqld restart</code></p><p>然后，我们需要给root用户分配一个replication slave的权限。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">登录主数据库</span></span><br><span class="line">mysql -u root -p</span><br><span class="line">GRANT REPLICATION SLAVE ON *.* TO 'root'@'%';</span><br><span class="line">flush privileges;</span><br><span class="line"><span class="meta">#</span><span class="bash">查看主节点同步状态：</span></span><br><span class="line">show master status;</span><br></pre></td></tr></table></figure><blockquote><p>在实际生产环境中，通常不会直接使用root用户，而会创建一个拥有全部权限的用户来负责主从同步。</p></blockquote><p><img src="https://images.lilhui.com/b133024aff1b96e4a6bc438f2c080c2e" alt="图片"></p><p>这个指令结果中的File和Position记录的是当前日志的binlog文件以及文件中的索引。</p><p>而后面的Binlog_Do_DB和Binlog_Ignore_DB这两个字段是表示需要记录binlog文件的库以及不需要记录binlog文件的库。目前我们没有进行配置，就表示是针对全库记录日志。这两个字段如何进行配置，会在后面进行介绍。</p><blockquote><p>开启binlog后，数据库中的所有操作都会被记录到datadir当中，以一组轮询文件的方式循环记录。而指令查到的File和Position就是当前日志的文件和位置。而在后面配置从服务时，就需要通过这个File和Position通知从服务从哪个地方开始记录binLog。</p><p><img src="https://images.lilhui.com/68f65942245478c912d6083c3fb9c278" alt="图片"></p></blockquote><h3 id="2》配置slave从服务"><a href="#2》配置slave从服务" class="headerlink" title="2》配置slave从服务"></a>2》配置slave从服务</h3><p>​    下一步，我们来配置从服务mysqls。 我们打开mysqls的配置文件my.cnf，修改配置文件：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[mysqld]</span></span><br><span class="line"><span class="comment">#主库和从库需要不一致</span></span><br><span class="line"><span class="attr">server-id</span>=<span class="number">48</span></span><br><span class="line"><span class="comment">#打开MySQL中继日志</span></span><br><span class="line"><span class="attr">relay-log-index</span>=slave-relay-bin.index</span><br><span class="line"><span class="attr">relay-log</span>=slave-relay-bin</span><br><span class="line"><span class="comment">#打开从服务二进制日志</span></span><br><span class="line"><span class="attr">log-bin</span>=mysql-bin</span><br><span class="line"><span class="comment">#使得更新的数据写进二进制日志中</span></span><br><span class="line"><span class="attr">log-slave-updates</span>=<span class="number">1</span></span><br><span class="line"><span class="comment"># 设置3306端口</span></span><br><span class="line"><span class="attr">port</span>=<span class="number">3306</span></span><br><span class="line"><span class="comment"># 设置mysql的安装目录</span></span><br><span class="line"><span class="attr">basedir</span>=/usr/local/mysql</span><br><span class="line"><span class="comment"># 设置mysql数据库的数据的存放目录</span></span><br><span class="line"><span class="attr">datadir</span>=/usr/local/mysql/mysql-files</span><br><span class="line"><span class="comment"># 允许最大连接数</span></span><br><span class="line"><span class="attr">max_connections</span>=<span class="number">200</span></span><br><span class="line"><span class="comment"># 允许连接失败的次数。</span></span><br><span class="line"><span class="attr">max_connect_errors</span>=<span class="number">10</span></span><br><span class="line"><span class="comment"># 服务端使用的字符集默认为UTF8</span></span><br><span class="line"><span class="attr">character-set-server</span>=utf8</span><br><span class="line"><span class="comment"># 创建新表时将使用的默认存储引擎</span></span><br><span class="line"><span class="attr">default-storage-engine</span>=INNODB</span><br><span class="line"><span class="comment"># 默认使用“mysql_native_password”插件认证</span></span><br><span class="line"><span class="comment">#mysql_native_password</span></span><br><span class="line"><span class="attr">default_authentication_plugin</span>=mysql_native_password</span><br></pre></td></tr></table></figure><blockquote><p>配置说明：主要需要关注的几个属性：</p><p>server-id：服务节点的唯一标识</p><p>relay-log：打开从服务的relay-log日志。</p><p>log-bin：打开从服务的bin-log日志记录。</p></blockquote><p>然后我们启动mysqls的服务，并设置他的主节点同步状态。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">登录从服务</span></span><br><span class="line">mysql -u root -p;</span><br><span class="line"><span class="meta">#</span><span class="bash">设置同步主节点：</span></span><br><span class="line">CHANGE MASTER TO</span><br><span class="line">MASTER_HOST='192.168.232.128',</span><br><span class="line">MASTER_PORT=3306,</span><br><span class="line">MASTER_USER='root',</span><br><span class="line">MASTER_PASSWORD='root',</span><br><span class="line">MASTER_LOG_FILE='master-bin.000004',</span><br><span class="line">MASTER_LOG_POS=156,</span><br><span class="line">GET_MASTER_PUBLIC_KEY=1;</span><br><span class="line"><span class="meta">#</span><span class="bash">开启slave</span></span><br><span class="line">start slave;</span><br><span class="line"><span class="meta">#</span><span class="bash">查看主从同步状态</span></span><br><span class="line">show slave status;</span><br><span class="line">或者用 show slave status \G; 这样查看比较简洁</span><br></pre></td></tr></table></figure><blockquote><p>注意，CHANGE MASTER指令中需要指定的MASTER_LOG_FILE和MASTER_LOG_POS必须与主服务中查到的保持一致。</p><p>并且后续如果要检查主从架构是否成功，也可以通过检查主服务与从服务之间的File和Position这两个属性是否一致来确定。</p></blockquote><p><img src="https://images.lilhui.com/649680b1ad101aa9f1a86d24bd4185fa" alt="图片"></p><blockquote><p>从这个指令的结果能够看到，有很多Replicate_开头的属性，这些属性指定了两个服务之间要同步哪些数据库、哪些表的配置。只是在我们这个示例中全都没有进行配置，就标识是全库进行同步。后面我们会补充如何配置需要同步的库和表。</p></blockquote><h3 id="3》主从集群测试"><a href="#3》主从集群测试" class="headerlink" title="3》主从集群测试"></a>3》主从集群测试</h3><p>测试时，我们先用showdatabases，查看下两个MySQL服务中的数据库情况</p><p><img src="https://images.lilhui.com/4ac069d810ed32dea205783c892860cd" alt="图片"></p><p>然后我们在主服务器上创建一个数据库</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create database syncdemo;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br></pre></td></tr></table></figure><p>然后我们再用show databases，来看下这个syncdemo的数据库是不是已经同步到了从服务。</p><p><img src="https://images.lilhui.com/55a30bd9b2d84ec0086b708659253daa" alt="图片"></p><p>接下来我们继续在syncdemo这个数据库中创建一个表，并插入一条数据。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; use syncdemo;</span><br><span class="line">Database changed</span><br><span class="line">mysql&gt; create table demoTable(id int not null);</span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into demoTable value(1);</span><br><span class="line">Query OK, 1 row affected (0.01 sec)</span><br></pre></td></tr></table></figure><p>然后我们也同样到主服务与从服务上都来查一下这个demoTable是否同步到了从服务。</p><p><img src="https://images.lilhui.com/141ac99dd42b48a659cec324e4718762" alt="图片"></p><p>从上面的实验过程看到，我们在主服务中进行的数据操作，就都已经同步到了从服务上。这样，我们一个主从集群就搭建完成了。</p><blockquote><p>另外，这个主从架构是有可能失败的，如果在slave从服务上查看slave状态，发现Slave_SQL_Running=no，就表示主从同步失败了。这有可能是因为在从数据库上进行了写操作，与同步过来的SQL操作冲突了，也有可能是slave从服务重启后有事务回滚了。</p><p>如果是因为slave从服务事务回滚的原因，可以按照以下方式重启主从同步：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; mysql&gt; stop slave ;</span><br><span class="line">&gt; mysql&gt; set GLOBAL SQL_SLAVE_SKIP_COUNTER=1;</span><br><span class="line">&gt; mysql&gt; start slave ;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><blockquote><p>而另一种解决方式就是重新记录主节点的binlog文件消息</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; mysql&gt; stop slave ;</span><br><span class="line">&gt; mysql&gt; change master to .....</span><br><span class="line">&gt; mysql&gt; start slave ;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><blockquote><p>但是这种方式要注意binlog的文件和位置，如果修改后和之前的同步接不上，那就会丢失部分数据。所以不太常用。</p></blockquote><h3 id="4》全库同步与部分同步："><a href="#4》全库同步与部分同步：" class="headerlink" title="4》全库同步与部分同步："></a>4》全库同步与部分同步：</h3><p>在完成这个基本的MySQL主从集群后，我们还可以进行后续的实验：</p><p>之前提到，我们目前配置的主从同步是针对全库配置的，而实际环境中，一般并不需要针对全库做备份，而只需要对一些特别重要的库或者表来进行同步。那如何针对库和表做同步配置呢？</p><p>首先在Master端：在my.cnf中，可以通过以下这些属性指定需要针对哪些库或者哪些表记录binlog</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#需要同步的二进制数据库名</span></span><br><span class="line"><span class="attr">binlog-do-db</span>=masterdemo</span><br><span class="line"><span class="comment">#只保留7天的二进制日志，以防磁盘被日志占满(可选)</span></span><br><span class="line"><span class="attr">expire-logs-days</span>  = <span class="number">7</span></span><br><span class="line"><span class="comment">#不备份的数据库</span></span><br><span class="line"><span class="attr">binlog-ignore-db</span>=information_schema</span><br><span class="line"><span class="attr">binlog-ignore-db</span>=performation_schema</span><br><span class="line"><span class="attr">binlog-ignore-db</span>=sys</span><br></pre></td></tr></table></figure><p>然后在Slave端：在my.cnf中，需要配置备份库与主服务的库的对应关系。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#如果salve库名称与master库名相同，使用本配置</span></span><br><span class="line"><span class="attr">replicate-do-db</span> = masterdemo </span><br><span class="line"><span class="comment">#如果master库名[mastdemo]与salve库名[mastdemo01]不同，使用以下配置[需要做映射]</span></span><br><span class="line"><span class="attr">replicate-rewrite-db</span> = masterdemo -&gt; masterdemo01</span><br><span class="line"><span class="comment">#如果不是要全部同步[默认全部同步]，则指定需要同步的表</span></span><br><span class="line"><span class="attr">replicate-wild-do-table</span>=masterdemo01.t_dict</span><br><span class="line"><span class="attr">replicate-wild-do-table</span>=masterdemo01.t_num</span><br></pre></td></tr></table></figure><p>配置完成了之后，在show master status指令中，就可以看到Binlog_Do_DB和Binlog_Ignore_DB两个参数的作用了。</p><h3 id="5》GTID同步集群"><a href="#5》GTID同步集群" class="headerlink" title="5》GTID同步集群"></a>5》GTID同步集群</h3><p>上面我们搭建的集群方式，是基于Binlog日志记录点的方式来搭建的，这也是最为传统的MySQL集群搭建方式。而在这个实验中，可以看到有一个Executed_Grid_Set列，暂时还没有用上。实际上，这就是另外一种搭建主从同步的方式，即GTID搭建方式。这种模式是从MySQL5.6版本引入的。</p><p>GTID的本质也是基于Binlog来实现主从同步，只是他会基于一个全局的事务ID来标识同步进度。GTID即全局事务ID，全局唯一并且趋势递增，他可以保证为每一个在主节点上提交的事务在复制集群中可以生成一个唯一的ID 。</p><p>在基于GTID的复制中，首先从服务器会告诉主服务器已经在从服务器执行完了哪些事务的GTID值，然后主库会有把所有没有在从库上执行的事务，发送到从库上进行执行，并且使用GTID的复制可以保证同一个事务只在指定的从库上执行一次，这样可以避免由于偏移量的问题造成数据不一致。</p><p>他的搭建方式跟我们上面的主从架构整体搭建方式差不多。只是需要在my.cnf中修改一些配置。</p><p>在主节点上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">gtid_mode=on</span><br><span class="line">enforce_gtid_consistency=on</span><br><span class="line">log_bin=on</span><br><span class="line">server_id=单独设置一个</span><br><span class="line">binlog_format=row</span><br></pre></td></tr></table></figure><p>​    在从节点上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gtid_mode=on</span><br><span class="line">enforce_gtid_consistency=on</span><br><span class="line">log_slave_updates=1</span><br><span class="line">server_id=单独设置一个</span><br></pre></td></tr></table></figure><p>然后分别重启主服务和从服务，就可以开启GTID同步复制方式。</p><h2 id="4、集群扩容与MySQL数据迁移"><a href="#4、集群扩容与MySQL数据迁移" class="headerlink" title="4、集群扩容与MySQL数据迁移"></a>4、集群扩容与MySQL数据迁移</h2><p>我们现在已经搭建成功了一主一从的MySQL集群架构，那要扩展到一主多从的集群架构，其实就比较简单了，只需要增加一个binlog复制就行了。</p><p>但是如果我们的集群是已经运行过一段时间，这时候如果要扩展新的从节点就有一个问题，之前的数据没办法从binlog来恢复了。这时候在扩展新的slave节点时，就需要增加一个数据复制的操作。</p><p>MySQL的数据备份恢复操作相对比较简单，可以通过SQL语句直接来完成。具体操作可以使用mysql的bin目录下的mysqldump工具。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -u root -p --all-databases &gt; backup.sql</span><br><span class="line"><span class="meta">#</span><span class="bash">输入密码</span></span><br></pre></td></tr></table></figure><p>​    通过这个指令，就可以将整个数据库的所有数据导出成backup.sql，然后把这个backup.sql分发到新的MySQL服务器上，并执行下面的指令将数据全部导入到新的MySQL服务中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p &lt; backup.sql</span><br><span class="line"><span class="meta">#</span><span class="bash">输入密码</span></span><br></pre></td></tr></table></figure><p>​    这样新的MySQL服务就已经有了所有的历史数据，然后就可以再按照上面的步骤，配置Slave从服务的数据同步了。</p><h2 id="5、搭建半同步复制"><a href="#5、搭建半同步复制" class="headerlink" title="5、搭建半同步复制"></a>5、搭建半同步复制</h2><h3 id="1》理解半同步复制"><a href="#1》理解半同步复制" class="headerlink" title="1》理解半同步复制"></a>1》理解半同步复制</h3><p>到现在为止，我们已经可以搭建MySQL的主从集群，互主集群，但是我们这个集群有一个隐患，就是有可能会丢数据。这是为什么呢？这要从MySQL主从数据复制分析起。</p><p>MySQL主从集群默认采用的是一种异步复制的机制。主服务在执行用户提交的事务后，写入binlog日志，然后就给客户端返回一个成功的响应了。而binlog会由一个dump线程异步发送给Slave从服务。</p><p><img src="https://images.lilhui.com/f00cfe2e202e067d638856b6dc26811a" alt="图片"></p><p>由于这个发送binlog的过程是异步的。主服务在向客户端反馈执行结果时，是不知道binlog是否同步成功了的。这时候如果主服务宕机了，而从服务还没有备份到新执行的binlog，那就有可能会丢数据。</p><p>那怎么解决这个问题呢，这就要靠MySQL的半同步复制机制来保证数据安全。</p><p>半同步复制机制是一种介于异步复制和全同步复制之前的机制。主库在执行完客户端提交的事务后，并不是立即返回客户端响应，而是等待至少一个从库接收并写到relay log中，才会返回给客户端。MySQL在等待确认时，默认会等10秒，如果超过10秒没有收到ack，就会降级成为异步复制。</p><p><img src="https://images.lilhui.com/f8963d1418d45bf84345b7a05e01f1f5" alt="图片"></p><p>这种半同步复制相比异步复制，能够有效的提高数据的安全性。但是这种安全性也不是绝对的，他只保证事务提交后的binlog至少传输到了一个从库，并且并不保证从库应用这个事务的binlog是成功的。另一方面，半同步复制机制也会造成一定程度的延迟，这个延迟时间最少是一个TCP/IP请求往返的时间。整个服务的性能是会有所下降的。而当从服务出现问题时，主服务需要等待的时间就会更长，要等到从服务的服务恢复或者请求超时才能给用户响应。</p><h3 id="2》搭建半同步复制集群"><a href="#2》搭建半同步复制集群" class="headerlink" title="2》搭建半同步复制集群"></a>2》搭建半同步复制集群</h3><p>半同步复制需要基于特定的扩展模块来实现。而mysql从5.5版本开始，往上的版本都默认自带了这个模块。这个模块包含在mysql安装目录下的lib/plugin目录下的semisync_master.so和semisync_slave.so两个文件中。需要在主服务上安装semisync_master模块，在从服务上安装semisync_slave模块。</p><p><img src="https://images.lilhui.com/b50a3d36a6c93aae470f46f4b234efb2" alt="图片"></p><p>首先我们登陆主服务，安装semisync_master模块：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; install plugin rpl_semi_sync_master soname 'semisync_master.so';</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show global variables like 'rpl_semi%';</span><br><span class="line">+<span class="comment">-------------------------------------------+------------+</span></span><br><span class="line">| Variable_name                             | Value      |</span><br><span class="line">+<span class="comment">-------------------------------------------+------------+</span></span><br><span class="line">| rpl_semi_sync_master_enabled              | OFF        |</span><br><span class="line">| rpl_semi_sync_master_timeout              | 10000      |</span><br><span class="line">| rpl_semi_sync_master_trace_level          | 32         |</span><br><span class="line">| rpl_semi_sync_master_wait_for_slave_count | 1          |</span><br><span class="line">| rpl_semi_sync_master_wait_no_slave        | ON         |</span><br><span class="line">| rpl_semi_sync_master_wait_point           | AFTER_SYNC |</span><br><span class="line">+<span class="comment">-------------------------------------------+------------+</span></span><br><span class="line">6 rows in <span class="keyword">set</span>, <span class="number">1</span> <span class="keyword">warning</span> (<span class="number">0.02</span> sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; <span class="keyword">set</span> <span class="keyword">global</span> rpl_semi_sync_master_enabled=<span class="keyword">ON</span>;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure><blockquote><p> 这三行指令中，第一行是通过扩展库来安装半同步复制模块，需要指定扩展库的文件名。</p><p> 第二行查看系统全局参数，rpl_semi_sync_master_timeout就是半同步复制时等待应答的最长等待时间，默认是10秒，可以根据情况自行调整。</p><p> 第三行则是打开半同步复制的开关。</p><p> 在第二行查看系统参数时，最后的一个参数rpl_semi_sync_master_wait_point其实表示一种半同步复制的方式。</p><p> 半同步复制有两种方式，一种是我们现在看到的这种默认的AFTER_SYNC方式。这种方式下，主库把日志写入binlog，并且复制给从库，然后开始等待从库的响应。从库返回成功后，主库再提交事务，接着给客户端返回一个成功响应。</p><p> 而另一种方式是叫做AFTER_COMMIT方式。他不是默认的。这种方式，在主库写入binlog后，等待binlog复制到从库，主库就提交自己的本地事务，再等待从库返回给自己一个成功响应，然后主库再给客户端返回响应。</p></blockquote><p>然后我们登陆从服务，安装smeisync_slave模块</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; install plugin rpl_semi_sync_slave soname 'semisync_slave.so';</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show global variables like 'rpl_semi%';</span><br><span class="line">+<span class="comment">---------------------------------+-------+</span></span><br><span class="line">| Variable_name                   | Value |</span><br><span class="line">+<span class="comment">---------------------------------+-------+</span></span><br><span class="line">| rpl_semi_sync_slave_enabled     | OFF   |</span><br><span class="line">| rpl_semi_sync_slave_trace_level | 32    |</span><br><span class="line">+<span class="comment">---------------------------------+-------+</span></span><br><span class="line">2 rows in <span class="keyword">set</span>, <span class="number">1</span> <span class="keyword">warning</span> (<span class="number">0.01</span> sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; <span class="keyword">set</span> <span class="keyword">global</span> rpl_semi_sync_slave_enabled = <span class="keyword">on</span>;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show global variables like 'rpl_semi%';</span><br><span class="line">+<span class="comment">---------------------------------+-------+</span></span><br><span class="line">| Variable_name                   | Value |</span><br><span class="line">+<span class="comment">---------------------------------+-------+</span></span><br><span class="line">| rpl_semi_sync_slave_enabled     | ON    |</span><br><span class="line">| rpl_semi_sync_slave_trace_level | 32    |</span><br><span class="line">+<span class="comment">---------------------------------+-------+</span></span><br><span class="line">2 rows in <span class="keyword">set</span>, <span class="number">1</span> <span class="keyword">warning</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; <span class="keyword">stop</span> <span class="keyword">slave</span>;</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; start slave;</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br></pre></td></tr></table></figure><blockquote><p>slave端的安装过程基本差不多，不过要注意下安装完slave端的半同步插件后，需要重启下slave服务。</p></blockquote><h2 id="6、主从集群与读写分离"><a href="#6、主从集群与读写分离" class="headerlink" title="6、主从集群与读写分离"></a>6、主从集群与读写分离</h2><p>我们要注意，目前我们的这个MySQL主从集群是单向的，也就是只能从主服务同步到从服务，而从服务的数据表更是无法同步到主服务的。</p><p><img src="https://images.lilhui.com/029f1e4978303c9df5af7d712300f566" alt="图片"></p><p>​    所以，在这种架构下，为了保证数据一致，通常会需要保证数据只在主服务上写，而从服务只进行数据读取。这个功能，就是大名鼎鼎的读写分离。但是这里要注意下，mysql主从本身是无法提供读写分离的服务的，需要由业务自己来实现。这也是我们后面要学的ShardingSphere的一个重要功能。</p><blockquote><p>到这里可以看到，在MySQL主从架构中，是需要严格限制从服务的数据写入的，一旦从服务有数据写入，就会造成数据不一致。并且从服务在执行事务期间还很容易造成数据同步失败。</p><p>如果需要限制用户写数据，我们可以在从服务中将read_only参数的值设为1( <code>set</code> <code>global read_only=1;</code> )。这样就可以限制用户写入数据。但是这个属性有两个需要注意的地方：</p><p>1、read_only=1设置的只读模式，不会影响slave同步复制的功能。 所以在MySQL slave库中设定了read_only=1后，通过 “show slave status\G” 命令查看salve状态，可以看到salve仍然会读取master上的日志，并且在slave库中应用日志，保证主从数据库同步一致；</p><p>2、read_only=1设置的只读模式， 限定的是普通用户进行数据修改的操作，但不会限定具有super权限的用户的数据修改操作。 在MySQL中设置read_only=1后，普通的应用用户进行insert、update、delete等会产生数据变化的DML操作时，都会报出数据库处于只读模式不能发生数据变化的错误，但具有super权限的用户，例如在本地或远程通过root用户登录到数据库，还是可以进行数据变化的DML操作； 如果需要限定super权限的用户写数据，可以设置super_read_only=0。另外 <strong>如果要想连super权限用户的写操作也禁止，就使用”flush tables with read lock;”，这样设置也会阻止主从同步复制！</strong></p></blockquote><h2 id="7、扩展更复杂的集群结构"><a href="#7、扩展更复杂的集群结构" class="headerlink" title="7、扩展更复杂的集群结构"></a>7、扩展更复杂的集群结构</h2><p>我们到这里搭建出了一个一主一从的MySQL主从同步集群，具有了数据同步的基础功能。而在生产环境中，通常会以此为基础，根据业务情况以及负载情况，搭建更大更复杂的集群。</p><p>例如<strong>为了进一步提高整个集群的读能力，可以扩展出一主多从</strong>。而为了减轻主节点进行数据同步的压力，可以继续扩展出多级从的主从集群。</p><p>而<strong>为了提高这个集群的写能力，可以搭建互主集群</strong>，即两个服务互为主从。这样不管写到哪个服务上，集群内的数据都是同步的。这样就可以用一个集群来分担写数据的压力。</p><p><strong>以此为基础，可以扩展出多主多从的集群，全方位提升集群的数据读写能力</strong>。甚至，我们也可以扩展出环形的主从集群，实现MySQL多活部署。</p><p>搭建互主集群只需要按照上面的方式，在主服务上打开一个slave进程，并且指向slave节点的binlog当前文件地址和位置。</p><p><img src="https://images.lilhui.com/ae88bde6c6041b35e0020dbe154fc763" alt="图片"></p><p>另外，在我们搭建的这个主从集群中，有一个比较隐藏的问题，就是这样的主从复制之间会有延迟。这在复杂集群中，做了读写分离后，会更容易体现出来。即数据往主服务写，而读数据在从服务读。这时候这个主从复制延迟就有可能造成主库上刚插入了数据但是从库查不到。当然，这在我们目前的这个集群中是很难出现的，但是在大型集群中会很容易出现。</p><p>出现这个问题的根本在于：面向业务的主服务数据都是多线程并发写入的，而从服务是单个线程慢慢拉取binlog，这中间就会有个效率差。所以解决这个问题的关键是要让从服务也用多线程并行复制binlog数据。</p><p>MySQL自5.7版本后就已经支持并行复制了。可以在从服务上设置slave_parallel_workers为一个大于0的数，然后把slave_parallel_type参数设置为LOGICAL_CLOCK，这就可以了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> show global variables like <span class="string">'slave_parallel%'</span>;</span></span><br><span class="line">+------------------------+----------+</span><br><span class="line">| Variable_name          | Value    |</span><br><span class="line">+------------------------+----------+</span><br><span class="line">| slave_parallel_type    | DATABASE |</span><br><span class="line">| slave_parallel_workers | 0        |</span><br><span class="line">+------------------------+----------+</span><br><span class="line">2 rows in set (0.01 sec)</span><br></pre></td></tr></table></figure><h1 id="三、了解MySQL的其他高可用方案"><a href="#三、了解MySQL的其他高可用方案" class="headerlink" title="三、了解MySQL的其他高可用方案"></a>三、了解MySQL的其他高可用方案</h1><p>我们之前的MySQL服务集群，都是使用MySQL自身的功能来搭建的集群。但是这样的集群，不具备高可用的功能。即如果是MySQL主服务挂了，从服务是没办法自动切换成主服务的。而如果要实现MySQL的高可用，需要借助一些第三方工具来实现。</p><blockquote><p>这一部分方案只需要了解即可，因为一方面，这些高可用方案通常都是运维需要考虑的事情，作为开发人员没有必要花费太多的时间精力，偶尔需要用到的时候能够用起来就够了。另一方面，随着业界技术的不断推进，也会冒出更多的新方案。例如ShardingSphere的5.x版本的目标实际上就是将ShardingSphere由一个数据库中间件升级成一个独立的数据库平台，而将MySQL、PostGreSql甚至是RocksDB这些组件作为数据库的后端支撑。等到新版本成熟时，又会冒出更多新的高可用方案。</p></blockquote><p>常见的MySQL集群方案有三种: MMM、MHA、MGR。这三种高可用框架都有一些共同点：</p><ul><li>对主从复制集群中的Master节点进行监控</li><li>自动的对Master进行迁移，通过VIP。</li><li>重新配置集群中的其它slave对新的Master进行同步</li></ul><h2 id="1、MMM"><a href="#1、MMM" class="headerlink" title="1、MMM"></a>1、MMM</h2><p>MMM(Master-Master replication managerfor Mysql，Mysql主主复制管理器)是一套由Perl语言实现的脚本程序，可以对mysql集群进行监控和故障迁移。他需要两个Master，同一时间只有一个Master对外提供服务，可以说是主备模式。</p><p>他是通过一个VIP(虚拟IP)的机制来保证集群的高可用。整个集群中，在主节点上会通过一个VIP地址来提供数据读写服务，而当出现故障时，VIP就会从原来的主节点漂移到其他节点，由其他节点提供服务。</p><p><img src="https://images.lilhui.com/efdeaf0c52e81f1413425212b2c1f1e3" alt="图片"></p><p>优点：</p><ul><li>提供了读写VIP的配置，使读写请求都可以达到高可用</li><li>工具包相对比较完善，不需要额外的开发脚本</li><li>完成故障转移之后可以对MySQL集群进行高可用监控</li></ul><p>缺点：</p><ul><li>故障简单粗暴，容易丢失事务，建议采用半同步复制方式，减少失败的概率</li><li>目前MMM社区已经缺少维护，不支持基于GTID的复制</li></ul><p>适用场景：</p><ul><li>读写都需要高可用的</li><li>基于日志点的复制方式</li></ul><h2 id="2、MHA"><a href="#2、MHA" class="headerlink" title="2、MHA"></a>2、MHA</h2><p>Master High Availability Manager and Tools for MySQL。是由日本人开发的一个基于Perl脚本写的工具。这个工具专门用于监控主库的状态，当发现master节点故障时，会提升其中拥有新数据的slave节点成为新的master节点，在此期间，MHA会通过其他从节点获取额外的信息来避免数据一致性方面的问题。MHA还提供了mater节点的在线切换功能，即按需切换master-slave节点。MHA能够在30秒内实现故障切换，并能在故障切换过程中，最大程度的保证数据一致性。在淘宝内部，也有一个相似的TMHA产品。</p><p>MHA是需要单独部署的，分为Manager节点和Node节点，两种节点。其中Manager节点一般是单独部署的一台机器。而Node节点一般是部署在每台MySQL机器上的。 Node节点得通过解析各个MySQL的日志来进行一些操作。</p><p>Manager节点会通过探测集群里的Node节点去判断各个Node所在机器上的MySQL运行是否正常，如果发现某个Master故障了，就直接把他的一个Slave提升为Master，然后让其他Slave都挂到新的Master上去，完全透明。</p><p><img src="https://images.lilhui.com/1c78691b2e62fe88bc76ab061fc70da5" alt="图片"></p><p>优点：</p><ul><li>MHA除了支持日志点的复制还支持GTID的方式</li><li>同MMM相比，MHA会尝试从旧的Master中恢复旧的二进制日志，只是未必每次都能成功。如果希望更少的数据丢失场景，建议使用MHA架构。</li></ul><p>缺点：</p><p>MHA需要自行开发VIP转移脚本。</p><p>MHA只监控Master的状态，未监控Slave的状态</p><h2 id="3、MGR"><a href="#3、MGR" class="headerlink" title="3、MGR"></a>3、MGR</h2><p>MGR：MySQL Group Replication。 是MySQL官方在5.7.17版本正式推出的一种组复制机制。主要是解决传统异步复制和半同步复制的数据一致性问题。</p><p>由若干个节点共同组成一个复制组，一个事务提交后，必须经过超过半数节点的决议并通过后，才可以提交。引入组复制，主要是为了解决传统异步复制和半同步复制可能产生数据不一致的问题。MGR依靠分布式一致性协议(Paxos协议的一个变体)，实现了分布式下数据的最终一致性，提供了真正的数据高可用方案(方案落地后是否可靠还有待商榷)。</p><p>支持多主模式，但官方推荐单主模式：</p><ul><li>多主模式下，客户端可以随机向MySQL节点写入数据</li><li>单主模式下，MGR集群会选出primary节点负责写请求，primary节点与其它节点都可以进行读请求处理.</li></ul><p><img src="https://images.lilhui.com/ed5dfe0ae24e7ec263c406ccdb3faee0" alt="图片"></p><p>优点：</p><ul><li>高一致性，基于原生复制及paxos协议的组复制技术，并以插件的方式提供，提供一致数据安全保证；</li><li>高容错性，只要不是大多数节点坏掉就可以继续工作，有自动检测机制，当不同节点产生资源争用冲突时，不会出现错误，按照先到者优先原则进行处理，并且内置了自动化脑裂防护机制；</li><li>高扩展性，节点的新增和移除都是自动的，新节点加入后，会自动从其他节点上同步状态，直到新节点和其他节点保持一致，如果某节点被移除了，其他节点自动更新组信息，自动维护新的组信息；</li><li>高灵活性，有单主模式和多主模式，单主模式下，会自动选主，所有更新操作都在主上进行；多主模式下，所有server都可以同时处理更新操作。</li></ul><p>缺点:</p><ul><li>仅支持InnoDB引擎，并且每张表一定要有一个主键，用于做write set的冲突检测；</li><li>必须打开GTID特性，二进制日志格式必须设置为ROW，用于选主与write set；主从状态信息存于表中（–master-info-repository=TABLE 、–relay-log-info-repository=TABLE），–log-slave-updates打开；</li><li>COMMIT可能会导致失败，类似于快照事务隔离级别的失败场景</li><li>目前一个MGR集群最多支持9个节点</li><li>不支持外键于save point特性，无法做全局间的约束检测与部分事务回滚</li></ul><p>适用的业务场景：</p><ul><li>对主从延迟比较敏感</li><li>希望对对写服务提供高可用，又不想安装第三方软件</li><li>数据强一致的场景</li></ul><p>而在目前互联网，基于云原生的思路，MySQL的服务高可用又可以有很多不同的实现方式。这里就不一一分享了。</p><h1 id="四、分库分表方案介绍"><a href="#四、分库分表方案介绍" class="headerlink" title="四、分库分表方案介绍"></a>四、分库分表方案介绍</h1><p>前面我们做的一大段实验，目的是为了大家能够理解MySQL的主从集群。而主从集群的作用，在我们开发角度更大的是作为读写分离的支持，也是我们后面学习ShardingSphere的重点。我们这一部分就来介绍下分库分表。</p><p>分库分表就是业务系统将数据写请求分发到master节点，而读请求分发到slave节点的一种方案，可以大大提高整个数据库集群的性能。但是要注意，分库分表的一整套逻辑全部是由客户端自行实现的。而对于MySQL集群，数据主从同步是实现读写分离的一个必要前提条件。</p><h2 id="1、分库分表有什么用"><a href="#1、分库分表有什么用" class="headerlink" title="1、分库分表有什么用"></a>1、分库分表有什么用</h2><p>分库分表就是为了解决由于数据量过大而导致数据库性能降低的问题，将原来独立的数据库拆分成若干数据库组成<br>，将数据大表拆分成若干数据表组成，使得单一数据库、单一数据表的数据量变小，从而达到提升数据库性能的目<br>的。</p><p>例如：微服务架构中，每个服务都分配一个独立的数据库，这就是分库。而对一些业务日志表，按月拆分成不同的表，这就是分表。</p><h2 id="2、分库分表的方式"><a href="#2、分库分表的方式" class="headerlink" title="2、分库分表的方式"></a>2、分库分表的方式</h2><p>分库分表包含分库和分表 两个部分，而这两个部分可以统称为数据分片，其目的都是将数据拆分成不同的存储单元。另外，从分拆的角度上，可以分为垂直分片和水平分片。</p><ul><li>垂直分片： 按照业务来对数据进行分片，又称为纵向分片。他的核心理念就是转库专用。在拆分之前，一个数据库由多个数据表组成，每个表对应不同的业务。而拆分之后，则是按照业务将表进行归类，分布到不同的数据库或表中，从而将压力分散至不同的数据库或表。例如，下图将用户表和订单表垂直分片到不同的数据库：</li></ul><p><img src="https://images.lilhui.com/1edc12784bd872eddc63cdb8ee972a42" alt="图片"></p><p>垂直分片往往需要对架构和设计进行调整。通常来讲，是来不及应对业务需求快速变化的。而且，他也无法真正的解决单点数据库的性能瓶颈。垂直分片可以缓解数据量和访问量带来的问题，但无法根治。如果垂直分片之后，表中的数据量依然超过单节点所能承载的阈值，则需要水平分片来进一步处理。</p><ul><li>水平分片：又称横向分片。相对于垂直分片，它不再将数据根据业务逻辑分类，而是通过某个字段(或某几个字段)，根据某种规则将数据分散至多个库或表中，每个分片仅包含数据的一部分。例如，像下图根据主键机构分片。</li></ul><p><img src="https://images.lilhui.com/c1c667ae26e91ecd6f8a2834363b8b26" alt="图片"></p><p>常用的分片策略有：</p><p>取余\取模  ： 优点 均匀存放数据，缺点 扩容非常麻烦</p><p>按照范围分片 ： 比较好扩容， 数据分布不够均匀</p><p>按照时间分片 ： 比较容易将热点数据区分出来。</p><p>按照枚举值分片 ： 例如按地区分片</p><p>按照目标字段前缀指定进行分区：自定义业务规则分片</p><p>水平分片从理论上突破了单机数据量处理的瓶颈，并且扩展相对自由，是分库分表的标准解决方案。</p><p>一般来说，在系统设计阶段就应该根据业务耦合松紧来确定垂直分库，垂直分表方案，在数据量及访问压力不是特别大的情况，首先考虑缓存、读写分离、索引技术等方案。若数据量极大，且持续增长，再考虑水平分库水平分表方案。</p><blockquote><p>扩展问题： 如何设计一个不需要数据迁移的取模分片扩容方案？</p></blockquote><h2 id="3、分库分表要解决哪些问题"><a href="#3、分库分表要解决哪些问题" class="headerlink" title="3、分库分表要解决哪些问题"></a>3、分库分表要解决哪些问题</h2><p>之前说过，分库分表其实并不只是字面意义上的拆分数据，他还有一系列的问题需要解决。虽然数据分片解决了性能、可用性以及单点备份恢复等问题，但是分布式的架构在获得收益的同时，也引入了非常多新的问题。而这些，都是一个成熟的分库分表方案需要考虑的问题。</p><ul><li><p>事务一致性问题</p><p>原本单机数据库有很好的事务机制能够帮我们保证数据一致性。但是分库分表后，由于数据分布在不同库甚至不同服务器，不可避免会带来分布式事务问题。</p></li><li><p>跨节点关联查询问题</p><p>在没有分库时，我们可以进行很容易的进行跨表的关联查询。但是在分库后，表被分散到了不同的数据库，就无法进行关联查询了。</p><p>这时就需要将关联查询拆分成多次查询，然后将获得的结果进行拼装。</p></li><li><p>跨节点分页、排序函数</p><p>跨节点多库进行查询时，limit分页、order by排序等问题，就变得比较复杂了。需要先在不同的分片节点中将数据<br>进行排序并返回，然后将不同分片返回的结果集进行汇总和再次排序。</p><p>这时非常容易出现内存崩溃的问题。</p></li><li><p>主键避重问题</p><p>在分库分表环境中，由于表中数据同时存在不同数据库中，主键值平时使用的自增长将无用武之地，某个分区数据<br>库生成的ID无法保证全局唯一。因此需要单独设计全局主键，以避免跨库主键重复问题。</p></li><li><p>公共表处理</p><p>实际的应用场景中，参数表、数据字典表等都是数据量较小，变动少，而且属于高频联合查询的依赖表。这一类表一般就需要在每个数据库中都保存一份，并且所有对公共表的操作都要分发到所有的分库去执行。</p></li><li><p>运维工作量</p><p>面对散乱的分库分表之后的数据，应用开发工程师和数据库管理员对数据库的操作都变得非常繁重。对于每一次数据读写操作，他们都需要知道要往哪个具体的数据库的分表去操作，这也是其中重要的挑战之一。</p></li></ul><h2 id="4、什么时候需要分库分表？"><a href="#4、什么时候需要分库分表？" class="headerlink" title="4、什么时候需要分库分表？"></a>4、什么时候需要分库分表？</h2><p>在阿里巴巴公布的开发手册中，建议MySQL单表记录如果达到500W这个级别，或者单表容量达到2GB，一般就建议进行分库分表。而考虑到分库分表需要对数据进行再平衡，所以如果要使用分库分表，就要在系统设计之初就详细考虑好分库分表的方案，这里要分两种情况。</p><p>一般对于用户数据这一类后期增长比较缓慢的数据，一般可以按照三年左右的业务量来预估使用人数，按照标准预设好分库分表的方案。</p><p>而对于业务数据这一类增长快速且稳定的数据，一般则需要按照预估量的两倍左右预设分库分表方案。并且由于分库分表的后期扩容是非常麻烦的，所以在进行分库分表时，尽量根据情况，多分一些表。最好是计算一下数据增量，永远不用增加更多的表。</p><p>另外，在设计分库分表方案时，要尽量兼顾业务场景和数据分布。在支持业务场景的前提下，尽量保证数据能够分得更均匀。</p><p>最后，一旦用到了分库分表，就会表现为对数据查询业务的灵活性有一定的影响，例如如果按userId进行分片，那按age来进行查询，就必然会增加很多麻烦。如果再要进行排序、分页、聚合等操作，很容易就扛不住了。这时候，都要尽量在分库分表的同时，再补充设计一个降级方案，例如将数据转存一份到ES，ES可以实现更灵活的大数据聚合查询。</p><h2 id="5、常见的分库分表组件"><a href="#5、常见的分库分表组件" class="headerlink" title="5、常见的分库分表组件"></a>5、常见的分库分表组件</h2><p>由于分库分表之后，数据被分散在不同的数据库、服务器。因此，对数据的操作也就无法通过常规方式完成，并且<br>它还带来了一系列的问题。好在，这些问题不是所有都需要我们在应用层面上解决，市面上有很多中间件可供我们<br>选择，我们来了解一下它。</p><ul><li>shardingsphere   官网地址：<a href="https://shardingsphere.apache.org/document/current/cn/overview/" target="_blank" rel="noopener">https://shardingsphere.apache.org/document/current/cn/overview/</a></li></ul><p>Sharding-JDBC是当当网研发的开源分布式数据库中间件，他是一套开源的分布式数据库中间件解决方案组成的生态圈，它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（计划中）这3款相互独立的产品组成。 他们均提供标准化的数据分片、分布式事务和<br>数据库治理功能，可适用于如Java同构、异构语言、容器、云原生等各种多样化的应用场景。</p><p>这也是我们这次学习的重点。</p><ul><li>mycat 官网地址：  <a href="http://www.mycat.org.cn/" target="_blank" rel="noopener">http://www.mycat.org.cn/</a></li></ul><p>基于阿里开源的Cobar产品而研发，Cobar的稳定性、可靠性、优秀的架构和性能以及众多成熟的使用案例使得MYCAT一开始就拥有一个很好的起点，站在巨人的肩膀上，我们能看到更远。业界优秀的开源项目和创新思路被广泛融入到MYCAT的基因中，使得MYCAT在很多方面都领先于目前其他一些同类的开源项目，甚至超越某些商业产品。</p><p>MyCAT虽然是从阿里的技术体系中出来的，但是跟阿里其实没什么关系。</p><ul><li>DBLE 官网地址：<a href="https://opensource.actionsky.com/" target="_blank" rel="noopener">https://opensource.actionsky.com/</a></li></ul><p>该网站包含几个重要产品。其中分布式中间件可以认为是MyCAT的一个增强版，专注于MySQL的集群化管理。另外还有数据传输组件和分布式事务框架组件可供选择。</p><h1 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h1><p>今天课程的内容，主要是给大家介绍MySQL的分布式集群化的主要思路和解决方案。但是，如果换成其他的数据库产品，比如Oracle、SqlServer、DB2等其他数据库，那么肯定又需要有不同的解决方案。所以，对于这次课程的内容，重点在于领会思想。</p><p>其实，分库分表和主从集群，这些方案背后的核心思想都是水平扩展，从单机往集群化发展。这种思想其实我们并不陌生，微服务体系也就是干的这个事情。只不过，由于数据库是一个重状态的组件，因此，在将服务进行集群化的过程中，也需要考虑状态如何分布。而这个事情，MySQL在做，其他的数据组件也都在做，比如Redis、MongoDB等等。对于今天课程的内容，你不妨同之前学过的Redis、MongoDB等其他组件进行数据同步的思路进行下横向的总结、对比，这对于你以后去理解其他没有接触过的新产品比如HBase、Clickhouse等会有帮助的。</p><p>并且，分布式已经是现在软件的主流，我们在以后肯定会要面临各种各样的分布式问题，数据库集群、服务集群、缓存集群、图片等静态资源集群、计算集群 等等。当面临各种各样的复杂场景，如何构建一个稳定高效的集群化方案，这是一个需要日积月累，不断沉淀的问题。而这次的MySQL集群化以及后面的ShardingSphere分库分表，就是一个很好的参考。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、MySQL高可用集群介绍&quot;&gt;&lt;a href=&quot;#一、MySQL高可用集群介绍&quot; class=&quot;headerlink&quot; title=&quot;一、MySQL高可用集群介绍&quot;&gt;&lt;/a&gt;一、MySQL高可用集群介绍&lt;/h1&gt;&lt;h2 id=&quot;1、数据库主从架构与分库分表&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="mysql" scheme="https://www.lilhui.com/categories/mysql/"/>
    
    
      <category term="mysql" scheme="https://www.lilhui.com/tags/mysql/"/>
    
      <category term="高可用" scheme="https://www.lilhui.com/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>【ShardingSphere 4】实践</title>
    <link href="https://www.lilhui.com/2022/12/06/java/shardingsphere/shardingsphere_4/"/>
    <id>https://www.lilhui.com/2022/12/06/java/shardingsphere/shardingsphere_4/</id>
    <published>2022-12-06T07:49:46.000Z</published>
    <updated>2022-12-06T10:56:58.162Z</updated>
    
    <content type="html"><![CDATA[<h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><ol><li>逻辑表：水平拆分的数据库的相同逻辑和数据结构表的总称</li><li>真实表：在分片的数据库中真实存在的物理表。</li><li>数据节点：数据分片的最小单元。由数据源名称和数据表组成</li><li>绑定表：分片规则一致的主表和子表。</li><li>广播表：也叫公共表，指素有的分片数据源中都存在的表，表结构和表中的数据<br>在每个数据库中都完全一致。例如字典表。</li><li>分片键：用于分片的数据库字段，是将数据库(表)进行水平拆分的关键字段。<br>SQL中若没有分片字段，将会执行全路由，性能会很差。</li><li>分片算法：通过分片算法将数据进行分片，支持通过=、BETWEEN和IN分片。<br>分片算法需要由应用开发者自行实现，可实现的灵活度非常高。</li><li>分片策略：真正用于进行分片操作的是分片键+分片算法，也就是分片策略。在<br>ShardingJDBC中一般采用基于Groovy表达式的inline分片策略，通过一个包含<br>分片键的算法表达式来制定分片策略，如t_user_$-&gt;{u_id%8}标识根据u_id模<br>8，分成8张表，表名称为t_user_0到t_user_7。</li></ol><h2 id="ShardingJDBC的分片算法"><a href="#ShardingJDBC的分片算法" class="headerlink" title="ShardingJDBC的分片算法"></a>ShardingJDBC的分片算法</h2><p>ShardingSphere目前提供了一共五种分片策略：</p><blockquote><p>NoneShardingStrategy</p></blockquote><p>不分片。这种严格来说不算是一种分片策略了。只是ShardingSphere也提供了<br>这么一个配置。</p><blockquote><p>InlineShardingStrategy</p></blockquote><ul><li><p>常用的分片方式  </p><ul><li>配置参数  inline.shardingColumn 分片键；inline.algorithmExpression<br>分片表达式</li><li>实现方式： 按照分片表达式来进行分片。</li></ul></li><li><p>StandardShardingStrategy<br>只支持单分片键的标准分片策略。</p><ul><li>配置方式： standard.sharding-column 分片键；standard.precisealgorithm-class-name 精确分片算法类名；standard.range-algorithmclass-name 范围分片算法类名</li><li>实现方式：shardingColumn指定分片算法。<br>preciseAlgorithmClassName 指向一个实现了<br>io.shardingsphere.api.algorithm.sharding.standard.PreciseShardingAl<br>gorithm接口的java类名，提供按照 = 或者 IN 逻辑的精确分片 示例：<br>com.roy.shardingDemo.algorithm.MyPreciseShardingAlgorit<br>hm<br>rangeAlgorithmClassName 指向一个实现了<br>io.shardingsphere.api.algorithm.sharding.standard.RangeShardingAlg<br>orithm接口的java类名，提供按照Between 条件进行的范围分片。示例：<br>com.roy.shardingDemo.algorithm.MyRangeShardingAlgorithm</li><li>说明：<br>其中精确分片算法是必须提供的，而范围分片算法则是可选的。</li></ul></li><li><p>ComplexShardingStrategy<br>支持多分片键的复杂分片策略。</p><ul><li>配置参数：complex.sharding-columns 分片键(多个);<br>complex.algorithm-class-name 分片算法实现类。</li><li>实现方式：<br>shardingColumn指定多个分片列。<br>algorithmClassName指向一个实现了<br>org.apache.shardingsphere.api.sharding.complex.ComplexKeysShardi<br>ngAlgorithm接口的java类名。提供按照多个分片列进行综合分片的算法。<br>示例：<br>com.roy.shardingDemo.algorithm.MyComplexKeysShardingAlg<br>orithm</li></ul></li><li>HintShardingStrategy<br>不需要分片键的强制分片策略。这个分片策略，简单来理解就是说，他的分片键<br>不再跟SQL语句相关联，而是用程序另行指定。对于一些复杂的情况，例如<br>select count(*) from (select userid from t_user where userid in (1,3,5,7,9))<br>这样的SQL语句，就没法通过SQL语句来指定一个分片键。这个时候就可以通过<br>程序，给他另行执行一个分片键，例如在按userid奇偶分片的策略下，可以指定<br>1作为分片键，然后自行指定他的分片策略。<ul><li>配置参数：hint.algorithm-class-name 分片算法实现类。</li><li>实现方式：<br>algorithmClassName指向一个实现了<br>org.apache.shardingsphere.api.sharding.hint.HintShardingAlgorithm<br>接口的java类名。 示例：<br>com.roy.shardingDemo.algorithm.MyHintShardingAlgorithm<br>在这个算法类中，同样是需要分片键的。而分片键的指定是通过<br>HintManager.addDatabaseShardingValue方法(分库)和<br>HintManager.addTableShardingValue(分表)来指定。<br>使用时要注意，这个分片键是线程隔离的，只在当前线程有效，所以通常建<br>议使用之后立即关闭，或者用try资源方式打开。</li></ul></li></ul><blockquote><p>而Hint分片策略并没有完全按照SQL解析树来构建分片策略，是绕开<br>了SQL解析的，所有对某些比较复杂的语句，Hint分片策略性能有可<br>能会比较好(情况太多了，无法一一分析)。<br>但是要注意，Hint强制路由在使用时有非常多的限制：</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 不支持UNION </span></span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> t_order1 <span class="keyword">UNION</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> t_order2 </span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> tbl_name (col1, col2, …) <span class="keyword">SELECT</span> col1, col2, … <span class="keyword">FROM</span> tbl_name <span class="keyword">WHERE</span> col3 = ? </span><br><span class="line"><span class="comment">-- 不支持多层子查询 </span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*) <span class="keyword">FROM</span> (<span class="keyword">SELECT</span> * <span class="keyword">FROM</span> t_order o <span class="keyword">WHERE</span> o.id <span class="keyword">IN</span> (<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> t_order <span class="keyword">WHERE</span> <span class="keyword">status</span> = ?)) </span><br><span class="line"><span class="comment">-- 不支持函数计算。ShardingSphere只能通过SQL字面提取用于分片的值</span></span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> t_order <span class="keyword">WHERE</span> <span class="keyword">to_date</span>(create_time, <span class="string">'yyyy-mm-dd'</span>) = <span class="string">'2019-01-01'</span>;</span><br></pre></td></tr></table></figure><h2 id="ShardingSphere的SQL使用限制"><a href="#ShardingSphere的SQL使用限制" class="headerlink" title="ShardingSphere的SQL使用限制"></a>ShardingSphere的SQL使用限制</h2><ul><li>支持的SQL</li></ul><p><img src="https://images.lilhui.com/8a563449ad2e4fa37a0f6c77dc7aee93" alt="图片"></p><p><img src="https://images.lilhui.com/4a8a259bfa95d5719e95ac70ed427998" alt="图片"></p><ul><li>不支持的SQL</li></ul><p><img src="https://images.lilhui.com/c11b2515d6e9eda52a55877e4079c0fb" alt="图片"></p><p><img src="https://images.lilhui.com/a8d13558c53a4119ad8ac941b54688eb" alt="图片"></p><ul><li>Distinct 说明</li></ul><p>支持的SQL</p><p><img src="https://images.lilhui.com/80da24607c50a02fa2b8024b26269246" alt="图片"></p><p>不支持的SQL</p><p><img src="https://images.lilhui.com/6c8cc83ca4fa19dc67a69aa6523b3ca9" alt="图片"></p><h2 id="分库分表带来的问题"><a href="#分库分表带来的问题" class="headerlink" title="分库分表带来的问题"></a>分库分表带来的问题</h2><p>1、分库分表，其实围绕的都是一个核心问题，就是单机数据库容量的问题。我们<br>要了解，在面对这个问题时，解决方案是很多的，并不止分库分表这一种。但是<br>ShardingSphere的这种分库分表，是希望在软件层面对硬件资源进行管理，从而便<br>于对数据库的横向扩展，这无疑是成本很小的一种方式。<br>大家想想还有哪些比较好的解决方案？  </p><p>2、一般情况下，如果单机数据库容量撑不住了，应先从缓存技术着手降低对数据<br>库的访问压力。如果缓存使用过后，数据库访问量还是非常大，可以考虑数据库读<br>写分离策略。如果数据库压力依然非常大，且业务数据持续增长无法估量，最后才<br>考虑分库分表，单表拆分数据应控制在1000万以内。<br>当然，随着互联网技术的不断发展，处理海量数据的选择也越来越多。在实际进<br>行系统设计时，最好是用MySQL数据库只用来存储关系性较强的热点数据，而对海<br>量数据采取另外的一些分布式存储产品。例如PostGreSQL、VoltDB甚至HBase、<br>Hive、ES等这些大数据组件来存储。  </p><p>3、从上一部分ShardingJDBC的分片算法中我们可以看到，由于SQL语句的功能<br>实在太多太全面了，所以分库分表后，对SQL语句的支持，其实是步步为艰的，稍<br>不小心，就会造成SQL语句不支持、业务数据混乱等很多很多问题。所以，实际使<br>用时，我们会建议这个分库分表，能不用就尽量不要用。<br>如果要使用优先在OLTP场景下使用，优先解决大量数据下的查询速度问题。而在<br>OLAP场景中，通常涉及到非常多复杂的SQL，分库分表的限制就会更加明显。当<br>然，这也是ShardingSphere以后改进的一个方向。  </p><p>4、如果确定要使用分库分表，就应该在系统设计之初开始对业务数据的耦合程度<br>和使用情况进行考量，尽量控制业务SQL语句的使用范围，将数据库往简单的增删<br>改查的数据存储层方向进行弱化。并首先详细规划垂直拆分的策略，使数据层架构<br>清晰明了。而至于水平拆分，会给后期带来非常非常多的数据问题，所以应该谨<br>慎、谨慎再谨慎。一般也就在日志表、操作记录表等很少的一些边缘场景才偶尔用<br>用。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;核心概念&quot;&gt;&lt;a href=&quot;#核心概念&quot; class=&quot;headerlink&quot; title=&quot;核心概念&quot;&gt;&lt;/a&gt;核心概念&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;逻辑表：水平拆分的数据库的相同逻辑和数据结构表的总称&lt;/li&gt;
&lt;li&gt;真实表：在分片的数据库中真实存在的物理表
      
    
    </summary>
    
      <category term="shardingsphere" scheme="https://www.lilhui.com/categories/shardingsphere/"/>
    
    
      <category term="分库，分表" scheme="https://www.lilhui.com/tags/%E5%88%86%E5%BA%93%EF%BC%8C%E5%88%86%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>【ShardingSphere 3】框架结构</title>
    <link href="https://www.lilhui.com/2022/12/06/java/shardingsphere/shardingsphere_3/"/>
    <id>https://www.lilhui.com/2022/12/06/java/shardingsphere/shardingsphere_3/</id>
    <published>2022-12-06T07:36:25.000Z</published>
    <updated>2022-12-06T07:51:31.284Z</updated>
    
    <content type="html"><![CDATA[<h2 id="产品介绍"><a href="#产品介绍" class="headerlink" title="产品介绍"></a>产品介绍</h2><h3 id="ShardingJDBC"><a href="#ShardingJDBC" class="headerlink" title="ShardingJDBC"></a>ShardingJDBC</h3><p><img src="https://images.lilhui.com/c5445ae0e66720968879d4db36684656" alt="图片"></p><h3 id="ShardingProxy"><a href="#ShardingProxy" class="headerlink" title="ShardingProxy"></a>ShardingProxy</h3><p><img src="https://images.lilhui.com/fecaf2e1b9ea81a2d44e2df2a09acfff" alt="图片"></p><h3 id="生态定位"><a href="#生态定位" class="headerlink" title="生态定位"></a>生态定位</h3><p>对于ShardingSphere，大家用得多的一般是他的4.x版本，这也是目前最具影响<br>力的一个系列版本。但是，ShardingSphere在2021年底，发布了5.x版本的第一个<br>发布版，这也标志着ShardingSphere的产品定位进入了一个新的阶段。官网上也重<br>点标识了一下ShardingSphere的发展路线：</p><p><img src="https://images.lilhui.com/115307036057dfb234ad174b82a665d9" alt="图片"></p><p>其实从4.x版本升级到5.x版本，ShardingSphere做了很多功能增强，但是其核心<br>功能并没有太大的变化。更大的区别其实是体现在产品定位上，在4.x版本中，<br>ShardingSphere是定位为一个数据库中间件，而到了5.x版本，ShardingSphere给<br>自己的定位成了DatabasePlus，旨在构建多模数据库上层的标准和生态，从而更接<br>近于Sphere(生态)的定位。</p><h3 id="架构演变"><a href="#架构演变" class="headerlink" title="架构演变"></a>架构演变</h3><p><img src="https://images.lilhui.com/0c5d95d6fc13c5dfeb9440239c0c84ef" alt="图片"></p><p>其中核心的理念就是图中的连接、增量、可拔插。一方面未来会支持更多的数据<br>库，甚至不光是MySQL、PostGreSQL这些关系型数据库，还包括了像RocksDB，<br>Redis这一类非关系型的数据库。又一方面会拓展ShardingSphere的数据库功能属<br>性，让用户可以完全基于ShardingSphere来构建上层应用，而其他的数据库只是作<br>为ShardingSphere的可选功能支持。另一方面形成 微内核+三层可拔插扩展 的模<br>型(图中的L1,L2,L3三层内核模型)，让开发者可以在ShardingSphere的内核基础<br>上，做更灵活的功能拓展，可以像搭积木一样定制属于自己的独特系统。</p><p>虽然从目前来看，ShardingSphere离他自己构建的这个宏伟蓝图还非常遥远，<br>但是从他逐渐清晰的功能定位可以看出，未来可期。而这也确确实实的带来了<br>github上关注度增长。相比MyCat、DBLE等其他产品，未来更有吸引力。</p><p>由于ShardingSphere5.X版本还只提出短短几个月的时间，所以接下来的实战部<br>分，我们依然会选用更为稳定的4.X版本。在课程最后会跟大家再来分享一下5.X版<br>本的一些新特性。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;产品介绍&quot;&gt;&lt;a href=&quot;#产品介绍&quot; class=&quot;headerlink&quot; title=&quot;产品介绍&quot;&gt;&lt;/a&gt;产品介绍&lt;/h2&gt;&lt;h3 id=&quot;ShardingJDBC&quot;&gt;&lt;a href=&quot;#ShardingJDBC&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="shardingsphere" scheme="https://www.lilhui.com/categories/shardingsphere/"/>
    
    
      <category term="分库，分表" scheme="https://www.lilhui.com/tags/%E5%88%86%E5%BA%93%EF%BC%8C%E5%88%86%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>学习工作方法总结</title>
    <link href="https://www.lilhui.com/2022/12/05/article/worker/learn_tool/"/>
    <id>https://www.lilhui.com/2022/12/05/article/worker/learn_tool/</id>
    <published>2022-12-05T08:12:08.000Z</published>
    <updated>2022-12-06T02:36:33.564Z</updated>
    
    <content type="html"><![CDATA[<h2 id="规划-工作计划"><a href="#规划-工作计划" class="headerlink" title="规划/工作计划"></a>规划/工作计划</h2><h3 id="OKR"><a href="#OKR" class="headerlink" title="OKR"></a>OKR</h3><p>合理地设定目标和分解关键成果来弥补KPI的缺陷。</p><p>更注重聚焦和逻辑</p><p>事前-事中-事后</p><h3 id="步骤-事前"><a href="#步骤-事前" class="headerlink" title="步骤-事前"></a>步骤-事前</h3><ol><li><p>聚焦业务目标（O)/对齐业务OKR(自上而下传导)</p><ul><li>聚焦重要的事情，真去形成合力和突破。</li><li>OKR规划最难的部分<ul><li>环境和处理的信息不稳定性。</li><li>不同人，制定的规划标准不同。</li></ul></li><li>探索，基类</li></ul></li><li><p>分解关键结果（KR)/补充专业OKR</p><ul><li>每个目标 2-5 个KR,收尾结果后，综合多个KPI评判是否达到目标。</li></ul></li></ol><h3 id="执行-事中"><a href="#执行-事中" class="headerlink" title="执行-事中"></a>执行-事中</h3><h4 id="多个备选方案"><a href="#多个备选方案" class="headerlink" title="多个备选方案"></a>多个备选方案</h4><ul><li>制定多个备选方案，系统地分析事情相关的方面，避免思维狭隘。</li><li><p>多执行几个方案（3-5），选择最优的。</p><ul><li>预研：设计多个方案</li><li>讨论：进行方案评审</li><li>决策：选择最终的执行方案</li></ul></li></ul><h4 id="PDCA-执行推进"><a href="#PDCA-执行推进" class="headerlink" title="PDCA 执行推进"></a>PDCA 执行推进</h4><p>plan - do - check - act</p><p>计划 - 执行 - 检查 - 行动</p><blockquote><p>遇到问题如何推进</p></blockquote><p>检查是否有长期问题，如果有长期问题，需要定一个中期或者长期计划。</p><p>解决好问题后，汇总，再把下一步的行动，做汇报。让领导做选择题~</p><p>我知道每个阶段要做什么，让领导知道我每个阶段要做什么。如果出了问题，我也知道要怎么做。</p><p>各个阶段的人，各个阶段的协作方，都知道做什么。</p><ul><li>四个环节</li></ul><ol><li>计划：确定具体任务，阶段目标，时间节点和具体负责人。<ol><li>处理紧急的事情，长短结合，有限解决事情，再配合长期根除。</li><li>需要但不紧急的事情，拆分成多个小项目。</li></ol></li><li><p>执行：按照计划落地的具体活动</p><ol><li>及时同步信息。</li></ol></li><li><p>检查：对照计划来检查结果。</p><ol><li>明确哪些符合预期，哪些不达到预期，哪些超出预期以及存在什么问题。</li></ol></li><li>行动：基于检查结果，总结明确下一步措施。<ol><li>做好总结汇报</li><li>每次挑3个以内的改进点落实到下一步措施。</li></ol></li></ol><h3 id="分析根本原因"><a href="#分析根本原因" class="headerlink" title="分析根本原因"></a>分析根本原因</h3><ol><li>通过五个为什么来深挖问题本质<br>下一个问题是对上一个问题的进一步深入。<br>问题数量不是关键，关键是找到根本原因才是关键。</li></ol><p>明确问题本身。</p><h3 id="金字塔汇报"><a href="#金字塔汇报" class="headerlink" title="金字塔汇报"></a>金字塔汇报</h3><ol><li>军训四个原则来汇总汇报成果。从而更容易获得更高级别人员的认可。</li><li>标准的回报内容包括 总体结论，具体分析，关键事项，总结改进。</li></ol><blockquote><p>总体结论</p></blockquote><p>全局改过整体工作情况，得出关键性结论，结果一目了然</p><blockquote><p>具体分析</p></blockquote><p>进一步阐述和分析结论，提供具体数据佐证。</p><p>逻辑自洽，有理有据。</p><blockquote><p>关键事项</p></blockquote><p>介绍工作，项目关键效果。</p><ol><li>不用金字塔原理</li><li>全局大图:展示整体情况</li><li>演进路径：展示个体情况。</li><li>时间轴：展示过程</li></ol><blockquote><p>总结改进</p></blockquote><p>总结经验教训和后续措施，措施也有理有据，有迹可循，3-5条。</p><blockquote><p>金字塔原理</p></blockquote><p>核心思想是任何事情都可以归纳出一个中心思想，中心思想可以有三至七个论点支持，每个论点可以由三至七个论据支持。</p><h2 id="业务能力提升"><a href="#业务能力提升" class="headerlink" title="业务能力提升"></a>业务能力提升</h2><blockquote><p>缺少业务能力</p></blockquote><ol><li>讨论需求，产品的需求不合理，实现代价很高，无法发现，知道设计升值编码阶段才发现，自己累，效果不好。出力不讨好。</li><li>处理线上故障，被动接受别人的分析和推断容易背锅~</li><li>不熟悉业务，无法承当整体需求分析和方案设计任务，导致个人能力得不到锻炼，失去晋升机会。</li></ol><blockquote><p>摆脱上线既再见，提升业务能力</p></blockquote><ol><li>无论是前端，客户端还是服务端的技术人员，最好都花点时间，通过业务缓来了解业务的整个流程。</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>要展示出来自己做的东西，而且做的很好。不能闷声做事。做事让人看不到，是白做。要懂得总结，汇报。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;规划-工作计划&quot;&gt;&lt;a href=&quot;#规划-工作计划&quot; class=&quot;headerlink&quot; title=&quot;规划/工作计划&quot;&gt;&lt;/a&gt;规划/工作计划&lt;/h2&gt;&lt;h3 id=&quot;OKR&quot;&gt;&lt;a href=&quot;#OKR&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
      <category term="learn" scheme="https://www.lilhui.com/categories/learn/"/>
    
    
      <category term="work" scheme="https://www.lilhui.com/tags/work/"/>
    
      <category term="method" scheme="https://www.lilhui.com/tags/method/"/>
    
  </entry>
  
  <entry>
    <title>海量数据查询和存储</title>
    <link href="https://www.lilhui.com/2022/12/02/java/distributed/big_data/"/>
    <id>https://www.lilhui.com/2022/12/02/java/distributed/big_data/</id>
    <published>2022-12-02T09:19:55.000Z</published>
    <updated>2022-12-05T05:42:40.457Z</updated>
    
    <content type="html"><![CDATA[<h2 id="存储选型"><a href="#存储选型" class="headerlink" title="存储选型"></a>存储选型</h2><p>存储系统的选择，决定了系统的性能上限。</p><p>Mysql: 1000W以内</p><h2 id="如何技术选型"><a href="#如何技术选型" class="headerlink" title="如何技术选型"></a>如何技术选型</h2><p>技术选型不能脱离业务，业务决定技术选型。</p><ul><li>业务系统类型<br>在线业务系统OLTP,分析系统OLAP</li></ul><h3 id="选型步骤"><a href="#选型步骤" class="headerlink" title="选型步骤"></a>选型步骤</h3><ol><li><p>评估规模<br>评估规模，一般估两年以后的量。实际的量，跟老板的期望会有折扣。</p></li><li><p>数据库选择<br>如果数据数量在千万（1GB)：mysql首选。 </p></li></ol><p>数量亿级（1TB): 数据进行分库分表，分片等。<br>只能事先对数据进行聚合计算，然后再聚合后的数据进行查询，这种情况放在HDFS。</p><h3 id="成本考虑"><a href="#成本考虑" class="headerlink" title="成本考虑"></a>成本考虑</h3><p>比如购买Oracle服务。市场MySQL人更容易找到，成本就会更低。尽量选择普遍的技术。学习成本高低,是否有坑。</p><h2 id="如何存储埋点之类的海量数据"><a href="#如何存储埋点之类的海量数据" class="headerlink" title="如何存储埋点之类的海量数据"></a>如何存储埋点之类的海量数据</h2><p>这种数据写的量巨大，先进入队列。kafka,rocketMq。</p><h2 id="分析类系统如何选择存储"><a href="#分析类系统如何选择存储" class="headerlink" title="分析类系统如何选择存储"></a>分析类系统如何选择存储</h2><p>分析类存储的需求有四点</p><ol><li>分析的数据量，会比业务数据量高几个数量级。需要存储系统能够保存海量数据。</li><li>还要能在海量数据上进行聚合，如果要快速请求返回，分析和查询操作。GB,TB,PB级别的海量数据，这种业务在毫秒级响应是不可能的。</li><li>大多数情况下数据都是异步写入</li></ol><p>关键点，还是根据业务决定技术。查询- 选择存储系统和数据结构。</p><h3 id="京东的仓库"><a href="#京东的仓库" class="headerlink" title="京东的仓库"></a>京东的仓库</h3><p>运营过程产生的物流数据。智能补货系统要用，运力调度的系统要用。每个系统使用的方式不同。<br>京东智能补货，需求仓库间补货的最短路径。</p><p><strong>分析</strong>  </p><p>补货系统:地域性，通过地域分片数据，先查询距离近的分片在汇总成区域物流数据。得到最优的发货点。</p><h2 id="商品系统需要保存哪些数据"><a href="#商品系统需要保存哪些数据" class="headerlink" title="商品系统需要保存哪些数据"></a>商品系统需要保存哪些数据</h2><p>商品详情页保存哪些信息？<br>基本信息：标题，副标题，原价，价格，促销价<br>详细信息：商品参数，商品介绍，图片视频<br>其他信息：促销信息，推荐商品，评论，评价，配送信息，店铺信息</p><p>商品详情页：静态化。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;存储选型&quot;&gt;&lt;a href=&quot;#存储选型&quot; class=&quot;headerlink&quot; title=&quot;存储选型&quot;&gt;&lt;/a&gt;存储选型&lt;/h2&gt;&lt;p&gt;存储系统的选择，决定了系统的性能上限。&lt;/p&gt;
&lt;p&gt;Mysql: 1000W以内&lt;/p&gt;
&lt;h2 id=&quot;如何技术选型&quot;&gt;
      
    
    </summary>
    
      <category term="concurrent" scheme="https://www.lilhui.com/categories/concurrent/"/>
    
    
      <category term="bigdata" scheme="https://www.lilhui.com/tags/bigdata/"/>
    
  </entry>
  
  <entry>
    <title>RocksDB详解</title>
    <link href="https://www.lilhui.com/2022/12/02/java/distributed/rocksDB/"/>
    <id>https://www.lilhui.com/2022/12/02/java/distributed/rocksDB/</id>
    <published>2022-12-02T06:39:04.000Z</published>
    <updated>2022-12-05T05:47:28.296Z</updated>
    
    <content type="html"><![CDATA[<h2 id="RocksDB-详解"><a href="#RocksDB-详解" class="headerlink" title="RocksDB 详解"></a>RocksDB 详解</h2><blockquote><p>性能好，支持事务。</p></blockquote><p>秒杀库存扣减中使用了缓存 + Write-Ahead Logging 技术。</p><p>事务随机读写。Redo日志是追加文件顺序读写，性能差异有30-40倍。</p><p>事务的实现上，MySQL使用的是WAL机制来的。所有的修改都先被写到日志中，然后再被应用到系统重。包括<br>redo,undo.</p><p>RocksDB是Facebook开源的高性能，持久化的KV存储引擎，最初是Facebook数据库工程师团队基于 Google LevelDB开发。<br>一般很少使用到RocksDB保存数据。</p><p>越来越多的新生代数据库都选择RocksDB作为他们的存储引擎。比如：CockroachDB(蟑螂)一个开源，可伸缩，跨地域复制且<br>兼容事务的ACID特性的分布式数据库，思路来源于Google的全球性分布式数据库Spanner，其理念是将数据分布在多数据中心的<br>多台服务上。</p><p>YugabyteDB，Tidb 作为CockroachDB的竞争产品，底层也是RocksDB.</p><p>MyRocks使用RocksDB给MySQL做引擎，目的是取代现有的InnoDB存储引擎。MySQL的请兄弟MariaDB已经接纳了MyRocks作为<br>它的存储引擎。</p><p>实时计算引擎Flink,其State就是一个KV存储，它用的也是RocksDB</p><p>MongoDB，Cassandra,Hbase都在开发基于RocksDB的引擎。</p><p>原因是 RocksDB性能高，并且支持事务。</p><blockquote><p>随机读写能达到: 18w-19w qps<br>覆盖操作能达到：9w tps<br>多读单鞋：10w qps</p></blockquote><p>所以用RocksDB实现 Write-Ahead Logging</p><h3 id="RocksDB为什么这么快呢"><a href="#RocksDB为什么这么快呢" class="headerlink" title="RocksDB为什么这么快呢"></a>RocksDB为什么这么快呢</h3><p>内存+磁盘IO,读写性能主要取决于他的存储结构。MySql B+树,Oracle B*,RocksDB LSM-tree</p><h4 id="LSM-Tree"><a href="#LSM-Tree" class="headerlink" title="LSM-Tree"></a>LSM-Tree</h4><p>保证顺序写入的前提下，还能保证很好的查询性能。<br>WAL,跳表和一个分层的有序表（sorted String table,SSTable).LSM-Tree专门为key-value设计的<br>存储系统，以牺牲部分读性能为代价提高写入性能。通常适合于写多读上的场景。</p><p>LSM-Tree 描述图如下 </p><p><img src="https://images.lilhui.com/28ee3b34af9b86ce6288179da1edd623" alt="图片"></p><p>在SSD搞并行下，扩展LevelDB以显示利用SSD的多通道，优化并发I/O请求的调度和调度策略，将常规SSD<br>上运行LevelDB的吞吐量再提高4倍。</p><p>Log写入是使用的WAL机制，顺序写。</p><p>MemTable，跳表（类似红黑树)</p><p>c端过来写MemTable和log后就可以返回了。MemTable 32M,写满后会Dump成ImultableMemTable（不可变）<br>如果write继续，会重新创建一个MemTable.</p><blockquote><p>问题：写入磁盘，部分有序全局无序。</p></blockquote><p>解决方案：Level0,Level1，会进行合并。</p><p>SSTable分层，越热的数据越靠上。对热数据比较友好。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;RocksDB-详解&quot;&gt;&lt;a href=&quot;#RocksDB-详解&quot; class=&quot;headerlink&quot; title=&quot;RocksDB 详解&quot;&gt;&lt;/a&gt;RocksDB 详解&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;性能好，支持事务。&lt;/p&gt;
&lt;/blockquot
      
    
    </summary>
    
      <category term="concurrent" scheme="https://www.lilhui.com/categories/concurrent/"/>
    
    
      <category term="rocksDB" scheme="https://www.lilhui.com/tags/rocksDB/"/>
    
  </entry>
  
  <entry>
    <title>多数据源项目下dubbo调用，获取的数据源不正确</title>
    <link href="https://www.lilhui.com/2022/12/01/bugfix/bugfix_0/"/>
    <id>https://www.lilhui.com/2022/12/01/bugfix/bugfix_0/</id>
    <published>2022-12-01T06:51:37.000Z</published>
    <updated>2022-12-05T06:53:16.581Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>每天定时任务会跑一次下个月的表是否存在，然后进行建表。dubbo调用。在线程上配置了 datasource选取规则。</p><p>初始化的时候会判断是否有建下个月的表，这个操作需要通过schema.xxx操作。但是shardingsphere不支持schema.xxx操作。所以我们创建了两个数据源，shardingDatasource和dataSource</p><p>1：如果 schema.xxx操作的话用 dataSource。<br>2：非schema.xxx操作的 用shardingDataSource。</p><p>在线程执行的时候通过ThreadLocal变量缓存dataSource。但是忘记cleanThreadLocal值了。<br>在短连接的时候是正常的，在长链接的调用下会有以下错误逻辑发生比如dubbo调用下的异常：</p><p>1：如果某次执行 获取了一个 dubboThread1，这个线程执行 先获取了未分表的数据源。并缓存了，如果没有清除数据源，下次拿到的还是这个数据源。</p><p>2：dubbo 协议的provider-consumer 链接是1：1，所以执行一次后，这个链接并没有被销毁，某个下单请求获取到了 这个dubboThread1，由于这个线程链接已经在1 操作中获取到了未分表的数据源 dataSource。就在母表上进行了业务操作。创建订单成功，但是订单所在的表示错误的。</p><p>3：回调来的请求操作是另外一个节点进行处理，获取到的是 dubboThread2 这个dubboThread2 未获取到数据源，所以按照上面的规则进行初始化数据源并缓存 得到shardingDatasource。根据订单号选择的是订单号归属的分表，此时无法找到这个订单。所以报错。</p><h2 id="bug修复"><a href="#bug修复" class="headerlink" title="bug修复"></a>bug修复</h2><p>在定时任务结束后清理dataSource类型缓存。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;每天定时任务会跑一次下个月的表是否存在，然后进行建表。dubbo调用。在线程上配置了 datasource选取规则。&lt;/p&gt;
&lt;p&gt;初始化的
      
    
    </summary>
    
      <category term="bug" scheme="https://www.lilhui.com/categories/bug/"/>
    
    
      <category term="dubbo" scheme="https://www.lilhui.com/tags/dubbo/"/>
    
      <category term="bug" scheme="https://www.lilhui.com/tags/bug/"/>
    
  </entry>
  
  <entry>
    <title>Spring boot gateway 网关压测时配置异常，导致服务返回405</title>
    <link href="https://www.lilhui.com/2022/12/01/bugfix/bugfix_1/"/>
    <id>https://www.lilhui.com/2022/12/01/bugfix/bugfix_1/</id>
    <published>2022-12-01T06:47:11.000Z</published>
    <updated>2022-12-05T05:48:02.246Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>网关选用的是Spring-boot-gateway，网关配置使用nacos持久化。</p><h2 id="Spring的网关源码分析"><a href="#Spring的网关源码分析" class="headerlink" title="Spring的网关源码分析"></a>Spring的网关源码分析</h2><p>通过网关的源码分析，StripPrefixGatewayFilterFactory 通过parts值来截断请求的前缀。正常的是1，在执行过程中被刷新成了5。导致截断请求错误。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   <span class="keyword">if</span> (<span class="keyword">this</span>.running.compareAndSet(<span class="keyword">false</span>, <span class="keyword">true</span>)) &#123;</span><br><span class="line">     # 30s 触发一次定时任务</span><br><span class="line">      <span class="keyword">this</span>.watchFuture = <span class="keyword">this</span>.taskScheduler.scheduleWithFixedDelay(</span><br><span class="line">            <span class="keyword">this</span>::nacosServicesWatch, <span class="keyword">this</span>.properties.getWatchDelay());</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nacosServicesWatch</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   <span class="comment">// 此处nacos 啥都没干, 就强制发送一个更新命令, 正常情况需要判断 service 是否存在更新</span></span><br><span class="line">   <span class="comment">// 因此此处可以作为修复bug的触发点</span></span><br><span class="line">   <span class="comment">// nacos doesn't support watch now , publish an event every 30 seconds.</span></span><br><span class="line">   <span class="keyword">this</span>.publisher.publishEvent(</span><br><span class="line">         <span class="keyword">new</span> HeartbeatEvent(<span class="keyword">this</span>, nacosWatchIndex.getAndIncrement()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="路由配置刷新机制"><a href="#路由配置刷新机制" class="headerlink" title="路由配置刷新机制"></a>路由配置刷新机制</h2><p>Spring gateway 启动后会缓存路由配置，并且，每隔30秒会从缓存刷新配置到具体的路由执行类。<br>在刷新路由配置的方法里加入了监控日志：<br>RouteDefinitionRouteLocator.loadGatewayFilters</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">ConfigurationUtils.bind(configuration, properties,</span><br><span class="line">      factory.shortcutFieldPrefix(), definition.getName(), validator);</span><br><span class="line"></span><br><span class="line">if (configuration instanceof StripPrefixGatewayFilterFactory.Config) &#123;</span><br><span class="line">   StripPrefixGatewayFilterFactory.Config stripConfig = (StripPrefixGatewayFilterFactory.Config)configuration;</span><br><span class="line">   if (stripConfig.getParts() &gt; 2) &#123;</span><br><span class="line">      String errorMessage = &quot;parts 异常：&quot; +  stripConfig.getParts()</span><br><span class="line">            + &quot;definition:&quot; + definition</span><br><span class="line">            + &quot;properties:&quot; + properties</span><br><span class="line">            + &quot;id:&quot; + id;</span><br><span class="line">      log.error(errorMessage, new RuntimeException(errorMessage));</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>properties 是个Map，存放的是待刷新的part值，configuration 是被刷新的配置类，有一个属性 int parts。通过网关通过ConfigurationUtils.bind 来注入 configuration中的parts值。<br>以上代码修改后的异常日志：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">2022-07-15 13:46:38,233 - parts 异常：5definition:FilterDefinition&#123;name=&apos;StripPrefix&apos;, args=&#123;parts=1&#125;&#125;properties:&#123;parts=1&#125;id:pay-api-web</span><br><span class="line">java.lang.RuntimeException: parts 异常：5definition:FilterDefinition&#123;name=&apos;StripPrefix&apos;, args=&#123;parts=1&#125;&#125;properties:&#123;parts=1&#125;id:pay-api-web</span><br><span class="line">at org.springframework.cloud.gateway.route.RouteDefinitionRouteLocator.loadGatewayFilters(RouteDefinitionRouteLocator.java:183)</span><br><span class="line">at org.springframework.cloud.gateway.route.RouteDefinitionRouteLocator.getFilters(RouteDefinitionRouteLocator.java:212)</span><br><span class="line">at org.springframework.cloud.gateway.route.RouteDefinitionRouteLocator.convertToRoute(RouteDefinitionRouteLocator.java:143)</span><br><span class="line">at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:100)</span><br><span class="line">at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:664)</span><br></pre></td></tr></table></figure><p>可以看到在绑定后的 值是5. 但是properties里的是 {parts=1}。 说明bug发生在</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ConfigurationUtils.bind(configuration, properties,</span><br><span class="line">      factory.shortcutFieldPrefix(), definition.getName(), validator);</span><br></pre></td></tr></table></figure><p>这一行ConfigurationUtils.bind 调用的是Spring 底层JavaBeanBinder的bind方法<br>进一步分析JavaBeanBinder.bind</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">private &lt;T&gt; boolean bind(BeanSupplier&lt;T&gt; beanSupplier, BeanPropertyBinder propertyBinder, BeanProperty property) &#123;</span><br><span class="line">   String propertyName = property.getName();</span><br><span class="line">   ResolvableType type = property.getType();</span><br><span class="line">   Supplier&lt;Object&gt; value = property.getValue(beanSupplier);</span><br><span class="line">   Annotation[] annotations = property.getAnnotations();</span><br><span class="line">   //这行在设置后返回bound=5。有错！</span><br><span class="line">   Object bound = propertyBinder.bindProperty(propertyName,</span><br><span class="line">         Bindable.of(type).withSuppliedValue(value).withAnnotations(annotations));</span><br><span class="line">   if (bound == null) &#123;</span><br><span class="line">      return false;</span><br><span class="line">   &#125;</span><br><span class="line">   if (property.isSettable()) &#123;</span><br><span class="line">      property.setValue(beanSupplier, bound);</span><br><span class="line">   &#125;</span><br><span class="line">   else if (value == null || !bound.equals(value.get())) &#123;</span><br><span class="line">      throw new IllegalStateException(&quot;No setter found for property: &quot; + property.getName());</span><br><span class="line">   &#125;</span><br><span class="line">   return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Object bound = propertyBinder.bindProperty(propertyName,</span><br><span class="line">         Bindable.of(type).withSuppliedValue(value).withAnnotations(annotations));</span><br></pre></td></tr></table></figure><p>JavaBeanBinder 是spring boot底层bean属性处理类。</p><h2 id="bind过程分析"><a href="#bind过程分析" class="headerlink" title="bind过程分析"></a>bind过程分析</h2><p>propertyBinder.bindProperty的后续调用链路<br>-&gt;Binder.bind<br>-&gt;BindConverter.cover<br>-&gt;TypeConverterSupport.convertIfNecessary<br>-&gt;TypeConverterSupport.doConvertValue<br>-&gt;TypeConverterSupport.doConvertTextValue</p><p>doConvertTextValue方法有两行代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">editor.setAsText(newTextValue);</span><br><span class="line">return editor.getValue();</span><br></pre></td></tr></table></figure><p>editor是通过PropertyEditorRegistrySupport.createDefaultEditors()初始化，一个类型一个对象。在执行的时候通过propertyEditorRegistry.getDefaultEditor(requiredType)获取。 如果requiredType相同，获取的就是同一个对象。<br>所以当有2次调用获取的editor相同，就可能有并发问题。时序如下：<br>A：editor.setAsText(1)<br>B：editor.setAsText(5)<br>A: return editor.getValue();<br>此时A获取到的就是5。与期望的值不同。造成执行错误。</p><h2 id="错误分析总结"><a href="#错误分析总结" class="headerlink" title="错误分析总结"></a>错误分析总结</h2><ol><li>spring cloud gateway和nacos30秒一次心跳，每次心跳会从内存中刷新路由规则到执行对象。<br>刷新过程调用的是ConfigurationUtils.bind方法，此方法依赖的PropertyEditor。对象对于每个类型是单例的，如果同时有2个相同类型的值进行bind，可能产生并发问题。</li><li>压测时gateway的负载高。RouteDefinitionRouteLocator.getRoutes()方法并发调用RouteDefinitionRouteLocator.loadGatewayFilters。</li><li>RouteDefinitionRouteLocator.loadGatewayFilters依赖的方法ConfigurationUtils.bind有并发问题 导致路由配置错乱。</li></ol><h2 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h2><p>重现方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.google.common.collect.Lists;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang3.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.junit.Before;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"><span class="keyword">import</span> org.junit.runner.RunWith;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.BeansException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.BeanFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.BeanFactoryAware;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.filter.FilterDefinition;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.filter.GatewayFilter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.filter.OrderedGatewayFilter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.filter.factory.GatewayFilterFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.filter.factory.StripPrefixGatewayFilterFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.filter.factory.StripPrefixGatewayFilterFactory.Config;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.support.ConfigurationUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.gateway.support.HasRouteId;</span><br><span class="line"><span class="keyword">import</span> org.springframework.core.Ordered;</span><br><span class="line"><span class="keyword">import</span> org.springframework.expression.spel.standard.SpelExpressionParser;</span><br><span class="line"><span class="keyword">import</span> org.springframework.test.context.ActiveProfiles;</span><br><span class="line"><span class="keyword">import</span> org.springframework.test.context.junit4.SpringRunner;</span><br><span class="line"><span class="keyword">import</span> org.springframework.validation.Validator;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> littlehui</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span> TODO</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2022/7/18 22:45</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@RunWith</span>(SpringRunner<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">@<span class="title">SpringBootTest</span>()</span></span><br><span class="line">@ActiveProfiles("local")</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RouteDefinitionRouteLocatorTest</span>   <span class="keyword">implements</span> <span class="title">BeanFactoryAware</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">   Logger logger = LoggerFactory.getLogger(RouteDefinitionRouteLocatorTest<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Autowired</span></span><br><span class="line">   <span class="keyword">private</span> Validator validator;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> SpelExpressionParser parser = <span class="keyword">new</span> SpelExpressionParser();</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span> BeanFactory beanFactory;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Autowired</span></span><br><span class="line">   <span class="keyword">private</span> List&lt;GatewayFilterFactory&gt; gatewayFilterFactoryList;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, GatewayFilterFactory&gt; gatewayFilterFactories = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">concurrentTest</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * assume we have below gateway route config</span></span><br><span class="line"><span class="comment">       *</span></span><br><span class="line"><span class="comment">       - id: r1</span></span><br><span class="line"><span class="comment">       uri: lb://service1</span></span><br><span class="line"><span class="comment">       predicates:</span></span><br><span class="line"><span class="comment">       - Path=/gateway/auth/**</span></span><br><span class="line"><span class="comment">       filters:</span></span><br><span class="line"><span class="comment">       - StripPrefix=1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">       - id: r2</span></span><br><span class="line"><span class="comment">       uri: lb://service2</span></span><br><span class="line"><span class="comment">       predicates:</span></span><br><span class="line"><span class="comment">       - Path=/gateway/api/business/**</span></span><br><span class="line"><span class="comment">       filters:</span></span><br><span class="line"><span class="comment">       - StripPrefix=2</span></span><br><span class="line"><span class="comment">       * then we can construct the  FilterDefinition to mock this config</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line"></span><br><span class="line">      FilterDefinition f1 = <span class="keyword">new</span> FilterDefinition();</span><br><span class="line">      f1.setName(<span class="string">"StripPrefix"</span>);</span><br><span class="line">      f1.setArgs(<span class="keyword">new</span> HashMap&lt;&gt;());</span><br><span class="line">      f1.getArgs().put(<span class="string">"_genkey_0"</span>, <span class="string">"1"</span>);</span><br><span class="line"></span><br><span class="line">      FilterDefinition f2 = <span class="keyword">new</span> FilterDefinition();</span><br><span class="line">      f2.setName(<span class="string">"Retry"</span>);</span><br><span class="line">      f2.setArgs(<span class="keyword">new</span> HashMap&lt;&gt;());</span><br><span class="line">      f2.getArgs().put(<span class="string">"retries"</span>, <span class="string">"5"</span>);</span><br><span class="line"></span><br><span class="line">      Thread t1 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">         <span class="meta">@Override</span></span><br><span class="line">         <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (!Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">               loadGatewayFilters(<span class="string">"r1"</span>, Lists.newArrayList(f1));</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;, <span class="string">"prefix1"</span>);</span><br><span class="line"></span><br><span class="line">      Thread t2 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">         <span class="meta">@Override</span></span><br><span class="line">         <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (!Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">               loadGatewayFilters(<span class="string">"r2"</span>, Lists.newArrayList(f2));</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;, <span class="string">"prefix2"</span>);</span><br><span class="line"></span><br><span class="line">      Thread t22 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">         <span class="meta">@Override</span></span><br><span class="line">         <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (!Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">               loadGatewayFilters(<span class="string">"r2"</span>, Lists.newArrayList(f2));</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;, <span class="string">"prefix2"</span>);</span><br><span class="line"></span><br><span class="line">      Thread t11 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">         <span class="meta">@Override</span></span><br><span class="line">         <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (!Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">               loadGatewayFilters(<span class="string">"r1"</span>, Lists.newArrayList(f1));</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;, <span class="string">"prefix1"</span>);</span><br><span class="line"></span><br><span class="line">      t1.start();</span><br><span class="line">      t2.start();</span><br><span class="line">      t11.start();</span><br><span class="line">      t22.start();</span><br><span class="line"></span><br><span class="line">      <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">         <span class="keyword">if</span> (t1.isInterrupted() || t11.isInterrupted() || t2.isInterrupted() || t22.isInterrupted()) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="function">List&lt;GatewayFilter&gt; <span class="title">loadGatewayFilters</span><span class="params">(String id,</span></span></span><br><span class="line"><span class="function"><span class="params">                                          List&lt;FilterDefinition&gt; filterDefinitions)</span> </span>&#123;</span><br><span class="line">      ArrayList&lt;GatewayFilter&gt; ordered = <span class="keyword">new</span> ArrayList&lt;&gt;(filterDefinitions.size());</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; filterDefinitions.size(); i++) &#123;</span><br><span class="line">         FilterDefinition definition = filterDefinitions.get(i);</span><br><span class="line">         GatewayFilterFactory factory = <span class="keyword">this</span>.gatewayFilterFactories</span><br><span class="line">                 .get(definition.getName());</span><br><span class="line">         <span class="keyword">if</span> (factory == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</span><br><span class="line">                    <span class="string">"Unable to find GatewayFilterFactory with name "</span></span><br><span class="line">                            + definition.getName());</span><br><span class="line">         &#125;</span><br><span class="line">         Map&lt;String, String&gt; args = definition.getArgs();</span><br><span class="line">         <span class="keyword">if</span> (logger.isDebugEnabled()) &#123;</span><br><span class="line">            logger.debug(<span class="string">"RouteDefinition "</span> + id + <span class="string">" applying filter "</span> + args + <span class="string">" to "</span></span><br><span class="line">                    + definition.getName());</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         Map&lt;String, Object&gt; properties = factory.shortcutType().normalize(args,</span><br><span class="line">                 factory, <span class="keyword">this</span>.parser, <span class="keyword">this</span>.beanFactory);</span><br><span class="line"></span><br><span class="line">         Object configuration = factory.newConfig();</span><br><span class="line"></span><br><span class="line"><span class="comment">/*          //加锁解决</span></span><br><span class="line"><span class="comment">            synchronized (this) &#123;</span></span><br><span class="line"><span class="comment">                ConfigurationUtils.bind(configuration, properties,</span></span><br><span class="line"><span class="comment">                        factory.shortcutFieldPrefix(), definition.getName(), validator);</span></span><br><span class="line"><span class="comment">            &#125;*/</span></span><br><span class="line"></span><br><span class="line">         ConfigurationUtils.bind(configuration, properties,</span><br><span class="line">                 factory.shortcutFieldPrefix(), definition.getName(), validator);</span><br><span class="line">         <span class="comment">// some filters require routeId</span></span><br><span class="line">         <span class="comment">// <span class="doctag">TODO:</span> is there a better place to apply this?</span></span><br><span class="line">         <span class="keyword">if</span> (configuration <span class="keyword">instanceof</span> HasRouteId) &#123;</span><br><span class="line">            HasRouteId hasRouteId = (HasRouteId) configuration;</span><br><span class="line">            hasRouteId.setRouteId(id);</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         GatewayFilter gatewayFilter = factory.apply(configuration);</span><br><span class="line"></span><br><span class="line">         <span class="comment">//asset statement start</span></span><br><span class="line">         <span class="keyword">if</span> (configuration <span class="keyword">instanceof</span> StripPrefixGatewayFilterFactory.Config) &#123;</span><br><span class="line">            <span class="keyword">int</span> parts = ((Config) configuration).getParts();</span><br><span class="line">            <span class="keyword">if</span> (StringUtils.equals(<span class="string">"r1"</span>, id) &amp;&amp; !StringUtils.equals(<span class="string">"1"</span>, String.valueOf(parts))) &#123;</span><br><span class="line">               logger.error(<span class="string">"for router id r1,expect parts is 1,but actual is &#123;&#125;"</span>, parts);</span><br><span class="line">               Thread.currentThread().interrupt();</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (StringUtils.equals(<span class="string">"r2"</span>, id) &amp;&amp; !StringUtils</span><br><span class="line">                    .equals(<span class="string">"5"</span>, String.valueOf(parts))) &#123;</span><br><span class="line">               logger.error(<span class="string">"for router id r2,expect parts is 2,but actual is &#123;&#125;"</span>, parts);</span><br><span class="line">               Thread.currentThread().interrupt();</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">//asset statement end</span></span><br><span class="line"></span><br><span class="line">         <span class="keyword">if</span> (gatewayFilter <span class="keyword">instanceof</span> Ordered) &#123;</span><br><span class="line">            ordered.add(gatewayFilter);</span><br><span class="line">         &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            ordered.add(<span class="keyword">new</span> OrderedGatewayFilter(gatewayFilter, i + <span class="number">1</span>));</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> ordered;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setBeanFactory</span><span class="params">(BeanFactory beanFactory)</span> <span class="keyword">throws</span> BeansException </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.beanFactory = beanFactory;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Before</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      gatewayFilterFactoryList.forEach(</span><br><span class="line">              factory -&gt; <span class="keyword">this</span>.gatewayFilterFactories.put(factory.name(), factory));</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;网关选用的是Spring-boot-gateway，网关配置使用nacos持久化。&lt;/p&gt;
&lt;h2 id=&quot;Spring的网关源码分析&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="bug" scheme="https://www.lilhui.com/categories/bug/"/>
    
    
      <category term="gateway" scheme="https://www.lilhui.com/tags/gateway/"/>
    
  </entry>
  
  <entry>
    <title>电商项目数据高可用架构设计</title>
    <link href="https://www.lilhui.com/2022/12/01/java/practice/trade_1/"/>
    <id>https://www.lilhui.com/2022/12/01/java/practice/trade_1/</id>
    <published>2022-12-01T06:37:30.000Z</published>
    <updated>2022-12-01T06:38:59.569Z</updated>
    
    <content type="html"><![CDATA[<h2 id="缓存数据库一致"><a href="#缓存数据库一致" class="headerlink" title="缓存数据库一致"></a>缓存数据库一致</h2><p>Canal : 基于Binlog的同步中间件。</p><p>Canal伪装成Mysql的从节点。收到Binlog 解析变更的binlog。</p><p>Canal Server - 接收Mysql 日志流。<br>Canal Client - 处理解析后的操作。可以在业务进行实现。</p><p>Canal也可以推送到Mq,kafka等。</p><p>RabbitMq不支持。Rocket可以支持。</p><h2 id="Mysql检查"><a href="#Mysql检查" class="headerlink" title="Mysql检查"></a>Mysql检查</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">show VARIABLES like %bin_log%</span><br><span class="line">show VARIABLES like %binlog_format%</span><br><span class="line">show VARIABLES like %server_id%</span><br></pre></td></tr></table></figure><ul><li>修改：</li></ul><p>my.conf</p><h2 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h2><p>创建canal用户，用来复制Mysql权限。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> mysql.user;</span><br></pre></td></tr></table></figure><h2 id="canal配置文件"><a href="#canal配置文件" class="headerlink" title="canal配置文件"></a>canal配置文件</h2><p>几个关键配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">//支持的表，支持正则表达黑丝</span><br><span class="line">canal.instance.filter.regex =</span><br><span class="line">canal.destination =</span><br></pre></td></tr></table></figure><ul><li>启动canal server</li><li>启动canal client</li></ul><h2 id="Binlog"><a href="#Binlog" class="headerlink" title="Binlog"></a>Binlog</h2><h3 id="Binlog的格式"><a href="#Binlog的格式" class="headerlink" title="Binlog的格式"></a>Binlog的格式</h3><ol><li>Row:幂等操作，所以canal选择这种。</li><li>Sql:可以幂等也可能非幂等。</li><li>Mix</li></ol><p>Canal 适用 Row格式Mysql Binlog</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;缓存数据库一致&quot;&gt;&lt;a href=&quot;#缓存数据库一致&quot; class=&quot;headerlink&quot; title=&quot;缓存数据库一致&quot;&gt;&lt;/a&gt;缓存数据库一致&lt;/h2&gt;&lt;p&gt;Canal : 基于Binlog的同步中间件。&lt;/p&gt;
&lt;p&gt;Canal伪装成Mysql的从节点。收
      
    
    </summary>
    
      <category term="practice" scheme="https://www.lilhui.com/categories/practice/"/>
    
    
      <category term="电商，数据高可用" scheme="https://www.lilhui.com/tags/%E7%94%B5%E5%95%86%EF%BC%8C%E6%95%B0%E6%8D%AE%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>大型网站的高并发读写总结</title>
    <link href="https://www.lilhui.com/2022/12/01/java/distributed/concurrent_read_write/"/>
    <id>https://www.lilhui.com/2022/12/01/java/distributed/concurrent_read_write/</id>
    <published>2022-12-01T06:22:20.000Z</published>
    <updated>2022-12-05T05:45:10.782Z</updated>
    
    <content type="html"><![CDATA[<h2 id="高并发的读写场景解析"><a href="#高并发的读写场景解析" class="headerlink" title="高并发的读写场景解析"></a>高并发的读写场景解析</h2><p>不管什么系统，都是做读和写。</p><h3 id="侧重”高并发读”的系统"><a href="#侧重”高并发读”的系统" class="headerlink" title="侧重”高并发读”的系统"></a>侧重”高并发读”的系统</h3><p>存储引擎 ES,solr等<br>终端用户-搜索（读）-&gt; 搜索引擎 &lt;-发布（写）- 内容生产者</p><ol><li>数量级的差别：终端用户成千上百万个。生产者是公司内部产生，数量级不会太高。</li><li>响应时间。读的响应时间要求在毫秒级。</li></ol><h3 id="侧重”高并发写”的系统"><a href="#侧重”高并发写”的系统" class="headerlink" title="侧重”高并发写”的系统"></a>侧重”高并发写”的系统</h3><p>广告位竞拍，扣费类的。如baidu的业务模式，抖音的广告投放扣费等。</p><ol><li>按照浏览次数，点击收费。需要写的实时性。C端每次浏览点击都要进行主账号上的扣减。</li></ol><h3 id="同时有-“高并发读”-和-“高并发写”"><a href="#同时有-“高并发读”-和-“高并发写”" class="headerlink" title="同时有 “高并发读” 和 “高并发写”"></a>同时有 “高并发读” 和 “高并发写”</h3><ol><li>电商的库存系统和秒杀系统</li><li>支付系统，微信红包</li><li>IM,微博朋友圈</li></ol><p>不同场景面面对的高并发压力不同，应对高并发读和高并发写的策略是不同的。</p><h2 id="高并发读常见解决策略"><a href="#高并发读常见解决策略" class="headerlink" title="高并发读常见解决策略"></a>高并发读常见解决策略</h2><h3 id="本地缓存或集中式缓存"><a href="#本地缓存或集中式缓存" class="headerlink" title="本地缓存或集中式缓存"></a>本地缓存或集中式缓存</h3><p>本地Map缓存<br>Redis缓存</p><ul><li>集中式缓存需要避免的问题</li></ul><ol><li>缓存高可用</li><li>缓存穿透</li><li>缓存击穿</li><li>大量热key过期</li></ol><h3 id="读副本"><a href="#读副本" class="headerlink" title="读副本"></a>读副本</h3><p>Mysql Master/Slave 增加一堆Slave（网易的Mysql用法）几百台Mysql slave树。</p><h3 id="CND-静态文件加速，动静分离"><a href="#CND-静态文件加速，动静分离" class="headerlink" title="CND/静态文件加速，动静分离"></a>CND/静态文件加速，动静分离</h3><ol><li>静态内容，数据不变。html,js,css,图片等，是静态，分发到CDN</li><li>动态内容，用户的信息，实时查询的数据，这些放在服务器进行处理。</li></ol><h3 id="并发读"><a href="#并发读" class="headerlink" title="并发读"></a>并发读</h3><h3 id="异步RPC"><a href="#异步RPC" class="headerlink" title="异步RPC"></a>异步RPC</h3><p>串行读 -&gt; 并发读</p><ol><li>在链路上的请求 并发执行。</li><li>冗余请求 Jeaf Dean 写的 The Tail at scale。肠胃耗时优化的经验。<br>案例：一个用户的请求需要100台服务器联合处理，每个服务器有1%的概率发生调用延迟（1秒延迟)。那么C端用户来说，响应时间<br>大于1秒的概率是63%<br>怎么算出来的呢？如果用户请求响应时间小于1s那么 100台服务器响应时间都小于1s。这个概念是100个99%相乘。<br>所以是 1- 0.99 100次方。 问题就很严重。</li></ol><p>此问题的解决方法：冗余请求。客户端同时向多台服务器发送请求，哪个返回快就用哪个，其他的丢弃。这种方法系统的调用量会翻倍。<br>调整一下：如果客户端在一定时间内没有收到服务端的响应，则马上给另一台或者多台发送同样的请求。客户端等待第一个响应到达之后，立即终止其他请求的处理<br>“一定时间” 定义为 ： 内部服务95%请求的响应时间。这种方法称之为 “对冲请求”。</p><p>测试数据：采用这种方法，可以仅用2%的额外请求将系统99.9%的请求响应时间从1800ms降低到74ms.</p><p>牛逼的 The Tail at Scale</p><p>另一个方法：<br>捆绑请求。 上游对下游服务器进行探测，找负载低的。在请求的时候顺便探测。</p><p>核心：用更多的机器来减少延迟，扛起高并发读</p><h3 id="重写轻读"><a href="#重写轻读" class="headerlink" title="重写轻读"></a>重写轻读</h3><h4 id="微博-feeds流的实现"><a href="#微博-feeds流的实现" class="headerlink" title="微博 feeds流的实现"></a>微博 feeds流的实现</h4><p>Feeds流 关注的n个人的微博进行排序成一个列表。有变更，冗余保存起来。<br>为每个人增加一个Feeds流，叫做收件箱。</p><p>将复杂的读逻辑，通过重写的方式，进行了简化。  </p><p>实现的方案：<br>Redis list 缓存。并对list大小进行限制。并且持久化，分库分表。根据业务进行设置分片键。</p><p>以上解决了读的高并发，又引来一个问题：假设一个用户的粉丝很多，每个粉丝的邮箱都复制一份，计算<br>和延迟会很大。比如某个明星有粉丝8000万，如果复制8000万份，对系统来说是个沉重的负担。</p><p>解决方法：回到最初的思路，在读的时候进行实时聚合。用’拉’的方式进行获取。</p><p>将粉丝用户分组，份成在线和不在线。只推送在线的粉丝。系统维护一个全局的，在线列表</p><p>对于读的一端一个用户关注的人当中。有的人是推给他的。有的人需要他去拉的，需要把两者聚合起来，再按时间排序，然后分页显示，这就是’推拉结合’。</p><h3 id="多表的关联查询：宽表于搜索引擎"><a href="#多表的关联查询：宽表于搜索引擎" class="headerlink" title="多表的关联查询：宽表于搜索引擎"></a>多表的关联查询：宽表于搜索引擎</h3><p>多表关联到情况下，通过加Slave解决。这种方法在没有分库的情况下可以实现。</p><p>如果已经分库了，那需要多个查询进行聚合，无法使用原声的Join功能。只能从程序中分别从两个库读取，再做聚合。</p><p>存在一个问题：如果需要把聚合出来的数据按某个维度进行排序分页，这个维度是临时计算出来的维度，而不是数据库本来就有的维度。</p><p>由于无法使用数据库的排序和分页功能，也无法再内存中通过实时计算来实现排序、分页此时如何处理？</p><p>采用类似微博重写轻读的思路：提前把关联数据计算好，存在一个地方，读的时候直接去读聚合好的数据，而不是读的时候去做join.</p><p>具体的操作：准备一张宽表，把关联表的数据算好后保存在宽表里。依据实际情况，定时计算，也可能任何一张原始表发生变化时进行宽表数据的计算。</p><p>也可以使用ES类的搜索引擎来实现：把多个表的join结果做成一个个的文档，放在搜索引擎里。可以林火实现排序和分页查询。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>读写分离Command Query Responsiblility Spareation<br>分别为读和写设计不同的数据结构。在C端，当同时面临读和写的高并发压力时，把系统分成读和写两个视角来设计，各自设计适合搞并发和读写的数据结构或模型。</p><p>缓存其实是读写分离的一个简化，或者是说特例，写业务DB和读缓存用了基本一样的数据结构。</p><h2 id="高并发写常见解决策略"><a href="#高并发写常见解决策略" class="headerlink" title="高并发写常见解决策略"></a>高并发写常见解决策略</h2><h3 id="数据分片"><a href="#数据分片" class="headerlink" title="数据分片"></a>数据分片</h3><p>数据分片后利用多台机器的资源进行分发写操作。</p><p>MySQL: 分库分表<br>Redis: Redis Cluster集群<br>ES: 分布式索引 sharder<br>10亿个网页或商品分成n份，建成n个小的索引。一个查询请求来了，并行地在n各索引上查询。</p><h3 id="异步化"><a href="#异步化" class="headerlink" title="异步化"></a>异步化</h3><p>异步化，无处不在。  </p><p>发送请求立即响应返回。客户端轮询或者其他方式进行获取结果。<br>客户端发起一个Http请求，不等结果，立即发送2，3个。数据库的事务提交Write-aheadLog 。</p><h4 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h4><ul><li>电商系统的拆单功能  </li><li>短信验证码或者登录</li><li>写内存 + Write-Ahead 日志。</li></ul><p>MySQL为了提高磁盘IO性能，使用了 Write-Ahead日志。也就是RedoLog。<br>高并发扣减MySQL中的账户余额，或者电商系统中扣减库存，直接在数据库中口，数据库可能扛不住。<br>可以在Redis中先扣，然后同时落地一条日志（日志可以在一个高可靠的消息中间件或数据库中插入一条条日志）。<br>当Redis宕机，把所有的日志重放完毕，再用数据库中的数据初始化Redis的数据。</p><h3 id="批量写"><a href="#批量写" class="headerlink" title="批量写"></a>批量写</h3><blockquote><p>广告计费的合并扣费</p></blockquote><p>假设有10个用户，对于1个广澳，每个用户点了1次，就意味着同1个广告的主账号要扣10次钱，每次扣1块（假设点击1次扣1次）如果改成<br>合并扣费，就是1次扣10块钱。</p><p>扣费模块一次性从持久化消息队列中取多条消息，对多条消息按照广告的主账号进行分类然后进行扣费。</p><blockquote><p>MySQL的小事务合并机制</p></blockquote><p>MySQL内核会自动合并小事务进行批量的事务操作。<br>Canal里 进行更新的时候，进行合并事务执行。</p><h3 id="侧重-‘高并发写’-的系统"><a href="#侧重-‘高并发写’-的系统" class="headerlink" title="侧重 ‘高并发写’ 的系统"></a>侧重 ‘高并发写’ 的系统</h3><blockquote><p>扣费系统:</p></blockquote><h2 id="商城秒杀中RocketDB数据详解"><a href="#商城秒杀中RocketDB数据详解" class="headerlink" title="商城秒杀中RocketDB数据详解"></a>商城秒杀中RocketDB数据详解</h2><p>异步下单 Redis挂了，但是单没有正常发出去。这时候哪里去找单呢？<br>引入写内存+ write ahead日志。将日志写到RocketDB</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;高并发的读写场景解析&quot;&gt;&lt;a href=&quot;#高并发的读写场景解析&quot; class=&quot;headerlink&quot; title=&quot;高并发的读写场景解析&quot;&gt;&lt;/a&gt;高并发的读写场景解析&lt;/h2&gt;&lt;p&gt;不管什么系统，都是做读和写。&lt;/p&gt;
&lt;h3 id=&quot;侧重”高并发读”的系统
      
    
    </summary>
    
      <category term="concurrent" scheme="https://www.lilhui.com/categories/concurrent/"/>
    
    
      <category term="高并发" scheme="https://www.lilhui.com/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>【秒杀系统4】订单链路兜底方案，限流和熔断降级</title>
    <link href="https://www.lilhui.com/2022/11/30/java/distributed/seckill_4/"/>
    <id>https://www.lilhui.com/2022/11/30/java/distributed/seckill_4/</id>
    <published>2022-11-30T02:54:26.000Z</published>
    <updated>2022-12-05T05:52:22.716Z</updated>
    
    <content type="html"><![CDATA[<h2 id="高并发场景下实现系统稳定运行"><a href="#高并发场景下实现系统稳定运行" class="headerlink" title="高并发场景下实现系统稳定运行"></a>高并发场景下实现系统稳定运行</h2><h2 id="微服务网关常见限流方案"><a href="#微服务网关常见限流方案" class="headerlink" title="微服务网关常见限流方案"></a>微服务网关常见限流方案</h2><p>客户端限流</p><p>服务端限流</p><p>网关限流</p><p>应用层限流</p><h3 id="微服务网关限流"><a href="#微服务网关限流" class="headerlink" title="微服务网关限流"></a>微服务网关限流</h3><p>详情页入口流量保护，黑订单，限制一个IP访问频率。</p><h4 id="基于Redis-Lua的脚本限流"><a href="#基于Redis-Lua的脚本限流" class="headerlink" title="基于Redis + Lua的脚本限流"></a>基于Redis + Lua的脚本限流</h4><p>RequestRateLimiter过滤工厂。算法：令牌桶。</p><p>初始化令牌数量。每次请求过来获取一个令牌，请求完成后，令牌返回桶。</p><h4 id="网关整合-Sentinel-Route-amp-API维度限流"><a href="#网关整合-Sentinel-Route-amp-API维度限流" class="headerlink" title="网关整合 Sentinel Route &amp; API维度限流"></a>网关整合 Sentinel Route &amp; API维度限流</h4><p>主要功能：<br>根据API流控，根据热点参数进行流控。</p><p>流控规则配置在Sentinel后台，分发到网关各节点。网关加入Sentinel jar包。<br>在接受请求时候，通过SlotChain记录并计算流控的结果。</p><h2 id="Sentinel-生产环境引入"><a href="#Sentinel-生产环境引入" class="headerlink" title="Sentinel 生产环境引入"></a>Sentinel 生产环境引入</h2><ul><li>2个维度</li></ul><ol><li>API维度。api流控。</li><li>Route维度。整个为服务进行流控</li></ol><ul><li>持久化<br>改造Senitnel支持Nacos持久化。规则从nacos分发到微服务网关。</li></ul><h2 id="下单引入Sentinel熔断"><a href="#下单引入Sentinel熔断" class="headerlink" title="下单引入Sentinel熔断"></a>下单引入Sentinel熔断</h2><ol><li>秒杀确认页，配置排队等待。匀速器设置。</li><li>热点参数限流。进行流控。<ol><li>商品ID进行流控。</li><li>用户ID为参数，针对一段时间频繁访问的用户ID进行限制。</li></ol></li></ol><p>PS:<br>热点参数规则需要使用@SentinalResource(“resourceName”)进行注解。<br>参数必须是7中基本数据类型才行。</p><h2 id="电商系统自适应保护方案"><a href="#电商系统自适应保护方案" class="headerlink" title="电商系统自适应保护方案"></a>电商系统自适应保护方案</h2><h3 id="降级"><a href="#降级" class="headerlink" title="降级"></a>降级</h3><p>系统容量达到一定程度时，限制或者关闭系统的某些非核心功能。把有限的资源保留给核心业务。<br>降级方案例子：</p><ol><li>当秒杀流量达到5w/s时，把成交记录的获取从展示20条降级到只展示5条。从20 到5，通过开关来配置实现。<br>降级的核心目标是，牺牲次要的功能和用户体验来保证核心业务流程的稳定。不得已为之的举措。例如：在双11时如果优惠券<br>系统扛不住，可能会临时降级商品详情的优惠券信息展示。把有限的资源用在保障交易系统正确展示优惠信息上。既保证用户<br>整整下单时的价格是正确的。</li></ol><h4 id="服务降级的策略"><a href="#服务降级的策略" class="headerlink" title="服务降级的策略"></a>服务降级的策略</h4><p><img src="https://images.lilhui.com/b2c1ecaebba2d0509d9f167867db4b98" alt="图片"></p><h3 id="熔断"><a href="#熔断" class="headerlink" title="熔断"></a>熔断</h3><p>对返回失败的借口，或者借口请求返回慢的。进行降级熔断。直接返回。不请求到后端服务。降低服务端的压力。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;高并发场景下实现系统稳定运行&quot;&gt;&lt;a href=&quot;#高并发场景下实现系统稳定运行&quot; class=&quot;headerlink&quot; title=&quot;高并发场景下实现系统稳定运行&quot;&gt;&lt;/a&gt;高并发场景下实现系统稳定运行&lt;/h2&gt;&lt;h2 id=&quot;微服务网关常见限流方案&quot;&gt;&lt;a h
      
    
    </summary>
    
      <category term="seckill" scheme="https://www.lilhui.com/categories/seckill/"/>
    
    
      <category term="限流，熔断" scheme="https://www.lilhui.com/tags/%E9%99%90%E6%B5%81%EF%BC%8C%E7%86%94%E6%96%AD/"/>
    
  </entry>
  
  <entry>
    <title>【秒杀系统3】优化订单交易全链路优化</title>
    <link href="https://www.lilhui.com/2022/11/30/java/distributed/seckill_3/"/>
    <id>https://www.lilhui.com/2022/11/30/java/distributed/seckill_3/</id>
    <published>2022-11-30T02:04:17.000Z</published>
    <updated>2022-12-05T05:49:10.813Z</updated>
    
    <content type="html"><![CDATA[<h2 id="下单定时检查的优化"><a href="#下单定时检查的优化" class="headerlink" title="下单定时检查的优化"></a>下单定时检查的优化</h2><p>RocketMq事务消息</p><h2 id="Redis扣减库存优化"><a href="#Redis扣减库存优化" class="headerlink" title="Redis扣减库存优化"></a>Redis扣减库存优化</h2><blockquote><p>分布式锁，存在锁竞争，一个商品对应一个锁。几百个商品同时秒杀，Redis压力巨大。</p></blockquote><p><strong>优化方案：</strong> 分布式锁变成本地锁。秒杀服务开始前，由配置中心给每个应用服务实例下发<br>一个库存数胡亮。然后每次下单，每个服务器只管自己的库存数量。与其他应用服务器完全不进行<br>库存同步。在各自的内存里扣减库存，然后定时批量扣减Redis里面的总库存。这样就不会有超卖的问题。减少了网络消耗，性能得到提升。</p><p><strong>引入的问题：</strong> 库存扣减不均衡。少卖了。这种情况是可以接受的。解决的方案有：返场。因为有的下单不支付<br>这些也是要加入到库存。</p><p>技术都是工具，工具的组合才是解决方法之道！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;下单定时检查的优化&quot;&gt;&lt;a href=&quot;#下单定时检查的优化&quot; class=&quot;headerlink&quot; title=&quot;下单定时检查的优化&quot;&gt;&lt;/a&gt;下单定时检查的优化&lt;/h2&gt;&lt;p&gt;RocketMq事务消息&lt;/p&gt;
&lt;h2 id=&quot;Redis扣减库存优化&quot;&gt;&lt;a h
      
    
    </summary>
    
      <category term="seckill" scheme="https://www.lilhui.com/categories/seckill/"/>
    
    
      <category term="全链路" scheme="https://www.lilhui.com/tags/%E5%85%A8%E9%93%BE%E8%B7%AF/"/>
    
  </entry>
  
  <entry>
    <title>【秒杀系统2】设计与实现下</title>
    <link href="https://www.lilhui.com/2022/11/29/java/distributed/seckill_2/"/>
    <id>https://www.lilhui.com/2022/11/29/java/distributed/seckill_2/</id>
    <published>2022-11-29T06:56:26.000Z</published>
    <updated>2022-12-01T08:15:06.076Z</updated>
    
    <content type="html"><![CDATA[<h2 id="秒杀前的流量控制"><a href="#秒杀前的流量控制" class="headerlink" title="秒杀前的流量控制"></a>秒杀前的流量控制</h2><h3 id="预约"><a href="#预约" class="headerlink" title="预约"></a>预约</h3><p>开放预约获得资格后才能参与秒杀。<br>    预约也有高并发所以需要一些设计：</p><ol><li>预约管理后台。</li><li>预约短信和消息提醒。</li><li>面向终端的雨夜核心微服务，提供给用户预约和取消资格能力。</li><li>详情页在展示时获取预约信息的能力，比如商品是否预约，当前预约人数等等。</li><li>秒杀下单时检查预约资格的能力。</li><li>核心在两个维度：<ol><li>预约活动和用户预约关系。所以需要2张表。预约活动表信息表，记录预约活动本身。预约活动开始和结束时间，<br>预约活动对应的秒杀信息，预约商品信息等。另一张表 用户预约关系表，用户的ID,预约的活动ID，预约商品等。</li></ol></li></ol><h3 id="预约系统优化"><a href="#预约系统优化" class="headerlink" title="预约系统优化"></a>预约系统优化</h3><p>用户预约关系表量非常大。方法：</p><ol><li>分库分表。用户预约关系表，写热点。</li><li>前置缓存。预约活动信息，读热点。</li></ol><p>计算预约量：</p><ol><li>用redis记录。</li><li>本地缓存累加，批量写入redis。</li></ol><h2 id="秒杀中流量控制-削峰"><a href="#秒杀中流量控制-削峰" class="headerlink" title="秒杀中流量控制-削峰"></a>秒杀中流量控制-削峰</h2><h3 id="削峰"><a href="#削峰" class="headerlink" title="削峰"></a>削峰</h3><p>无损削峰：限流技术是有损。<br>有损削峰：验证码，问答题，以及一部消息队列。</p><p>加验证码的作用：本来需要0.1秒完成的操作，拉长到10秒或者更长时间。拉长了时间<br>降低的最高的峰值。</p><h3 id="流量削峰"><a href="#流量削峰" class="headerlink" title="流量削峰"></a>流量削峰</h3><p>异步下单：<br>引入消息队列：kafka,RocketMQ,RabbitMQ</p><p>异步支付和订单不一致如何解决？</p><p>订单支付页，定时检查秒杀订单是否已经生成！WebSocket 等等。下单查库问题不大，比访问量第很多。</p><h3 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h3><h2 id="秒杀中的流量控制-限流"><a href="#秒杀中的流量控制-限流" class="headerlink" title="秒杀中的流量控制-限流"></a>秒杀中的流量控制-限流</h2><p>自我保护的直接手段，整个链路都可以进行限流：逐级限流、分层过滤。</p><p>常用算法：令牌桶和漏铜。</p><p><img src="https://images.lilhui.com/2b1147408ad1ebece871df0d32ae979b" alt="图片"></p><h3 id="nginx限流"><a href="#nginx限流" class="headerlink" title="nginx限流"></a>nginx限流</h3><p>HttpLimitZone,HttpLimitRequest<br>HttpLimitZone: 用来限制一个客户端的并发连接数。<br>HttpLimitRequest: 通过漏桶算法进行限制用户的链接频率。</p><p><img src="https://images.lilhui.com/b957e25c0046c74e56476b84ba3d032b" alt="图片"></p><p>limit_req_zone: 指令名称，关键字，只能在http块中使用。<br>$binary_remote_addr Nginx内置绑定变量，比如$remote_port是指客户端端口号。<br>zone=one：规则名称zai limit_req_zone申明过。<br>burst=2: 制定最大突然请求数，超过这个数目的请求会被延迟。<br>nodelay: 突发请求大于burst时候，立即返回503.不排队了。<br>rate:每秒允许通过的请求，每个IP。<br>zone=one:10m :1M可以支持 16000个链接。 10M就是160000个会话链接。</p><h3 id="线程池限流"><a href="#线程池限流" class="headerlink" title="线程池限流"></a>线程池限流</h3><p>Java，Tomcat原生线程池，配置最大连接数，请求处理队列长度以及拒绝策略来达到限流的目的。</p><h3 id="API限流"><a href="#API限流" class="headerlink" title="API限流"></a>API限流</h3><p>线程池限流是一种并发限流。并发恒定的情况下，处理速度越快。QPS越高。</p><p>大部分情况是根据QPS来限流。可以使用Google的RateLimiter开源包。基于令牌桶的算法实现。</p><p>开源的组件Sentinel整合了流量控制、流量整型、流量路由、熔断升级、系统自适应。</p><h3 id="自定义限流"><a href="#自定义限流" class="headerlink" title="自定义限流"></a>自定义限流</h3><p>订单的重复下单问题。订单结算也的时候进行判断（生成ID服务）。下单的时候用这个订单来校验下单是否重复。<br>如果高并发回拖慢秒杀的速度，所以需要进行改造：</p><ol><li>OrderId预生成，放在队列里。缓存在本地。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">OrderIdList = <span class="keyword">new</span> ConcurrentLinkedQueue();</span><br><span class="line">OrderItemList = <span class="keyword">new</span> ConcurrentLinkedQueue();</span><br></pre></td></tr></table></figure></li></ol><p>100毫秒产生200个订单号。所以1秒内只能有2000个订单过来。类似令牌桶限流。更精细的可以控制某个商品的发放速度。</p><ol start="2"><li>商品库存分发到本地。</li></ol><h2 id="限购、秒杀的库存与降级、热点"><a href="#限购、秒杀的库存与降级、热点" class="headerlink" title="限购、秒杀的库存与降级、热点"></a>限购、秒杀的库存与降级、热点</h2><p>重点问题：</p><ol><li>库存超卖，库存扣减的热点。</li></ol><p>在库存服务里解决。</p><h3 id="限购"><a href="#限购" class="headerlink" title="限购"></a>限购</h3><p>全部流量不能直接打到库存服务。需要有个系统来承接大流量没并且脂肪商品库存和匹配的请求到库存服务。限购就是这样的角色。<br>限购之于库存，就像秒杀之于下单。欠着都是后者的滤网和保护伞。</p><p>限购： 做商品的限制购买。因为参加秒杀活动的商品都是爆品、稀缺品，所以为了让更多的用户参与进来，并让有限的投放量汇集<br>更多的人，所以往往会对商品的售卖做限制，一般限制的维度包括两个方面。</p><p><strong>商品维度限购</strong>：每次参加秒杀的活动商品投放量。针对不同地区投放。</p><p><strong>个人维度限购</strong>：校验个人是否能购买数量。</p><h3 id="库存扣减"><a href="#库存扣减" class="headerlink" title="库存扣减"></a>库存扣减</h3><p>如何不超卖 -&gt; 查询用户库存。</p><p>库存扣减必须实现原子性和一致性，如何实现呢？<br>两个操作</p><h4 id="利用乐观锁"><a href="#利用乐观锁" class="headerlink" title="利用乐观锁"></a>利用乐观锁</h4><ol><li><p>查询库存。<br>乐观锁 version 每次扣减的时候带上这个版本号比如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> stock,<span class="keyword">version</span> <span class="keyword">from</span> product <span class="keyword">where</span> <span class="keyword">id</span> = ? ;</span><br></pre></td></tr></table></figure></li><li><p>扣减库存</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">update</span> product <span class="keyword">set</span> stock = stock - ?,<span class="keyword">version</span> = <span class="keyword">version</span> + <span class="number">1</span> <span class="keyword">where</span> <span class="keyword">id</span> = ? <span class="keyword">and</span> <span class="keyword">version</span> = ?</span><br></pre></td></tr></table></figure></li></ol><h4 id="利用数据库特性"><a href="#利用数据库特性" class="headerlink" title="利用数据库特性"></a>利用数据库特性</h4><p><strong>数据库方案：</strong> 行锁。查询和扣减放在一个事务，for update。事务结束后进行释放锁。<br><strong>通过SQL语句</strong>: where条件，保证库存不会被溅到0以下。</p><h4 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h4><p>redis分布式锁可以实现。<br>弊端：需要超时机制。但是有超时机制，又占用时间，与高并发的秒杀系统是相悖的。不建议使用。</p><h4 id="高并发扣减"><a href="#高并发扣减" class="headerlink" title="高并发扣减"></a>高并发扣减</h4><p>流量洪峰来临时，TP99指标变差，CPU升高，IO等待边长。系统变得不稳定。需要对非核心服务进行降级，减轻<br>系统负担，这种降级一般是有损的。属于 ‘弃卒保帅’</p><p>秒杀的核心问题是解决单个商品搞并发读和写的问题。是典型的热点数据问题。我们需要响应的机制，避免热点数据打垮<br>系统。</p><p>Redis库存扣减。宁可少卖，不可超卖。</p><p>如何实现：</p><ol><li>对缓存进行扣减。<br>redis lua eval原子脚本：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">local c_s = redis.call(&apos;get&apos;, KEYS[1])</span><br><span class="line">if (not c_s or  tonumber(c_s) &lt; tonumber(KEYS[2]) then</span><br><span class="line">    return 0</span><br><span class="line">end</span><br><span class="line">redis.call(&apos;decrby&apos;,KEYS[1],KEYS[2])</span><br></pre></td></tr></table></figure></li></ol><p>下单失败需要还原数量。</p><p>问题：Redis挂了怎么办?<br>快速持久化扣减记录，采用WAL机制实现。保存到本地RockDB数据库。</p><h4 id="降级"><a href="#降级" class="headerlink" title="降级"></a>降级</h4><ul><li>写服务降级</li></ul><p>Redis高并发扣减就是一种写降级</p><ul><li>读服务降级</li></ul><p>在不影响正常购买的流程中。将一些无关紧要的信息隐藏。完成读降级。<br>例子：</p><p>问题：双11时登录后，切换几分钟后需要重新登陆。平时并不用重新登陆。</p><p>登录信息缓存失效时间减少。腾出缓存资源。<br><strong>牢记：</strong>微服务资深所依赖的外服中间件或者系统跟本身可用性无关。</p><h2 id="秒杀的防刷，风控，容灾"><a href="#秒杀的防刷，风控，容灾" class="headerlink" title="秒杀的防刷，风控，容灾"></a>秒杀的防刷，风控，容灾</h2><h3 id="防刷"><a href="#防刷" class="headerlink" title="防刷"></a>防刷</h3><p>秒杀商品有限，防止黄牛<br>有效流量： 6：1：3</p><p>6： 黄牛用户<br>1： 错误用户<br>3： 正常请求  </p><p>防刷方法有：</p><ol><li>Nginx限流机制。限制IP高频访问。</li><li>Token机制，用来做鉴权。防止直接访问下单接口。在订单详情页时候获取Token，在下单时候带上原Token并再产生一个Token,每个环节进行校验。保证用户的操作是连续的。<br> 例子：在header_filter_by_lua_block 返回 的header里增加流程Token</li></ol><h3 id="风控"><a href="#风控" class="headerlink" title="风控"></a>风控</h3><p>如果已经有风控系统，可以拿到黑名单列表。进行封闭。</p><h3 id="容灾"><a href="#容灾" class="headerlink" title="容灾"></a>容灾</h3><p>防天灾，机房容灾。</p><p>异地双活：跨城市备份。有物理时延比较难实现。（招行实现）<br>同城双活：同城双活，物理距离比价近，延迟低。同城机房，同事承担部分流量。主机房承担写，部分读，备份机房部分读。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;秒杀前的流量控制&quot;&gt;&lt;a href=&quot;#秒杀前的流量控制&quot; class=&quot;headerlink&quot; title=&quot;秒杀前的流量控制&quot;&gt;&lt;/a&gt;秒杀前的流量控制&lt;/h2&gt;&lt;h3 id=&quot;预约&quot;&gt;&lt;a href=&quot;#预约&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
      <category term="seckill" scheme="https://www.lilhui.com/categories/seckill/"/>
    
    
      <category term="秒杀" scheme="https://www.lilhui.com/tags/%E7%A7%92%E6%9D%80/"/>
    
  </entry>
  
  <entry>
    <title>【秒杀系统1】设计与实现上</title>
    <link href="https://www.lilhui.com/2022/11/29/java/distributed/seckill_1/"/>
    <id>https://www.lilhui.com/2022/11/29/java/distributed/seckill_1/</id>
    <published>2022-11-29T01:58:14.000Z</published>
    <updated>2022-11-30T02:06:34.801Z</updated>
    
    <content type="html"><![CDATA[<h2 id="业务分析-系统挑战"><a href="#业务分析-系统挑战" class="headerlink" title="业务分析 系统挑战"></a>业务分析 系统挑战</h2><ol><li>瞬时流量</li><li>库存有限</li><li>持续时间短</li><li>预约，限购</li><li>涉及 商品详情页，订单结算，支付</li></ol><h2 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h2><ol><li>瞬时流量带来的服务端压力，造成单个请求增加。打挂服务器，用户体验不佳。</li><li>库存有限。造成多卖，超卖。</li><li>刷子流量，黄牛抢单，刷订单。黑产！道高一尺魔高一丈。</li></ol><h2 id="通用秒杀架构"><a href="#通用秒杀架构" class="headerlink" title="通用秒杀架构"></a>通用秒杀架构</h2><h3 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h3><p><strong><em>解决大流量问题</em></strong></p><ul><li>Http请求路径</li></ul><p>用户 -&gt; DNS -&gt; NGINX -&gt; Web服务 -&gt; RPC调用</p><p>解决流量问题，就是在链路上的个个节点进行优化。</p><p>NGINX：负载均衡，反向代理，静态资源服务器。流量过滤，限流。<br>Web服务：集群，业务聚合。<br>RPC调用：数据库，缓存等基础服务。</p><h3 id="NGINX"><a href="#NGINX" class="headerlink" title="NGINX"></a>NGINX</h3><p>流量筛选，缓存接口（openretry)</p><p>引入Openrestry 处理商品展示页面相关接口。</p><p>Nginx启动后，产生Master进程。Master生成多个Worker进程，处理相关请求。<br>Worker进程数可以配置。一般跟CPU数量保持一致。或者CPU跟Worker进行绑定，减少上下文切换，提升性能。</p><p>OpenRestry将LuaJIT的虚拟机嵌入到Nginx的管理进程和Worker进程。性能上OpenRestry接近或者超过C的模块，开发效率高。</p><p>Nginx将Http请求分成多个阶段，一个Http请求分给多个模块进行处理。每个模块专注一个独立简单的功能处理。</p><p>9个模块：</p><p>OpenRestry在Http处理阶段基础上分别在Rewrite/Access阶段、Content阶段、Log阶段注册了自己的Handler，加上系统初始阶段<br>Master的两个阶段，共11 个阶段为Lua脚本提供了介入的能力。</p><p>init_by_lua：进程加载Nginx配置文件时运行，一般用于注册全局变量，或者预加载Lua模块。<br>init_worker_by_lua：每个worker进程启动时执行，通常用于定时拉取配置数据或则进行后端服务的健康检查。<br>set_by_lua：变量初始化。<br>rewrite_by_lua：可以实现复杂的转发，重定向逻辑。<br>access_by_lua：准入，接口权限等情况集中处理。<br>content_by_lua：内容处理器，接收请求处理并输出响应。<br>header_filter_by_lua：响应头部或者Cookie处理。<br>body_filter_by_lua： 对响应数据进行过滤，如截断或者替换。<br>log_by_lua:会话完成后，本地异步完成日志记录。  </p><h3 id="商城中的OpenRestry"><a href="#商城中的OpenRestry" class="headerlink" title="商城中的OpenRestry"></a>商城中的OpenRestry</h3><ol><li>负载均衡</li><li>网关</li><li>反向代理</li></ol><h4 id="详情页静态化"><a href="#详情页静态化" class="headerlink" title="详情页静态化"></a>详情页静态化</h4><p><strong>页面</strong>：商品详情页静态化。比商城页面静态化更彻底的静态化。  </p><p>秒杀的商品是独立提报的。秒杀商品详情页的模板是类似的。抽出相同部分，通过freemark生成静态页面，缓存到ftp服务器。通过nginx直接访问。<br>具体做法：  </p><ol><li>准备提报脚本，自动化处理 生成html静态文件。推送到nginx服务端。</li><li>秒杀管理后台，开启秒杀开关，选取商品进行商详面静态化。</li><li>sftp 上传到nginx服务器。</li><li>访问链接和具体页面进行映射。通过RestyTemplate</li><li>OpenRestry二次模板化。活动详情的渲染等。通过RestyTemplate</li></ol><h4 id="库存获取"><a href="#库存获取" class="headerlink" title="库存获取"></a>库存获取</h4><p><strong>库存</strong>：库存直接从redis进行获取。不用通过后端服务。</p><ol><li>OpenResty直接访问Redis获取库存。resty.redis开源模块。</li><li>Nginx 和 Redis从服务器放在一起，避免链路层和传输层的开销。完全避免网络开销需要用到Unix Domain Socket变成进程间通信 IPC！</li></ol><p>Unix Domain Socket: 进程间通讯。</p><h2 id="秒杀隔离设计"><a href="#秒杀隔离设计" class="headerlink" title="秒杀隔离设计"></a>秒杀隔离设计</h2><p>隔离策略,秒杀商品和普通商品隔离。</p><h3 id="如何隔离"><a href="#如何隔离" class="headerlink" title="如何隔离"></a>如何隔离</h3><ol><li>业务上的隔离</li><li>系统隔离。流量大的系统进行隔离（订单，支付,库存)</li><li>数据的隔离</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;业务分析-系统挑战&quot;&gt;&lt;a href=&quot;#业务分析-系统挑战&quot; class=&quot;headerlink&quot; title=&quot;业务分析 系统挑战&quot;&gt;&lt;/a&gt;业务分析 系统挑战&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;瞬时流量&lt;/li&gt;
&lt;li&gt;库存有限&lt;/li&gt;
&lt;li&gt;持续时间短&lt;/l
      
    
    </summary>
    
      <category term="seckill" scheme="https://www.lilhui.com/categories/seckill/"/>
    
    
      <category term="秒杀" scheme="https://www.lilhui.com/tags/%E7%A7%92%E6%9D%80/"/>
    
  </entry>
  
  <entry>
    <title>【tomcat调优系列4】Tomcat 类加载机制，和热部署</title>
    <link href="https://www.lilhui.com/2022/11/23/tomcat/tomcat_4/"/>
    <id>https://www.lilhui.com/2022/11/23/tomcat/tomcat_4/</id>
    <published>2022-11-23T06:55:17.000Z</published>
    <updated>2022-11-23T13:54:40.278Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Tomcat类加载机制"><a href="#Tomcat类加载机制" class="headerlink" title="Tomcat类加载机制"></a>Tomcat类加载机制</h2><h3 id="JVM类加载器"><a href="#JVM类加载器" class="headerlink" title="JVM类加载器"></a>JVM类加载器</h3><p>Java中有3个类加载器，并且你可以自定义加载器。</p><ul><li>BoostrapClassLoader 是启动类加载器，由C预演实现，用来加载JVM启动时所需的核心类，比如rt.jar。</li><li>ExtClassLoader是扩展类加载器，用来加载\jre\lib\ext 目录下Jar包。扩展加载器的 #getParent()返回null,实际上扩展类加载器的<br>父类加载器就是启动类加载器。</li><li>AppClassLoader是系统类加载器，用来加载ClassPath下的类。应用程序默认用它来加载类。程序可以通过#getSystemClassLoader()来获取系统类加载器。</li><li>自定义加载器，用来加载自定义路径下的类。</li></ul><h3 id="双亲委派机制"><a href="#双亲委派机制" class="headerlink" title="双亲委派机制"></a>双亲委派机制</h3><p>加载某个类时会先委派父类加载器寻找目标类，找不到再委托上层父加载器，如果所有父加载器都找不到目标类，则在自己的类加载器路径中查找，并载入目标类。</p><p><img src="https://images.lilhui.com/c9cdb1fc55bcbd323b25aa274b6f2916" alt="图片"></p><p><img src="https://images.lilhui.com/23455a00f586de4dcebe1e4dd8453b05" alt="图片"></p><p>上图：ClassLoader#loadClass加载过程</p><p>问题： 为什么要设计双亲委派机制？</p><ul><li><strong>沙箱安全机制</strong>：自己写的java.lang.String.class类不会被夹在，防止API库被篡改。</li><li><strong>避免类的重复加载</strong>：当父亲已经加载了该类，就没有必要子ClassLoader再加载一次，保证加载类的唯一性。</li></ul><h3 id="Tomcat类加载机制-1"><a href="#Tomcat类加载机制-1" class="headerlink" title="Tomcat类加载机制"></a>Tomcat类加载机制</h3><p>Tomcat作为Servlet容器，它负责加载我们的Servlet类，此外还负责加载Servlet所依赖的Jar包。并且Tomcat本身也是一个Java程序。<br>因此它需要加载自己的类和依赖的Jar包。</p><p>问题：Tomcat如何隔离Web应用的？</p><p>Tomcat 自定义了一个类加载器WebAppClassLoader，并且给每个Web应用创建一个类加载器实例，每个Context容器负责创建和维护一个<br>WebAppClassLoader加载器实例。其实现的原理就是<strong>不同的类加载器实例加载的类被认为是不同的类，即使它们的类名相同（不同类加载器<br>实例加载的类是相互隔离的）</strong>。</p><p>Tomcat的自定义类加载器WebAppClassLoader打破了双亲委派机制。它首先自己尝试加载某个类，如果找不到再代理给父类加载器，其目的是<br>优先加载Web应用自己定义的类。具体实现就是重写ClassLoader的2个方法：findClass和loadClass.</p><p>findClass步骤：</p><ol><li>在Web应用本地目录下查找要加载的类。</li><li>如果没有找到，交给父加载器去查找，它的付加载器就是上面提到的系统类加载器。AppClassLoader.</li><li>如果父加载器也没找到这个类，抛出ClassNotFound异常。</li></ol><p>loadClass有6个步骤：</p><ol><li>现在本地Cache查找该类是否加载过，也就是说Tomcat的类加载器是否已经加载过这个类。</li><li>如果Tomcat加载器没加载过这个类，再看系统类加载器是否加载过。</li><li>如果都没有，就让ExtClassLoader去加载，这一步比较关键，目的防止 Web 应用自己的类覆盖 JRE 的核心类。因为 Tomcat 需要打破双<br>亲委托机制，假如 Web 应用里自定义了一个叫 Object 的类，如果先加载这个 Object 类，就会覆盖 JRE 里面的那个 Object 类，这就<br>是为什么 Tomcat 的类加载器会优先尝试用 ExtClassLoader 去加载，因为 ExtClassLoader 会委托给 BootstrapClassLoader 去加载，BootstrapClassLoader 发现自己已经加载了 Object 类，直接返回给 Tomcat 的类加载器，这样 Tomcat 的类加载器就不会去加载 Web 应用下的 Object 类了，也就避免了覆盖 JRE 核心类的问题。</li><li>如果 ExtClassLoader 加载器加载失败，也就是说 JRE 核心类中没有这类，那么就在本地 Web 应用目录下查找并加载。</li><li>如果本地目录下没有这个类，说明不是 Web 应用自己定义的类，那么由系统类加载器去加载。这里请你注意，Web 应用是通过Class.forName调用交给系统类加载器的，因为Class.forName的默认加载器就是系统类加载器。</li><li>如果上述加载过程全部失败，抛出 ClassNotFound 异常。</li></ol><p>本地cache -&gt; ExtendClassLoader -&gt; WebAppClassLoader -&gt; AppClassLoader</p><p>所以本地可以覆盖jar包里的实现。</p><h3 id="Tomcat类加载器的层次结构"><a href="#Tomcat类加载器的层次结构" class="headerlink" title="Tomcat类加载器的层次结构"></a>Tomcat类加载器的层次结构</h3><p>Tomcat 拥有不同的自定义类加载器，以实现对各种资源库的控制。 Tomcat 主要用类加载器解决以下 4 个问题：<br>同一个 Web 服务器里，各个 Web 项目之间各自使用的 Java 类库要互相隔离。</p><ul><li>同一个 Web 服务器里，各个 Web 项目之间各自使用的 Java 类库要互相隔离。</li><li>同一个 Web 服务器里，各个 Web 项目之间可以提供共享的 Java 类库 。</li><li>为了使服务器不受 Web 项目的影响，应该使服务器的类库与应用程序的类库互相独立。</li><li>对于支持 JSP 的 Web 服务器，应该支持热插拔（ HotSwap ）功能 。  </li></ul><p>Tomcat提供了四组目录供用户存放第三方类库：</p><ul><li>放置在/common目录中：类库可被Tomcat和所有的 Web应用程序共同使用。</li><li>放置在/server目录中：类库可被Tomcat使用，对所有的Web应用程序都不可见。</li><li>放置在/shared目录中：类库可被所有的Web应用程序共同使用，但对 Tomcat自己不可见。</li><li>放置在/WebApp/WEB-INF目录中：类库仅仅可以被此Web应用程序使用，对 Tomcat和其他Web应用程序都不可见。</li></ul><p>Tomcat自定义了多个类加载器</p><ol><li>CommonClassLoader   加载 /common</li><li>CatalinaClassLoader 加载 /server/</li><li>SharedClassLoader  加载 /shared/</li><li>WebappClassLoader  加载 /WebApp/WEB-INF/</li></ol><p><img src="https://images.lilhui.com/a4bfcb6f0ae2ddbd691e12746461c7cc" alt="图片"></p><h3 id="线程上下文加载器"><a href="#线程上下文加载器" class="headerlink" title="线程上下文加载器"></a>线程上下文加载器</h3><p>在 JVM 的实现中有一条隐含的规则，默认情况下，如果一个类由类加载器 A 加载，那么这个类的依赖类也是由相同的类加载器加载。比如 Spring 作为一个 Bean 工厂，它需要创建业务类的实例，并且在创建业务类实例之前需要加载这些类。<br>思考：如果spring作为共享第三方jar包，交给SharedClassLoader加载，但是业务类在web目录下，不在SharedClassLoader的加载路径下，那spring如何加载web应用目录下的业务bean呢？</p><p>问题： 如果spring作为共享第三方jar包，交给SharedClassLoader加载，但是业务类在web目录下，不在SharedClassLoader的加载路径下，那spring如何加载web应用目录下的业务bean呢？</p><p>Tomcat为每个Web应用创建一个WebAppClassLoader加载器，并在启动Web应用的线程设置上下文加载器。这样Spring在启动时就将现成上下文加载器取出来，用来加载Bean。</p><p>线程上下文加载器是一种类加载器传递机制，因为这个类加载器保存在线程私有数据里，只要是同一个线程，一旦设置了线程上下文加载器，在线程后续执行过程中就能把这个类加载器取出来用。<br>Thread.currentThread().getContextClassLoader()</p><p>线程上下文加载器不仅仅可以用在 Tomcat 和 Spring 类加载的场景里，核心框架类需要加载具体实现类时都可以用到它，比如我们熟悉的 JDBC 就是通过上下文类加载器来加载不同的数据库驱动的</p><p>线程上下文加载器，在SPI实现上用的比较多。</p><h2 id="Tomcat热加载和热部署"><a href="#Tomcat热加载和热部署" class="headerlink" title="Tomcat热加载和热部署"></a>Tomcat热加载和热部署</h2><p>在项目开发过程中，经常要改动Java/JSP 文件，但是又不想重新启动Tomcat，有两种方式:热加载和热部署。热部署表示重新部署应⽤，它的执⾏主体是Host。 热加载表示重新加载class，它的执⾏主体是Context。<br>热加载：在server.xml -&gt; context 标签中 设置 reloadable=”true”</p><ul><li>热加载：在server.xml -&gt; context 标签中 设置 reloadable=”true”</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Context</span> <span class="attr">docBase</span>=<span class="string">"D:\mvc"</span> <span class="attr">path</span>=<span class="string">"/mvc"</span>  <span class="attr">reloadable</span>=<span class="string">"true"</span> /&gt;</span></span><br><span class="line">热部署：在server.xml -&gt; Host标签中 设置  autoDeploy="true"</span><br></pre></td></tr></table></figure><ul><li>热部署：在server.xml -&gt; Host标签中 设置  autoDeploy=”true”</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Host</span> <span class="attr">name</span>=<span class="string">"localhost"</span>  <span class="attr">appBase</span>=<span class="string">"webapps"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">unpackWARs</span>=<span class="string">"true"</span> <span class="attr">autoDeploy</span>=<span class="string">"true"</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>他们的区别</strong></p><ul><li>热加载的实现方式是 Web 容器启动一个后台线程，定期检测类文件的变化，如果有变化，就重新加载类，在这个过程中不会清空 Session ，一般用在开发环境。</li><li>热部署原理类似，也是由后台线程定时检测 Web 应用的变化，但它会重新加载整个 Web 应用。这种方式会清空 Session，比热加载更加干净、彻底，一般用在生产环境。</li></ul><p>问题： Tomcat是如何用后台线程来实现热加载和热部署的</p><h3 id="Tomcat开启后台线程执行周期性任务"><a href="#Tomcat开启后台线程执行周期性任务" class="headerlink" title="Tomcat开启后台线程执行周期性任务"></a>Tomcat开启后台线程执行周期性任务</h3><p>Tomcat 通过开启后台线程ContainerBase.ContainerBackgroundProcessor，使得各个层次的容器组件都有机会完成一些周期性任务。我们在实际工作中，往往也需要执行一些周期性的任务，比如监控程序周期性拉取系统的健康状态，就可以借鉴这种设计。<br>Tomcat9 是通过ScheduledThreadPoolExecutor来开启后台线程的，它除了具有线程池的功能，还能够执行周期性的任务。</p><p><img src="https://images.lilhui.com/0121b5252cd38720749f046807893124" alt="图片"></p><p>此后台线程会调用当前容器的 backgroundProcess 方法，以及递归调用子孙的 backgroundProcess 方法，backgroundProcess 方法会触发容器的周期性任务。</p><p><img src="https://images.lilhui.com/5c90f19905daff7d323025a58de15ebd" alt="图片"></p><p>有了 ContainerBase 中的后台线程和 backgroundProcess 方法，各种子容器和通用 组件不需要各自弄一个后台线程来处理周期性任务，这样的设计显得优雅和整洁。</p><h3 id="热加载实现原理"><a href="#热加载实现原理" class="headerlink" title="热加载实现原理"></a>热加载实现原理</h3><p>有了 ContainerBase 的周期性任务处理“框架”，作为具体容器子类，只需要实现自 己的周期性任务就行。而 Tomcat 的热加载，就是在 Context 容器中实现的。Context 容 器的 backgroundProcess 方法是这样实现的：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//  StandardContext#backgroundProcess</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//WebappLoader 周期性的检查 WEB-INF/classes 和 WEB-INF/lib 目录下的类文件</span></span><br><span class="line"><span class="comment">// 热加载</span></span><br><span class="line">Loader loader = getLoader();</span><br><span class="line"><span class="keyword">if</span> (loader != <span class="keyword">null</span>) &#123;</span><br><span class="line">    loader.backgroundProcess();        </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>WebappLoader 实现热加载的逻辑：它主要是调用了 Context 容器的 reload 方法，先stop Context容器，再start Context容器。具体的实现：<br>停止和销毁 Context 容器及其所有子容器，子容器其实就是 Wrapper，也就是说 Wrapper 里面 Servlet 实例也被销毁了。</p><ol><li>停止和销毁 Context 容器及其所有子容器，子容器其实就是 Wrapper，也就是说 Wrapper 里面 Servlet 实例也被销毁了。</li><li>停止和销毁 Context 容器关联的 Listener 和 Filter。</li><li>停止和销毁 Context 下的 Pipeline 和各种 Valve。</li><li>停止和销毁 Context 的类加载器，以及类加载器加载的类文件资源。</li><li>启动 Context 容器，在这个过程中会重新创建前面四步被销毁的资源。</li></ol><p>在这个过程中，类加载器发挥着关键作用。一个 Context 容器对应一个类加载器，类加载器在销毁的过程中会把它加载的所有类也全部销毁。Context 容器在启动过程中，会创建一个新的类加载器来加载新的类文件。</p><h3 id="Tomcat热部署原理"><a href="#Tomcat热部署原理" class="headerlink" title="Tomcat热部署原理"></a>Tomcat热部署原理</h3><p>热部署跟热加载的本质区别是，热部署会重新部署 Web 应用，原来的 Context 对象会整个被销毁掉，因此这个 Context 所关联的一切资源都会被销毁，包括 Session。<br>Host 容器并没有在 backgroundProcess 方法中实现周期性检测的任务，而是通过监听器 HostConfig 来实现的</p><p>Host 容器并没有在 backgroundProcess 方法中实现周期性检测的任务，而是通过监听器 HostConfig 来实现的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// HostConfig#lifecycleEvent</span></span><br><span class="line"><span class="comment">// 周期性任务</span></span><br><span class="line"><span class="keyword">if</span> (event.getType().equals(Lifecycle.PERIODIC_EVENT)) &#123;</span><br><span class="line">    check();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">check</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (host.getAutoDeploy()) &#123;</span><br><span class="line">        <span class="comment">// Check for resources modification to trigger redeployment</span></span><br><span class="line">        DeployedApplication[] apps = deployed.values().toArray(<span class="keyword">new</span> DeployedApplication[<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">for</span> (DeployedApplication app : apps) &#123;</span><br><span class="line">            <span class="keyword">if</span> (tryAddServiced(app.name)) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// 检查 Web 应用目录是否有变化</span></span><br><span class="line">                    checkResources(app, <span class="keyword">false</span>);</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    removeServiced(app.name);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Check for old versions of applications that can now be undeployed</span></span><br><span class="line">        <span class="keyword">if</span> (host.getUndeployOldVersions()) &#123;</span><br><span class="line">            checkUndeploy();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Hotdeploy applications</span></span><br><span class="line">        <span class="comment">//热部署</span></span><br><span class="line">        deployApps();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>HostConfig 会检查 webapps 目录下的所有 Web 应用：</p><ul><li>如果原来 Web 应用目录被删掉了，就把相应 Context 容器整个销毁掉。</li><li>是否有新的 Web 应用目录放进来了，或者有新的 WAR 包放进来了，就部署相应的 Web 应用。</li></ul><p>因此 HostConfig 做的事情都是比较“宏观”的，它不会去检查具体类文件或者资源文件是否有变化，而是检查 Web 应用目录级别的变化。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Tomcat类加载机制&quot;&gt;&lt;a href=&quot;#Tomcat类加载机制&quot; class=&quot;headerlink&quot; title=&quot;Tomcat类加载机制&quot;&gt;&lt;/a&gt;Tomcat类加载机制&lt;/h2&gt;&lt;h3 id=&quot;JVM类加载器&quot;&gt;&lt;a href=&quot;#JVM类加载器&quot; c
      
    
    </summary>
    
      <category term="tomcat" scheme="https://www.lilhui.com/categories/tomcat/"/>
    
    
      <category term="tomcat" scheme="https://www.lilhui.com/tags/tomcat/"/>
    
      <category term="类加载，热部署" scheme="https://www.lilhui.com/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD%EF%BC%8C%E7%83%AD%E9%83%A8%E7%BD%B2/"/>
    
  </entry>
  
  <entry>
    <title>【tomcat调优系列3】Tomcat底层BIO和NIO实现原理</title>
    <link href="https://www.lilhui.com/2022/11/22/tomcat/tomcat_3/"/>
    <id>https://www.lilhui.com/2022/11/22/tomcat/tomcat_3/</id>
    <published>2022-11-22T03:02:16.000Z</published>
    <updated>2022-11-23T06:55:40.261Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Tomcat-IO选择历史"><a href="#Tomcat-IO选择历史" class="headerlink" title="Tomcat IO选择历史"></a>Tomcat IO选择历史</h2><ol><li>Tomcat7时默认用的BIO,同步阻塞。可以通过配置修改为NIO</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Connector</span> <span class="attr">port</span>=<span class="string">"8080"</span> <span class="attr">protocol</span>=<span class="string">"org.apache.coyote.http11.Http11Ni oProtocol"</span> </span></span><br><span class="line"><span class="tag"><span class="attr">connectionTimeout</span>=<span class="string">"20000"</span> <span class="attr">redirectPort</span>=<span class="string">"8443"</span> /&gt;</span></span><br></pre></td></tr></table></figure><ol start="2"><li>Tomcat8.5以后默认用的是NIO.</li></ol><h2 id="阻塞与非阻塞"><a href="#阻塞与非阻塞" class="headerlink" title="阻塞与非阻塞"></a>阻塞与非阻塞</h2><p>Socket通信过程分两个部分：</p><ol><li>连接准备</li><li>拷贝内核缓存到用户缓存。<br>阻塞和非阻塞的概念是在连接准备阶段的描述。</li></ol><h2 id="Tomcat的BIO实现"><a href="#Tomcat的BIO实现" class="headerlink" title="Tomcat的BIO实现"></a>Tomcat的BIO实现</h2><ol><li>JioEndpoint的Acceptor线程负责循环阻塞接收sock连接。</li><li>每接收到一个socket连接就包装成SocketProcessor扔进线程池Executor.SocketProcessor是一个Runnable</li><li>SocketProcess负责从scoket阻塞读取数据，并且向socket中阻塞写入数据。</li></ol><p>Acceptor现成数量默认为1，可以通过acceptorThreadCount参数进行配置。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Executor</span> <span class="attr">name</span>=<span class="string">"tomcatThreadPool"</span> <span class="attr">namePrefix</span>=<span class="string">"catalina-exec-"</span> </span></span><br><span class="line"><span class="tag">        <span class="attr">maxThreads</span>=<span class="string">"150"</span> <span class="attr">minSpareThreads</span>=<span class="string">"4"</span>/&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">Connector</span> <span class="attr">port</span>=<span class="string">"8080"</span> <span class="attr">protocol</span>=<span class="string">"org.apache.coyote.http11.Http11Ni oProtocol"</span> </span></span><br><span class="line"><span class="tag">        <span class="attr">connectionTimeout</span>=<span class="string">"20000"</span> </span></span><br><span class="line"><span class="tag">           <span class="attr">redirectPort</span>=<span class="string">"8443"</span> <span class="attr">executor</span>=<span class="string">"tomcatThreadPool"</span>/&gt;</span></span><br></pre></td></tr></table></figure><p>Tomcat中每个Connector都会创建一个线程池，并且默认值：</p><ol><li>最小线程数量10</li><li>最大线程数量20</li></ol><p>使用BIO处理请求时：</p><ol><li>当请求数量比较大时，可以提高Acceptor线程数量，提高接收请求的速率。</li><li>当请求比较耗时时，可以提高线程池Executor的最大线程数量。</li></ol><p>原理图：</p><p><img src="https://images.lilhui.com/1f62e4fafb4b3b53161a55d323656dc1" alt="图片"></p><h2 id="Tomcat的NIO实现"><a href="#Tomcat的NIO实现" class="headerlink" title="Tomcat的NIO实现"></a>Tomcat的NIO实现</h2><p>NIO非阻塞接收socket连接，非阻塞从socket读取数据，非阻塞将数据写入socket中。</p><p>在Tomcat中，只有从socket读取请求行，请求头数据时是非阻塞的。在读取请求体是阻塞的，响应数据也是阻塞的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Tomcat-IO选择历史&quot;&gt;&lt;a href=&quot;#Tomcat-IO选择历史&quot; class=&quot;headerlink&quot; title=&quot;Tomcat IO选择历史&quot;&gt;&lt;/a&gt;Tomcat IO选择历史&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Tomcat7时默认用的BIO,同步阻塞
      
    
    </summary>
    
      <category term="tomcat" scheme="https://www.lilhui.com/categories/tomcat/"/>
    
    
      <category term="tomcat" scheme="https://www.lilhui.com/tags/tomcat/"/>
    
      <category term="bio" scheme="https://www.lilhui.com/tags/bio/"/>
    
      <category term="nio" scheme="https://www.lilhui.com/tags/nio/"/>
    
  </entry>
  
  <entry>
    <title>【tomcat调优系列2】Tomcat响应数据过程</title>
    <link href="https://www.lilhui.com/2022/11/18/tomcat/tomcat_2/"/>
    <id>https://www.lilhui.com/2022/11/18/tomcat/tomcat_2/</id>
    <published>2022-11-18T07:30:18.000Z</published>
    <updated>2022-11-20T02:04:38.481Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Tomcat响应数据过程"><a href="#Tomcat响应数据过程" class="headerlink" title="Tomcat响应数据过程"></a>Tomcat响应数据过程</h2><h3 id="关键部件解释"><a href="#关键部件解释" class="headerlink" title="关键部件解释"></a>关键部件解释</h3><ol><li>OutputStream： 用于response的输出流。Tomcat这里是CoyoteOutputStream</li><li>OutputBuffer: 输出流的缓冲</li><li>ByteChunk: OutputBuffer的一个对象，缓冲的，缓冲区。</li><li>ByteChunk的buff构成，大小8192.</li><li>ByteOutputChannel：ByteChunk的out。缓冲区的数据流向的渠道。其实就是socket.</li><li>realWriteBytes方法：ByteOutputChannel的方法。会把src的数据发送给对应的驱动。</li><li>org.apache.coyote.Response：发送逻辑</li></ol><h3 id="触发缓冲区标记的发送"><a href="#触发缓冲区标记的发送" class="headerlink" title="触发缓冲区标记的发送"></a>触发缓冲区标记的发送</h3><ol><li>缓冲区满的情况：ByteChunk.append -&gt; out.realWriteBytes(src,off,len)。换冲突的大小为8192 ByteChunk</li><li>缓冲区没满：调用outputStream.flush</li></ol><h3 id="ouputStream-flush的方法"><a href="#ouputStream-flush的方法" class="headerlink" title="ouputStream.flush的方法"></a>ouputStream.flush的方法</h3><ol><li>判断是否发送过响应头，没发送则发送相应头。</li><li>调用ByteChunk的flushBuffer方法，把缓冲区的数据发送出去。</li><li>发送时候是从 ByteBuffer 发送到SocketBuffer(也是ByteChunk实现的)。SocketBuffer发送给socket</li></ol><h3 id="coyoteResponse-doWrite-outputChunk"><a href="#coyoteResponse-doWrite-outputChunk" class="headerlink" title="coyoteResponse.doWrite(outputChunk)"></a>coyoteResponse.doWrite(outputChunk)</h3><ol><li>调用方法：outputBuffer.doWrite(chunk, this).OutputBuffer是InternalOutputBuffer。</li><li>该doWrite⽅法中，⾸先会判断响应头是否已经发送，如果没有发送，则会构造响应头，并发响应头发送给 socketBuffer，发送完响应头，会调⽤响应的output的activeFilters，对于不同的响应体需要使⽤不同的 发送逻辑。⽐如ChunkedOutputFilter是⽤来发送分块响应体的，IdentityOutputFilter是⽤来发送 Content-length响应体的，VoidOutputFilter不会真正的把数据发送出去。</li><li>在构造响应头时，会识别响应体应该通过什么OutputFilter来发送，如果响应中存在content-length那么 则使⽤IdentityOutputFilter来发送响应体，否则使⽤ChunkedOutputFilter，当然还有⼀些异常情况下会 使⽤VoidOutputFilter，表示不会发送响应体。</li></ol><h3 id="响应的Content-lenth什么时候确定"><a href="#响应的Content-lenth什么时候确定" class="headerlink" title="响应的Content-lenth什么时候确定"></a>响应的Content-lenth什么时候确定</h3><p>答案是：当请求在servlet中执⾏完成后，会调⽤response.finishResponse()⽅法，该⽅法会调⽤ outputBuffer.close()，该outputBuffer就是org.apache.catalina.connector.OutputBuffer，该⽅法会 判断响应体是否已发送，如果在调⽤这个close时响应头还没有发送，则表示响应体的数据在之前⼀直没有 发送过，⼀直存在了第⼀层缓冲区中，并且⼀直没有塞满该缓冲区，因为该缓冲区如果被塞满了，则会发 送响应头，所以当执⾏到close⽅法是，响应头还没发送过，那么缓冲区中的数据就是响应体全部的数据， 即，缓冲区数据的⻓度就是content-length。 反之，在调⽤close⽅法之前，就已经发送过数据了，那么响应头中就没有content-length，就会⽤ ChunkedOutputFilter来发送数据。</p><p>并且在执⾏close⽅法时，会先将响应头的数据发送给socketbuffer，然后将第⼀层缓冲区的数据通过对应 的OutputFilter发送给socketbuffer，然后调⽤OutputFilter的end⽅法，IdentityOutputFilter的end⽅ 法实现很简单，⽽ChunkedOutputFilter的end⽅法则相对做的事情更多⼀点，因为 ChunkedOutputFilter的doWrite⼀次只会发送⼀块数据，所以end要负责循环调⽤doWrite⽅法，把全部 的数据库发送完。</p><p>最后将socketbuffer中的数据发送给socket。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Tomcat响应数据过程&quot;&gt;&lt;a href=&quot;#Tomcat响应数据过程&quot; class=&quot;headerlink&quot; title=&quot;Tomcat响应数据过程&quot;&gt;&lt;/a&gt;Tomcat响应数据过程&lt;/h2&gt;&lt;h3 id=&quot;关键部件解释&quot;&gt;&lt;a href=&quot;#关键部件解释&quot;
      
    
    </summary>
    
      <category term="tomcat" scheme="https://www.lilhui.com/categories/tomcat/"/>
    
    
      <category term="tomcat" scheme="https://www.lilhui.com/tags/tomcat/"/>
    
      <category term="调优" scheme="https://www.lilhui.com/tags/%E8%B0%83%E4%BC%98/"/>
    
  </entry>
  
  <entry>
    <title>【tomcat调优系列1】Tomcat的请求过程</title>
    <link href="https://www.lilhui.com/2022/11/18/tomcat/tomcat_1/"/>
    <id>https://www.lilhui.com/2022/11/18/tomcat/tomcat_1/</id>
    <published>2022-11-18T06:57:04.000Z</published>
    <updated>2022-11-20T02:04:38.477Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Tomcat请求过程"><a href="#Tomcat请求过程" class="headerlink" title="Tomcat请求过程"></a>Tomcat请求过程</h2><h3 id="几个部件："><a href="#几个部件：" class="headerlink" title="几个部件："></a>几个部件：</h3><ol><li>Endpoint： tomcat接收socket链接的组件。</li><li>Socket：请求的通道链接</li><li>InputBuffer. InternalInputBuffer,AbstractInputBuffer：缓冲内存</li><li>Request：请求对象</li><li>MessageBytes: 请求对象的消息内容</li><li>ByteChunk：</li><li>Connection：Java层面的链接对象</li><li>Servlet：处理请求的组件</li><li>Response：请求处理后的返回</li></ol><h3 id="请求过程"><a href="#请求过程" class="headerlink" title="请求过程"></a>请求过程</h3><ul><li>请求的解析</li></ul><ol><li>Endpoint接收socket链接。</li><li>从socket中获取数据并缓存到InputBuffer。BIO是InternalInputBuffer继承自AbstractInputBuffer</li><li>从InputBuffer中解析请求。将完整的请求协议和请求体封装到Request对象。</li><li>Request中的messageByte进行标记。标记url,header,请求体等。</li><li>解析头，解析请求。</li><li>初始化请求头的一些参数：Connextion keepalive，Content-length等。包括请求体处理的InputFilter</li><li>将请求交给容器</li></ol><ul><li>请求的处理</li></ul><ol start="8"><li>容器将请求分发到具体的Servlet进行处理。</li><li>Servlet处理请求利用Response进行响应。将返回的数据写入缓冲区，调用flush或者close时，把缓冲区的数据发送给socket.</li><li>servlet处理完请求后，检查是否需要把响应数据发送给socket.</li><li>看请求体是否处理结束，是否还有剩余数据，如果有剩余数据，把这些数据处理掉。以便获取下个请求的数据。</li><li>回到第一步处理下一个请求。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Tomcat请求过程&quot;&gt;&lt;a href=&quot;#Tomcat请求过程&quot; class=&quot;headerlink&quot; title=&quot;Tomcat请求过程&quot;&gt;&lt;/a&gt;Tomcat请求过程&lt;/h2&gt;&lt;h3 id=&quot;几个部件：&quot;&gt;&lt;a href=&quot;#几个部件：&quot; class=&quot;he
      
    
    </summary>
    
      <category term="tomcat" scheme="https://www.lilhui.com/categories/tomcat/"/>
    
    
      <category term="tomcat" scheme="https://www.lilhui.com/tags/tomcat/"/>
    
      <category term="调优" scheme="https://www.lilhui.com/tags/%E8%B0%83%E4%BC%98/"/>
    
  </entry>
  
  <entry>
    <title>云原生下的Java虚拟机 GraalVM</title>
    <link href="https://www.lilhui.com/2022/10/27/java/jvm_tuning/tuning_2/"/>
    <id>https://www.lilhui.com/2022/10/27/java/jvm_tuning/tuning_2/</id>
    <published>2022-10-27T03:44:31.000Z</published>
    <updated>2022-10-27T07:08:59.961Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>java 的编译器<br>C1,C2<br>C1不进行优化，C2会进行优化。热点代码缓存,JIT等等。</p><p>C2 C++写的，太复杂，不维护，而且有bug<br>java语言一直在进步，C2没有办法维护，需要一种新的编译器来进行支持，所以有了GraalVM</p><ul><li><p>事实<br>JIT,性能优化、垃圾回收等代表的特性需要一段时间来达到最佳性能。<br>java是面向大规模、长时间的服务应而设计。</p></li><li><p>矛盾<br>  微服务时代对启动速度、达到高性能的时间提出了新的要求。</p></li></ul><h3 id="问题根源"><a href="#问题根源" class="headerlink" title="问题根源"></a>问题根源</h3><p>Java离不开虚拟机（JVM)</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p><strong>革命派：</strong> 直接而干掉Java和Java生态。（Golang的诞生）<br><strong>保守派：</strong> 保留原有主流Java生态和技术资产，朝着微服务、云原生环境靠拢（GraalVM)</p><h2 id="GraalVM的技术"><a href="#GraalVM的技术" class="headerlink" title="GraalVM的技术"></a>GraalVM的技术</h2><p><strong>AOT技术：</strong> ahead of time</p><p>编译成native代码花费时间太大，这部分时间无法节省，所以引入AOT，减少这部分时间。</p><h3 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h3><ul><li>C++<br>  微软的Stackless模式单台1000万个链接。<br>  腾讯微信团队：libco</li><li>Java<br>  JVM（Loom:fibers轻量级用户线程）<br>  基于JNI<br>  操控字节码</li></ul><h2 id="GraalVM介绍"><a href="#GraalVM介绍" class="headerlink" title="GraalVM介绍"></a>GraalVM介绍</h2><p>C2编译器比较缓和，GraalVM比较激进</p><p><img src="https://images.lilhui.com/a0c5bf2ee63b97dcd762ee4843e6a734" alt="图片"></p><p>JVMCI: JVM compile interface</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;java 的编译器&lt;br&gt;C1,C2&lt;br&gt;C1不进行优化，C2会进行优化。热点代码缓存,JIT等等。&lt;/p&gt;
&lt;p&gt;C2 C++写的，太复
      
    
    </summary>
    
      <category term="java" scheme="https://www.lilhui.com/categories/java/"/>
    
    
      <category term="GraalVM" scheme="https://www.lilhui.com/tags/GraalVM/"/>
    
  </entry>
  
</feed>
