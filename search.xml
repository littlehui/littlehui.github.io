<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis数据结构介绍]]></title>
    <url>%2F2017%2F09%2F18%2Fredis%2FRedis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Redis数据结构介绍 Redis数据结构分为 STRING,LIST,SET,HASH,ZSET五种。与其他数据库或者缓存有相互对应关系。又有他自己的特点。 结构类型 值类型 读写能力 STRING 字符串，整数，浮点数，基本类型 对整个字符串或者字符串其中的一部分进行操作，对整数和浮点数进行自增或者自减 LIST 一个链表，链表上的每个节点都包含了一个字符串 从链表的两端推入或者弹出元素，根据偏移量对链表进行修剪，读取单个或者多个元素；根据值查找或者移除元素 SET 包含字符串的无序搜集器（unordered collection)，并且被包含的每个字符串都是独一无二，各不相同的 添加，获取，移除单个元素；检查一个元素是否存在于集合中；计算交集，并集，差集；从集合里随机获取元素 HASH 包含键值对的无序散列表 添加、获取、移除单个键值对；获取所有键值对 ZSET(有序集合) 字符串成员（member）与浮点数值（score）之间的有序映射，元素的排列顺序由分值的大小决定 添加、获取、删除、单个元素；根据分值范围（染个）或者成员来获取元素 字符串（STRING)基本操作： 命令 行为 GET 获取存储在给定键值中的值 SET 设置存储在给定键中的值 DEL 删除存储在给定键中的值（所有类型适用） 列表（List)基本操作： 命令 行为 RPUSH 给定的值推入列表的右端 LRANGE 获取列表在给定范围上的所有值 LINDEX 获取在列表给定位置上的单个元素 LPOP 从列表的左端弹出一个值，并返回被弹出的值 集合（SET） 和集合一样可以存储多个字符串，不同的是 列表中可以村粗多个相同的字符串。而集合则通过使用散列来保证自己存储的每个字符串都是各自不同的（这些散列只有键没有键值） 基本操作：命令 | 行为— | —SADD | 将给定元素添加到集合SMEMBERS | 返回集合包含的所有元素SISMEMBER | 检查给定元素是存在于集合中SREM | 如果给定的元素存在于集合中，那么移除这个元素 另外的操作SINTER,SUNION, SDIFF 分别执行交集计算、并集计算和差集计算。 散列（HASH） Redis的散列可以存储多个键值间的映射。其值，可以是字符串有可以是数字值。也可以对散列存储的值进行自增或自减。 散列在很多方面就是一个缩小版的Redis，不少字符串都有相应的散列版本。 基本操作： 命令 行为 HSET 在散列里面关联起给定的键值对 HGET 获取指定散列键的值 HGETALL 获取散列包含所有键值对 HDEL 如果给定键存在于散列里，那么移除这个键 Redis的散列可以看做文档数据库里的文档，在开发过程中可以很好的对应。在关系书库里可以看做关系数据库里的行。散列、文档、数据行这三者都允许用户同时访问或者修改一个火多个域。 有序集（ZSET） 和散列一样，有序集都用于存储键值对：有序集合的键称为 成员（member）每个成员都各不相同；有序集的值被称为分值（score）必须为浮点数。是唯一一个可以根据成员访问元素，又可以根据分值以及分值的排序来访问元素的结构。 基本操作： 命令 行为 ZADD 将一个带有给定成分值的成员添加到有序集合里 ZRANGE 根据元素在有序排列中所处处的位置，从有序集合中获取多个元素 ZRANGEBYSCORE 获取有序集合给定分值范围内的所有属性 ZREM 如果给定成员存在，移除这个成员]]></content>
      <categories>
        <category>缓存</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql缓存与Memcached,Redis区别]]></title>
    <url>%2F2017%2F09%2F18%2Fsearch%2FMysql%E7%9A%84%E7%BC%93%E5%AD%98%E4%B8%8EMemcached%2CRedis%E7%BC%93%E5%AD%98%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[前言 我们在做Web开发的时候从至上而下的技术分层里，缓存始终贯穿其中。浏览器层–》业务层–》数据库层。每个层面上的缓存都有各自的功能与场景。我们今天探讨下业务层到数据库层上缓存的功能和区别。 业务层缓存MemcachedMemcached 严格上讲还不能说是完整的分布式缓存系统。它有很多第三方工具支撑其分布式功能。Memcached 通过内部固定的大小的chunk预申请内存数据。使得分配和回收内存的效率很高。读写性能也很高。64k对象的情况下，单机QPS可以达到15W以上。Memcached 的集群架构中，单个节点对其他节点是相互独立的，没有数据方面的通信。不具备failover能力。Memcached 支持多语言，有相当的稳定性。 RedisRedis 显著的特点是不仅支持普通的K，V 类型存储，还支持其独特的 五种数据结构 详见Redis数据结构Redis 也支持集群，Redis支持的集群是Master-Slave模式。其有点是可以在宕机时切换到备份机。可用性方面有一定的提升。Redis 单纯当做缓存存储在内存时速度和Memcached不相上下。存储到硬盘时，性能和速度会下降很多，介于 Memcahced 和mysql之间。Redis 有特殊的订阅功能，使得它经常被用于当做内存队列使用。Redis 扩展方面不如Memcached，无法做到持续的线性扩容。目前支持通过复制的方式，产生一主多备架构并升级容量。 数据库层缓存mysql缓存MySQL将缓存分为Buffer缓存和Cache缓存。Buffer缓存:由于硬盘的写入速度过慢，或者频繁的I/O，对于硬盘来说是极大的效率浪费。那么可以等到缓存中储存一定量的数据之后，一次性的写入到硬盘中。Buffer 缓存主要用于写数据，提升I/O性能。Cache 缓存:Cache 是在开启缓存功能前提下，在通过的每次sql进行hash计算，生成此条sql的唯一hash作为存储的Key值。SO select是区分大小写的。生成缓存之后，如果涉及的table有任何数据的变动（整个talbe),所有的cache就会被删除。如果Cache缓存已经存储满，则启用LRU算法，进行数据淘汰。淘汰掉最远未使用的数据，从而开辟新的存储空间。不过对于特大型的网站，依靠这种策略很难缓解高频率的读请求，一般会把访问非常频繁的数据静态化，直接由nginx返还给用户。程序和数据库I/O设备交互的越少，则效率越高。 问题既然有Memcached,Redis 为什么还要用Mysql缓存呢？ 解答 从整体架构上看，Memcached和Redis支持扩展分布式缓存。适用于大型Web项目。单从单节点功能上看，Mysql由于自身的cache 删除方式。使得其缓存有相对的局限性。并且无法简单的管控。需要更好的使用的话，需要对业务上进行更详尽细致的分析。在数据库的逻辑设计层面细分出能够说回合mysql缓存的场景。单节点，数据简单，无太多修改的数据面前，但根据场景来，mysql缓存还是有一定价值的。比Memcached Redis简单易用，效率更好。 参考：https://dev.mysql.com/doc/refman/5.7/en/query-cache.html]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux expect ssh自动登录详解]]></title>
    <url>%2F2017%2F09%2F14%2Flinux%2Flinux%20expect%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[简介 Expect是用于自动化交互式应用程序的工具，如telnet，ftp，passwd，fsck，rlogin，tip等。使用起来很简单。 使用方法 首行加上/usr/bin/expect spawn: 后面加上需要执行的shell 命令，比如说spawn sudo touch testfile expect: 只有spawn 执行的命令结果才会被expect 捕捉到，因为spawn 会启动一个进程，只有这个进程的相关信息才会被捕捉到，主要包括：标准输入的提示信息，eof 和timeout。 send 和send_user：send 会将expect 脚本中需要的信息发送给spawn 启动的那个进程，而send_user 只是回显用户发出的信息，类似于shell 中的echo 而已。 实例1:远程拷贝文件1234567891011121314151617181920set timeout 10set host [lindex $argv 0]set username [lindex $argv 1]set password [lindex $argv 2]set src_file [lindex $argv 3]set dest_file [lindex $argv 4]spawn scp $src_file $username@$host:$dest_file expect &#123; &quot;(yes/no)?&quot; &#123; send &quot;yes\n&quot; expect &quot;*assword:&quot; &#123; send &quot;$password\n&quot;&#125; &#125; &quot;*assword:&quot; &#123; send &quot;$password\n&quot; &#125; &#125; expect &quot;100%&quot; expect eof 2:执行远程命令1234567891011121314151617181920set timeout 10set host [lindex $argv 0]set username [lindex $argv 1]set password [lindex $argv 2]set cmd [lindex $argv 3]spawn ssh -t -p $port $username@$host &apos;cmd&apos; expect &#123; &quot;(yes/no)?&quot; &#123; send &quot;yes\n&quot; expect &quot;*assword:&quot; &#123; send &quot;$password\n&quot;&#125; &#125; &quot;*assword:&quot; &#123; send &quot;$password\n&quot; &#125; &#125; expect &quot;100%&quot; expect eof 3：与SSH合用 123/usr/bin/expect &lt;&lt;-EOF//TODO这里写expect脚本 EOF]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[alfred结合七牛实现快速插入markdown格式图片]]></title>
    <url>%2F2017%2F09%2F13%2Fblog%2Falfred%E7%BB%93%E5%90%88%E4%B8%83%E7%89%9B%E5%AE%9E%E7%8E%B0%E5%BF%AB%E9%80%9F%E6%8F%92%E5%85%A5markdown%E6%A0%BC%E5%BC%8F%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[详细过程可以访问：https://github.com/tiann/markdown-img-upload 问题修复 由于retina截屏的图片会放大，所以在markdown脚本里做了处理：有遇到缩放的会进行指定宽度大小。所以会插入&lt;img 标签。但是这不符合markdown的图片方式，这里做了一下改进。将 计算后的size插入七牛的样式图片里就可以解决。 打开workflow的脚本修改保存1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# coding: utf-8from clipboard import get_paste_img_filefrom upload import upload_qiniuimport utilimport osimport subprocessimport sysimport timeif not os.path.exists(util.CONFIG_FILE): util.generate_config_file()config = util.read_config()if not config: util.notice('请先设置你的七牛图床信息') util.open_with_editor(util.CONFIG_FILE) sys.exit(0)url = '%s/%s' % (config['url'], config['prefix'])styleprefix = 'imageView2/2/w/'stylesubfix = '/h/640/format/jpg/q/100|watermark/2/text/d3d3LmxpbGh1aS5jb20=/font/5b6u6L2v6ZuF6buR/fontsize/400/fill/Izk2OEM4Qw==/dissolve/100/gravity/SouthEast/dx/10/dy/10|imageslim'mkdprefix='![图片]('mkdsubfix=')'img_file, need_format, format = get_paste_img_file()if img_file: # has image # use time to generate a unique upload_file name, we can not use the tmp file name upload_name = "%s.%s" % (int(time.time() * 1000), format) if need_format: size_str = subprocess.check_output('sips -g pixelWidth %s | tail -n1 | cut -d" " -f4' % img_file.name, shell=True) size = int(size_str.strip()) / 2 #markdown_url = '&lt;img src="%s/%s-1960" width="%d"/&gt;' % (url, upload_name, size) markdown_url = '%s%s/%s?%s%d%s%s' % (mkdprefix, url, upload_name, styleprefix, size, stylesubfix, mkdsubfix) else: markdown_url = '%s%s/%s-960%s' % (mkdprefix, url, upload_name, mkdsubfix) # make it to clipboard os.system("echo '%s' | pbcopy" % markdown_url) os.system('osascript -e \'tell application "System Events" to keystroke "v" using command down\'') upload_file = util.try_compress_png(img_file, format!='gif') if not upload_qiniu(upload_file.name, upload_name): util.notice("上传图片到图床失败，请检查网络后重试")else: util.notice("剪切版里没有图片！") 上面是我修改后的脚本信息，修改的地方是：1markdown_url = &apos;%s%s/%s?%s%d%s%s&apos; % (mkdprefix, url, upload_name, styleprefix, size, stylesubfix, mkdsubfix) 注意这两个变量12styleprefix = &apos;imageView2/2/w/&apos; stylesubfix =&apos;/h/640/format/jpg/q/100|watermark/2/text/d3d3LmxpbGh1aS5jb20=/font/5b6u6L2v6ZuF6buR/fontsize/400/fill/Izk2OEM4Qw==/dissolve/100/gravity/SouthEast/dx/10/dy/10|imageslim&apos; 根据自己的七牛图片拼装 markdown_url即可。我这里用的是通过改变七牛提供的链接图片 size 进行替换。中间拼装计算好的原始图片size即变成正常大小。既： styleprefix + size + stylesubfix]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>alfred</tag>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[solr高级查询edismax函数详解]]></title>
    <url>%2F2017%2F09%2F11%2Fsearch%2Fsolr%E9%AB%98%E7%BA%A7%E6%9F%A5%E8%AF%A2edismax%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[前言 最近遇到solr查询中加入字段权重的需求，自然而然地想到了edismax这个功能。通过系统的学习和文档阅读，大概了解solr 对于函数式查询的支持方式。为了便于记忆，这里对常用公式进行整理说明。 使用方式详细见官方文档介绍，这里不做说明，我们重点讲solr edismax所涉及到的函数。 bf函数列表 constant 支持小数点的常量例如，1.5，查询表达式就是：val:1.5 fieldvalue 返回numberic field的名字.域必须是index的，非multivalue。格式为该域的名字。如果这个域没值，就返回0 ord ord，返回你要查询的那个特定的值在这个顺序中的排名。 非multiValued的，当没有值存在的时候，将返回0 例如：某个特定的域只能去三个值，“apple”、“banana”、“pear”，那么ord（“apple”）=1，ord（“banana”）=2，ord（“pear”）=3 需要注意的是，ord（）这个函数，依赖于值在索引中的位置，所以当有文档被删除、或者添加的时候，ord（）的值就会发生变化。当你使用MultiSearcher的时候，这个值也就是不定的了。 rord 函数将会返回与ord相对应的倒排序的排名。 格式: rord(myIndexedField). sum 就是表示多个数值的“和”。 格式： sum(x,1) sum(x,y) sum(sqrt(x),log(y),z,0.5) product 多个参数的乘积，参数可以是数值，也可以是函数，当为函数时，表示为此函数的计算值乘积。 格式： product(x,2) product(x,y) div 两个参数做除法。支持函数参数 格式： div(x,y) div(sum(x,100),max(y,1)) pow 幂值计算，pow(x,y)=x^y 。支持函数参数。 格式： pow(x,0.5) 标识开方 pow(x, log(y)) abs 返回表达式的绝对值，支持函数参数。 格式： abx(-5) abc(x) log返回对数操作，支持函数参数。格式：log(x)log(sum(x,100)) sqrt返回平方根。与pow(x，0.5)一样。格式：sqrt(2)sqrt(sum(x,100)) map区间检测如果 min&lt;=x&lt;=max，那么map(x,min,max,target)=target，如果x不在[min,max]这个区间内，那么map(x,min,max,target)=x. scala限制参数区间例如：scale(x,minTarget,maxTarget) 这个函数将会把x的值限制在[minTarget,maxTarget]范围内。 query计算subquery查询分数例如：query(subquery,default)表示返回给定的subquery的分数，如果subquery与文档不匹配，那么将会返回默认值。任何的查询类型都是受支持的。可以通过引用的方式，也可以直接指定查询串。q=product(popularity, query({!dismax v=’solr rocks’})) 将会返回popularity和通过dismax 查询得到的分数的乘积q=product(popularity, query($qq)&amp;qq={!dismax}solr rocks) 跟上一个例子的效果是一样的。不过这里使用的是引用的方式q=product(popularity, query($qq,0.1)&amp;qq={!dismax}solr rocks) 在前一个例子的基础上又加了一个默认值。 linear线性函数计算例如：liner(x,m,c)其中 x为变量或者函数，m,c为常量。整个函数取值为： xm+c的值。liner(x,2,4)=2x+4 reciprecip(x,m,a,b) 函数表达式 a/(m*x+b)其中，m、a、b是常量，x是变量或者一个函数。当a=b，并且x&gt;=0的时候，这个函数的最大值是1，值的大小随着x的增大而减小。 max比较大小例如：max(x,c) x可以为变量或者函数，c为常数，返回两个之间最大值。 场景应用 某地的新闻网页库中原本的逻辑是对仓库里的数据字段 subject，message进行搜索。默认是通过score检索字段匹配得分进行排序输出。随着时间的推移，大量的搜索可能会展示两年前，三年前匹配度更高的数据，这些搜索结果明显不合适的。那么我们需要对其进行改造，加入发布时间权重排序。 原本的参数： 1subject:武则天 OR message:武则天 搜索得出结果： 文档得分： 上面我们可以看到，tid为666811的文档排在第一位，得分27.811375 它的dateline时间是：1239781944明显早于第二位 tid：10364925的 1503334472，得分：26.519054。第三位是 tid:9759987 得分：26.511488。这样的搜索结果显然不是很令人满意的。 开启edismax 加入 1bf=sqrt(log(dateline))^100 搜索得出结果： 文档得分： 经过调整，我们得出的结果中排在第一位的是 tid:9759987 其时间dateline是1473820016 得分：330.85 是原本的第三位。原来的排第一的 tid:666811排在了第三位，得分 329.40 原来的第二tid:10364925 得分：329.50 调整后的排序大致满足我们的需求。那么为什么调整后会变成这样的排序呢？ 首先我们要清楚solr的打分机制默认是通过匹配度计算文档相似度得来的。也就是第一次搜索的默认得分，引入edismax的bf函数后我们来分析下最终的结果是怎样，以第一次搜索排名前三的数据为例子： tid | dateline | 初始得分 | 引入bf重新计算 ---|---|---|--- 666811 | 1239781944 | 27.811382 | 329.40198 10364925 | 1503334472 | 26.519054 |329.50174 9759987 | 1473820016 | 26.511488 | 330.85834 根据bf=sqrt(log(dateline))^100 分别计算上面三个的新得分 1234567891011121314151617sqrt(log(1239781944)) = 3.0155174194591075 权重乘100 得: 301.55174194591075再加 27.811382 =329.36312394591073sqrt(log(1503334472)) = 3.029365546794402权重乘100 得:302.9365546794402再加 26.519054=329.45560867944016sqrt(log(1473820016)) = 3.0279439311841663权重乘100 得:302.79439311841663再加 26.511488=329.3058811184166 纳尼。很奇怪为什么 9759987 计算最小 不对劲 于是翻看原来前面查询的debug列表分析仔细看原来是原图： 添加edismax后： 对比以上靓图，原来是我们的Qparser不一样。在普通查询的时候我么使用的是定制化的 SWMCLuceneQparser 查询解析器。而 用edimax后，解析器变成了 ExtendDismaxQparser 这两个差别在于 定制化的 SWMCLuceneQparser会将查询字段通过IK分词转换后进行查询。其parsedquery_tostring 变成1&quot;parsedquery&quot;:&quot;PhraseQuery(subject:\&quot;武 则 天\&quot;) PhraseQuery(message:\&quot;武 则 天\&quot;)&quot;, ExtendDismaxQparser的 parsedquery_tostringshi :1&quot;parsedquery_toString&quot;:&quot;+((subject:武 subject:则 subject:天) (message:武 message:则 message:天)) (sqrt(log(long(dateline))))^10.0&quot;, 两者稍有不同，所以在计算最终权重的时候有些差异。]]></content>
      <categories>
        <category>搜索</category>
      </categories>
      <tags>
        <tag>solr</tag>
        <tag>edismax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo技术博客搭建日记]]></title>
    <url>%2F2017%2F09%2F02%2Fblog%2Fhexo%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%97%A5%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[9月2号听说Hexo 案例1 案例2 9月3号了解Hexo搭建博客方式 hexo搭建参考1 hexo搭建参考2 hexo主题 9月5号搭建完成 9月6号添加域名解析 9月7号添加Gitment评论功能 Gitment的github地址 9月9号配置结合alfred + 七牛 快捷插入markdown图片工具 Github地址 9月11号第一篇文章登陆 9月12号完善主题配置 9月13日添加站点收录 npm install hexo-generator-sitemap –save npm install hexo-generator-baidu-sitemap –save 搜索引擎站点收录]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>IntelliJ IDEA</tag>
        <tag>Git</tag>
        <tag>Github</tag>
      </tags>
  </entry>
</search>
