<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[SP image 128G 1.0版本发布 RG350M专用]]></title>
    <url>%2F2021%2F08%2F29%2Fopendingux%2Fspimge1%2F</url>
    <content type="text"><![CDATA[SP image 1.0发布在开源掌机圈不误正业了很久，一直在寻找一款软件硬件兼备的理想掌机。但是以目前的市场状况,希望渺茫。与其等商家完善，不如自己动手，于是本人基于 Simplemenu 9.0 + 官方底包整合了一个 128G 镜像，完成很久了，虽然还有一些不完善的地方，但是玩着还不错。独乐乐，不如众乐乐，发布出来一起交流体验。感谢所有为开源软件做出努力的人。本镜像禁止商用！！ 镜像特性：前端： 底包基于官方包 基于Simplemenu9.0 支持中文游戏列表。 支持三种主题：EpicCody，GBA35Remix,OA 快捷键说明 开始：调出设置屏幕。 选择：Rom 选项。让我们选择自动启动、模拟器（如果为所选部分定义了多个模拟器）和超频。 上：选择上一场比赛/上一节/上一组 向下：选择下一场比赛/下一节/下一组 左：跳到当前部分的上一页。 右：跳到当前部分的下一页。 R1：在菜单和全屏模式之间切换。 R2：刷新当前部分（以防您在菜单运行时添加了一些 ROM）。在 RFW 中使用“B+R1”。 A：启动游戏/程序。 X：在常规列表，将游戏标记为收藏，在收藏夹部分，将其从收藏夹列表中删除。 L2 转到藏夹列表。 B：如果按下并松开，它会将您带回一屏。如果按住，则在游戏列表中时，它充当与其他键组合的热键 B + 左：跳到上一个字母。 B + 右：跳到下一个字母。 B + Up：转到上一部分，不显示徽标。 B + 向下：转到下一部分，不显示徽标。 B+选择：随机选择。 B + X：删除选定的 rom，无需确认。不适用于收藏夹部分或应用和游戏部分。 B + A：如果模拟器支持作为独立应用程序运行，则启动模拟器本身而不是 rom。 游戏列表页面按住select可以选择执行的模拟器。目前以下有多个模拟器选择 MD GBA SNES FBA 模拟器： 移植了fba-a320 三国战纪等游戏满帧。（可以在游戏列表按select进行切换模拟器） pocketsnes 修复浪漫沙迦，圣剑传说3字体显示（感谢CC的技术支持） picodrive 升级到1.97 fba 拳皇等游戏硬件拉升，可以全屏。不会有右边的竖纹。 ROM: 所有ROM名字以第一个拼音字母开头。在游戏列表按B+上，下 进行索引。 snes,nes，GBA,FBA 适配了几百个金手指。方便游玩。（部分金手指可能无效） 部分截图 游戏截图 金手指 拳皇97硬件拉升支持全屏 封面Logo 前端设置 选择模拟器（select) 收藏夹（L2) FBA街机Logo 游戏列表中文 下载链接链接：https://pan.baidu.com/s/1QkROboHxoFIjIm59sVGuhg提取码：87bs 本镜像用于玩家交流使用，禁止商用！！]]></content>
      <categories>
        <category>opendingux</category>
      </categories>
      <tags>
        <tag>开源掌机</tag>
        <tag>simplemenu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Mysql深入理解系列8】Mysql慢查询工具]]></title>
    <url>%2F2021%2F06%2F01%2Fmysql%2Fmysql_deep_8%2F</url>
    <content type="text"><![CDATA[几个参数 slow_query_log 这个参数设置为ON，可以捕获执行时间超过一定数值的SQL语句。 long_query_time 当SQL语句执行时间超过此数值时，就会被记录到日志中，建议设置为1或者更短。 slow_query_log_file 记录日志的文件名。 log_queries_not_using_indexes 这个参数设置为ON，可以捕获到所有未使用索引的SQL语句，尽管这个SQL语句有可能执行得挺快。 几个命令 SHOW PROCESSLIST Id列：一个标识，你要kill一个语句的时候很有用，用命令杀掉此查询 /*/mysqladmin kill 进程号。 User列：显示单前用户，如果不是root，这个命令就只显示你权限范围内的sql语句。 Host列：显示这个语句是从哪个ip的哪个端口上发出的。用于追踪出问题语句的用户。 db列：显示这个进程目前连接的是哪个数据库。 Command列：显示当前连接的执行的命令，一般就是休眠（sleep），查询（query），连接（connect）。 Time列：此这个状态持续的时间，单位是秒。 State列：显示使用当前连接的sql语句的状态，很重要的列，后续会有所有的状态的描述，请注意，state只是语句执行中的某一个状态，一个 sql语句，以查询为例，可能需要经过copying to tmp table，Sorting result，Sending data等状态才可以完成 Info列；显示这个sql语句，因为长度有限，所以长的sql语句就显示不全，但是一个判断问题语句的重要依据。 这个命令中最关键的就是state列，MySQL列出的状态主要有以下几种： Checking table：正在检查数据表（这是自动的）。 Closing tables：正在将表中修改的数据刷新到磁盘中，同时正在关闭已经用完的表。这是一个很快的操作，如果不是这样的话，就应该确认磁盘空间是否已经满了或者磁盘是否正处于重负中。 Connect Out：复制从服务器正在连接主服务器。 Copying to tmp table on disk：由于临时结果集大于tmp_table_size，正在将临时表从内存存储转为磁盘存储以此节省内存。 Creating tmp table：正在创建临时表以存放部分查询结果。 deleting from main table：服务器正在执行多表删除中的第一部分，刚删除第一个表。 deleting from reference tables：服务器正在执行多表删除中的第二部分，正在删除其他表的记录。 Flushing tables：正在执行FLUSH TABLES，等待其他线程关闭数据表。 Killed：发送了一个kill请求给某线程，那么这个线程将会检查kill标志位，同时会放弃下一个kill请求。MySQL会在每次的主循环中检查kill标志位，不过有些情况下该线程可能会过一小段才能死掉。如果该线程程被其他线程锁住了，那么kill请求会在锁释放时马上生效。 Locked：被其他查询锁住了。 Sending data：正在处理SELECT查询的记录，同时正在把结果发送给客户端。 Sorting for group：正在为GROUP BY做排序。 Sorting for order：正在为ORDER BY做排序。 Opening tables：这个过程应该会很快，除非受到其他因素的干扰。例如，在执ALTER TABLE或LOCK TABLE语句行完以前，数据表无法被其他线程打开。正尝试打开一个表。 Removing duplicates：正在执行一个SELECT DISTINCT方式的查询，但是MySQL无法在前一个阶段优化掉那些重复的记录。因此，MySQL需要再次去掉重复的记录，然后再把结果发送给客户端。 Reopen table：获得了对一个表的锁，但是必须在表结构修改之后才能获得这个锁。已经释放锁，关闭数据表，正尝试重新打开数据表。 Repair by sorting：修复指令正在排序以创建索引。 Repair with keycache：修复指令正在利用索引缓存一个一个地创建新索引。它会比Repair by sorting慢些。 Searching rows for update：正在讲符合条件的记录找出来以备更新。它必须在UPDATE要修改相关的记录之前就完成了。 Sleeping：正在等待客户端发送新请求. System lock：正在等待取得一个外部的系统锁。如果当前没有运行多个mysqld服务器同时请求同一个表，那么可以通过增加–skip-external-locking参数来禁止外部系统锁。 Upgrading lock：INSERT DELAYED正在尝试取得一个锁表以插入新记录。 Updating：正在搜索匹配的记录，并且修改它们。 User Lock：正在等待GET_LOCK()。 Waiting for tables：该线程得到通知，数据表结构已经被修改了，需要重新打开数据表以取得新的结构。然后，为了能的重新打开数据表，必须等到所有其他线程关闭这个表。以下几种情况下会产生这个通知：FLUSH TABLES tbl_name, ALTER TABLE, RENAME TABLE, REPAIR TABLE, ANALYZE TABLE,或OPTIMIZE TABLE。 waiting for handler insert：INSERT DELAYED已经处理完了所有待处理的插入操作，正在等待新的请求。 大部分状态对应很快的操作，只要有一个线程保持同一个状态好几秒钟，那么可能是有问题发生了，需要检查一下。 还有其他的状态没在上面中列出来，不过它们大部分只是在查看服务器是否有存在错误是才用得着。 explain table列：显示这一行的数据是关于哪张表的 type列：这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为const、eq_reg、ref、range、index和ALL possible_keys 列：显示可能应用在这张表中的索引。如果为空，没有可能的索引。可以为相关的域从WHERE语句中选择一个合适的语句 key列：实际使用的索引。如果为NULL，则没有使用索引。很少的情况下，MYSQL会选择优化不足的索引。这种情况下，可以在SELECT语句 中使用USE INDEX（indexname）来强制使用一个索引或者用IGNORE INDEX（indexname）来强制MYSQL忽略索引 key_len列：使用的索引的长度。在不损失精确性的情况下，长度越短越好 ref列：显示索引的哪一列被使用了，如果可能的话，是一个常数 rows列：MYSQL认为必须检查的用来返回请求数据的行数 Extra列：关于MYSQL如何解析查询的额外信息。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>sql优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Mysql深入理解系列7】MVCC与BufferPool缓存机制]]></title>
    <url>%2F2021%2F05%2F11%2Fmysql%2Fmysql_deep_7%2F</url>
    <content type="text"><![CDATA[MVCC与BufferPool Undo 日志版本链与ReadView机制详解。 MVCC多版本并发控制详解。 Innodb引擎BufferPoll缓存机制详解。 Redo与Undo日志详解。 MVCC多版本并发控制机制 Undo日志版本链 事务开始时候会生成一个Undo日志。包括数据值，事务ID。Redview活跃的事务列表。 ReadView 可见，不可见 在可重复读隔离级别，当事务开启，执行任何查询sql时会生成当前事务的一致性视图read-view，该视图在事务结束之前都不会变化(如果是读已提交隔离级别在每次执行查询sql时都会重新生成)，这个视图由执行查询时所有未提交事务id数组（数组里最小的id为min_id）和已创建的最大事务id（max_id）组成，事务里的任何sql查询结果需要从对应版本链里的最新数据开始逐条跟read-view做比对从而得到最终的快照结果。 Mysql会将Undo链分成三个集合 已提交事务，未提交与已提交事务，未开始事务。 版本链对比规则 如果 row 的 trx_id 落在绿色部分( trx_idmax_id )，表示这个版本是由将来启动的事务生成的，是不可见的(若row 的 trx_id 就是当前自己的事务是可见的）。 如果 row 的 trx_id 落在黄色部分(min_id &lt;=trx_id&lt;= max_id)，那就包括两种情况：a. 若 row 的 trx_id 在视图数组中，表示这个版本是由还没提交的事务生成的，不可见(若 row 的 trx_id 就是当前自己的事务是可见的)；b. 若 row 的 trx_id 不在视图数组中，表示这个版本是已经提交了的事务生成的，可见。 Innodb引擎BufferPoolRedo与UndoBufferPool是Innodb中的一块内存，缓存池。用于更新日志时缓存数据。 update数据过程。 加载叶子节点到innodb引擎中。 bufferPool 写undo日志 更新缓存日志。 写redo日志 准备提交事务，redo日志写入磁盘。（commit) 准备提交事务，写binlog。所有存储引擎都有些binlog日志的操作。 写一个commit标记到redo日志。为了redo与binlog数据一致。 随机写入磁盘以page为单位写入。 当bufferPool丢失，redo日志可以用来还原。 BufferPool非常重要，整个mysql的增删改查都先进过BufferPool。为什么这么设计？提高效率。基于内存效率更高。 BufferPool过程中会进行undo和redo的读写。这样效率高吗？ undo,redo是顺序写。数据库是随机写。顺序效率&gt;随机 (2倍以上性能)]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>MVCC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Mysql深入理解系列6】事务隔离级别]]></title>
    <url>%2F2021%2F05%2F11%2Fmysql%2Fmysql_deep_6%2F</url>
    <content type="text"><![CDATA[事务隔离级别深入理解 Mysql事务级ACID特性详解 Mysql事务隔离级别详解 Mysql锁机制详解 Mysql锁优化建议 事务隔离级别ACID事务及其ACID属性。事务的特性 ACID: ACID是原子性，一致性，持久性，独立性的缩写。 原子性：一个操作不是成功就是失败，要么执行成功，要么执行失败。 一致性：事务的索引规则，约束等不受破坏。事务开始中，所有相关的数据结果都必须保持状态一致，比如一个事务对三个数据进行修改，事务结束后三个状态必须都是被修改过的，保持一致。 隔离性： 每个事务之间不要相互影响。A事务查的结果不要被别的影响。就是说A事务执行过程中，结果集不能变。 持久性：事务完成后的对结果产生影响要持久。不能一会儿变来变去。 并发事务带来的问题 更新丢失(脏写) 事务A对数据进行+1，事务B对数据进行-1。B的更新操作把A覆盖掉了。 脏读 事务A读取了事务B还未提交的数据，但是事务B进行了回滚。事务A读到了脏数据。 不可重复读 事务A读取了数据1，但是被B修改成了2，事务A再读变成了2。与之前的不同。 幻影读 事务A，count了一个数据块，事务B插入了一条数据，事务A再进行count的 时候数据变了。 以上问题都是事务隔离性问题。所以要引入事务隔离级别来解决这些问题。 事务隔离级别 事务隔离级别是Mysql提供的预设的几种级别。 未提交读：事务T在读取数据的时候并未对数据进行加锁，事务T在修改数据的时候对数据增加行级共享锁，这种隔离级别没解决脏读。 已提交读：事务T在读取数据时增加行级共享锁，读取一旦结束，立即释放；事务T在修改数据时增加行级排它锁，直到事务结束才释放，这种隔离级别解决了脏读。 可重复读：事务T在数据读取时，必须增加行级共享锁，直到事务结束；事务T在修改数据过程中，必须增加行级排它锁，直到数据结束；这种隔离级别没解决幻读。 序列化：事务T在读取数据时，必须先增加表级共享锁，直到事务结束时才释放；事务T在修改数据时，必须先增加表级排它锁，直到事务结束才释放。 这些隔离级别采用的是MVCC:multi version concurrency controller 锁机制详解锁机制是事务隔离级别的实现方式 锁分类性能上分：悲观锁，乐观锁。数据库操作上分：读锁，写锁。从数据库的操作力度来分：表锁，行锁。 表锁开销小，加锁快。锁力度大， 一般在离线操作数据迁移的时候进行，比较少会用。 读锁（s)可以进行共享读。 写锁（x)不能进行写。也不能进行读。 重点 行锁开销大，加锁慢。innodb支持行锁。支持事务。 间隙锁innodb采用间隙锁，在可重复读级别解决了幻读问题。 临键锁（next-ke）行锁 + 间隙锁 锁优化建议行锁分析1show status like &apos;innodb_row_locks&apos; 1234567891011121314-- 查看事务select * from INFORMATION_SCHEMA_INNODB_TRX-- 查看锁select * from INFORMATION_SCHEMA_INNODB_LOCKS-- 查看锁等待select * from INFORMATION_SCHEMA_INNODB_LOCK_WAITS-- 释放锁。trx_mysql_thread_id可以从INNODB_TRX表里查看到kill trx_mysql_thread_id 锁优化建议 尽可能让所有数据检索都通过索引来完成，避免误索引锁升级为表锁。 合理设计索引，尽量缩小锁的范围。 尽可能减少检索条件范围，避免间隙锁。 尽量控制事务大小，减少锁定资源和时间长度，涉及事务加锁的sql尽量放在事务后执行。 尽可能低级别事务隔离。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Mysql深入理解系列4】索引优化1]]></title>
    <url>%2F2021%2F05%2F11%2Fmysql%2Fmysql_deep_4%2F</url>
    <content type="text"><![CDATA[索引优化 详解 优化索引选择探究 索引优化Orderby与Group byy UsingfileSort文件排序详解。 索引设计原则与实战。 索引优化原则避免ALL权标扫描。即时没走索引也要避免回表 扫描行数不决定查询快慢，还有回表啊什么的影响。大多情况下不用去改mysql的优化查询。（force dindex 不一定会更快) PS: 字符串不加单引号索引失效。2. 三个键的组合索引，范围查询放中间或者后面是可以走索引的。 1. 强制走索引。扫描行数可能少了，但是执行时间并不一定减少。 覆盖索引优化。 in和or在表数量比较大的情况下回走索引，在表记录不多的情况下选择走权标扫描。 like kk%不管表数据量大小都会走索引。 概念：索引下推。like KK%就是用到了索引下推优化。 索引下推5.6引入的。索引下推查询：在二级索引树过滤完like的字段后会再过滤后面条件的内容。符合的话进行会标。所谓的索引下面在推断。非下推（5.6之前）：在二级索引树过滤完like后没进行后面条件判断，直接回表，在回表的内容里在进行筛选。 索引下推意味着每次索引后，要再进行比对。like结果集少的话（like xxx%)，比对就比较快。mysql会使用。如果数量非常大的话(column &gt; xxx)，每次都要比对，不一定比回表快。 使用 trace进行分析。列出explain sql执行的过程，mysql各个节点预估的消耗量。 优化总结 mysql支持两种方式的排序filesort 和index, Using Index是指Mysql扫描索引本身完成排序，index效率高，filesort效率低。 order by 满足两种情况会使用Using index order by语句使用索引最左前列。 使用where子句与order by子句条件组合满足索引最左前列。 尽量在索引列上完成排序，遵循索引建立的最左前缀法则。 如果 order by的条件不在索引列上，就会产生Using filesort 能用覆盖索引尽量用覆盖索引。 group by 与order by很类似。其实质是先排序后分组，遵照索引创建顺序的最左前缀法则。对group by的优化如果不需要排序的可以加上order by null禁止排序。注意，where高于having,能卸载where先定条件就不要去having限定。 单路排序：一次性取出满足条件行的所有字段，在sortbuffer中进行排序，用trace工具可以看到sort_mode信息显示。sort_key,additional_files或者 sort_key,packed_additional_fileds不用回表。占用内存大。双路排序：根据条件取出相应的排序字段和可以直接定位行数据的ID,然后在sort buffer中进行爱旭。排序完后需要取回其他需要的字段、用trace工具可以看到sort_mode信息显示 sort_key,rowid。需要回表，暂用内存小。 可设置max_length_for_sort_data默认1024 。如果参与排序的字段小于这个的话，使用单路排序。如果大于的话，会使用双路排序。一般不去设置。 sort_buffer 排序内存。如果它比较小的话可以适当把max_length_for_sort_data配置小点，让优化器选择双路排序。（双路排序用ID,不用tmpfile) sort_buffer可以考虑配置更大的max_length_for_sort_data从而使用单路排序。 非DBA就不要去调整了。 怎么建索引建完表后，一般主体的业务开发完后，把跟表相关的sql语句都拉出来。根据sql语句建索引。 原则： 代码先行，主体业务完成后，建索引。 联合索引尽量覆盖到你业务的所有查询。order by group by这些都需要考虑。 不要在小基数字段上建立索引。 长字符串可以采用前缀索引。varchar(255) 建索引耗费太大的空间，可以 Key index（name(20),age,position)。前缀的一部分进行建索引 where 与order by冲突时优先where 基于慢sql查询进行建索引。slow_query_log=1 （provice,city,sex,age)age一般范围查询，放后面，在实际查询中，查询可以把 sex按照in塞进去，这样age就可以走索引。一般一个组合索引里保持只有一个范围查询的字段。 经验：10个字段左右的表。一个表里建2-3个组合二级索引就差不多了。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>索引优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Mysql深入理解系列5】索引优化2]]></title>
    <url>%2F2021%2F05%2F11%2Fmysql%2Fmysql_deep_5%2F</url>
    <content type="text"><![CDATA[分页查询优化详解。 表JOIN关联原理以及优化。 表COUNT查询优化。 阿里巴巴MYSQL规范解读。 MYSQL数据类型选择分析。 分页查询优化一般的分页：select * from employee limit 1,100 优化方式： 根据自增连续主键排序的分页：改成 id&gt;xxx limit 10; 用innerjoin来改写。select from employees order by name limit 90000,5可以改写成：select from employees e inner join(select id from employees order by name limit 90000,5) ed on e.id = ed.id 表JOIN关联select * from t1 inner join t2 on t1.a = t2.a 在Mysql的实现中，Nested-Loop Join有3种实现的算法： Simple Nested-Loop Join：SNLJ，简单嵌套循环连接Index Nested-Loop Join：INLJ，索引嵌套循环连接Block Nested-Loop Join：BNLJ，缓存块嵌套循环连接 嵌套循环链接 Nested-LoopJoin Simple Nested-Loop 简单嵌套循环连接实际上就是简单粗暴的嵌套循环，如果table1有1万条数据，table2有1万条数据，那么数据比较的次数=1万 * 1万 =1亿次，这种查询效率会非常慢。 Index Nested-Loop 索引嵌套循环连接是基于索引进行连接的算法，索引是基于内层表的，通过外层表匹配条件直接与内层表索引进行匹配，避免和内层表的每条记录进行比较， 从而利用索引的查询减少了对内层表的匹配次数，优势极大的提升了 join的性能： 使用场景：只有内层表join的列有索引时，才能用到Index Nested-LoopJoin进行连接。由于用到索引，如果索引是辅助索引而且返回的数据还包括内层表的其他数据，则会回内层表查询数据，多了一些IO操作。 基于块的嵌套循环链接Block Nested-Loop Join算法把驱动表的数据读入到join_buffer然后被驱动表扫描，与join_buffer的数据做对比。极端条件下，会过滤 t1 数量 * t2 数量词。 缓存块嵌套循环连接通过一次性缓存多条数据，把参与查询的列缓存到Join Buffer 里，然后拿join buffer里的数据批量与内层表的数据进行匹配，从而减少了内层循环的次数（遍历一次内层表就可以批量匹配一次Join Buffer里面的外层表数据）。 当不使用Index Nested-Loop Join的时候，默认使用Block Nested-Loop Join。 什么是Join Buffer？（1）Join Buffer会缓存所有参与查询的列而不是只有Join的列。（2）可以通过调整join_buffer_size缓存大小（3）join_buffer_size的默认值是256K，join_buffer_size的最大值在MySQL 5.1.22版本前是4G-1，而之后的版本才能在64位操作系统下申请大于4G的Join Buffer空间。（4）使用Block Nested-Loop Join算法需要开启优化器管理配置的optimizer_switch的设置block_nested_loop为on，默认为开启。 优化JOIN 用小结果集驱动大结果集，减少外层循环的数据量，从而减少内层循环次数：如果小结果集和大结果集连接的列都是索引列，mysql在内连接时也会选择用小结果集驱动大结果集，因为索引查询的成本是比较固定的，这时候外层的循环越少，join的速度便越快。 为匹配的条件增加索引：争取使用INLJ，减少内层表的循环次数 增大join buffer size的大小：当使用BNLJ时，一次缓存的数据越多，那么内层表循环的次数就越少 减少不必要的字段查询：（1）当用到BNLJ时，字段越少，join buffer 所缓存的数据就越多，内层表的循环次数就越少；（2）当用到INLJ时，如果可以不回表查询，即利用到覆盖索引，则可能可以提示速度。（未经验证，只是一个推论 in和exsits优化exists少用，能用join替代用join。记住。小表驱动大表。 表COUNT执行5.7版本 count(1),count(id),count(*)一样，几乎不用管。 分析：count(1) 不取值按行累加。count(*)也一样。count(字段) 拿出值走二级索引。count(id)走聚簇索引。聚簇索引一般比二级索引大，所以count(字段有索引)比count(id)效率大一点点。 常见优化方法维护表数据量。 innodb为什么不维护全表数量。是因为MVCC。多版本数据控制。不同的事务count（*）可能不一样。 count(*) 2.对总记录数没有特别精确可以用： show table status like &apos;employees&apos;; redis维护。数据库缓存双写一致代价很高。 增加数据库计数表。 阿里巴巴Mysql规范手册解读单标行不要超过500万行，或者单标容量超过2G，推荐分表。如果预计三年后的数据量根本达不到这个级别，就不要在建表时就进行分表。 索引规约 有唯一键字段，即使是组合字段，也要建成唯一字段。 超过三个表不能进行join. 在varchar上建立索引，必须指定索引长度。 页面搜索严禁使用做模糊或者全模糊。这种场景适合走搜索引擎。 数据类型选择]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Mysql深入理解系列3】执行原理]]></title>
    <url>%2F2021%2F05%2F11%2Fmysql%2Fmysql_deep_3%2F</url>
    <content type="text"><![CDATA[登录建立连接 登录维持session 建立连接，权限缓存 权限缓存在链接里。不用每次查询都校验。效率高。 查看链接数：1show processlist; my.conf query_cache_type一般不用。 查看缓存命中情况。1show status like &apos;%Qcache%&apos;&apos; 为什么这种缓存是鸡肋？ 缓存的时候会经常刷新，不适用热点业务。 词法分析器sql语句拆分成语法树。 语法树：结构化的存储。 语法树拆分后的使用场景：在分布式事务中 二阶段提交。commit,rollback 通过语法树会记录反向操作。在回滚的时候直接rollback。 补偿机制。构建补偿sql。进行回滚重放。3.优化器 条件查询，会判断哪种效率高用哪种，或者判断用哪种索引或者不用索引。 执行器调用响应的引擎执行操作。 bin-log归档不小心删了库怎么找回来？ server层实现的 bin-log技术。 bin-log记录的逻辑语句的影响。 bin-log格式有三种statement，row，mixed 12binlog-format=ROWsync-binlog=1 statement:记录的是这条操作语句的逻辑， 产生结果的过程。row: 记录这个语句影响那条记录之后的结果。row: mixed两种都记录。 如果记录的是statement 1update * from xxx where h=xx or b=xxx 优化器走的索引不一致，可能产生主从不一致。 所以最好bin-log用row bin-log恢复1flush logs; 重新开个bin-log文件进行记录。 恢复1mysqlbinlog --no-defaults /**/*/mysql-bin.00001 | mysql -uroot -p xxx 参数： 12--start-position--end-position]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>执行原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Mysql深入理解系列2】执行计划]]></title>
    <url>%2F2021%2F05%2F11%2Fmysql%2Fmysql_deep_2%2F</url>
    <content type="text"><![CDATA[执行计划分析sql执行数据explain 语法：explain ${sql} 12explain extended select * from (select * from film where id = 1) tmp;show warnings; TYPE 类型： SYSTEM:查询的整张表只有1个 select （select 1 from) const:查询的结果跟const有的比。select 1 from eq_ref:使用的唯一索引，效率仅次于 const ref:普通索引，可能查出多条。或者唯一索引的部分前缀。联合索引等。 range:索引查出了范围集。 以上都是走索引。 优化的方向 index:全索引扫描。尽量优化。 ALL:全聚簇索引扫描。 索引选择有优化，有的全表扫描效率更高就不选择索引。 如果结果集二级索引和主键索引全包含的情况下：有主键索引也有二级索引，会优先索引二级索引。主键索引比较大。 key_len 组合索引(联合索引)，说明用到了多长的索引。 key_len计算规则： 字符串char(n) :字节长短varchar(n): 3n+2。 +2存储字符串长度。 数值类型tinyint:1字节。smallint:2字节。int：4字节。bigint: 8字节。 时间类型date: 3字节timestamp:4字节 extra Using index说明查询的结果集在索引里，不用回表。 覆盖索引一种查找方式，结果集在一颗索引树里。不用回表。 Using where使用了where但是没有被索引覆盖。 Using index condition查询的列不完全被索引覆盖，where条件中是一个前导列的范围。 Using templrary,Using indexUsing templrary 使用了临时表。 查询语句有distint但是没有走索引的话，会在内存里建立临时表去重。如果有走索引的话，会在所以查询的时候直接进行distinc去重。变成 Using fileSort 查询里有order by。但是没有建立索引。如果有建索引会变成 Using index。因为索引已经是排好序了。 将用外部排序二不是所以你排序，数据较小时从内存排序。否则需要在磁盘完成。 select tables optimized away有max,min查询。使用了索引。 like查询 like ‘ts%’ 会使用索引like ‘%ts’ 不会使用索引。但是可以优化成全覆盖索引 原则：少用or 因为or一次就是扫描一次。or多次可能比全表扫还慢。 范围查找优化 select * from employee where age &gt; 10 and age &lt; 1000可能不走索引，印为mysql判断后可能全表扫描会比较快。 索引总结表 like kk%相当于=常量，%kk和%kk%相当于范围。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>执行计划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Mysql深入理解系列1】数据结构]]></title>
    <url>%2F2021%2F05%2F11%2Fmysql%2Fmysql_deep_1%2F</url>
    <content type="text"><![CDATA[数据结构基础https://www.cs.usfca.edu/~galles/visualization/Algorithms.html 数据结构 二叉树：可能产生单边链，对查询效率就很低。 红黑树：二插平衡树。 树的高度会很高。 B树： 非叶子节点也有存data。一个元素占用1K。一个NODE最大 16个元素。 所以数量大的话，树高度也会很高。 PS：大概估计是1kb 总共能存16个元素 B+树：平衡，且树矮索引的基本结构：B+树 非叶子节点不存储data，只存储所以。 叶子节点包含所有索引字段 叶子节点用指针连接。提高访问的性能。 一个NODE(树的节点） 16K 按照页来分配，一个16K。一次磁盘IO很慢，内存很快。所以比较费时间的是从磁盘node到NODE查询。 一个索引8B一个地址6B 16KB可以放 16KB/(8+6)个元素1170 那么2层的B+tree1170 * 1170 = 1368900 叶子节点有data一个NODE放16个元素。一个元素1K.算上叶子节点 1170 1170 16个元素。大概2000多万。树的高度3 所以只要3次IO。根节点常住内存。 存储引擎mysam 叶子节点存的数据地址。 innodb 叶子节点存的是具体的data值。 索引类型聚簇索引MyInSamID主键是非聚簇索引。 InodbID主键是聚簇索引。 关于主键 建立索引：组织B+。如果没有索引的话，选择第一列所有元素都不相等的元素来组织。如果没找到，建立一个隐藏列。这个隐藏列是唯一ID 组织B+树。 整型ID的作用：在建立索引和查询索引的过程中，会进行多次的比大小。Int效率高。如果是String的话必须每个字符都要对比。并且占用空间也小，节省固态硬盘，节省成本。 自增：HASH索引下。很快可以对应到磁盘文件地址。优点：等值查询很快。缺点：范围查询效率不好。并且会产生HAHD冲突。 聚簇索引和非聚簇索引那个快？聚簇索引会比较快。 非主键索引：非聚簇索引的叶子节点的数据放的是聚簇索引索引节点值。PS：INODB只有一个聚簇索引。为什么不直接放数据？节约存储空间，可以多存放非常多数据。 联合索引联合索引底层存储 索引是帮助Mysql搞笑查询排好序的数据结构。 联合索引也是排好序的数据结构。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【JVM深入理解系列6】OOM调优]]></title>
    <url>%2F2021%2F05%2F11%2Fjava%2Fjvm%2Fjvm_deep_6%2F</url>
    <content type="text"><![CDATA[JVM OOM 堆区Heap 方法区Per 栈区StackOverFlow 元空间调优参数 12-XX:MetaspaceSize=10m-XX:MaxMetaspaceSize=10m 1、最大、最小设置成一样大。2、程序运行起来后，通过visualVM、arthas查看占用了多少内存，向上调优，预留20%以上的空间。 虚拟机堆1234567[GC (Allocation Failure) [PSYoungGen: 1344K-&gt;320K(2048K)] 7894K-&gt;7118K(9216K), 0.0071516 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] [GC类型 (GC原因) [新生代垃圾收集器: gc前新生代的内存使用情况-&gt;gc后新生代的内存使用情况(新生代总内存)] gc前堆内存的使用情况-&gt;gc后堆内存的使用情况(堆总内存), gc耗时] [Times: gc阶段用户空间耗时 gc阶段内核空间耗时, gc阶段实际耗时] [Full GC (Ergonomics) [PSYoungGen: 320K-&gt;0K(2048K)] [ParOldGen: 6798K-&gt;5930K(7168K)] 7118K-&gt;5930K(9216K), [Metaspace: 9296K-&gt;9233K(1058816K)], 0.6733958 secs] [Times: user=1.76 sys=0.00, real=0.68 secs] [GC类型 (GC原因) [新生代垃圾收集器: gc前新生代的内存使用情况-&gt;gc后新生代的内存使用情况(新生代总内存)] [老年代垃圾收集器: gc前老年代的内存使用情况-&gt;gc后老年代的内存使用情况(新生代总内存)] gc前堆内存的使用情况-&gt;gc后堆内存的使用情况(堆总内存), [Metaspace: gc前元空间的内存使用情况-&gt;gc后元空间的内存使用情况(元空间总内存)], gc耗时] [Times: gc阶段用户空间耗时 gc阶段内核空间耗时, gc阶段实际耗时] 调优参数 -Xms10m -Xmx10m 1、预留30%以上的空间2、周期性看日志，重点关注full gc频率 虚拟机栈 调优参数 -Xmss200k 栈大小相同，栈深度不同，为什么？因为栈上会分配数据。导致栈帧变大。深度会变浅。 调优工具 jps -q：只显示Java进程的ID -m：输出Java进程的ID + main函数所在类的名词 + 传递给main函数的参数 -l：输出Java进程的ID + main函数所在类的全限定名（包名 + 类名） -v：输出Java进程的ID + main函数所在类的名称 + 传递给JVM的参数应用：可通过此方式快速查看JVM参数是否设置成功 -V、hostid基本用不到，这里就不做介绍了，感兴趣的同学可以自行百度学习。 如何识别Java进程 jps输出的信息全是Java进程的信息，是如何做到的？ Java进程在创建的时候，会生成相应的文件，进程相关的信息会写入该文件中。Windows下默认理解是 jstate Hotspot自带的工具，通过该工具可实时了解某个进程的class、compile、gc、memory的相关信息。具体可通过该工具查看哪些信息可通过jstat -options查看. 为什么说是实时呢，因为底层实现是mmap，及内存映射文件 jstat输出的这些值从哪来的PerfData文件Windows下默认理解是C:\Users\username\AppData\Local\Temp\hsperfdata_usernameLinux下默认路径是/tmp/hsperfdata_username PerfData文件 1、文件创建取决于两个参数-XX:-/+UsePerfData默认是开启的关闭方式：-XX:-UsePerfData。如果关闭了，就不会创建PerfData文件-XX:-/+PerfDisableSharedMem（禁用共享内存）默认是关闭的，即支持内存共享。如果禁用了，依赖于PerfData文件的工具就无法正常工作了2、文件删除默认情况下随Java进程的结束而销毁3、文件更新-XX:PerfDataSamplingInterval = 50ms即内存与PerfData文件的数据延迟为50ms 纯Java编写\openjdk\jdk\src\share\classes\sun\tools\jstat\Jstat.java 3、jinfo4、jstack5、jmap6、jconsole7、visualVM8、arthas Java agent1、命令行2、attach 实战1、统计线程数 1jstack -l 6972 | grep &apos;java.lang.Thread.State&apos; | wc -l 2、检测死锁 可使用jstack、jconsle、visualVM 3、CPU占用过高 定位到占用CPU最高的进程 1top -H -p 6290 线程ID由十进制转成十六进制，用Python jstack 6290（进程ID）|grep 18a1（线程ID，十六进制） -A 30 问题：模拟OOM并思考如何调优死锁、CPU占用过高问题排查Java Agent的两种实现方式自己写DEMO]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【JVM深入理解系列5】精通垃圾回收]]></title>
    <url>%2F2021%2F05%2F11%2Fjava%2Fjvm%2Fjvm_deep_5%2F</url>
    <content type="text"><![CDATA[分代复制算法指针移动原理数据发生了移动，为什么依然能够访问到。 JVM四大层面 java语法java字节码openjdk原理 openJdk源码 强软弱虚引用前提：未发生GC 所有的对象都是白色。发生GC时新建的对象都是hi黑色。 标记阶段做的事情 初始化标记只标记 GC Roots直接关联的对象 对象直接充当GC Root 只标记A,E 标记成灰色 会STW，耗时很少。 并发标记阶段 （三色标记）不需要STW耗时很久将GC Roots直接关联的对象所有引用链全部跑一遍一层一层遍历，正常所有被标记的都会变成黑色。 三色标记 GC:串行用户线程会STW一个Thread执行gc并行用户线程STW,多个GC线程运行并发不需要STW,用户线程，GC线程并发。（需要三色标记） 最终标记 并发标记会带来三个问题 多标A-&gt;B-C A是黑色，B是灰色，C是白色，此时 A不引用B了。B还是灰色，没有变成黑色。 不会被回收。 少标标记程序在运行的过程中，用户线程依然创建对象。 由于是新创建的所以是黑色的。创建的对象会躲过这次GC,但是下次GC有可能会被回收。 漏标GC标记程序运行过程中，引用链发生改变。 B（灰）对D引用取消了。A（黑）引用了D.这个会导致D被回收，执行就会报错。 解决方法：增量更新，原始快照。 多标和少标在下轮GC会被回收掉。 如何解决漏标： 当黑色对象直接引用了一个白色对象后，我们就将这个黑色对象记录下来（加入 oopMap)，在扫描完成后，重新对这个黑色对象扫描,这个就是增量更新（Incremental Update） 当删除了灰色对象到白色对象的直接或间接引用后，就将这个灰色对象记录下来，再以此灰色对象为根，重新扫描一次。这个就是原始快照（Snapshot At TheBeginning，SATB） 读写屏障 原方法write 在执行前加上 pre_write,在执行之后执行 post_write。 核心垃圾回收期现在的垃圾回收期发展趋势：模块化，支持并发。默认 Parallel Scvenge，Parallel Old CMS分代写屏障 + 增量更新 G1基于region 默认2M，4M,8M,16,32M 2048个Regin每个 region都可以是e,f,to老年代，但是一个region只能有一个角色。 控制耗时 Garbege First == G1 为什么耗内存？20% - 30% 内存存一些数据结构。优先队列维护一个 Region优先级数据。每次回收10ms。能回收几个region算几个。 空间换时间。 记忆集与卡表 首先跨代引用的问题？ 存在跨代引用时，在进行YGC时，如果young generation的Y对象被old generation中O对象引用，那么称O对象存在跨代引用，而且Y对象应该在本次垃圾回收中存活下来，所以old generation的对象在YGC时也是Strong root的一部分，如果每次YGC都去扫描old generation中所有对象的话，肯定会非常耗时。 解决跨代引用老年代引用新生代。YGC时候对象被回收了。老年代会报错新生代引用老年代。YGC时候，也要扫描整个老年代，非常耗时。 记忆集：GenRemSet卡表：CardTable 记忆集是一个理论，卡表是实现。 卡表的实现原理每个Region 2M.卡表卡页 卡表中有2048个卡页 一个卡页对应一个Region一个卡页是512B 卡页中的一个B标识Region中的4KB(2M/512)00000001标记这个region是否有对年轻代的引用。 如果没有记忆集：需要遍历所有的老年代的region,遍历所有region中的所有对象。 说白了，记忆标记了某个region是否有引用年亲代引用，然后只遍历有年轻代引用的region。减少了遍历的region数量。 savePoint 安全点： 150 + 90 + 275 - 40 =]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【JVM深入理解系列4】精通String]]></title>
    <url>%2F2021%2F05%2F11%2Fjava%2Fjvm%2Fjvm_deep_4%2F</url>
    <content type="text"><![CDATA[遗留问题String s2 = “dd” + new String(“test”);四个 string3个char 数组UseCompressedoops压缩的是对象指针的长度 UseCompressedClassPointers压缩的是klass对象指针的长度 如果不压缩，则在arrayOopDesc中声明的非静态字段之后分配，如果压缩，它将占用oopDesc中_klass字段的后半部分。 数组长度怎么算 数组对应的klass是：TypeArrayKlass实例对应的oop：TypeArrayOop 对象的内存布局 对象头 mark word klass pointer 实例数据 填充 不开启解压的情况：Mark word 8Bklass pointmetadata._compressed_klass数组长度4B 这种情况下，klass + 数组长度用了多少字节 12 = 8 + 4 开启压缩的情况下： _metadata._compressed_klass 数组长度4B klass + 数组长度= 4 + 4 = 8B ===== 垃圾回收算法可重入锁很像 lock + 1 unlock -1 计数==0释放 对象存活依据 引用计数 例外，无法处理循环依赖。 初始化死锁 可达性分析 GC Rootsoop局部变量表字符串常量池 JVM的GC 给存活的对象打标机，回收没有标记的对象。 内存池 内存分配算法指针碰撞（openJdk, 无限CAS-失败就是已经被使用了 ) 空闲列表：维护一个表存放 已用，空闲，已回收 描述。 Memory Pool内存池管理内存块。list m_chunks;是一个列表，存放所有向OS申请的内存块。 能做的事情向OS要内存mall哦错，calloc释放内存没有垃圾回收器，需要手动释放 其他打印chunk信息 Memory chunk直接持有内存 Memory Cellchunk中的单元。内存块。 Memory Pool 根据要的内存对齐后计算出要申请的内存大小。 向操作系统申请内存。 根据不同的垃圾回收算法填充不同的list标记清除，标记-整理，回收的是整个chunk. m_avaliable_table m_used_table 分代+复制算法， 空闲 可用 已用 待交换 标记-清除算法面向整个堆产生碎片 如果你需要分配大对象，需要连续的空间。但是内存是碎片化的。 标记-整理算法内存碎片合并老年代基本属于这个算法。 合并内存，解决碎片问题。耗CPU Eden区，对象朝生夕死。碎片很多。 碎片很多，合并碎片的时候需要STW。 合并碎片的时候有两种对象需要处理： 1. 这个空间已被释放。直接合并 2. 这个空间的空间未被释放 对象搬家（合并内存，数据移动，指针移动） 分代-复制算法JVM使用这个算法，解决标记合并碎片消耗性能过高、GC停止用户线程过长问题。举例 将内存分段。 一半用（0-10） from，一半闲（11-20）to 发生GC的时候不需要整理，交换空间标记，角色切换。标记角色切换原先from区的内存处理标记的对象清理。存活的对象需要移动到新的内存区域（to 区）数据整理指针整理 注意：不管现在的9种垃圾回收器，还是以后出现的垃圾回收器，都是这三种垃圾回收算法。 指针移动，老的指针地址不能变，这个怎么做到？(对象的hashCode不变)指针是动态计算出来的。公式依赖的变量在变。 return (pvoid)((ulong)chunk-&gt;get_data() + get_start()* chunk-&gt;get_align_size() )卡表，记忆集 总结内存池，JVM不需要手动释放内存，由垃圾回收器自动回收。 自动回收算法 标记-清除算法。面向整个堆，会产生碎片，在申请大对象时候，会有问题。 标记-整理算法。老年代常用，会在标记清理后整理内存，但是CPU耗费太大，STW时间会比较长。标记，清理，数据整理，指针整理。 数据块(chunk cell)整理过程从前到后合并一次从后到前合并一次分代-复制解决整理算法性能太低，而且新生代的特点是朝生夕死。 不需要清理，只需要转移数据和指针切换 from,to角色 问题： 指针切换了以后为什么可以访问？ hashcode会一直变。运行时计算出来的，所以没影响。 PS:对象模型，为什么要字节对齐。8BCPU提升速率。CPU读是 4 当数据从1字节开始的时候，问题很复杂，首先先将前4个字节读到寄存器，并再次读取4-7字节的数据进寄存器，接着把0字节，4,6,7字节的数据剔除，最后合并1,2,3,4字节的数据进寄存器，对一个内存未对齐的寄存器进行了这么多额外操作，大大降低了CPU的性能。 但是这还属于乐观情况，上文提到内存对齐的作用之一是平台的移植原因，因为只有部分CPU肯干，其他部分CPU遇到未对齐边界就直接罢工了。]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【JVM深入理解系列3】底层优化]]></title>
    <url>%2F2021%2F05%2F10%2Fjava%2Fjvm%2Fjvm_deep_3%2F</url>
    <content type="text"><![CDATA[对象布局 对象头 Mark Word 32bit 4B 64bit 8B 类型指针 Klass pointer 对象所属类的元信息的实例指针 instanceKlass 指针压缩 开启后 4B 关闭 8B 数组长度 如果这个对象不是数组 占 0B 如果这个对象是数组 占4B 表示这个对象数组的元素个数 实例数据 类的非静态属性，生成对象就是实例数据。 对象属性 boolean 2B byte 1B char 2B int 4B float 4B double 8B 引用类型：4B(指针压缩) 8B(不压缩) long 8B 对齐填充 8B字节对齐，java中所有的对象都是8B字节对齐。 如果一个对象占3个字节，JVM会补2个字节凑成32B达到8字节对齐。 为什么要做填充？ 1. 效率提高 计算类大小 指针压缩开启后指针压缩16B = 8B（markword)+ 4B(klass point) + 0B + 0B = 12需要补到16关闭指针压缩16B = 8 + 8 + 0 + 0 数组对象开启指针压缩 数组对象在关闭指针压缩的情况下，会出现两端填充。不止这一种情况。 一个OOP能标识最大堆空间 32bit内存最大 4G 一个OOP,存储的时候是3B,32bit使用的时候胃部补了3个0， 35bit OOP32G瓶颈 32G不够用了，需要扩容怎么办？解决方法：8字节对齐 改成16字节对齐。 8 自己对齐，内存地址会补3个0.16字节对齐会补4个032G*2 = 64G改源码。 JDK为什么没用16字节对齐 1. 没必要 32G已经极限了。GC耗费CPU资源。太大，暂停时间太长。 2. 非空间 总结 对象的两种内存结构 kclass,oop 计算三种类型的对象大小。 指针压缩 调优 项目上线前的预估调优。 项目上线初期，基于日志做一些基础调优。 发生oom，频繁full gc，做测地的调优 调优的点 jvm内存模型的调优。 热点代码缓冲区的调优。 案例 亿级流量项目的调优 一个UV会访问20个左右的PV500W用户。 下单转换率 10% = 50W 40%订单在前两小时四完成。每分钟1200笔订单。周边流量都加起来，大概 没妙产生200M对象总共2700M 每个操作要3秒 200 * 3 = 600每秒钟 600M对象进入Eden区 14秒发生一次young gc 600M对象还存活，无法被回收 触发空间担保。 老年代6400M多长时间触发一次fullgc 9 * 14 = 126秒一次full gc 本质：有对象在young gc时未被清理干净。触发空间担保，动态年龄判断，15次进入了老年代。 解决之道： 对象尽量在 young gc阶段回收掉。 堆最小是物理内存的64份之一，最大是物理内存的4分之一。 oopjava对象在JVM中的存在形式 opp-klass模型 两种对象内存结构条虫 计算三种类型的对象开启指针压缩关闭指针压缩指针压缩实现原理32G瓶颈如何扩展JDK源码，OS源码何为JVM调优 预估调优 小规模调优 OOM,full gc频繁调什么？ 方法区 虚拟机栈 堆区 热点代码缓冲区 亿级流量预估调试实战 GC日志 减少fullgc stw时间太长。]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【JVM深入理解系列2】执行引擎]]></title>
    <url>%2F2021%2F05%2F10%2Fjava%2Fjvm%2Fjvm_deep_2%2F</url>
    <content type="text"><![CDATA[执行引擎JVM运行Java程序的一套子系统 两种解释器 字节码解释器 Java字节码-&gt; C++代码-&gt;硬件编码 模板解释器 Java字节码-&gt;硬件编码 底层实现过程 1. 申请一块内存：可读可写可执行。2. 将处理new字节码的硬编码拿过来 3. 将处理new字节码的硬编码写入申请的内存。 4. 申请一个函数指针，用这个函数指针执行这块内存。 5. 调用的时候，直接通过这个指针调用。 三种运行模式 -Xint -Xcomp -Xmixed 编译优化正常的C++函数生成的硬编码都有堆栈操作。 字节码解释器解释执行的和编译器没关系 模板解释器执行的因编码是即时编译器编译的。 JIT即时编译器 C1 c1编译器在client模式下的即时编译器 1. 比C2搜集的数据少。触发宽松。 2. 编译优化比较浅。 3. C1编译器生成的代码执行效率低。 C2 C2编译器是server模式下的即时编译器 1. 触发条件比较严格，程序运行一段时间后才执行。 2. 优化比较深。 3. 编译生成的代码比C1效率高 混合编译器 GraalVM 即时编译触发条件 硬编码热点代码 注意：即时编译的最小单位是代码块。 N热度： 生成热点代码client，N默认是1500server，N默认是10000 1java -client -XX:+PrintFlagsFinal -version 热度衰减：new 7000一段时间么执行后会2倍速递减 -&gt; 3500 经典故障 业务增长，加节点。热机切冷机 冷机：刚运行不久热机：运行了一段时间 节点。相同配置节点加入。负载均衡平摊压力。 热机有热点代码缓存了，并发更大。 热机能承受的并发大于冷机。 冷机一边在增加流量一遍在即时编译。性能就降低。 问题：热点代码缓存在哪里？方法区：CodeCache（调优方向之一）server 2496 2M，client模式下160k 即时编译是如何运行的VM_THREADGC 队列存放及时编译任务。当触发即时编译时会将编译任务放到及时编译队列里。 1、 触发及时编译任务入队列。2、 VM_THREAD执行队列任务。 异步。 即时编译的线程有多少，如何调优？ 硬编码，热点代码热点代码存在哪里？热点代码缓冲区在哪里？ 热点代码缓冲区，在方法区。 逃逸分析 逃逸是一种现象 对象作用域 局部变量，非逃逸 非局部变量，逃逸。方法外，线程外。 基于逃逸技术，JVM开发了三种优化技术。 1. 栈上分配 2. 标量替换 标量： 不可再分，java中的基本类型就是标量。 3. 锁消除 没竞争的锁，会消除掉。 栈上分配 如何通过代码测试？ 对象在兑取分配 对象在虚拟机栈上分配。 HSDB JDK8的栈上分配存在吗？ 生成一个对象100W次，在栈上是不是又100W个。如果没有，就存在栈上分配，不发生GC的情况下。]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【JVM深入理解系列1】JVM底层加载]]></title>
    <url>%2F2021%2F05%2F10%2Fjava%2Fjvm%2Fjvm_deep_1%2F</url>
    <content type="text"><![CDATA[klass模型java的每个类在JVM中都有一个对应的klass类实例与之对应，存储类的元信息：常量池、属性信息、方法信息 MetaspaceObj Metadata klass instanceKlass instanceMirrorKlass买奥数java.lang.Class实例 instanceRefKlass描述java.lang.Reference的子类 instanceClassLoaderKlass ArrayKlass TypeArrayKlass描述java基本类型数组的数据结构 ObjectArrayKlass描述java中引用类型数组的数据结构。 类的元信息是存储在元空间的。 普通的Java类在JVM对应的是instanceKlass的实例。三个类： InstanceMirrorKlass:用于表示java.lang.class, Java代码中获取到的class对象，实际上是这个C++类的实例。存储在堆区，学名镜像类。 InstanceRefClass：用于表示Java.lang.ref.Referece的子类。 InstanceClassLoader:用于遍历某个加载器加载的类。 Java中的数组不是静态数组类型，是动态数据类型，既是运行时期生成的，Java数组的元信息用ArrayKlass的子类来表示 TypeArrayKlass:表示基本类型的数组。 ObjectArrayKlass:表示引用类型的数组。 类加载的过程七个过程： loading -&gt; verification -preparation -&gt; resolution-&gt; initialization -&gt; Using -&gt; Unloading 加载 通过类的全限定名获取存储该类的class文件。 解析成运行时数据，InstanceKlasss实例。存放在方法区。 在堆区生成该类的class对象，InstanceMirrorKlass实例。 程序怎么写都可以。只要满足上面三个效果就OK。改写OpenJdk源码，满足上面三个条件就Ok 何时加载 主动使用时 new, getstatic, putstatic, invokestatic 反射 初始化一个类的子类去加载其父类。 启动类（main函数所在类） 当使用JDK1.7动态语言时，如果一个java.lang.invoke.MethodHandler实例最后的解析结果。REF_getStatic,REF_putStatic,REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行初始化，则需要先触发其初始化。 预加载：包装类，String, Thread 因为没有指明必须从哪里获取class文件，脑洞大开的工程师开发了这些： 从压缩包中读取，jar，war 从网络中读取，web applet 动态生成，如 动态代理，CGLIB 由其他文件生成，如JSP 从数据库读取。 从加密文件中读取 验证 文件格式验证 元数据验证 字节码验证 符号引用验证 准备为静态变量分配内存，赋初值。实例变量是在创建对象的时候完成赋值的，没有赋初值一说。 int,long,short,char,byte,boolean,float,double,reference 如果被final修饰，在编译的时候会给属性添加ConstantValue属性，准备阶段直接完成赋值，既没有赋初值这一说。 解析将常量池中的符号引用转为直接引用 解析后的信息存储在ConstantPoolCache类实例中 类或接口的解析。 字段解析 方法解析 接口方法解析 何时解析 思路： 加载阶段解析常量池时 用的时候 openjdk是第二种思路，在执行特定的字节码指令之前进行解析： 初始化执行静态代码块，完成静态变量的赋值。静态字段，静态代码段，字节码层面会生成clinit方法。方法中语句的先手顺序与代码的编写顺序相关。 类加载细节有空了再补]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【深入理解并发编程系列5】抽象队列同步器AQS Lock详解]]></title>
    <url>%2F2021%2F04%2F01%2Fjava%2Fconcurrent%2Fconcurrent_5%2F</url>
    <content type="text"><![CDATA[背景为了提升锁性能引入了 锁粗化技术。 锁粗化：多个同步都加统一个对象。反复不停进出一个对象。JVM会对这样的代码进行逃逸分析。对整个代码块进行扫描。如果符合这种特征代码的话，会将多个同步块合并成一个大的同步快,变粗了。 锁消除：如果对象不可能被多个对象访问到。通过逃逸分析，会对锁进行消除。比如只加在对象上的锁。对象的生命周期是线程调用周期，对象只被一个线程访问。此时会对锁进行消除。 还有一个典型的就是栈上分配的对象，符合逃逸分析的对象，分配在栈上。并且对这个对象进行了加锁。此时，也只有这个线程能对对象进行访问，就会进行锁消除。 PS:逃逸分析后会做的优化:锁消除，锁粗化，标量替换等。标量:八大基本类型。 AQS LOCK详解 AQS还没出现之前，如果需要规定一个线程占用CPU使用时间的话，可能用到while循环。 或者用：lock.pack(); lock.Unpack(THread) 停止，阻塞方法。 unpack CASLock三大核心：自旋，LockSupport,CAS,队列 队列的FIFO用来实现公平，非公平锁。 CAS依赖硬件元语：cmpxchg() LockSupport:线程阻塞工具。底层是native的方法 UNSAFE.xx AQS具备特性： 阻塞等待队列 共享/独占 公平/非公平 可重入 允许中断 除了Lock外，Java.concurrent.util当中同步器的实现如Latch,Barrier,BlockingQueue等， 都是基于AQS框架实现 AQS内部维护属性volatile int state (32位) state表示资源可用状态。 state三种访问方式： getState() setState(int) compareAndSetState() AQS定义两种资源共享方式 Exclusive-独占，只有一个线程能执行，如ReentrantLock。 Share-共享，多个线程可以同时执行，如Semaphore/CountDownLatch。 同步等待队列 同步等待队列 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共 享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/ 唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法： isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去 实现它。 tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回 false。 tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回 false。 tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成 功，但没有剩余可用资源；正数表示成功，且有剩余资源。]]></content>
      <categories>
        <category>java</category>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【深入理解并发编程系列4】JVM内置锁 synchronized关键字详解]]></title>
    <url>%2F2021%2F03%2F29%2Fjava%2Fconcurrent%2Fconcurrent_4%2F</url>
    <content type="text"><![CDATA[ReentrantLock历史：李二狗看到Synchronized效率太低，自己实现了一套基于AQS的锁。支持可重入，公平，非公平等特性。 Synchronized历史：1.6之前效率低下，重量锁。1.6之后进行了升级，追加了锁的升级过程。 偏向锁-&gt;轻量级锁-&gt;重量级锁。 效率和ReentrantLock差不多 一个图： 锁升级过程 JVM锁膨胀过程 膨胀过程： 新建实例： 匿名偏向锁。 第一个线程过来加锁，变成偏向锁。（高23位记录了对象的线程ID) 第二个线程来后，触发 偏向锁升级，轻量级锁。 重量锁膨胀： 新建实例，匿名偏向锁 第一个线程过来，变成偏向锁。 第二个线程过来，触发轻量级锁。（高30位，指向线程，栈中锁记录的指针-比偏向锁要精确） 轻量级锁一直被占用，第二个线程自旋无法获取。此时升级成重量级锁。 （高30位存互斥量指针）。 加锁hashcode，会变成轻量级锁的原因： 偏向锁没有hashcode,轻量级锁有个叫replace lock record。在栈帧里。 轻量级锁升级的时候 高30位记录了线程栈上锁的块，lockrecord .hashcode存在这个lockrecord。并且初始的mark word也存在了线程栈上。 hashcode存的位置 什么是Monitor? 一种同步工具，是java的一个对象。所有的java对象天生就是monitor。所有对象在新建的时候都会有一把看不见的锁。叫做内部锁，或者Monitor锁。就是Synchronized锁。MarkWord锁标记为10.其中指针指向 的地址就是Monitor对象的起始地址。在java虚拟机中（hotspot)Monitor是由ObjectMonitor实现的。源码在C++的ObjectMonitor.http文件中。]]></content>
      <categories>
        <category>java</category>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【深入理解并发编程系列3】JMM-CPU缓存一致性协议MESI]]></title>
    <url>%2F2021%2F03%2F26%2Fjava%2Fconcurrent%2Fconcurrent_3%2F</url>
    <content type="text"><![CDATA[volatile可见性实现的原理编译后的汇编会增加一个lock前缀 CPU指令 lock前缀是总线锁 CPU访问内存必须通过总线桥访问。lock前缀加了总线锁，其他CPU就无法通过总线桥获取内存数据。 这个是古老的CPU用的。这种方式会降低多核性能。 MESI M:modifyE:独占S:shareI：已失效 总线嗅探： CPU会嗅探Bus总线的通知状态。 当CPU都要进行对某个缓存行进行加锁的时候（64byte)会发一个消息出来。我要加锁了。让总线来判断，是否加锁成功。总线裁决。 LOCK的时候告诉CPU采用缓存一致性协议来处理这个被修饰的变量。 缓存行是最大64byte有时候变量大于64byte，这时候会升级总线锁。 缓存一致性协议无法对寄存器生效。所以如果已经被加载到了寄存器里面进行操作的话 CPU中有一个 StoreBufer。cpu修改变量后，会发送一个I信号给其他cpu，其他cpu信息收到后确认后会回复一个已经失效消息。这时后才进行storo操作。所以会先把操作后的数据存在storeBuffer.（内部CPU的ACK机制） 接收后 storeBuffer放回缓存行，在写到内存。 Happens-before指令重排需要遵循的规则。 Thread().startThread().interupt这种是不会被重排的 八大规则：]]></content>
      <categories>
        <category>java</category>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【深入理解并发编程系列2】JVM内存模型]]></title>
    <url>%2F2021%2F03%2F24%2Fjava%2Fconcurrent%2Fconcurrent_2%2F</url>
    <content type="text"><![CDATA[内存模型Java原生支持多线程，这种模型是为了适配不同操作系统架构。屏蔽掉系统和底层硬件的差异。工作模型如下： JVM的内存模型是JVM定义抽象的定义。工作内存对应的JVM哪一个模块不重要因为，不同的JVM实现，实现的也不一样。 数据八大原子操作 lock: 作用于主内存的变量，把一个变量标记为一条线程独占状态。 unlock：与loc相反的操作。 read： 作用于主内存的变量，把一个变量从主内存传输到线程的工作内存中，以便后续的load动作。 load: 作用于工作内存的操作，把read操作从主内存中得到的变量放入工作内存的变量副本中。 use： 作用于工作内存的操作，把工作内存中的一个变量值传给执行引擎。 assign： 作用于工作内存，把一个从执行引擎接收到的值赋值给工作内存的变量。 store： 作用于工作内存，把工作内存中的一个变量的值传送到主内存中，以便随后的write。 write：作用于工作内存，把store操作从工作内存中的一个变量的值传送到主内存变量中。 来：lock-&gt;read-&gt;load-&gt;use去：assign-&gt;store-&gt;write-&gt;unlock 内存可见性关键词：MESI 协议 volatile 用于保证有序性 解决可见性问题syncronized用于保证原子性 volatile 解决可见性问题 保证及时看到。不加的话，也有可能看到。只是不及时。如何理解：JVM定义的这些模型语义，不会去描述多线程程序如何执行，而是描述多线程程序于许表现出来的行为。任何执行策略，只要产生的是允许的行为，那他就是一个可以接受的策略。 空循环优先级超高。 synronized可以保证内存块操作的原子性。 指令重排 as-if-serial happen-before volatile指令重排优化内存屏障是cpu指令，作用两个： 保证特定操作的执行顺序。 保证某些变量的可见性。（volatile的可见性） 原理：内存屏障技术ifence： 一种Load barrier读屏障。sfence： 一种Store Barrier写屏障mfence ： 全能型屏障，具备ifence和sfence能力。Lock前缀 Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为PUC指令的一种锁。它后面可以跟 ADD，ADC,AND，BTC，BTR,BTS，CMPXCHG,CMPXCH8B,DEC,INC,NEG,NOT,OR,SBB,SUB,XOR,XADD,and XCHG指令。 手动加内存屏障Unsafe.fullFence]]></content>
      <categories>
        <category>java</category>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【深入理解并发编程系列1】操作系统与虚拟机]]></title>
    <url>%2F2021%2F03%2F21%2Fjava%2Fconcurrent%2Fconcurrent_1%2F</url>
    <content type="text"><![CDATA[概要 冯诺依曼计算机模型 cpu缓存结构剖析。 操作系统内存管理与线程模型。 虚拟机指令集架构详解。 分诺依曼计算机体系 CPU缓存架构 多级缓存： L1 cache 数据缓存和指令缓存，逻辑独占。一般 256K L2 cache 物理核独占，逻辑核共享。 一般1M左右 L3 cache， 所有物理核共享 一般8M 缓存由缓存行构成（cacheline)64byte大小 CPU读取内存数据的过程： L1-&gt;l2-&gt;L3 一次判断，如果有，直接读取到寄存器。 如果L1,2,3都没有，从内存，读到L3，从L3复制到L2,从L2复制到L1。L1读到寄存器。 CPU读取数据的特性 空间局部性 CPU从内存拿数据，不仅是拿目标数据，紧邻的一片一次性加载到L3缓存里。 时间局部性 如果一个信息正在被访问那么近期它还可能被访问，比如循环，递归方法的反复调用。 操作系统内存管理操作系统内存空间分为 用户空间 内核空间 为什么进行内存空间的划分？ 目的是为了做到程序运行的安全隔离与稳定。32G 4G大小内存为例。内核空间 1G用户空间3G CPU运行的安全等级ring0： 内核态，权限最高。各种操作都可以做。 ring1ring2ring3权限一次降低。 运用运行的级别一般在用户态。JVM,app等等。 内核线程模型内核线程（KLT) ，系统内核管理线程内核保存线程额上下文信息，线程阻塞不会引起进程阻塞。在多处理器系统上，多线程在多处理器上并行执行。线程的创建调度和管理由内核完成。效率比ULT要慢，比进程操作快。 用户线程模型 进程与线程现代操作系统在运行一个程序时，会为其创建一个进程，例如：启动一个java程序，操作系统就会创建一个java进程。进程是OS操作系统资源分配的最小单位 线程是OS操作系统调度CPU的最小单元。也叫轻量级进程（Light Weight Process)，在一个进程里可以创建多个线程。这些线程拥有各自的计数器，堆栈，局部变量等属性。并且能够访问共享的内存变量，CPU在这些线程上高速切换。让使用者感觉到这些线程在同时执行，既并发的感觉。相似的还有并行 线程上下文切换过程： 虚拟机指令集架构CPU执行架构分两种，指令集架构和，寄存器指令集架构。 指令集架构 设计和实现更简单，适用于资源受限的系统。 避开了寄存器分配难题，使用零地址指令方式分配。 指令流中的指令大部分是零地址指令，其执行过程依赖于操作栈，指令集更小，编译器容易实现。 不需要硬件支持，可移植性更好，更容易实现跨平台。 寄存器指令集架构 典型的应用如二进制指令集。传统的PC一级Android的Davilk虚拟机。 指令集架构则完全依赖硬件，可移植性差。 性能优秀和执行更高效。 花费更少的指令去完成一项操作。 在大部分情况下，基于寄存器架构的指令集往往都以一地址，二地址指令和三地址指令为主。而基于栈架构的指令集涉及出栈入栈等操作。Java，Python，GO]]></content>
      <categories>
        <category>java</category>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈判的四大金刚]]></title>
    <url>%2F2020%2F08%2F25%2Farticle%2Fteammanager%2Fteammanager_3%2F</url>
    <content type="text"><![CDATA[一个单体的个人对外界信息的反馈可以分为 梦想型 计划型 恋人型 勇士型 梦想型，主导方向（激励）。计划型，做逻辑预算（基于自我表达）。恋人型，拉近距离（共情）。勇士型，坚毅行动（直接的怼）。 不同的场景应用以上不同的组合兵来将挡，水来土掩。一切的故事从针锋相对开始，到化干戈为玉帛结束。 运用好，表现在在个人社交上，是魅力。在工作上是领导力。表现在家庭生活上是责任担当。 逻辑是可以从不便的事物中推理出改变的轨迹。然而人与人之间不讲逻辑的时候居多。 与死物讲逻辑，与活物打太极。绕进自己框架，将意识移植。改变不了对方的想法，就改变自己的想法。这是个非零和博弈。 谈判三断式 赞同 A 中立 B 共情 C 反对 D 有不同意见时候，采取比较适合的方式： ABDC A开场，B阐述事实，D跑出观点，C安慰。]]></content>
      <categories>
        <category>技术之外</category>
      </categories>
      <tags>
        <tag>管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列:中介者模式]]></title>
    <url>%2F2020%2F04%2F07%2Fjava%2Fpatterndesign%2Fpatterndesign_22%2F</url>
    <content type="text"><![CDATA[概念 定义一个中介者对象, 封装一系列对象的交互关系, 使得各对象不必显示的相互引用,从而使其耦合松散, 而且可以独立的改变它们的交互. 实现以智能家居为例，小爱控制只能家居。 类图 代码 SmartDevice 智能设备抽象 12345678910111213141516package com.littlehui.design.mediator;/** * @Description TODO * @ClassName SmartDevice * @Author littlehui * @Date 2020/4/9 18:12 * @Version 1.0 **/public abstract class SmartDevice &#123; public abstract void operateDevice(String instruction, SmartMediator mediator); public abstract void readyState(String instruction);&#125; SmartMediator 中介者 123456789101112131415161718192021222324package com.littlehui.design.mediator;/** * @Description TODO * @ClassName SmartMediator * @Author littlehui * @Date 2020/4/9 18:12 * @Version 1.0 **/public abstract class SmartMediator &#123; SmartDevice bd; SmartDevice md; SmartDevice cd; public SmartMediator(SmartDevice bd, SmartDevice md, SmartDevice cd) &#123; super(); this.bd = bd; this.md = md; this.cd = cd; &#125; public abstract void music(String instruction); public abstract void curtain(String instruction); public abstract void bath(String instruction);&#125; MusicDevice 智能播放器 12345678910111213141516171819202122package com.littlehui.design.mediator;/** * @Description TODO * @ClassName MusicDevice * @Author littlehui * @Date 2020/4/9 18:15 * @Version 1.0 **/public class MusicDevice extends SmartDevice &#123; @Override public void operateDevice(String instruction,SmartMediator mediator) &#123; System.out.println("音乐设备"+instruction); mediator.music(instruction); &#125; @Override public void readyState(String instruction) &#123; System.out.println("音乐设备准备"+instruction); &#125;&#125; CurtainDevice 智能窗帘 12345678910111213141516171819202122package com.littlehui.design.mediator;/** * @Description TODO * @ClassName CurtainDevice * @Author littlehui * @Date 2020/4/9 18:14 * @Version 1.0 **/public class CurtainDevice extends SmartDevice &#123; @Override public void operateDevice(String instruction, SmartMediator mediator) &#123; System.out.println("窗帘已"+instruction); mediator.curtain(instruction); &#125; @Override public void readyState(String instruction) &#123; System.out.println("窗帘设备准备"+instruction); &#125;&#125; BathDevice 洗浴室 123456789101112131415161718192021222324package com.littlehui.design.mediator;/** * @Description TODO * @ClassName BathDevice * @Author littlehui * @Date 2020/4/9 18:16 * @Version 1.0 **/public class BathDevice extends SmartDevice &#123; @Override public void operateDevice(String instruction, SmartMediator mediator) &#123; System.out.println("洗浴设备"+instruction); mediator.bath(instruction); &#125; @Override public void readyState(String instruction) &#123; System.out.println("洗浴设备正在准备"+instruction); &#125;&#125; Xiaoai 具体中介者 小爱 123456789101112131415161718192021222324252627282930313233343536package com.littlehui.design.mediator;/** * @Description TODO * @ClassName Xiaoai * @Author littlehui * @Date 2020/4/9 18:13 * @Version 1.0 **/public class Xiaoai extends SmartMediator &#123; public Xiaoai(SmartDevice bd, SmartDevice md, SmartDevice cd) &#123; super(bd, md, cd); &#125; @Override public void music(String instruction) &#123; System.out.println("小爱操作音乐音乐"); cd.readyState(instruction); bd.readyState(instruction); &#125; @Override public void curtain(String instruction) &#123; System.out.println("小爱操作窗帘"); md.readyState(instruction); bd.readyState(instruction); &#125; @Override public void bath(String instruction) &#123; System.out.println("小爱操作浴室"); cd.readyState(instruction); md.readyState(instruction); &#125;&#125; Client 客户端 1234567891011121314151617181920package com.littlehui.design.mediator;/** * @Description TODO * @ClassName Client * @Author littlehui * @Date 2020/4/9 18:18 * @Version 1.0 **/public class Client &#123; public static void main(String[] args) &#123; SmartDevice bd = new BathDevice(); SmartDevice cd = new CurtainDevice(); SmartDevice md = new MusicDevice(); SmartMediator sm = new Xiaoai(bd, cd, md); cd.operateDevice("open",sm); md.operateDevice("close",sm); &#125;&#125; 执行结果 12345678910Connected to the target VM, address: &apos;127.0.0.1:60536&apos;, transport: &apos;socket&apos;窗帘已open小爱操作窗帘窗帘设备准备open洗浴设备正在准备open音乐设备已close小爱操作音乐音乐音乐设备准备close洗浴设备正在准备closeDisconnected from the target VM, address: &apos;127.0.0.1:60536&apos;, transport: &apos;socket&apos; 场景当有多个对象彼此间相互交互的时候，自然就会想到对象间的耦合度过高，解决办法就是封装对象间的交互行为，因此就能想到中介者模式就是干这行的。 总结 中介者的核心是抽离依赖关系。通过依赖关系来描述整个业务场景。使得复杂的逻辑可以内聚。 中介者模式优点 通过让对象彼此解耦，增加对象的复用性 通过将控制逻辑集中，可以简化系统维护通过中介者使一对所变成了一堆一，便于理解 缺点 如果设计不好，引入中介者会使程序变的复杂 中介者承担过多责任，维护不好会出大事]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>中介者模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列:访问者模式]]></title>
    <url>%2F2020%2F04%2F07%2Fjava%2Fpatterndesign%2Fpatterndesign_21%2F</url>
    <content type="text"><![CDATA[概念 访问者模式有点复杂。一般不轻易使用。他的主要任务是通过不同的访问器，访问问相同的对象，得到不同的信息生成不同的报表等。 实现类图 代码 Coputer被访问者 12345678910111213141516171819202122/** * @Description TODO * @ClassName Computer * @Author littlehui * @Date 2020/4/7 18:20 * @Version 1.0 **/public class Computer implements ComputerPart &#123; ComputerPart[] parts; public Computer()&#123; parts = new ComputerPart[] &#123;new Screen(), new Keyboard()&#125;; &#125; public void accept(ComputerPartVisitor computerPartVisitor) &#123; for (int i = 0; i &lt; parts.length; i++) &#123; parts[i].accept(computerPartVisitor); &#125; &#125;&#125; ComputerPart 被访问者，被访问的部分 123456public interface ComputerPart &#123; public void accept(ComputerPartVisitor computerPartVisitor);&#125; ComputerPartVisitor 访问者 1234public interface ComputerPartVisitor &#123; public void visit(Screen screen); public void visit(Keyboard keyboard);&#125; Keyboard ,Screen 具体的电脑访问部分对象 1234567891011public class Keyboard implements ComputerPart &#123; public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125;public class Screen implements ComputerPart &#123; public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125; 访问接口 Visitor 1234public interface Visitor &#123; public void visit(ComputerPart computerPart);&#125; Client客户端调用方式 1234567public class Client &#123; public static void main(String[] args) &#123; ComputerPart computer = new Computer(); computer.accept(new ComputerPartDisplayVisitor()); &#125;&#125; 执行结果 123456Connected to the target VM, address: &apos;127.0.0.1:51341&apos;, transport: &apos;socket&apos;this is computer screenthis is computer keyboardDisconnected from the target VM, address: &apos;127.0.0.1:51341&apos;, transport: &apos;socket&apos;Process finished with exit code 0 场景访问者模式一般用于当对象属性或者信息太多，太杂的时候，通过不同的访问器（观察角度），访问不同的信息。并且可以对信息进行二次加工。具体场景如：1：员工的绩效评估，工程师和HR评估的角度不同。访问角度不同，这时候访问者模式就比较适合。2：报表，老板看到的报表和团队看到的项目报表肯定不一样。这时就满足访问者模式场景。 总结总的来讲，访问者模式提供多角度对同个对象的观测方式。对其理解不深很深刻，总结可能不到位，以后再总结。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>访问者模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列:解释器模式]]></title>
    <url>%2F2020%2F04%2F07%2Fjava%2Fpatterndesign%2Fpatterndesign_23%2F</url>
    <content type="text"><![CDATA[概念 解释器模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。 实现类图 代码 Expression 123456789101112package com.littlehui.design;/** * @Description TODO * @ClassName Expression * @Author littlehui * @Date 2020/4/10 09:51 * @Version 1.0 **/public interface Expression &#123; public boolean interpret(String context);&#125; OrExpression 1234567891011121314151617181920212223package com.littlehui.design;/** * @Description TODO * @ClassName OrExpress * @Author littlehui * @Date 2020/4/10 10:25 * @Version 1.0 **/public class OrExpression implements Expression &#123; private Expression expr1 = null; private Expression expr2 = null; public OrExpression(Expression expr1, Expression expr2) &#123; this.expr1 = expr1; this.expr2 = expr2; &#125; public boolean interpret(String context) &#123; return expr1.interpret(context) || expr2.interpret(context); &#125;&#125; AndExpression 1234567891011121314151617181920212223package com.littlehui.design;/** * @Description TODO * @ClassName AndExpression * @Author littlehui * @Date 2020/4/10 10:25 * @Version 1.0 **/public class AndExpression implements Expression &#123; private Expression expr1 = null; private Expression expr2 = null; public AndExpression(Expression expr1, Expression expr2) &#123; this.expr1 = expr1; this.expr2 = expr2; &#125; public boolean interpret(String context) &#123; return expr1.interpret(context) &amp;&amp; expr2.interpret(context); &#125;&#125; Client 12345678910111213141516171819202122232425262728293031323334package com.littlehui.design;/** * @Description TODO * @ClassName Client * @Author littlehui * @Date 2020/4/10 10:26 * @Version 1.0 **/public class Client &#123; //规则：Robert 和 John 是男性 public static Expression getMaleExpression()&#123; Expression robert = new TerminalExpression("Robert"); Expression john = new TerminalExpression("John"); return new OrExpression(robert, john); &#125; //规则：Julie 是一个已婚的女性 public static Expression getMarriedWomanExpression()&#123; Expression julie = new TerminalExpression("Julie"); Expression married = new TerminalExpression("Married"); return new AndExpression(julie, married); &#125; public static void main(String[] args) &#123; Expression isMale = getMaleExpression(); Expression isMarriedWoman = getMarriedWomanExpression(); System.out.println("John is male? " + isMale.interpret("John")); System.out.println("Julie is a married women? " + isMarriedWoman.interpret("Married Julie")); &#125;&#125; 执行结果 123456Connected to the target VM, address: &apos;127.0.0.1:61783&apos;, transport: &apos;socket&apos;John is male? trueJulie is a married women? trueDisconnected from the target VM, address: &apos;127.0.0.1:61783&apos;, transport: &apos;socket&apos;Process finished with exit code 0 场景 可以将一个需要解释执行的语言中的句子表示为一个抽象语法树 一些重复出现的问题可以用一种简单的语言来表达 一个简单语法需要解释的场景 在一些编译器，运算表达式，正则表达式经常有使用。 总结 优点：1、可扩展性比较好，灵活。2、增加了新的解释表达式的方式。3、易于实现简单文法。 缺点：1、可利用场景比较少。2、对于复杂的文法比较难维护。3、解释器模式会引起类膨胀。4、解释器模式采用递归调用方法。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>解释器模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列:备忘录模式]]></title>
    <url>%2F2020%2F01%2F08%2Fjava%2Fpatterndesign%2Fpatterndesign_19%2F</url>
    <content type="text"><![CDATA[概念 备忘录保存的是类内部状态。在适当的时候可以用来恢复当时的类状态。还原现场。 实现类图 代码 Originator执行者，封装备忘录具体属性信息。 1234567891011121314151617181920212223242526272829303132333435package com.littlehui.design.memoto;/** * @Description TODO * @ClassName Originator * @Author littlehui * @Date 2020/4/7 14:45 * @Version 1.0 **/public class Originator &#123; private String state; /** * 创建一个新的备忘录对象 */ public Memento createMemento()&#123; return new Memento(state); &#125; /** * 将发起者的状态恢复到备忘录的状态 */ public void restore(Memento memento)&#123; this.state = memento.getState(); &#125; public String getState() &#123; return state; &#125; public void setState(String state) &#123; this.state = state; &#125;&#125; Caretaker备忘录管理者。包含一个备忘录具体对象，可以是list。 123456789101112131415161718192021package com.littlehui.design.memoto;/** * @Description TODO * @ClassName Caretaker * @Author littlehui * @Date 2020/4/7 14:46 * @Version 1.0 **/public class Caretaker &#123; private Memento mMemento; public Memento restoreMemento()&#123; return mMemento; &#125; public void storeMemengto(Memento memento)&#123; this.mMemento = memento; &#125;&#125; Memento备忘录的具体类。 12345678910111213141516171819202122232425package com.littlehui.design.memoto;/** * @Description TODO * @ClassName Memento * @Author littlehui * @Date 2020/4/7 14:45 * @Version 1.0 **/public class Memento &#123; private String state; public Memento(String state)&#123; this.state = state; &#125; public String getState() &#123; return state; &#125; public void setState(String state) &#123; this.state = state; &#125;&#125; Client执行流程 12345678910111213141516171819202122232425262728package com.littlehui.design.memoto;/** * @Description TODO * @ClassName Client * @Author littlehui * @Date 2020/4/7 14:45 * @Version 1.0 **/public class Client &#123; public static void main(String[] args) &#123; //发起 并初始化 Originator originator = new Originator(); originator.setState("state1"); //备忘录管理 Caretaker caretaker = new Caretaker(); caretaker.storeMemengto(originator.createMemento()); originator.setState("state2"); System.out.println(originator); //备忘录 恢复 originator.restore(caretaker.restoreMemento()); System.out.println(originator); &#125;&#125; 场景比如在玩游戏保存游戏进度的时候可以用来实现回退功能。回退到上一个保存点。等等 总结 优点备忘录模式存在的意义也是在于他的回复机制。并且其特点是在用户不必关心类的内部细节情况下完成了。实现了信息封装。 缺点由于备忘录的保存需要额外的存储空间，所以在类属性多的情况下，多次的备忘录操作比较消耗资源。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>备忘录模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列:命令模式]]></title>
    <url>%2F2020%2F01%2F08%2Fjava%2Fpatterndesign%2Fpatterndesign_18%2F</url>
    <content type="text"><![CDATA[概念 命令模式将命令的执行和发送命令的责任分隔开，委派给不同的对象执行。 ###涉及角色 客户端(Client)角色：创建一个具体命令(ConcreteCommand)对象并确定其接收者。 命令(Command)角色：声明了一个给所有具体命令类的抽象接口。 具体命令(ConcreteCommand)角色：定义一个接收者和行为之间的弱耦合；实现execute()方法，负责调用接收者的相应操作。execute()方法通常叫做执行方法。 请求者(Invoker)角色：负责调用命令对象执行请求，相关的方法叫做行动方法。 接收者(Receiver)角色：负责具体实施和执行一个请求。任何一个类都可以成为接收者，实施和执行请求的方法叫做行动方法。 实现类图 代码 客户端FishCommander 12345678910111213141516171819202122package com.littlehui.design.command;/** * @Description 鱼长官 * @ClassName Client * @Author littlehui * @Date 2020/1/8 16:29 * @Version 1.0 **/public class FishCommander &#123; public static void main(String[] args) &#123; FishSoldier fishSoldier = new FishSoldier(); Command huntingFishCommand = new HuntingFishCommand(fishSoldier); Command cookingFishCommand = new CookingFishCommand(fishSoldier); CommandBrodCast commandBrodCast = new CommandBrodCast(); commandBrodCast.setCookingFishCommand(cookingFishCommand); commandBrodCast.setHuntingFishCommand(huntingFishCommand); commandBrodCast.huntingFish(); commandBrodCast.cookingFish(); &#125;&#125; 命令Command接口 123456package com.littlehui.design.command;public interface Command &#123; public void execute();&#125; HuntingFishCommand123456789101112131415161718192021package com.littlehui.design.command;/** * @Description TODO * @ClassName HuntingFish * @Author littlehui * @Date 2020/1/8 16:31 * @Version 1.0 **/public class HuntingFishCommand implements Command &#123; FishSoldier fishSoldier; public HuntingFishCommand(FishSoldier fishSoldier) &#123; this.fishSoldier = fishSoldier; &#125; public void execute() &#123; fishSoldier.doHuntingFish(); &#125;&#125; CookingFishCommand123456789101112131415161718192021package com.littlehui.design.command;/** * @Description TODO * @ClassName CookingFishCommand * @Author littlehui * @Date 2020/1/8 16:32 * @Version 1.0 **/public class CookingFishCommand implements Command &#123; FishSoldier fishSoldier; public CookingFishCommand(FishSoldier fishSoldier) &#123; this.fishSoldier = fishSoldier; &#125; public void execute() &#123; fishSoldier.doCookingFish(); &#125;&#125; 命令发送者请求者 CommandBrodCast1234567891011121314151617181920212223242526272829303132package com.littlehui.design.command;/** * @Description TODO * @ClassName CommandInvoder * @Author littlehui * @Date 2020/1/8 16:34 * @Version 1.0 **/public class CommandBrodCast &#123; private Command huntingFishCommand; private Command cookingFishCommand; public void setCookingFishCommand(Command cookingFishCommand) &#123; this.cookingFishCommand = cookingFishCommand; &#125; public void setHuntingFishCommand(Command huntingFishCommand) &#123; this.huntingFishCommand = huntingFishCommand; &#125; public void cookingFish() &#123; cookingFishCommand.execute(); &#125; public void huntingFish() &#123; huntingFishCommand.execute(); &#125;&#125; 命令接收者 FishSoldier12345678910111213141516171819package com.littlehui.design.command;/** * @Description TODO * @ClassName Soldier * @Author littlehui * @Date 2020/1/8 16:38 * @Version 1.0 **/public class FishSoldier &#123; public void doHuntingFish() &#123; System.out.println("hunting fish"); &#125; public void doCookingFish() &#123; System.out.println("cooking fish"); &#125;&#125; 场景命令模式的场景经常用在对外系统调用的时候使用。比如一个http请求封装成一个命模式。不同的参数也可以封装成不同的命令。命令执行端，服务端的业务发生改变时或者url调用方式发生改变时，客户端不需要调整。只要修改相应的命令封装器就好了。有效地做到了修改的隔离。 总结命令模式的最大特点就是隔离了命令的发送端和执行端。命令的发送端无需知道命令执行端具体怎么执行。这种隔离方式的好处是调用的透明化。具有更好的扩展性。由于命令是一个个相互独立的，所以可以很自然的做到复合命令。命令已经是封装过的，所以可以对他进行有效的参数化。综合以上他有几种特点： 更松散的耦合 更动态的控制 支持复合命令 更好的扩展性]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>命令模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列:状态模式]]></title>
    <url>%2F2020%2F01%2F08%2Fjava%2Fpatterndesign%2Fpatterndesign_20%2F</url>
    <content type="text"><![CDATA[概念 状态模式是将对象的状态接口抽出，从状态的维度出发描述对象。对象千千万，状态就那么几个，所以从状态的维度度量。业务上会清晰很多。 实现类图 代码 抽象状态 CarState 12345678910111213package com.littlehui.design.state;/** * @Description TODO * @ClassName CarState * @Author littlehui * @Date 2020/4/7 17:09 * @Version 1.0 **/public interface CarState &#123; public void doCarAction(Car car);&#125; 具体状态 start,run,stop 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.littlehui.design.state;/** * @Description TODO * @ClassName CarStart * @Author littlehui * @Date 2020/4/7 17:10 * @Version 1.0 **/public class CarStart implements CarState &#123; public void doCarAction(Car car) &#123; System.out.println("汽车启动中。"); car.setState(1); &#125;&#125;package com.littlehui.design.state;/** * @Description TODO * @ClassName CarRun * @Author littlehui * @Date 2020/4/7 17:10 * @Version 1.0 **/public class CarRun implements CarState &#123; public void doCarAction(Car car) &#123; car.setState(2); System.out.println("汽车在行驶中。"); &#125;&#125;package com.littlehui.design.state;/** * @Description TODO * @ClassName CarStop * @Author littlehui * @Date 2020/4/7 17:11 * @Version 1.0 **/public class CarStop implements CarState &#123; public void doCarAction(Car car) &#123; car.setState(0); System.out.println("汽车停止。"); &#125;&#125; 上下文 Car 1234567891011121314151617181920212223242526package com.littlehui.design.state;/** * @Description TODO * @ClassName Context * @Author littlehui * @Date 2020/4/7 17:07 * @Version 1.0 **/public class Car &#123; /** * 0 停止 * 1 启动中 * 2 奔跑中 */ private int state; public int getState() &#123; return state; &#125; public void setState(int state) &#123; this.state = state; &#125;&#125; 客户端调用 12345678910111213141516171819202122package com.littlehui.design.state;/** * @Description TODO * @ClassName Client * @Author littlehui * @Date 2020/4/7 17:18 * @Version 1.0 **/public class Client &#123; public static void main(String[] args) &#123; Car car = new Car(); CarStart carStart = new CarStart(); carStart.doCarAction(car); CarRun carRun = new CarRun(); carRun.doCarAction(car); CarStop carStop = new CarStop(); carStop.doCarAction(car); &#125;&#125; 执行结果 123456Connected to the target VM, address: &apos;127.0.0.1:64995&apos;, transport: &apos;socket&apos;汽车启动中。汽车在行驶中。汽车停止。Disconnected from the target VM, address: &apos;127.0.0.1:64995&apos;, transport: &apos;socket&apos; 场景总结 好处状态控制放到了服务的内部，客户端不用操作具体的状态流转业务逻辑。可以分节点操作，扩展性能比较好。上面这个例子只是很简单的模仿了一下工作流控制状态的跳转。状态模式最主要的好处就是把状态的判断与控制放到了其服务端的内部，使得客户端不需要去写很多代码判断，来控制自己的节点跳转，而且这样实现的话，我们可以把每个节点都分开来处理，当流程流转到某个节点的时候，可以去写自己的节点流转方法。 坏处状态类要同时实现。耦合度会高。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>状态模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Communications link failure 问题解决]]></title>
    <url>%2F2019%2F11%2F01%2Fmysql%2FMysql_2%2F</url>
    <content type="text"><![CDATA[症状 节点挂机一个晚上后会首次请求会 Communications link failure 原因分析产生 Communications link failure是由于使用了被关闭的数据库连接导致。 关键配置分析maxEvictableIdleTimeMillis配置，默认25200000毫秒 deruid连接最大存活时间。 minEvictableIdleTimeMillis 300 秒 druid连接最小存活时间 mysql wait_close 时间 8小时 httpProxy连数据库的 代理 超时时间 1000秒 testWhileidle 空闲时间检测配置300秒。300秒检测一次，如果连接年龄大于300秒，则回收。 minIdle 配置为1 连接池最小少保留一个连接。 几种连接会被关闭的情况：1：当数据库连接超过8小时，会被mysql关闭。 2：当一次查询大量数据超过1000秒，会被httpProxy关闭。 3：连接存活时间大于300秒，并且是空闲的，会被testWhileidle关闭。druid关闭。 综合分析：基于以上三种关闭情况是不会产生 communications link failure的。但是由于minIdle配置的是1，在druid进行空闲连接清理的时候总有一个被保留，当这个连接超过了mysql_close的8小时后，会被mysql关闭。此时如果有请求过来，就会使用这个连接，导致 Communications link failure。至此破案。 我们实际情况，就是隔夜后，第二天早上初次请求发生了这种状况。分析过后以上的情况后，建议使用druid的配置注意如下： 设置maxEvictableIdleTimeMillis（最大生存时间）也要小于数据库连接超时时间1000s 配置时，mysql的wait_timeout &gt;nginx的 proxy_connect_timeout &gt; druid的maxEvictableIdleTimeMillis. 优化慢查询，将支付平台可能的最长允许sql执行时间设置给proxy_timeout]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>缓存</tag>
        <tag>druid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【更好的工作 tips4】理解事物的脉络]]></title>
    <url>%2F2019%2F10%2F09%2Farticle%2Fworker%2Fworker_3%2F</url>
    <content type="text"><![CDATA[脉络是什么 各种事，各种情况，各种状态，都有一定的内在规律可循。称之为事物的脉络。掌握到事物的脉络就会很清楚的理解事物为什么这样发展，他的轨迹为什么是这样的。能为后面预测事物发展作为依据让人自然而然地会理解到后面可能会面对的挑战，并且为迎接挑战而做准备。 怎么把握到脉络事物的脉络是依托于原始轨迹。需要深度思考原来的轨迹模式为什么是这样的。从表象开始思考剥离无关的因素，就会得到一张完整的发展骨架。从骨架出发，结合因果律，整体的事物脉络就会很清晰地展现在你面前。 实际工作怎么用到把握事物的脉络，小到技术上的选型，大道公司运转层面的方向把握，都有用处。比如在学习Sentinel流量控制技术时，代码是技术上的表象，从表象上可以看到Sentinel用到的几种模式。比如责任链，比如工厂等等，算法如：漏铜，漏斗等。基于这些算法那和模式，构建了他的核心功能-对流量的控制管理。从这里就找到一副完整的技术骨架：基于漏桶算法和责任链模式。围绕着这个骨架的因果，周边构建出了规则配置，流量整形，监控等等非核心业务功能。这样，Sentinel的脉络就很清晰了。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>事物的脉络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[角色转变]]></title>
    <url>%2F2019%2F10%2F08%2Farticle%2Fteammanager%2Fteammanager_2%2F</url>
    <content type="text"><![CDATA[什么是角色转变 角色转变，使你不仅仅是自然人的你。 角色转变转变了什么不同的角色转变，转变的形式不同。之于部门，你代表的是部门。之于具体项目，这个角色可能是项目组。那么多不同的角色转变之下，实际上都保持着转变的共性。归根结底两个：思维转变，做事风格转变。 思维转变思维转变在于，考虑的问题角度发生变化。 做事风格做事风格，是由于考虑角度的风格发生了变化。自然而然影响到了具体做事的风格。 如何适应角色的转变在角色转变过程中，迅速切换，抓住处于不同角色时候需要做到的关键决策尤为重要。]]></content>
      <categories>
        <category>技术之外</category>
      </categories>
      <tags>
        <tag>管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【流量控制系列1】引言和索引]]></title>
    <url>%2F2019%2F07%2F29%2Fjava%2Fflowcontroller%2Fflowcontroller_1%2F</url>
    <content type="text"><![CDATA[目的 自底向上构建流量控制知识体系。在后面遇到流量控制相关问题，可以举一反三快速得到解决方案。 对sentinel流控产品有一定的了解，在使用的时候能够快速入手，并且根据具体业务场景开发和扩展。 流量控制背景在平时的正常的访问流量下，系统可以正常运行，但是当遇到热点事件，流量突然间增大的情况下。但是预估值和真实的访问量可能会有很大的出入，流量是不能准确估算的，所以要对我们的系统制定应急预案，防范流量突然暴涨的情况下我们的系统被压垮。 应用的场景 秒杀活动。 高并发流量控制。 一些需要提高服务稳定性的场景。 文档索引【流量控制系列1】引言和索引【流量控制系列2】流量控制的基础方法和算法【流量控制系列3】Semaphore信号量介绍【流量控制系列4】Sentinel和Hystrix对比【流量控制系列5】Sentinel 详细介绍【流量控制系列6】Sentinel 详细介绍-SlotChain源码解析【流量控制系列7】Sentinel实践]]></content>
      <categories>
        <category>java</category>
        <category>流量控制</category>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>限流</tag>
        <tag>Sentinel</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【流量控制系列2】流量控制的基础方法和算法]]></title>
    <url>%2F2019%2F07%2F29%2Fjava%2Fflowcontroller%2Fflowcontroller_2%2F</url>
    <content type="text"><![CDATA[流量控制的方法白名单机制： 可以采用白名单的机制来限制访问，没有加入白名单的用户不让访问系统 令牌池机制也叫令牌桶 用户访问系统必须获得令牌池中的令牌，才能进行访问。令牌池每秒钟，阀门开启一次，所有的请求去令牌池中并发的抢夺令牌，获得令牌的可以访问系统，没有获得的返回“系统正忙”或者让该请求加入队列然后重试（注意：这里是一个坑，不能让请求加入到队列中，因为加入队列后会带来很大的问题，访问的请求底层是一个socket连接，我们不知道要过多长时间才能获得访问，hold住这个socket连接要耗费系统的资源，如果保存的请求量比较大的，系统的load会非常的高，会带来很大的系统负载压力。最好的方法是让直接拒绝掉访问的请求，返回给用户，让用户重试，重新访问）。可以通过控制令牌池中令牌的数量来控制访问，当一个请求访问获得令牌时令牌池中的令牌数量减一，当访问结束后要把令牌还回到令牌池中，令牌数量加一。 限QPS 阀门每秒开启一次，开启后重新初始化令牌池根据初始化的令牌数量限制每秒能够进行的请求数量，取了令牌后不用归还。 限并发 限制同一时间的请求只能敷在多少。他的令牌池是固定的，直接限制并发，取令牌进行访问，访问结束后归还令牌。 简单的实现实例：java信号量实现方式 漏桶算法每个接口限定一个固定的处理请求能力，相当于一个固定的桶能承载的最大的水的容量，而这个桶的大小就是最多能处理的请求并发数能力，然后每处理完一个请求，那么漏桶里面的水就会漏出去一些，如果请求来的时候，漏桶已达到承载极限（水装满了），这时就是请求速度大于处理速度并且堆积的请求太多了的情况。最终漏桶的水将会溢出，就相当于拒绝了请求。 漏斗有一个进水口 和 一个出水口，出水口以一定速率出水，并且有一个最大出水速率： 在漏斗中没有水的时候， 如果进水速率小于等于最大出水速率，那么，出水速率等于进水速率，此时，不会积水 如果进水速率大于最大出水速率，那么，漏斗以最大速率出水，此时，多余的水会积在漏斗中 在漏斗中有水的时候 出水口以最大速率出水 如果漏斗未满，且有进水的话，那么这些水会积在漏斗中 如果漏斗已满，且有进水的话，那么这些水会溢出到漏斗之外 漏桶与令牌桶的比较漏桶的出水速度是恒定的，那么意味着如果瞬时大流量的话，将有大部分请求被丢弃掉（也就是所谓的溢出）。 令牌桶来说，生成令牌的速度是恒定的，而请求去拿令牌是没有速度限制的。这意味，面对瞬时大流量，该算法可以在短时间内请求拿到大量令牌，而且拿令牌的过程并不是消耗很大的事情。 文档索引【流量控制系列1】引言和索引【流量控制系列2】流量控制的基础方法和算法【流量控制系列3】Semaphore信号量介绍【流量控制系列4】Sentinel和Hystrix对比【流量控制系列5】Sentinel 详细介绍【流量控制系列6】Sentinel 详细介绍-SlotChain源码解析【流量控制系列7】Sentinel实践]]></content>
      <categories>
        <category>java</category>
        <category>流量控制</category>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>限流</tag>
        <tag>Sentinel</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【流量控制系列4】Sentinel和Hystrix对比]]></title>
    <url>%2F2019%2F07%2F29%2Fjava%2Fflowcontroller%2Fflowcontroller_4%2F</url>
    <content type="text"><![CDATA[Sentinel和hystrix对比 Hystrix侧重点 隔离熔断为主的容错机制 sentinel侧重点S 多样化的流量控制 熔断降级 系统负载保护 实时监控和控制台 共同特征 资源类型和执行模型 sentinel的特色1. 轻量，高性能 2. 流量控制 3. 负载保护 4. 实时监控和控制面板 5. 生态 总结 对比项 Sentinel Hystrix 隔离策略 信号量隔离 线程池隔离/信号量隔离 熔断降级策略 基于响应实践活动失败比率 基于失败比率 实时指标实现 滑动窗口 滑动窗口（基于RxJava) 规则配置 支持多种数据源 支持多种数据源 扩展性 多个扩展点 插件的形式 基于注解的支持 支持 支持 限流 基于QPS,支持基于调用关系的限流 有限的支持 流量整型 支持慢启动、匀速器模式 不支持 负载均衡保护 支持 不支持 控制台 开箱即用，可配置规则、查看秒级监控、机器发现等 不完善 常见的框架适配 Servlet,Spring Cloud,Dubbo,gRPC等 Servlet,Spring Cloud Netflix 开源否 开源 半开源 结论从产品层面来看，sentinel提供了更为丰富的功能和控制入口。更容易实现项目级的扩展。Hystrix的功能更偏向线程、信号量的隔离，作为插件的方式集成在服务中会比较适合，更偏向包级扩展。 所以在这里建议： 在单纯的流量控制需求下，建议使用sentinel 在需求到线程池隔离的功能下使用Hystrix 文档索引【流量控制系列1】引言和索引【流量控制系列2】流量控制的基础方法和算法【流量控制系列3】Semaphore信号量介绍【流量控制系列4】Sentinel和Hystrix对比【流量控制系列5】Sentinel 详细介绍【流量控制系列6】Sentinel 详细介绍-SlotChain源码解析【流量控制系列7】Sentinel实践]]></content>
      <categories>
        <category>java</category>
        <category>流量控制</category>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>限流</tag>
        <tag>Sentinel</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【流量控制系列3】Semaphore信号量介绍]]></title>
    <url>%2F2019%2F07%2F29%2Fjava%2Fflowcontroller%2Fflowcontroller_3%2F</url>
    <content type="text"><![CDATA[简介Semaphore当前在多线程环境下被扩放使用，操作系统的信号量是个很重要的概念，在进程控制方面都有应用。Java 并发库 的Semaphore 可以很轻松完成信号量控制，Semaphore可以控制某个资源可被同时访问的个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。比如在Windows下可以设置共享文件的最大客户端访问个数。 实现原理和规则Semaphore实现的功能就类似厕所有5个坑，假如有10个人要上厕所，那么同时只能有多少个人去上厕所呢？同时只能有5个人能够占用，当5个人中 的任何一个人让开后，其中等待的另外5个人中又有一个人可以占用了。另外等待的5个人中可以是随机获得优先机会，也可以是按照先来后到的顺序获得机会，这取决于构造Semaphore对象时传入的参数选项。单个信号量的Semaphore对象可以实现互斥锁的功能，并且可以是由一个线程获得了“锁”，再由另一个线程释放“锁”，这可应用于死锁恢复的一些场合。 Semaphore维护了当前访问的个数，提供同步机制，控制同时访问的个数。在数据结构中链表可以保存“无限”的节点，用Semaphore可以实现有限大小的链表。另外重入锁 ReentrantLock 也可以实现该功能，但实现上要复杂些。 demo下面的Demo中申明了一个只有5个许可的Semaphore，而有20个线程要访问这个资源，通过acquire()和release()获取和释放访问许可。 123456789101112131415161718192021222324252627282930313233343536package com.test;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Semaphore;public class TestSemaphore &#123; public static void main(String[] args) &#123; // 线程池 ExecutorService exec = Executors.newCachedThreadPool(); //只能5个线程同时访问 final Semaphore semp = new Semaphore(5); //模拟20个客户端访问 for (int index = 0; index &lt; 20; index++) &#123; final int NO = index; Runnable run = new Runnable() &#123; public void run() &#123; try &#123; // 获取许可 semp.acquire(); System.out.println("Accessing: " + NO); Thread.sleep((long) (Math.random() * 10000)); // 访问完后，释放 semp.release(); System.out.println("-----------------"+semp.availablePermits()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; exec.execute(run); &#125; // 退出线程池 exec.shutdown(); &#125;&#125; 文档索引【流量控制系列1】引言和索引【流量控制系列2】流量控制的基础方法和算法【流量控制系列3】Semaphore信号量介绍【流量控制系列4】Sentinel和Hystrix对比【流量控制系列5】Sentinel 详细介绍【流量控制系列6】Sentinel 详细介绍-SlotChain源码解析【流量控制系列7】Sentinel实践]]></content>
      <categories>
        <category>java</category>
        <category>流量控制</category>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>限流</tag>
        <tag>Sentinel</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【流量控制系列6】Sentinal 详细介绍-SlotChain源码解析]]></title>
    <url>%2F2019%2F07%2F29%2Fjava%2Fflowcontroller%2Fflowcontroller_6%2F</url>
    <content type="text"><![CDATA[核心实现责任链模式责任链模式介绍-扩展链接 时序图 限流功能-基于FlowSlot SoltChain源码解析 类图 SoltChain内部 12345678910public interface ProcessorSlot&lt;T&gt; &#123; void entry(Context context, ResourceWrapper resourceWrapper, T param, int count, boolean prioritized, Object... args) throws Throwable; void fireEntry(Context context, ResourceWrapper resourceWrapper, Object obj, int count, boolean prioritized, Object... args) throws Throwable; void exit(Context context, ResourceWrapper resourceWrapper, int count, Object... args); void fireExit(Context context, ResourceWrapper resourceWrapper, int count, Object... args);&#125; 12345678910111213141516171819202122232425262728293031public abstract class AbstractLinkedProcessorSlot&lt;T&gt; implements ProcessorSlot&lt;T&gt; &#123; private AbstractLinkedProcessorSlot&lt;?&gt; next = null; @Override public void fireEntry(Context context, ResourceWrapper resourceWrapper, Object obj, int count, boolean prioritized, Object... args) throws Throwable &#123; if (next != null) &#123; next.transformEntry(context, resourceWrapper, obj, count, prioritized, args); &#125; &#125; @SuppressWarnings("unchecked") void transformEntry(Context context, ResourceWrapper resourceWrapper, Object o, int count, boolean prioritized, Object... args) throws Throwable &#123; T t = (T)o; entry(context, resourceWrapper, t, count, prioritized, args); &#125; @Override public void fireExit(Context context, ResourceWrapper resourceWrapper, int count, Object... args) &#123; if (next != null) &#123; next.exit(context, resourceWrapper, count, args); &#125; &#125; public AbstractLinkedProcessorSlot&lt;?&gt; getNext() &#123; return next; &#125; public void setNext(AbstractLinkedProcessorSlot&lt;?&gt; next) &#123; this.next = next; &#125;&#125; AbstractLinkedProcessorSlot为一个Slot节点，通过setNext指定下一个Slot节点,通过 fireEntry()方法，调用下一个节点的transformEntry()最终调用到下一个Slot节点的entry方法,本身的结构类似于 123clsss Slot &#123; Slot next;&#125; ProcessorSlotChain和DefaultProcessorSlotChain 123456public abstract class ProcessorSlotChain extends AbstractLinkedProcessorSlot&lt;Object&gt; &#123; //添加头节点 public abstract void addFirst(AbstractLinkedProcessorSlot&lt;?&gt; protocolProcessor); //添加下一个节点 public abstract void addLast(AbstractLinkedProcessorSlot&lt;?&gt; protocolProcessor);&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class DefaultProcessorSlotChain extends ProcessorSlotChain &#123; AbstractLinkedProcessorSlot&lt;?&gt; first = new AbstractLinkedProcessorSlot&lt;Object&gt;() &#123; @Override public void entry(Context context, ResourceWrapper resourceWrapper, Object t, int count, boolean prioritized, Object... args) throws Throwable &#123; super.fireEntry(context, resourceWrapper, t, count, prioritized, args); &#125; @Override public void exit(Context context, ResourceWrapper resourceWrapper, int count, Object... args) &#123; super.fireExit(context, resourceWrapper, count, args); &#125; &#125;; AbstractLinkedProcessorSlot&lt;?&gt; end = first; @Override public void addFirst(AbstractLinkedProcessorSlot&lt;?&gt; protocolProcessor) &#123; protocolProcessor.setNext(first.getNext()); first.setNext(protocolProcessor); if (end == first) &#123; end = protocolProcessor; &#125; &#125; @Override public void addLast(AbstractLinkedProcessorSlot&lt;?&gt; protocolProcessor) &#123; end.setNext(protocolProcessor); end = protocolProcessor; &#125; @Override public void setNext(AbstractLinkedProcessorSlot&lt;?&gt; next) &#123; addLast(next); &#125; @Override public AbstractLinkedProcessorSlot&lt;?&gt; getNext() &#123; return first.getNext(); &#125; @Override public void entry(Context context, ResourceWrapper resourceWrapper, Object t, int count, boolean prioritized, Object... args) throws Throwable &#123; first.transformEntry(context, resourceWrapper, t, count, prioritized, args); &#125; @Override public void exit(Context context, ResourceWrapper resourceWrapper, int count, Object... args) &#123; first.exit(context, resourceWrapper, count, args); &#125;&#125; DefaultProcessorSlotChain实质是指定头节点FirstSlot和endSnot的链表。就如下面结构 : 1234public Class Chain&#123; Slot first; Slot end;&#125; com.alibaba.csp.sentinel.slots.DefaultSlotChainBuilde 123456789101112public ProcessorSlotChain build() &#123; ProcessorSlotChain chain = new DefaultProcessorSlotChain(); chain.addLast(new NodeSelectorSlot()); chain.addLast(new ClusterBuilderSlot()); chain.addLast(new LogSlot()); chain.addLast(new StatisticSlot()); chain.addLast(new SystemSlot()); chain.addLast(new AuthoritySlot()); chain.addLast(new FlowSlot()); chain.addLast(new DegradeSlot()); return chain;&#125; 结构图 各个slot职责 NodeSelectorSlot 负责收集资源的路径，并将这些资源的调用路径，以树状结构存储起来，用于根据调用路径来限流降级； ClusterBuilderSlot则用于存储资源的统计信息以及调用者信息，例如该资源的 RT, QPS, thread count 等等，这些信息将用作为多维度限流，降级的依据； StatistcSlot 则用于记录，统计不同纬度的 runtime 信息； SystemSlot 则通过系统的状态，例如 load1 等，来控制总的入口流量； AuthorizationSlot 则根据黑白名单，来做黑白名单控制； FlowSlot则用于根据预设的限流规则，以及前面 slot 统计的状态，来进行限流； DegradeSlot则通过统计信息，以及预设的规则，来做熔断降级； 可以看到，我需要的熔断，限流，白名单控制都可以通过配置AuthorizationSlot，FlowSlot，DegradeSlot实现。 扩展基于SPI与责任链模式的实现扩展。 新增自己的Slot。继承AbstractLinkedProcessorSlot。实现自己的流控业务。 sentinel-core下的SPI配置：com.alibaba.csp.sentinel.soltchain.SoltChainBuilder初始化追加扩展的Solt 参考：【sentinel】深入浅出之原理篇SlotChain 文档索引【流量控制系列1】引言和索引【流量控制系列2】流量控制的基础方法和算法【流量控制系列3】Semaphore信号量介绍【流量控制系列4】Sentinel和Hystrix对比【流量控制系列5】Sentinel 详细介绍【流量控制系列6】Sentinel 详细介绍-SlotChain源码解析【流量控制系列7】Sentinel实践]]></content>
      <categories>
        <category>java</category>
        <category>流量控制</category>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>限流</tag>
        <tag>Sentinel</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【流量控制系列5】Sentinal 详细介绍]]></title>
    <url>%2F2019%2F07%2F29%2Fjava%2Fflowcontroller%2Fflowcontroller_5%2F</url>
    <content type="text"><![CDATA[Sentinal 详细介绍历史2012 年，Sentinel 诞生，主要功能为入口流量控制。2013-2017 年，Sentinel 在阿里巴巴集团内部迅速发展，成为基础技术模块，覆盖了所有的核心场景。Sentinel 也因此积累了大量的流量归整场景以及生产实践。2018 年，Sentinel 开源。 现在的版本1.6.1 特性功能组成: 基本概念 资源 资源是 Sentinel 的关键概念。它可以是 Java 应用程序中的任何内容，例如，由应用程序提供的服务，或由应用程序调用的其它应用提供的服务，甚至可以是一段代码。在接下来的文档中，我们都会用资源来描述代码块。 只要通过 Sentinel API 定义的代码，就是资源，能够被 Sentinel 保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源。 规则 围绕资源的实时状态设定的规则，可以包括流量控制规则、熔断降级规则以及系统保护规则。所有规则可以动态实时调整。 常用功能流量控制 熔断降级除了流量控制以外，对调用链路中不稳定的资源进行熔断降级也是保障高可用的重要措施之一。由于调用关系的复杂性，如果调用链路中的某个资源不稳定，最终会导致请求发生堆积。Sentinel 熔断降级会在调用链路中某个资源出现不稳定状态时（例如调用超时或异常比例升高），对这个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联错误。当资源被降级后，在接下来的降级时间窗口之内，对该资源的调用都自动熔断（默认行为是抛出 DegradeException）。 降级策略我们通常用以下几种方式来衡量资源是否处于稳定的状态： 平均响应时间 (DEGRADE_GRADE_RT)：当 1s 内持续进入 5 个请求，对应时刻的平均响应时间（秒级）均超过阈值（count，以 ms 为单位），那么在接下的时间窗口（DegradeRule 中的 timeWindow，以 s 为单位）之内，对这个方法的调用都会自动地熔断（抛出 DegradeException）。注意 Sentinel 默认统计的 RT 上限是 4900 ms，超出此阈值的都会算作 4900 ms，若需要变更此上限可以通过启动配置项 -Dcsp.sentinel.statistic.max.rt=xxx 来配置。 异常比例 (DEGRADE_GRADE_EXCEPTION_RATIO)：当资源的每秒请求量 &gt;= 5，并且每秒异常总数占通过量的比值超过阈值（DegradeRule 中的 count）之后，资源进入降级状态，即在接下的时间窗口（DegradeRule 中的 timeWindow，以 s 为单位）之内，对这个方法的调用都会自动地返回。异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。 异常数 (DEGRADE_GRADE_EXCEPTION_COUNT)：当资源近 1 分钟的异常数目超过阈值之后会进行熔断。注意由于统计时间窗口是分钟级别的，若 timeWindow 小于 60s，则结束熔断状态后仍可能再进入熔断状态。 注意：异常降级仅针对业务异常，对 Sentinel 限流降级本身的异常（BlockException）不生效。为了统计异常比例或异常数，需要通过 Tracer.trace(ex) 记录业务异常。示例： 123456789101112131415Entry entry = null;try &#123; entry = SphU.entry(key, EntryType.IN, key); // Write your biz code here. // &lt;&lt;BIZ CODE&gt;&gt;&#125; catch (Throwable t) &#123; if (!BlockException.isBlockException(t)) &#123; Tracer.trace(t); &#125;&#125; finally &#123; if (entry != null) &#123; entry.exit(); &#125;&#125; 集群方案 基于nacos配置中心： 在 Sentinel 控制台配置项中需要指定 nacos 的地址，启动时即创建nacos链接。 针对每个应用（appName），每种规则设置不同的 path（可随时修改）；或者约定大于配置（如 path 的模式统一为 /sentinel_rules/{appName}/{ruleType}，e.g. sentinel_rules/appA/flowRule） 规则配置页需要进行相应的改造，直接针对应用维度进行规则配置；修改同个应用多个资源的规则时可以批量进行推送，也可以分别推送。Sentinel 控制台将规则缓存在内存中（如 InMemFlowRuleStore），可以对其进行改造使其支持应用维度的规则缓存（key 为 appName），每次添加/修改/删除规则都先更新内存中的规则缓存，然后需要推送的时候从规则缓存中获取全量规则，然后通过上面实现的 Client 将规则推送到 nacos。 应用客户端需要注册对应的读数据源以监听变更。 文档索引【流量控制系列1】引言和索引【流量控制系列2】流量控制的基础方法和算法【流量控制系列3】Semaphore信号量介绍【流量控制系列4】Sentinel和Hystrix对比【流量控制系列5】Sentinel 详细介绍【流量控制系列6】Sentinel 详细介绍-SlotChain源码解析【流量控制系列7】Sentinel实践]]></content>
      <categories>
        <category>java</category>
        <category>流量控制</category>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>限流</tag>
        <tag>Sentinel</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【流量控制系列7】Sentinel实践]]></title>
    <url>%2F2019%2F07%2F29%2Fjava%2Fflowcontroller%2Fflowcontroller_7%2F</url>
    <content type="text"><![CDATA[sentinel的使用架构方式 Sentinel dashboard改造默认是支持单机，现在需要改造成集群配置方式。 页面controller改造将test下的nacos文件夹复制到包rule下启用类：FlowControllerV2provider注入123456@Autowired@Qualifier(&quot;flowRuleNacosProvider&quot;)private DynamicRuleProvider&lt;List&lt;FlowRuleEntity&gt;&gt; ruleProvider;@Autowired@Qualifier(&quot;flowRuleNacosPublisher&quot;)private DynamicRulePublisher&lt;List&lt;FlowRuleEntity&gt;&gt; rulePublisher; 前端页面sidebar替换app.js 123456789101112131415.state(&apos;dashboard.flow&apos;, &#123; templateUrl: &apos;app/views/flow_v2.html&apos;, url: &apos;/v2/flow/:app&apos;, controller: &apos;FlowControllerV2&apos;, resolve: &#123; loadMyFiles: [&apos;$ocLazyLoad&apos;, function ($ocLazyLoad) &#123; return $ocLazyLoad.load(&#123; name: &apos;sentinelDashboardApp&apos;, files: [ &apos;app/scripts/controllers/flow_v2.js&apos;, ] &#125;); &#125;] &#125;&#125;) 配置改造追加nacos配置 12345678910111213141516171819server.port=8091#spring settingsspring.http.encoding.force=truespring.http.encoding.charset=UTF-8spring.http.encoding.enabled=true#logging settingslogging.level.org.springframework.web=INFOlogging.file=$&#123;user.home&#125;/logs/csp/sentinel-dashboard.loglogging.pattern.file= %d&#123;yyyy-MM-dd HH:mm:ss&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n#logging.pattern.console= %d&#123;yyyy-MM-dd HH:mm:ss&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n#auth settingsauth.filter.exclude-urls=/,/auth/login,/auth/logout,/registry/machineauth.filter.exclude-url-suffixes=htm,html,js,css,map,ico,ttf,woff,pngauth.username=sentinelauth.password=sentinelnacos.server=10.5.117.217 nacos集群部署 追加配置 distribution 下的resource配置1234db.num=1db.url.0=jdbc:mysql://10.59.118.120:3306/nacos?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=prog_admindb.password=prog_nacos cluster.conf 12310.59.118.126:884810.59.118.127:884810.59.118.121:8848 编译 1$ mvn -Prelease-nacos -DskipTests clean install - 启动 1$NACOS_HOME/bin/startup.sh 支付平台配置改造Web项目引入包： 12345678910111213141516171819&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-transport-simple-http&lt;/artifactId&gt; &lt;version&gt;$&#123;sentinel-version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-cluster-client-default&lt;/artifactId&gt; &lt;version&gt;$&#123;sentinel-version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;version&gt;$&#123;sentinel-version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-web-servlet&lt;/artifactId&gt;&lt;/dependency&gt; 追加nacos配置 12###限流配置###nexos.host=@filter.nexos.host@ 追加拦截器SentinelFilter123456789101112131415161718192021222324252627282930@Overridepublic void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest sRequest = (HttpServletRequest)request; Entry entry = null; try &#123; // 根据请求生成的资源 String target = FilterUtil.filterTarget(sRequest); if (!target.startsWith(&quot;/admin&quot;)) &#123; target = WebCallbackManager.getUrlCleaner().clean(target); entry = SphU.entry(target, EntryType.IN, 1); &#125; // 如果能成功“申请”到资源，则说明未被限流 // 则将请求放行 chain.doFilter(request, response); &#125; catch (BlockException e) &#123; // 否则如果捕获了BlockException异常，说明请求被限流了 // 则将请求重定向到一个默认的页面 //System.out.println(&quot;触发限流规则&quot;); throw new RuntimeException(&quot;触发限流规则&quot;); &#125; catch (IOException e2) &#123; // 省略部分代码 &#125; finally &#123; if (entry != null) &#123; entry.exit(); &#125; &#125;&#125; 监听 nacos配置变更 123456789101112131415161718private void initSentinalClusterClientConfig() &#123; String REMOTE_ADDRESS = propertyPlaceholderConfigurer.getCtxProp(&quot;nexos.host&quot;); //初始化一个配置ClusterClientConfig的 Nacos 数据源 ReadableDataSource&lt;String, ClusterClientAssignConfig&gt; ds = new NacosDataSource&lt;&gt;(REMOTE_ADDRESS, GROUP_ID, CLIENT_CONFIG_DATA, source -&gt; JSON.parseObject(source, new TypeReference&lt;ClusterClientAssignConfig&gt;() &#123;&#125;)); ClusterClientConfigManager.registerServerAssignProperty(ds.getProperty());&#125;private void initClientFlow() &#123; String REMOTE_ADDRESS = propertyPlaceholderConfigurer.getCtxProp(&quot;nexos.host&quot;); //使用 Nacos 数据源作为配置中心，需要在 REMOTE_ADDRESS 上启动一个 Nacos 的服务 ReadableDataSource&lt;String, List&lt;FlowRule&gt;&gt; ds = new NacosDataSource&lt;&gt;(REMOTE_ADDRESS, GROUP_ID, APP_NAME + FLOW_POSTFIX, source -&gt; JSON.parseObject(source, new TypeReference&lt;List&lt;FlowRule&gt;&gt;() &#123;&#125;)); //为集群客户端注册动态规则源 FlowRuleManager.register2Property(ds.getProperty());&#125; 启动启动加入：1-Dcsp.sentinel.dashboard.server=10.5.32.97:8091 -Dproject.name=littlehui-17pay 遇到的坑 sentinel配置的限流规则。来源app字段limitApp指的是请求来源，常用default，如果指定app那么非app来源的请求获取不到rule列表。 sentinel客户端不支持nacos的命名空间配置，所以用的是默认的public空间。 附件源码nacos-1.0.0-RC3源码sentinel-1.6.0源码 文档索引【流量控制系列1】引言和索引【流量控制系列2】流量控制的基础方法和算法【流量控制系列3】Semaphore信号量介绍【流量控制系列4】Sentinel和Hystrix对比【流量控制系列5】Sentinel 详细介绍【流量控制系列6】Sentinel 详细介绍-SlotChain源码解析【流量控制系列7】Sentinel实践]]></content>
      <categories>
        <category>java</category>
        <category>流量控制</category>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>限流</tag>
        <tag>Sentinel</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列:责任链模式]]></title>
    <url>%2F2019%2F07%2F28%2Fjava%2Fpatterndesign%2Fpatterndesign_17%2F</url>
    <content type="text"><![CDATA[概念 责任链模式顾名思义，它是由一连串单一职责的对象构成链式结构。此结构一般为请求接受者做前置业务处理，主要目的是为发送者和接收者进行解耦。其特点是，每个对象都只处理自己成处理的请求，如果处理不了，会把请求传给下一个接收者。以此类推。 实现一个简单的日志记录链 类图 代码AbstractLogger123456789101112131415161718192021222324252627282930313233343536package com.littlehui.design.responsebilitychain;/** * @Description TODO * @ClassName AbstractLogger * @Author littlehui * @Date 2019/7/29 15:12 * @Version 1.0 **/public abstract class AbstractLogger &#123; public static int INFO = 1; public static int WARN = 2; public static int ERROR = 3; protected int level; AbstractLogger nextLogger; public void setNextLogger(AbstractLogger nextLogger) &#123; this.nextLogger = nextLogger; &#125; public void logMessage(int level, String message)&#123; if(this.level &lt;= level)&#123; write(message); &#125; if(nextLogger !=null)&#123; nextLogger.logMessage(level, message); &#125; &#125; abstract protected void write(String message);&#125; ErrorLogger 1234567891011121314151617181920package com.littlehui.design.responsebilitychain;/** * @Description TODO * @ClassName ErrorLogger * @Author littlehui * @Date 2019/7/29 15:15 * @Version 1.0 **/public class ErrorLogger extends AbstractLogger &#123; public ErrorLogger(int level)&#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println("Error Console::Logger: " + message); &#125;&#125; InfoLogger 1234567891011121314151617181920package com.littlehui.design.responsebilitychain;/** * @Description TODO * @ClassName InfoLogger * @Author littlehui * @Date 2019/7/29 15:16 * @Version 1.0 **/public class InfoLogger extends AbstractLogger &#123; public InfoLogger(int level)&#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println("Error Console::Logger: " + message); &#125;&#125; WarnLogger 1234567891011121314151617181920package com.littlehui.design.responsebilitychain;/** * @Description TODO * @ClassName WarnLogger * @Author littlehui * @Date 2019/7/29 15:16 * @Version 1.0 **/public class WarnLogger extends AbstractLogger &#123; public WarnLogger(int level)&#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println("Error Console::Logger: " + message); &#125;&#125; Demo 1234567891011121314151617181920212223242526272829303132package com.littlehui.design.responsebilitychain;/** * @Description TODO * @ClassName Demo * @Author littlehui * @Date 2019/7/29 15:18 * @Version 1.0 **/public class Demo &#123; private static AbstractLogger getChainOfLoggers()&#123; AbstractLogger errorLogger = new ErrorLogger(AbstractLogger.ERROR); AbstractLogger infoLogger = new InfoLogger(AbstractLogger.INFO); AbstractLogger warnLogger = new WarnLogger(AbstractLogger.WARN); errorLogger.setNextLogger(infoLogger); infoLogger.setNextLogger(warnLogger); return errorLogger; &#125; public static void main(String[] args) &#123; AbstractLogger loggerChain = getChainOfLoggers(); loggerChain.logMessage(AbstractLogger.INFO, "This is an information."); loggerChain.logMessage(AbstractLogger.WARN, "This is a warn level information."); loggerChain.logMessage(AbstractLogger.ERROR, "This is an error information."); &#125;&#125; 执行结果：1234567891011/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/bin/java -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:65034,suspend=y,server=n -Dfile.encoding=UTF-8 -classpath "/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/lib/tools.jar:/Users/littlehui/WorkSpaces/Home/pattern/out/production/responsbilitychain:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar" com.littlehui.design.responsebilitychain.DemoConnected to the target VM, address: '127.0.0.1:65034', transport: 'socket'Error Console::Logger: This is an information.Error Console::Logger: This is a warn level information.Error Console::Logger: This is a warn level information.Error Console::Logger: This is an error information.Error Console::Logger: This is an error information.Error Console::Logger: This is an error information.Disconnected from the target VM, address: '127.0.0.1:65034', transport: 'socket'Process finished with exit code 0 场景 Spring MVC的filter，Interceptor各种Handler等等 日志记录 总结责任链的特点是单一职责，链式结构。前提是统一的输入端。在遇到复杂业务，特别是复杂请求时候。输入端是统一的，这时候就可以考虑将业务处理拆分成单一的职责。再将对象链接起来。这样的好处是，解耦了接收端的处理。并且提升了扩展性能。维护也方便。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>责任链模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列:迭代器模式]]></title>
    <url>%2F2019%2F07%2F28%2Fjava%2Fpatterndesign%2Fpatterndesign_16%2F</url>
    <content type="text"><![CDATA[概念 迭代器一般用于访问聚合对象内部元素。只暴露该暴露的，隐藏该隐藏的。比如隐藏掉容器内部的实现逻辑，只暴露遍历的接口。 实现类图 代码 Iterator 1234567891011121314151617package com.littlehui.design.iterator;/** * @Description TODO * @ClassName Iterator * @Author littlehui * @Date 2019/10/12 14:56 * @Version 1.0 **/public interface Iterator &#123; boolean hasNext(); Object next(); void remove();&#125; IteratorCreator 12345678910111213package com.littlehui.design.iterator;/** * @Description TODO * @ClassName IteratorCreator * @Author littlehui * @Date 2019/10/12 14:57 * @Version 1.0 **/public interface IteratorCreator &#123; public Iterator createIterator();&#125; MenuItem 1234567891011121314151617181920212223242526272829303132333435363738394041package com.littlehui.design.iterator;/** * @Description TODO * @ClassName MenuItem * @Author littlehui * @Date 2019/10/12 14:57 * @Version 1.0 **/public class MenuItem &#123; private String code; private String menuName; public MenuItem(String code, String menuName) &#123; this.code = code; this.menuName = menuName; &#125; public String getCode() &#123; return code; &#125; public void setCode(String code) &#123; this.code = code; &#125; public String getMenuName() &#123; return menuName; &#125; public void setMenuName(String menuName) &#123; this.menuName = menuName; &#125; public void printMenu() &#123; System.out.println("编码：" + code + "名称：" + menuName); &#125;&#125; MenuContainer 1234567891011121314151617181920212223242526272829303132333435363738package com.littlehui.design.iterator;import java.util.ArrayList;import java.util.List;/** * @Description TODO * @ClassName MenuContainer * @Author littlehui * @Date 2019/10/12 14:57 * @Version 1.0 **/public class MenuContainer implements IteratorCreator &#123; private List&lt;MenuItem&gt; menuItems; public MenuContainer(List&lt;MenuItem&gt; menuItems) &#123; this.menuItems = menuItems; &#125; public MenuContainer() &#123; &#125; public void addMenuItem(MenuItem menuItem) &#123; if (menuItems == null) &#123; menuItems = new ArrayList&lt;MenuItem&gt;(); &#125; menuItems.add(menuItem); &#125; @Override public Iterator createIterator() &#123; return new MenuContainerIterator(menuItems); &#125;&#125; MenuContainerIterator 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.littlehui.design.iterator;import java.util.ArrayList;import java.util.List;/** * @Description TODO * @ClassName MenuContainerIterator * @Author littlehui * @Date 2019/10/12 14:58 * @Version 1.0 **/public class MenuContainerIterator implements Iterator &#123; private List&lt;MenuItem&gt; menuItemList = null; private int currentIndex = -1; private int lastIndex = 0; public MenuContainerIterator(List&lt;MenuItem&gt; menuItemList) &#123; this.menuItemList = menuItemList; lastIndex = menuItemList.size() - 1; &#125; @Override public boolean hasNext() &#123; if (currentIndex &lt; lastIndex) &#123; return true; &#125; else &#123; return false; &#125; &#125; @Override public Object next() &#123; MenuItem currentItem = menuItemList.get(++currentIndex); return currentItem; &#125; @Override public void remove() &#123; menuItemList.remove(currentIndex); --currentIndex; lastIndex = menuItemList.size() - 1; &#125;&#125; Client 123456789101112131415161718192021222324252627282930313233package com.littlehui.design.iterator;import java.util.ArrayList;import java.util.List;/** * @Description TODO * @ClassName Client * @Author littlehui * @Date 2019/10/12 15:16 * @Version 1.0 **/public class Client &#123; public static void main(String[] args) &#123; List&lt;MenuItem&gt; menuItemList = new ArrayList(); menuItemList.add(new MenuItem("CODE_1", "第一个菜单")); menuItemList.add(new MenuItem("CODE_2", "第二个菜单")); menuItemList.add(new MenuItem("CODE_3", "第三个菜单")); MenuContainer menuContainer = new MenuContainer(menuItemList); Iterator iterator = menuContainer.createIterator(); while (iterator.hasNext()) &#123; MenuItem item = (MenuItem)iterator.next(); if ("CODE_2".equals(item.getCode())) &#123; iterator.remove(); &#125; else &#123; item.printMenu(); &#125; &#125; &#125;&#125; 执行 123456Connected to the target VM, address: '127.0.0.1:51875', transport: 'socket'编码：CODE_1名称：第一个菜单编码：CODE_3名称：第三个菜单Disconnected from the target VM, address: '127.0.0.1:51875', transport: 'socket'Process finished with exit code 0 场景如上简单描述了一个菜单面板利用迭代器模式的遍历过程。 总结]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>迭代器模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux dump现场工具]]></title>
    <url>%2F2019%2F07%2F17%2Flinux%2Flinux_6%2F</url>
    <content type="text"><![CDATA[linux dump工具123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187#!/usr/bin/env bash### use demo #### 1)upload dump.sh# 2)dos2unix dump.sh;chmod +x dump.sh# 3)usage: # 1. /data/sh/java/dump.sh /tmp/dump /usr/local/java/jdk1.8.0_05 23554# 2. /data/sh/java/dump.sh /tmp/dump /usr/local/java/jdk1.8.0_05 23554 -F### parameter description #### 1 ./tmp/dump is save dump file dir. # 2 /usr/local/java/jdk1.8.0_05 is java_home. # 3 23554 is java-pid. # 4 -F force jvm dum, optional.declare SNAPSHOT_BASE_DIRECTORY=$1declare JAVA_HOME=$2declare PID=$3declare JVM_FORCE_OPTS=$4# remove the last '/' charJAVA_HOME=$&#123;JAVA_HOME/%\//&#125;SNAPSHOT_BASE_DIRECTORY=$&#123;SNAPSHOT_BASE_DIRECTORY/%\//&#125;declare FULL_TIME_FORMAT="+%Y-%m-%d_%H_%M_%S_%N"declare SHORT_TIME_FORMAT="+%H-%M-%S-%N"declare TIMESTAMP=`date ""$&#123;FULL_TIME_FORMAT&#125;"" `declare RESULT_DIRECTORY=$&#123;SNAPSHOT_BASE_DIRECTORY&#125;/$&#123;PID&#125;/$&#123;TIMESTAMP&#125;declare RUN_LOG_PATH="$&#123;RESULT_DIRECTORY&#125;/run.log"run_log()&#123; declare log_msg="$(date ""$&#123;FULL_TIME_FORMAT&#125;""): $1" echo $&#123;log_msg&#125; echo $&#123;log_msg&#125; &gt;&gt;$&#123;RUN_LOG_PATH&#125;&#125;is_no_null()&#123; if [ -z $1 ];then return 0; else return 1; fi&#125;is_valid_number()&#123; is_no_null $1 if [ $? -eq 0 ];then return 0; fi if [ $1 -gt 0 ] 2&gt;/dev/null ;then return 1; else return 0; fi&#125;echo_blank_line()&#123; echo &#125;valid_param()&#123; if [ ! -d $&#123;RESULT_DIRECTORY&#125; ]; then mkdir -p $&#123;RESULT_DIRECTORY&#125; run_log "tip: Create RESULT_DIRECTORY=$&#123;RESULT_DIRECTORY&#125;" fi run_log "tip: RESULT_DIRECTORY=$&#123;RESULT_DIRECTORY&#125;" is_no_null $&#123;SNAPSHOT_BASE_DIRECTORY&#125; if [ $? -eq 0 ];then run_log "Param 1 SNAPSHOT_BASE_DIRECTORY is no exist and exit ,such as /tmp/dump" exit 1; else run_log "tip: SNAPSHOT_BASE_DIRECTORY=$&#123;SNAPSHOT_BASE_DIRECTORY&#125;" fi if [ -d "$&#123;JAVA_HOME&#125;" ];then run_log "tip: JAVA HOME: $&#123;JAVA_HOME&#125;" else run_log "Param2 JAVA_HOME is no exist and exit ,such as /usr/local/java/jdk1.8.0_05" exit 2; fi is_valid_number $&#123;PID&#125; if [ $? -eq 0 ];then run_log "Param3 PID is invalid and exit" exit 3; fi&#125;valid_paramrun_log "RESULT_DIRECTORY=$&#123;RESULT_DIRECTORY&#125;"machine_dump()&#123; declare filename=$1; type $1 &gt;/dev/null 2&gt;&amp;1 &amp;&amp; &#123; run_log "Start $1 $2 dump" declare timestamp=$(date ""$&#123;SHORT_TIME_FORMAT&#125;""); run_log "Execute $1 $2 &gt;&gt; $&#123;RESULT_DIRECTORY&#125;/machine_$&#123;filename&#125;_$&#123;timestamp&#125;.dump" $1 $2 &gt;&gt; $&#123;RESULT_DIRECTORY&#125;/machine_$&#123;filename&#125;_$&#123;timestamp&#125;.dump run_log "End $1 $2 dump" echo_blank_line &#125;&#125;machine_dump_pipeline()&#123; declare filename=$1; type $2 &gt;/dev/null 2&gt;&amp;1 &amp;&amp; &#123; run_log "Start $2 $3 | $4 dump" declare timestamp=$(date ""$&#123;SHORT_TIME_FORMAT&#125;""); run_log "Execute $2 $3 | $4 &gt;&gt; $&#123;RESULT_DIRECTORY&#125;/machine_$&#123;filename&#125;_$&#123;timestamp&#125;.dump" $2 $3 | $4 &gt;&gt; $&#123;RESULT_DIRECTORY&#125;/machine_$&#123;filename&#125;_$&#123;timestamp&#125;.dump run_log "End $2 $3 | $4 dump" echo_blank_line &#125;&#125;# 3 times interval 1sdeclare machine_static_frequency="1 3"# machine real time statistics informationecho_blank_linemachine_dump_pipeline "top-50-process" top "-b" "head -n 50" machine_dump free -gltmachine_dump vmstat "-t $&#123;machine_static_frequency&#125;"machine_dump mpstat "-A $&#123;machine_static_frequency&#125;"machine_dump iostat "$&#123;machine_static_frequency&#125;"machine_dump iotop "-o -b -n 3"machine_dump netstat "-an"machine_dump lsof "-p $&#123;PID&#125;"# machine history statistics informationmachine_dump sar -Aget_pid_user()&#123; user_tip=`ps u -p $1 | tail -n 1 | awk '&#123;print $1&#125;'` is_valid_number $&#123;user_tip&#125; if [ $? -eq 0 ];then echo $&#123;user_tip&#125; else echo `cat /etc/passwd |grep x:$&#123;user_tip&#125; | awk -F ':' '&#123;print $1&#125;'` fi&#125;PID_USER=`get_pid_user $&#123;PID&#125;`jvm_dump()&#123; declare filename; if [ ! -z $3 ];then filename=$3 else filename=$1 fi run_log "Start $1 $2 dump" declare timestamp=$(date ""$&#123;SHORT_TIME_FORMAT&#125;""); run_log "su -l $&#123;PID_USER&#125; -s /bin/bash -c \"$&#123;JAVA_HOME&#125;/bin/$1 $2 \" &gt;&gt; $&#123;RESULT_DIRECTORY&#125;/jvm_$&#123;filename&#125;_$&#123;timestamp&#125;.dump" su -l $&#123;PID_USER&#125; -s /bin/bash -c "$&#123;JAVA_HOME&#125;/bin/$1 $2 " &gt;&gt; $&#123;RESULT_DIRECTORY&#125;/jvm_$&#123;filename&#125;_$&#123;timestamp&#125;.dump run_log "End $1 $2 dump" echo_blank_line&#125;# 8 times interval 1sdeclare jvm_static_frequency="1000 8"# jvm real time statistics informationjvm_dump jinfo "$&#123;PID&#125;"jvm_dump jstat "-gcutil $&#123;PID&#125; $&#123;jvm_static_frequency&#125;" "jstat-gcutil"machine_dump_pipeline "top-100-high-thread" top "-H -b -n 1 -p $&#123;PID&#125;" "head -n 100"chown $&#123;PID_USER&#125;:$&#123;PID_USER&#125; $&#123;RESULT_DIRECTORY&#125;# topH have must together with jstackjvm_dump jstack "$&#123;JVM_FORCE_OPTS&#125; $&#123;PID&#125;"# dump jvm_head_dump()&#123; run_log "Start jmap $1 dump" declare timestamp=$(date ""$&#123;SHORT_TIME_FORMAT&#125;""); run_log "su -l $&#123;PID_USER&#125; -s /bin/bash -c \"$&#123;JAVA_HOME&#125;/bin/jmap $&#123;JVM_FORCE_OPTS&#125; -dump:format=b,file=$&#123;RESULT_DIRECTORY&#125;/jvm_jmap_$&#123;timestamp&#125;.hprof $1\"" #su -l $&#123;PID_USER&#125; -s /bin/bash -c "$&#123;JAVA_HOME&#125;/bin/jmap $&#123;JVM_FORCE_OPTS&#125; -dump:format=b,file=$&#123;RESULT_DIRECTORY&#125;/jvm_jmap_$&#123;timestamp&#125;.hprof $1" $&#123;JAVA_HOME&#125;/bin/jmap $&#123;JVM_FORCE_OPTS&#125; -dump:format=b,file=$&#123;RESULT_DIRECTORY&#125;/jvm_jmap_$&#123;timestamp&#125;.hprof $1 run_log "End jmap $1 dump" echo_blank_line&#125;jvm_head_dump $&#123;PID&#125;# statistics all kinds of tcp statuscat $&#123;RESULT_DIRECTORY&#125;/machine_netstat*.dump | awk '/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;' &gt; $&#123;RESULT_DIRECTORY&#125;/machine_netstat_status_statistics.dump]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>dump</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[结果导向]]></title>
    <url>%2F2019%2F06%2F13%2Farticle%2Fteammanager%2Fteammanager_1%2F</url>
    <content type="text"><![CDATA[什么是结果导向 结果导向是质量管理体系、绩效管理理论中的基本概念核心思想之一。强调工作的结果。这里记录另外一种思考。称之为结果导向在过程中的作用和价值。 结果导向在过程中的作用和价值结果导向，字面上意思是注重结果。实际在执行工作过程中体现的是恰恰是过程中的重要性。在过程中强调结果导向，其目的是强调在工作过程中朝着最终的结果靠拢。随着工作过程的推进，这个路径慢慢向结果收敛靠近。它可以作为纠正工作中偏离最终设定结果的工具。]]></content>
      <categories>
        <category>技术之外</category>
      </categories>
      <tags>
        <tag>管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【更好的工作 tips3】敏捷开发原则]]></title>
    <url>%2F2019%2F06%2F12%2Farticle%2Fworker%2Fworker_2%2F</url>
    <content type="text"><![CDATA[前言 敏捷开发的核心目的是利用有限技术资源，实现软件开发的效能的最大化。一些原则或者方法贯穿着敏捷开发的整个过程。 #原则 简单 拥抱变化 可持续性 递增 资源最大化 有目的地建模 多种模型 高质量的工作 快速反馈 主要目标-软件 轻量前行 成功的结果 随机应变 自主权 分享经验]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>敏捷开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【更好工作的 tips1】临时工作的安排]]></title>
    <url>%2F2019%2F06%2F11%2Farticle%2Fworker%2Fworker_0%2F</url>
    <content type="text"><![CDATA[临时工作的安排 口头，或者会议结论提出的临时工作任务。在安排好手上的工作后，立即着手对临时达成协议内容进行安排，花五分钟时间进行记录和规划，上报。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>随想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【更好工作的 tips2】会议的要点]]></title>
    <url>%2F2019%2F06%2F11%2Farticle%2Fworker%2Fworker_1%2F</url>
    <content type="text"><![CDATA[会议的要点 会议或大，或小，或长或短，目的要明确。要明确要解决的问题、确认的问题、达成的共识等。当会议快结束时候确认会议达成的共识或者解决问题的方案，分配相应的任务。特别是技术类、需求类会议。最终都需要达成一个超目标迈进的可执行方案。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>随想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文档编写的过程]]></title>
    <url>%2F2019%2F06%2F11%2Farticle%2Fword%2Fword_0%2F</url>
    <content type="text"><![CDATA[前言 一个好的软件工程师在工作的过程中，不仅仅要求编写计算机高效运行的代码，更需要能够将自己所做工作完美呈现出来的文档能力。 重要性思维过程零碎的思维碎片-&gt;初始文档-&gt;汇报文件(ppt等)以上，从0开始的文档整理过程都是这样过来。首先开始思考有了零碎的思维碎片，此时可能还不能完整的串联起来，但是不要紧，思维碎片完成后。从中提取完整的脉络简单的可以从时间维度、业务发展维度等进行提取。在大概一天的提取后可以大概完成一个具象化的初始文档，初始文档比较粗糙，需要进行润色，加素材。这个过程一般经过一到两天润色或者素材完成后，已经是一份对自己来说完成度较高的文档了。此时如果不需要进行汇报或者演讲，可以直接封板。如果需要汇报或者培训演讲，就需要在此基础上进行提炼提炼更精炼的数据汇总成PPT。]]></content>
      <categories>
        <category>技术之外</category>
      </categories>
      <tags>
        <tag>文档能力</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk基础]]></title>
    <url>%2F2019%2F06%2F05%2Flinux%2Flinux_5%2F</url>
    <content type="text"><![CDATA[前言 awk是由Alfred Aho, Peter Weinberger和 Brian Kernighan三人创造的，wak由三人的姓氏的首个字母组成早期是在unix上实现的。在unix上的叫gawk既GNU awk awk语法 awk命令形式 1awk [-F|-f|-v] 'BEGIN&#123;&#125;//&#123;command1;command2&#125;END&#123;&#125;' file 命令解释 命令 解释 [-F &#124; -f &#124; -v] -F指定分隔符，f调用脚本，-v 定义变量， var=value ‘ ‘ 引用代码块 BEGIN 初始代码块，在对每一行进行处理之前，初始化代码，主要是引用全局变量，设置FS分隔符 // 匹配代码块。可以是字符串或正则表达式 {} 命令代码块。包含一条或者多条命令，多条命令用分号分隔 END 结尾代码块。在对每一行进行处理之后再执行的代码块，主要是进行最终计算或输出结尾摘要信息 awk内置变量 变量名 解释 例子 FILENAME awk浏览的文件名 FNR 与NR类似，多文件记录不递增，每个文件都从1开始 FS 设置输入字段分隔符，同-F选项 NF 浏览记录的字段个数 awk ‘{print NF}’ file //显示每行有多少字段 $NF 最后一个字段的值 awk ‘{print $NF}’ file //将每行第NF个字段的值打印出来 NR 已读的记录数，理解为行号，多文件行号递增 awk ‘NR==5{print}’ file //显示第5行 OFS 输出数据时，每个字段间以OFS制定的字符作为分隔符 awk ‘{print $3,$5,$4}’ OFS=”\n” file ORS 输出数据时，每行记录间以OFS制定的字符作为分羹 awk ‘{print $3,$5,$4}’ ORS=”\n” file awk的大参数 参数模式 1awk [-F|-f|-v] 'BEGIN&#123;&#125; // &#123;command1; command2&#125; END&#123;&#125;' file -F制定分隔符 可以不写，默认用空格。一个或多个连续的空格看做一个分隔符，也可以定义多个分隔符，如果： -F[./]是指，同时以 “.”和”/“作为分隔符。 -f与 -v 略 awky的引用代码块1awk [-F|-f|-v] ‘BEGIN&#123;&#125; // &#123;command1; command2&#125; END&#123;&#125;’ file 操作符 引用代码块是一个编程环境，支持条件运算，逻辑运算等。 符号 解释 实例 == 等于，精确比较 awk ‘$3==”48” {print $0}’ file 只打印第3个字段等于”48”的记录 != 不等于，精确比较 awk ‘$1 != “abc”‘ file //提取第一个字段不是abc的行 ~ 匹配，与==相比不是精确比较 awk ‘{if ($4~/abc/) print $0}’ file //表示如果第四个字段包含abc，就打印整行 !~ 不匹配，不精确比较 awk ‘$0 !~ /abc/‘ file 打印整条不包含abc的记录 &amp;&amp; 和 awk ‘{if ( $1==”a” &amp;&amp; $2==”b” ) print $0}’ file //如果第1、第2个字段值是a和b，打印整行 &#124;&#124; 或 awk ‘{if ($1==”a” &#124;&#124; $1==”b”) print $0}’ temp //如果第1、第2个字段值是a或b，打印整行 > 大于 awk ‘$1&gt;500 {print $2}’ file //如果字段1的值大于500，则打印字段2 >= 大于等于 awk ‘$1&gt;=400 {print $2}’ file //如果字段1的值大于等于400，则打印字段2 \&lt; 小于 awk ‘$1&lt;200 {print $2}’ file //如果字段1的值小于200，则打印字段2 \&lt;= 小于等于 awk ‘$1&lt;=100 {print $2}’ file //如果字段1的值小于等于100，则打印字段2 + 加 awk ‘{print $3+10}’ file //字段3数值加10 - 减 awk ‘{print $3-10}’ file //字段3数值减10 * 乘 awk ‘{print $3*10}’ file //字段3数值乘10 \/ 除 awk ‘{print $3/10}’ file //字段3数值除10 字符匹配代码块 1awk [-F|-f|-v] ‘BEGIN&#123;&#125; // &#123;command1; command2&#125; END&#123;&#125;’ file 字符匹配代码支持针对字符串的操作 字符匹配代码块支持正则表达式 if语句 必须在{}里，且比较内容用()扩起来，支持if else 12345awk -F: '&#123;if($1~/abc/) print $1&#125;' file //简写awk -F: '&#123;if($1~/abc/) &#123;print $1&#125;&#125;' file //全写awk -F: '&#123;if($1~/abc/) &#123;print $1&#125; else &#123;print $2&#125;&#125;' file //if...else... 有时不用if语句也可以实现同样的效果图，如123awk -F: '&#123;if($1~/abc/) &#123;print $1&#125;&#125;' file //$1为指定内容才显示awk -F: '$1~/abc/ &#123;print $1&#125;' file //与上面相同效果，没有用if语句，条件写在‘’外 while语句 与其他语言的while语句类似，条件为True时执行循环语句，False时不执行。 数组 123netstat -anp|awk 'NR!=1&#123;a[$6]++&#125; END&#123;for (i in a) print i,"\t",a[i]&#125;'netstat -anp|awk 'NR!=1&#123;a[$6]++&#125; END&#123;for (i in a) printf "%-20s %-10s %-5s \n", i,"\t",a[i]&#125;' 应用 指定输出 1234567awk -F: '&#123;print NF&#125;' helloworld.sh //输出文件每行有多少字段awk -F: '&#123;print $1,$2,$3,$4,$5&#125;' helloworld.sh //输出前5个字段awk -F: '&#123;print $1,$2,$3,$4,$5&#125;' OFS='\t' helloworld.sh //输出前5个字段并使用制表符分隔输出awk -F: '&#123;print NR,$1,$2,$3,$4,$5&#125;' OFS='\t' helloworld.sh //制表符分隔输出前5个字段，并打印行号 指定分隔符并且输出 1234567awk -F'[:#]' '&#123;print NF&#125;' helloworld.sh //指定多个分隔符: #，输出每行多少字段awk -F'[:#]' '&#123;print $1,$2,$3,$4,$5,$6,$7&#125;' OFS='\t' helloworld.sh //制表符分隔输出多字段awk -F'[:#/]' '&#123;print NF&#125;' helloworld.sh //指定三个分隔符，并输出每行字段数awk -F'[:#/]' '&#123;print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12&#125;' helloworld.sh //制表符分隔输出多字段 简单计算 计算/home目录下，普通文件的大小，使用KB作为单位 123ls -l|awk 'BEGIN&#123;sum=0&#125; !/^d/&#123;sum+=$5&#125; END&#123;print "total size is:",sum/1024,"KB"&#125;'ls -l|awk 'BEGIN&#123;sum=0&#125; !/^d/&#123;sum+=$5&#125; END&#123;print "total size is:",int(sum/1024),"KB"&#125;' //int是取整的意思 统计 统计netstat -anp 状态为LISTEN和CONNECT的连接数量分别是多少 1netstat -anp|awk '$6~/LISTEN|CONNECTED/&#123;sum[$6]++&#125; END&#123;for (i in sum) printf "%-10s %-6s %-3s \n", i," ",sum[i]&#125;' 统计/home目录下不同用户的普通文件的总数是多少？ 1netstat -anp|awk '$6~/LISTEN|CONNECTED/&#123;sum[$6]++&#125; END&#123;for (i in sum) printf "%-10s %-6s %-3s \n", i," ",sum[i]&#125;' 统计/home目录下不同用户的普通文件的总数是多少？ 1ls -l|awk 'NR!=1 &amp;&amp; !/^d/&#123;sum[$3]++&#125; END&#123;for (i in sum) printf "%-6s %-5s %-3s \n",i," ",sum[i]&#125;' 统计/home目录下不同用户的普通文件的大小总size是多少？ 1ls -l|awk 'NR!=1 &amp;&amp; !/^d/&#123;sum[$3]+=$5&#125; END&#123;for (i in sum) printf "%-6s %-5s %-3s %-2s \n",i," ",sum[i]/1024/1024,"MB"&#125;' 复杂表格输出 12345678910111213awk 'BEGIN&#123;math=0;eng=0;com=0;printf "Lineno. Name No. Math English Computer Total\n";printf "------------------------------------------------------------\n"&#125;&#123;math+=$3; eng+=$4; com+=$5;printf "%-8s %-7s %-7s %-7s %-9s %-10s %-7s \n",NR,$1,$2,$3,$4,$5,$3+$4+$5&#125; END&#123;printf "------------------------------------------------------------\n";printf "%-24s %-7s %-9s %-20s \n","Total:",math,eng,com;printf "%-24s %-7s %-9s %-20s \n","Avg:",math/NR,eng/NR,com/NR&#125;' test0cat test0 Marry 2143 78 84 77Jack 2321 66 78 45Tom 2122 48 77 71Mike 2537 87 97 95Bob 2415 40 57 62]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【代码审查系列8】阿里巴巴编码规范]]></title>
    <url>%2F2019%2F06%2F04%2Farticle%2Fcodereview%2Farticle_8%2F</url>
    <content type="text"><![CDATA[阿里巴巴编码规范详情]]></content>
      <categories>
        <category>技术之外</category>
      </categories>
      <tags>
        <tag>代码审查</tag>
        <tag>CODEREVIEW</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【代码审查系列7】如何做人性化的代码审查]]></title>
    <url>%2F2019%2F06%2F04%2Farticle%2Fcodereview%2Farticle_7%2F</url>
    <content type="text"><![CDATA[如何做人性化的代码审查详情]]></content>
  </entry>
  <entry>
    <title><![CDATA[【代码审查系列6】GIT修改注释模板方式]]></title>
    <url>%2F2019%2F06%2F04%2Farticle%2Fcodereview%2Farticle_6%2F</url>
    <content type="text"><![CDATA[在使用Git做版本控制工具的团队协助开发中，保证团队成员在提交代码后能够更详尽的追溯源头下。规范代码注释的必要性就得以体现。通过制定这种规范约束，可以显著提高代码提交的目的可追溯性。这里介绍Git修改注释模板方式。 创建过程 git命令下创建注释模板 创建 XX_template文件，内容为团队制定的git提交规范例如： 123Desgraption: Date: Author: 通过git config配置commit_template,如下： 1git config –-global commit.template /d/develop/Git/Git_Home/commit_template 设置git commit时填写注释所用的编辑器，如下： 1git config --global core.editor vim 设置后，提交试用git commit]]></content>
      <categories>
        <category>技术之外</category>
      </categories>
      <tags>
        <tag>代码审查</tag>
        <tag>CODEREVIEW</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【代码审查系列5】upsource使用简介]]></title>
    <url>%2F2019%2F06%2F04%2Farticle%2Fcodereview%2Farticle_5%2F</url>
    <content type="text"><![CDATA[upsource使用简介]]></content>
      <categories>
        <category>技术之外</category>
      </categories>
      <tags>
        <tag>代码审查</tag>
        <tag>CODEREVIEW</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【代码审查系列4】CODE REVIEW 代码审查清单]]></title>
    <url>%2F2019%2F06%2F04%2Farticle%2Fcodereview%2Farticle_4%2F</url>
    <content type="text"><![CDATA[整洁的代码 清单项 分类 使用可以表达实际意图的名称 有意义的名称 每一个概念只用一个词 有意义的名称 使用方案/问题领域名称 有意义的名称 类应该是比较小的 类 函数应该是比较小的 函数 只做一件事 函数 DRY(拒绝重复) 函数 用代码来注释自己的做法 注释 确定应用了代码格式化 格式 使用异常而不是返回码 异常 不要返回NULL 异常 安全性问题 清单项 分类 如果不用继承，使用final类 基础 避免重复代码 基础 权限限制：程序应该运行在保证功能正常的最小权限模式下 基础 最小化类和成员的可访问性 基础 注释安全相关的信息 基础 系统的输入必须检查是否有效和在允许范围内 拒绝服务 避免对于一些不寻常行为的过分日志 拒绝服务 在任何情况下都释放资源（流，连接等） 拒绝服务 从异常中清楚敏感信息（暴露文件路径，系统内部相关，配置，IP等） 秘密信息 不把高敏感度的信息写到日志 秘密信息 考虑把高度敏感的信息在使用后从内存中删除 密码信息 限制包，类，接口，方法和域的可访问性 可访问性的扩展 限制类和方法的可扩展性 可访问性的扩展 检验输入（有效数据，大小，范围，边界） 输入检验 把从不可信对象得到的输出作为输入来检验 输入检验 为native方法定义包装类（而不是定义native方法为public） 输入检验 把从不可信对象得到的输出作为输入来对待 可变性 使public static域为final（避免调用方法（caller）修改它的值） 可变性 避免暴露敏感类的构造函数 对象构造 避免安全敏感类的序列化 序列化反序列化（Serialization Deserialization) 通过序列化来保护敏感数据 序列化反序列化 小心地缓存潜在的特权操作结果 序列化反序列化 性能 清单项目 分类 避免过分的同步 并发 保持同步于去比较小 并发 知道String连接的性能情况 综合编程 避免创建不需要的对象 创建和销毁对象]]></content>
      <categories>
        <category>技术之外</category>
      </categories>
      <tags>
        <tag>代码审查</tag>
        <tag>CODEREVIEW</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【代码审查系列3】CODE REVIEW代码审查执行方法]]></title>
    <url>%2F2019%2F06%2F04%2Farticle%2Fcodereview%2Farticle_3%2F</url>
    <content type="text"><![CDATA[前言 建立完善的代码审查机制有助于提升开发团队的协作能力，和提升代码质量。并不是件简单的事情。不同团队所处的公司，项目客观环境不同，所采用的审查流程也不尽相同。本文根据目前公司项目状态和团队人员状况指定简单的可执行方案。希望对开展代码审查机制有帮助。 默认约定review方法约定这里暂时用两种方式 结对review 在项目或者需求计划完成时由reviewer或者项目负责人对关键功能点进行评估是否进行结对review 当需要进行结对review的功能点开发完成后，由codeowner通知review约定一个具体时间对关键代码的解说，reviewer跟着coderowner的流程进行review提出可能隐藏的逻辑错误。 异步review codeowner每天提交完整的可编译的代码。 codeviewer每天拉取完整的代码。 项目实际开发天数&gt;7人日（含）：在项目阶段的每个周四固定一个时间段进行已提交的完整代码review。再另外在提测前两天进行review一遍。如果两者时间有冲突，那么以提测前 两天为主。 如果项目或者需求实际时间小于7人日，在提测前两天进行review一遍。 codeowner在接收到review comment时。最迟第二天进行答复。和codereview协商完成comment处理。 codereview在提测前一天下午前，进行完整审查。寻找未处理的reviewcomment灭掉。 流程前置条件 代码上传到Gitlab 配置好upsource代码库 安装upsource idea插件 划分角色CODEROWNER: 代码作者 REVIEWER: 代码审查者 流程图123456789graph TB开始 --&gt; 开发计划开发计划 --&gt; 划分角色开发计划 --&gt; review计划划分角色 --&gt; 开发提交代码review计划 --&gt; 开发提交代码开发提交代码 --&gt; 进行review进行review --&gt; 开发提交代码进行review --&gt; 提测 核心流程详解 划分角色和review计划制定 开发计划制定后进行角色划分。code reviewer一般是项目负责人。同时也可以是coder rewiver将要进行的项目上传到gitlab和upsource。并配置好项目在upsource上的配置。 coder 配置好idea插件 根据功能划分制定review方式。 按照功能进行开发 在功能开发过程中按照指定好的review计划进行codereview CODE REVIEW的方法代码审查方式 关注点 代码审查清单列表 代码的设计是否符合要求 逻辑是否正确 执行过程 角色： Reviewerreviewer为各个项目负责人可以同时是CodeOwner CodeOwnerCoderOwner为这个代码的作者, 每天由Codeowner提交代码。Reviewer通过idea插件或者 upsource的hub页面筛查自己需要 审查的代码进行审查。并提交相关建议。 结果反馈略 审查工具和附件 upsource 注释模板设置方式 代码审查清单 git注释模板]]></content>
      <categories>
        <category>技术之外</category>
      </categories>
      <tags>
        <tag>代码审查</tag>
        <tag>CODEREVIEW</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【代码审查系列2】CODE REVIEW 代码审查分类-以及选取方式]]></title>
    <url>%2F2019%2F06%2F04%2Farticle%2Fcodereview%2Farticle_2%2F</url>
    <content type="text"><![CDATA[代码审查主要可以划分4种类型。每一种代码审查类型都有它特有的优缺点。在高层面，代码审查归为两大类：正式的审查，轻量级的审查。以下详细说明： 正式的审查正式的审查与开发流程绑定作为流程中不可或缺的一部分。实践方式有很多种，其中最流行的实践方式是 范根检查法（Faganinspection）。它为视图寻找代码缺陷提供了一种非常结构化的流程，并且，还可以用于发现规范中的或者设计中的缺陷。 范根检查法步骤 计划 概述 准备 召开检查会议 重做 追查 其基本思想为：预先制定好每一个步骤所需要达到的输出要求。当进行到某个过程时，检查现在的输出，并与之前指定的理想输出要求做比较。然后，由此决定是否进入下一个步骤。或者仍需在当前步骤继续工作。这种结构化的流程比较繁琐，用的不多。成本较高。一般团队很少使用。然而，如果开发的软件生死攸关，会因为有缺陷而让人丧命，那么以这种结构化的方式查找软件缺陷就显得很合理。比如动车调度，飞机自动驾驶等等。 轻量级审查相比于正式的代码审查，轻量级代码审查正在被更多的开发团队所使用。其子分类有： 瞬时代码审查，也称为结对编程。 一般情况： 当一个开发者在敲代码的同时，另一个开发盯着代码，注意着代码中潜在的问题，并在此过程中给出提升代码质量的建议。 解决复杂问题的情况： 此种方法比较适用于，仔细找解决方案的时候两个大脑汇集起来增加成功的概率。让两个头脑思考同一个问题，并且互相讨论可行的方案，这样你更可能覆盖到问题的一些边界情况。在遇到需要很多复杂业务逻辑的任务时候，可以用结对编程。 需要学习新技术时候的情况： 例如：在使用一个新的框架，或者在探索之前没用过的新技术。最好还是单独行动，因为这时可以根据自己的情况作出快速调整。为了弄清楚技术是如何工作的，需要网络上搜索大量资料。或者阅读文档。这时，结对编程帮助就不大，因为不同的人可能获取知识的方式不同。另一方面，当你被问题卡主之后，与同事之间交流一下解决方案，往往会有意想不到的收获。 开发者水平差距问题的影响： 当一个初级开发者和高级开发者进行结对编程，效果并不好。在初级代码开发者负责写代码时，坐在旁边的高级程序员可能因为他写的太慢而感到烦恼。如此设定，这个高级程序员的能力就被限制住了，从而浪费时间。当键盘在高级程序员手上时，又敲得太快，初级程序员跟不上高级程序员的思路。几分钟后，初级程序员就迷失在代码上下文了，或者需要更多的时间解释代码的含义。徒增时间成本。 总结 结对编程适用于两个有相似经验水平的开发者处理复杂的业务问题的情况。 同步代码审查，既时代码审查。 运行方式： 一个开发者独自编写代码，当她写完代码后，立即找代码审查者进行审查。审查者来到开发者的桌前，看着同一个屏幕，一起审查、讨论和改进代码。 审查者不清楚这个任务的目标时： 这种代码审查类型会很有效果。它会在这种情况下发生：团队里没有优化会议，或者sprint计划会议，来预先讨论每一项任务。此种做法会导致一种结果：只有特定的开发人员才能知道某项任务的需求。这种情况下，在代码审查之前，向审查者介绍下任务的目标是很有帮助的。 期待大量的代码改进时：如果代码编写者缺乏经验，写出的代码需要很大的改进，那么同步代码审查也很有效。 如果一个经验丰富的高级开发者将要对一个很初级的程序员写出的一段代码进行审查，那么，当初级程序员写完代码后和高级开发者一起改进这块代码，效率是远远高于初级程序员一个人看的。 缺点：它强行切换了审查者的思路，不仅让审查者感到沮丧，也拖慢了整个团队的效率。 异步的代码审查，工具支持的代码审查。 运行方式： 开发者在写完代码后，让这些代码对审查者课件，让后开始他的下一个任务。当审查者有时间了，他会在自己的桌子上按自己的时间表进行审查。他不需要和开发者进行沟通，而是通过工具写一些评论。在完成审查后，那些工具会把评论和需要改动的通知给开发者。开发者就会根据评论改进代码，同样的，以自己的时间进行这些事情。这种循环，会以代码改动再次提交到审查者这里又重新开始。开发者修改代码，知道没有评论需要改进。最后改动完成，并且同意，合并到主分支。同步和异步的代码审查有较大的不同。 好处： 没有直接的依赖，异步发生。开发者不需要直接依赖于审查者，并且时间安排相对自由。 缺点： 可能有许多次循环的审查，可能持续好几天，最终被接受。可能发生的详情如下：当开发者完成代码后，需要几个小时候审查者才开始做代码审查。很多事会后，审查者给出的建议在第二天才能被开发者修复。这样，第一次审查周期就用了一天，如果有多次循环，审查的时间久延续了一整周，还不算代码和测试的时间。 解决方案： 在团队里，我们规定，每天上午，每个开发者在开始做其他工作之前，都需要处理挤压的代码审查任务，同样的，在中午午休结束后也类似的工作安排。在较长的休息时间后，开发者已经不出在他的代码思路里了。这时进行代码审查，冰没有强制他们进行不自然的思路切换，并且能够让代码在合适的时间内得到审查。 总结：异步的代码审查应该作为每一个专业开发团队的默认选项。但是在为什么这么做之前，要想清楚这些代码审查分类原则。 偶尔的代码审查，基于回忆的代码审查。 执行方式： 坐在会议室，一个开发者展示并解释他最近写的一段困难的代码。其他开发者尝试寻找潜在的缺陷，发表评论，给出如何改进代码的建议。 适用场景： 当整个团队都没有代码审查的经验时，把每个人都聚集起来，一起做代码审查，这样弄几次后，可能帮助每个人理解代码审查的目标和意义。长远看来，此种方式并不是一个合适的技术，因为让劝阻审核一段代码是很低效的。 如何选择 正式的代码审查，不流行，较难实现较难用于实践。 轻量级的代码审查选择 瞬时代码审查用于结对编程，在解决复杂业务时候使用。 同步代码审查，用于审查者不知道大量改进时。 异步审查，避免了强行切换思路带来的问题，对大多数用例都工作的很好。 偶尔的代码审查，对于专业团队来说不是长期的选择。 总结主要用轻量级代码审查。在轻量级代码审查中按照不同情况进行选择审查方式。 默认使用异步审查。 在开发一个新系统新业务时候，评估业务复杂度如果复杂度高，进行结对编程。]]></content>
      <categories>
        <category>技术之外</category>
      </categories>
      <tags>
        <tag>代码审查</tag>
        <tag>CODEREVIEW</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【代码审查系列1】CODE REVIEW机制目标规划]]></title>
    <url>%2F2019%2F06%2F04%2Farticle%2Fcodereview%2Farticle_1%2F</url>
    <content type="text"><![CDATA[前言 代码审查是软件生产过程中用于把控软件质量的一种方式。通常的目的是查找系统缺陷，保证软件总体质量和提高开发者自身水平。如何建立长远的审核机制，以保证代码的持续健康优化，是个相对复杂的过程。本文对代码审查的规划做一个简单的分析。 目标 代码规范化 更好的设计 技术成长 原则通过制度和规范的手段对代码审核进行合理化推行，在执行的潜移默化中落实到实际操作 最终在团队变更或者其他事物发生变迁的情况下依然能够完整执行并且收效。 目前的状态当前项目的状态是：项目小，数量多，项目人员分散。 外部环境的状态：需求不定期加入，维护性工作不定期进行。 内部人员状态：对于老员工来讲，习惯旧有的思考方式和做事方式。对社招新员工来讲，带着之前的思维方式做事风格，还在适应新环境中。对于校招员工来讲规则尚未建立，接受新鲜事物规则较快。 推行面临的问题 时间不够 应对措施：在开发计划制定时预留1-2天时间进行review。 需求变化 应对措施：在需求变化后重新进行review. 人员态度 应对措施：局部某个项目开始进行review，养成习惯，各个击破。进而扩展到整体团队review 目标分解阶段一 完成代码规范 CODE REVIEW习惯养成CODE REVIEW机制建立初始化，团队内部养成习惯，作为工作的一部分。 阶段二 更好的设计 发现隐藏缺陷Bug发现并尽量避免隐藏Bug的发生，对不合理的设计进行重新评审。 阶段三 技术成长 REVIEWER能力的提升提升代码审查的效率和准确率。 CODER的技术提升提升代码设计的质量 参考： 审查类型和选择方式 代码审查执行方法 代码审查执行方法 附件 注释模板设置方式 代码审查清单]]></content>
      <categories>
        <category>技术之外</category>
      </categories>
      <tags>
        <tag>代码审查</tag>
        <tag>CODEREVIEW</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[团队管理中的三个时期]]></title>
    <url>%2F2019%2F06%2F04%2Farticle%2Fteammanager%2Fteammanager_0%2F</url>
    <content type="text"><![CDATA[团队建设 前期重教育 完成团队前期的人员了解和结构梳理 中期重规范 建立团队运作规范，技术规范，技术外的流程规范 后期重辅导 具体协助过程的配合]]></content>
      <categories>
        <category>技术之外</category>
      </categories>
      <tags>
        <tag>管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch 配置解释]]></title>
    <url>%2F2018%2F10%2F31%2Fsearch%2Fes_1%2F</url>
    <content type="text"><![CDATA[elasticsearch.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102# ======================== Elasticsearch Configuration =========================## NOTE: Elasticsearch comes with reasonable defaults for most settings.# Before you set out to tweak and tune the configuration, make sure you# understand what are you trying to accomplish and the consequences.## The primary way of configuring a node is via this file. This template lists# the most important settings you may want to configure for a production cluster.## Please consult the documentation for further information on configuration options:# https://www.elastic.co/guide/en/elasticsearch/reference/index.html## ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster:#cluster.name: localCluster## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:# 默认从 /lib/elasticsearch-6.4.2.jar!config/names.txt选择一个node.name: node-1## Add custom attributes to the node:##node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):#path.data: /Users/littlehui/WorkSpaces/Office/Search/es/search/data## Path to log files:#path.logs: /Users/littlehui/WorkSpaces/Office/Search/es/search/logs## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:#bootstrap.memory_lock: true## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.## Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------## Set the bind address to a specific IP (IPv4 or IPv6):#network.host: 127.0.0.1## Set a custom port for HTTP:#http.port: 9200## For more information, consult the network module documentation.## --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when new node is started:# The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]## 当启动节点时，通过这个Ip列表进行发现，组建集群默认节点127.0.0.1，标识ipv4的回环地址# [::1]ipv6的回环地址## es1.x默认组播 multicast# es2.x 默认单播 unicast# 注意：如果发现其他服务器中的es服务，可以不指定端口 （9300），如果发现同一个服务器的es服务，需要制定端口。## 多播用于动态扩展配置# discovery.zen.ping.multicast# group,port,ttl,address#discovery.zen.ping.unicast.hosts: [&quot;127.0.0.1:9300&quot;, &quot;127.0.0.1:9301&quot;, &quot;127.0.0.1:9302&quot;]## Prevent the &quot;split brain&quot; by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1):#discovery.zen.minimum_master_nodes: 2# 节点间心跳 秒discovery.zen.ping_timeout: 10## For more information, consult the zen discovery module documentation.## ---------------------------------- Gateway -----------------------------------## Block initial recovery after a full cluster restart until N nodes are started:##gateway.recover_after_nodes: 3## For more information, consult the gateway module documentation.## ---------------------------------- Various -----------------------------------## Require explicit names when deleting indices:##action.destructive_requires_name: true]]></content>
      <categories>
        <category>搜索</category>
      </categories>
      <tags>
        <tag>es，配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch 启动步骤]]></title>
    <url>%2F2018%2F10%2F31%2Fsearch%2Fes_0%2F</url>
    <content type="text"><![CDATA[背景ES的版本迭代较快每个版本启动和运行方式有所差异，本文以6.4.2版本说明。6.4.2版本下载地址：https://www.elastic.co/downloads/elasticsearch 启动步骤ES启动是通过下载包的 ./bin/elasticsearch叫本进行启动的。脚本定义了一些es和java的默认参数。可以通过修改脚本参数内容方式启动，控制台运行，比如修改esJVM大小等等。 Elasticsearch启动后 Elasticsearch类解析 Elasticsearch类启动时候运行main()函数，如下: Elasticsearch初始化各种Option Elasticsearch内部解释： 运行System.setSecurityManager 配置默认管理器，默认使用的是 $JAVA_HOME/jre/lib/security/java.policy 注册Errorlistener,LogConfigurator.registerErrorListener();用于在失败的时候报错。 12345678910111213141516171819/** * Main entry point for starting elasticsearch */public static void main(final String[] args) throws Exception &#123; // we want the JVM to think there is a security manager installed so that if internal policy decisions that would be based on the // presence of a security manager or lack thereof act as if there is a security manager present (e.g., DNS cache policy) System.setSecurityManager(new SecurityManager() &#123; @Override public void checkPermission(Permission perm) &#123; // grant all permissions so that we can later set the security manager to the one that we want &#125; &#125;); LogConfigurator.registerErrorListener(); final Elasticsearch elasticsearch = new Elasticsearch(); int status = main(args, elasticsearch, Terminal.DEFAULT); if (status != ExitCodes.OK) &#123; exit(status); &#125;&#125; 启动Elasticsearch命令行客户端EnvironmentAwareCommand和对应用来输入Terminal Elasticsearch 123static int main(final String[] args, final Elasticsearch elasticsearch, final Terminal terminal) throws Exception &#123; return elasticsearch.main(args, terminal);&#125; EnvironmentAwareCommand 1234567891011121314151617181920212223242526@Overrideprotected void execute(Terminal terminal, OptionSet options) throws Exception &#123; final Map&lt;String, String&gt; settings = new HashMap&lt;&gt;(); for (final KeyValuePair kvp : settingOption.values(options)) &#123; if (kvp.value.isEmpty()) &#123; throw new UserException(ExitCodes.USAGE, "setting [" + kvp.key + "] must not be empty"); &#125; if (settings.containsKey(kvp.key)) &#123; final String message = String.format( Locale.ROOT, "setting [%s] already set, saw [%s] and [%s]", kvp.key, settings.get(kvp.key), kvp.value); throw new UserException(ExitCodes.USAGE, message); &#125; settings.put(kvp.key, kvp.value); &#125; putSystemPropertyIfSettingIsMissing(settings, "path.data", "es.path.data"); putSystemPropertyIfSettingIsMissing(settings, "path.home", "es.path.home"); putSystemPropertyIfSettingIsMissing(settings, "path.logs", "es.path.logs"); execute(terminal, options, createEnv(terminal, settings));&#125; Elasticsearch 123456789101112131415161718Elasticsearch() &#123; super("starts elasticsearch", () -&gt; &#123;&#125;); // we configure logging later so we override the base class from configuring logging versionOption = parser.acceptsAll(Arrays.asList("V", "version"), "Prints elasticsearch version information and exits"); daemonizeOption = parser.acceptsAll(Arrays.asList("d", "daemonize"), "Starts Elasticsearch in the background") .availableUnless(versionOption); pidfileOption = parser.acceptsAll(Arrays.asList("p", "pidfile"), "Creates a pid file in the specified path on start") .availableUnless(versionOption) .withRequiredArg() .withValuesConvertedBy(new PathConverter()); quietOption = parser.acceptsAll(Arrays.asList("q", "quiet"), "Turns off standard output/error streams logging in console") .availableUnless(versionOption) .availableUnless(daemonizeOption);&#125; 创建Setting（HashMap)设置Elasticsearch配置 进行命令行相关的设置，初始化之后，跳转到Bootstrap中进行操作 init Elasticsearch 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Overrideprotected void execute(Terminal terminal, OptionSet options, Environment env) throws UserException &#123; if (options.nonOptionArguments().isEmpty() == false) &#123; throw new UserException(ExitCodes.USAGE, "Positional arguments not allowed, found " + options.nonOptionArguments()); &#125; if (options.has(versionOption)) &#123; final String versionOutput = String.format( Locale.ROOT, "Version: %s, Build: %s/%s/%s/%s, JVM: %s", Version.displayVersion(Version.CURRENT, Build.CURRENT.isSnapshot()), Build.CURRENT.flavor().displayName(), Build.CURRENT.type().displayName(), Build.CURRENT.shortHash(), Build.CURRENT.date(), JvmInfo.jvmInfo().version()); terminal.println(versionOutput); return; &#125; final boolean daemonize = options.has(daemonizeOption); final Path pidFile = pidfileOption.value(options); final boolean quiet = options.has(quietOption); // a misconfigured java.io.tmpdir can cause hard-to-diagnose problems later, so reject it immediately try &#123; env.validateTmpFile(); &#125; catch (IOException e) &#123; throw new UserException(ExitCodes.CONFIG, e.getMessage()); &#125; try &#123; init(daemonize, pidFile, quiet, env); &#125; catch (NodeValidationException e) &#123; throw new UserException(ExitCodes.CONFIG, e.getMessage()); &#125;&#125;void init(final boolean daemonize, final Path pidFile, final boolean quiet, Environment initialEnv) throws NodeValidationException, UserException &#123; try &#123; Bootstrap.init(!daemonize, pidFile, quiet, initialEnv); &#125; catch (BootstrapException | RuntimeException e) &#123; // format exceptions to the console in a special way // to avoid 2MB stacktraces from guice, etc. throw new StartupException(e); &#125;&#125; Bootstrap内部 初始化一个KeepAlive线程，内部的countDownLatch用于启动之后的心跳。保证节点运行期间Bootstrap一直存在。可以接受相关的命令退出 做了一些检查，SSL加密customConfFile 创建PID文件 checkLucene版本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107/** * This method is invoked by &#123;@link Elasticsearch#main(String[])&#125; to startup elasticsearch. */ static void init( final boolean foreground, final Path pidFile, final boolean quiet, final Environment initialEnv) throws BootstrapException, NodeValidationException, UserException &#123; // force the class initializer for BootstrapInfo to run before // the security manager is installed BootstrapInfo.init(); INSTANCE = new Bootstrap(); final SecureSettings keystore = loadSecureSettings(initialEnv); final Environment environment = createEnvironment(foreground, pidFile, keystore, initialEnv.settings(), initialEnv.configFile()); try &#123; LogConfigurator.configure(environment); &#125; catch (IOException e) &#123; throw new BootstrapException(e); &#125; if (environment.pidFile() != null) &#123; try &#123; PidFile.create(environment.pidFile(), true); &#125; catch (IOException e) &#123; throw new BootstrapException(e); &#125; &#125; final boolean closeStandardStreams = (foreground == false) || quiet; try &#123; if (closeStandardStreams) &#123; final Logger rootLogger = ESLoggerFactory.getRootLogger(); final Appender maybeConsoleAppender = Loggers.findAppender(rootLogger, ConsoleAppender.class); if (maybeConsoleAppender != null) &#123; Loggers.removeAppender(rootLogger, maybeConsoleAppender); &#125; closeSystOut(); &#125; // fail if somebody replaced the lucene jars checkLucene(); // install the default uncaught exception handler; must be done before security is // initialized as we do not want to grant the runtime permission // setDefaultUncaughtExceptionHandler Thread.setDefaultUncaughtExceptionHandler( new ElasticsearchUncaughtExceptionHandler(() -&gt; Node.NODE_NAME_SETTING.get(environment.settings()))); INSTANCE.setup(true, environment); try &#123; // any secure settings must be read during node construction IOUtils.close(keystore); &#125; catch (IOException e) &#123; throw new BootstrapException(e); &#125; INSTANCE.start(); if (closeStandardStreams) &#123; closeSysError(); &#125; &#125; catch (NodeValidationException | RuntimeException e) &#123; // disable console logging, so user does not see the exception twice (jvm will show it already) final Logger rootLogger = ESLoggerFactory.getRootLogger(); final Appender maybeConsoleAppender = Loggers.findAppender(rootLogger, ConsoleAppender.class); if (foreground &amp;&amp; maybeConsoleAppender != null) &#123; Loggers.removeAppender(rootLogger, maybeConsoleAppender); &#125; Logger logger = Loggers.getLogger(Bootstrap.class); if (INSTANCE.node != null) &#123; logger = Loggers.getLogger(Bootstrap.class, Node.NODE_NAME_SETTING.get(INSTANCE.node.settings())); &#125; // HACK, it sucks to do this, but we will run users out of disk space otherwise if (e instanceof CreationException) &#123; // guice: log the shortened exc to the log file ByteArrayOutputStream os = new ByteArrayOutputStream(); PrintStream ps = null; try &#123; ps = new PrintStream(os, false, "UTF-8"); &#125; catch (UnsupportedEncodingException uee) &#123; assert false; e.addSuppressed(uee); &#125; new StartupException(e).printStackTrace(ps); ps.flush(); try &#123; logger.error("Guice Exception: &#123;&#125;", os.toString("UTF-8")); &#125; catch (UnsupportedEncodingException uee) &#123; assert false; e.addSuppressed(uee); &#125; &#125; else if (e instanceof NodeValidationException) &#123; logger.error("node validation exception\n&#123;&#125;", e.getMessage()); &#125; else &#123; // full exception logger.error("Exception", e); &#125; // re-enable it if appropriate, so they can see any logging during the shutdown process if (foreground &amp;&amp; maybeConsoleAppender != null) &#123; Loggers.addAppender(rootLogger, maybeConsoleAppender); &#125; throw e; &#125; &#125; Node节点 根据Pid和是否守护进程等信息和之前是setting，创建运行时环境environment和pid文件。 检查所需的Lucene jar包 根据之前的environment,为每个plugin创建本地插件控制器：spawner 初始化本地资源（native方法进行一些OS调用和JVM信息，比如mlock/系统最大资源之类的） 初始化两种probes（探测），将提供给ES start时所需的一些进程信息和OS层面信息。 检查重复的jar包，并打印在日志中（JarHell.checkJarHell()) 初始化Node节点（本地节点） 配置一个检查非回路的IP监测点 初始化nodeId和nodeName(new NodeEnvironment) 促使华ES各个功能模块的Service和module，并将service和module绑定 核心：真正启动Node和keeplive线程node启动是在node中各个模块的胡同，通过guice获取各个module的service接口并启动内部包括了master选举机制等。]]></content>
      <categories>
        <category>搜索</category>
      </categories>
      <tags>
        <tag>es</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【好文】滴滴出行技术总监：关于技术选型的那些事儿]]></title>
    <url>%2F2018%2F07%2F27%2Farticle%2Farticle_1%2F</url>
    <content type="text"><![CDATA[转载：https://news.cnblogs.com/n/563792/ 杜欢，滴滴出行技术总监，负责滴滴小巴业务的技术管理工作。在互联网领域已经有十年工作经验，曾就职于微软、百度，也曾自主创业两次，来到滴滴之后也经历过很多项目和业务的变化，是一个“什么都懂”工程师，对前端、客户端、服务端、运维等方面都有不少实战经验。平时是一个 ACG 宅，也喜欢阅读各种技术和非技术的文章扩大视野，不愿主动交谈，但一旦放松了就聊到停不下来。 技术选型案例 今天会聊技术选型这个话题，主要就是因为我经历相对比较丰富，亲历过不少项目选型的过程，自己也做过不少靠谱或者不靠谱的决策，在这个方面也有些自己的思考。我想先从几个案例开始，像讲故事一样聊聊选型背后的事，作为话题的开始。 在我刚开始工作时就经历过一次很大的选型事件，我是这件事情的旁观者。当时公司希望做一个非常酷炫的手机界面系统，恰逢 Windows Vista 一系列新技术的发布，包括 WPF、Silverlight、C# 这些技术非常火，公司对它们抱有极高的期望，所以就想第一时间用在新一代 Windows Mobile 上面。确实界面开发和各种效果可以做的很酷炫也节省了界面开发时间，但是很尴尬的遇到了另外一个问题，性能问题。 这些东西都是跑在移动设备上面，当年的移动设备内存能有 32MB，CPU 能到 1GHz 就很不错了，根本不能很好的支撑这一整套界面系统对性能的要求。后来，当公司发现确实在当时的硬件环境下突破性能问题，就对所有界面做了一次重写，回到了用 C++ 和各种 API 传统写界面方式上才解决问题，这里面涉及到将近一千名工程师一年多的时间，可以说是个很大的人力和时间的损失。 当时我还不是很理解，为什么公司不能更早一点止损，后来我慢慢发现，这真的是当局者迷，当一个决策作出之后大家就天然的希望能通过努力来解决眼前的问题，结果反而越陷越深。这也意味着最初选型的时候得十分谨慎，特别是选型影响面巨大时保守点会更好。 后来加入了真正的互联网公司，我看到了技术选型是稳定压倒一切。比如 gcc、linux 内核这些非常底层和关键的东西，在互联网公司里基本不会去追最新版，只是保持了解和跟进，非常克制的将一些 patch 和功能引入到线上环境，真正上线也会经历相当久的灰度验证过程。 我印象挺深的是当年（2009 年）对 lighttpd 和 apache 的选型，当时 lighttpd 单机性能明显优于 apache，同时也支持 php 扩展，能够以 mod 形式运行 php，看起来使用 lighttpd 全面替换 apache 就好了，但实际上为了业务稳定性，真正的用法是将 lighttpd 做反向代理，后面还是使用 apache + mod_php 来提供服务。这里面的思考就是对于一个新技术的天然不信任，在技术接受程度还不够高且公司内没有人能吃透这个技术的情况下，不愿意让自己的业务做第一个吃螃蟹的人。 谨慎确实是个美德，不过如果在一个非常追求速度的业务里，这可能也意味着过于保守，会延误时机。 我在自己创业的过程中选型就比较激进，也玩的比较 high。 比如我会积极的使用 MongoDB，我对它灵活的数据结构、强大的查询语句和内置的高可用机制等非常认可，当它刚刚 1.0 的时候就将它用在一些不重要的数据上，后来等到 2.x 发布后就开始尝试用在新业务上作为核心数据库。我也曾经遇到一些严重的坑，比如数据损坏、扩容不及时造成停机等，但是由于业务对这些问题容忍度较高，同时也有一些兜底方案，所以还不至于成为业务瓶颈，总体来说利大于弊，可以节省业务开发人员的宝贵时间。 我也曾决策使用 Node.js 作为主力服务器开发工具，当时（2013 年）因为客户端要使用 Javascript 作为主力语言，服务端和客户端会有不少能够复用的代码，所以挺想使用 Node.js 来提升开发效率。 为了验证 Node.js 是否靠谱，我自己通读了源码、阅读了不少相关文章、看了下官方 release note 及社区活跃程度（github issues、stackoverflow 讨论等）、还做了一些基本的压测，最后的结论是，它的性能可以满足要求，在稳定性方面基本合格，考虑到只是用它做无状态服务，且单台服务器上都会跑多个实例（当时使用 supervisord 管理），简单的崩溃不会对系统有明显影响，再加上当时确实也有些公司将它作为主力服务，所以最终选择了它。 后来加入滴滴后，我在技术选型方面综合了以前所有的经验，有做得好的，也有犯错的时候。 2015 年滴滴有一个很大的内部代码重构项目，涉及到服务端和客户端大量代码。客户端的技术选型做的相对较好，针对当时代码库多业务耦合严重，大家开发时候模块间冲突频繁的问题，评估并引入了 cocoapods 和 maven/gradle 作为 iOS 和 Android 的项目拆分工具，并且通过代码重构，将客户端项目分成几个独立的仓库，可以让业务独立开发的同时，也能通过构建脚本轻松的整合成一个完成的 app。 服务端的选型则比较错误，当时考虑到滴滴的业务模式非常类似于 erlang 的 actor 模型，一个叫车流程会涉及到非常多可复用的 actor，如果我们直接实现一个分布式的 actor 模型和数据流管理机制，那么很多问题就迎刃而解了。可是当时并不存在一套这样的机制，我们自己在实现的时候采用 Go + kafka 分别实现 actor 和数据流存储，过程中遇到了 kafka 消息丢失不好定位、actor 模型过于抽象不容易在整个团队贯彻执行等问题，最终放弃了整个方案。 技术选型方法论技术选型关键需要思考三个角度：技术、业务和人。 角度之一：技术 技术选型首先考虑的当然是技术本身，这里提到的技术包括语言、框架、工具、设计模式、开发模式等。 在选择技术时有两个大原则。第一，要取其长避其短；第二，要关注技术的发展前景。 每种技术都是有它特定的适用场景的，“没有银弹”。开发者经常犯的错误就是盲目追新，当一个新语言、框架、工具出现后，特别是开发者自己学会了这种新技术后，就会有种“拿着锤子找钉子”的感觉，将新技术滥用于各种项目。 比如最近几年 Go 在国内很火，我自己也非常使用它开发项目，但绝对不应该将它用于所有项目。Go 的优点是上手快、运行时性能高、方便的使用多核运算能力等，经常被提起的特性是超轻线程 goroutine、内置的内存队列 chan、极快的编译速度，非常适合于编写各种无状态应用服务，无需使用任何的第三方框架都能轻松写出一个高性能的 http 服务。 但它的缺点也非常明显，最痛的一点是 gc。Go 在设计之初就号称要实现一个世界上最优秀的 gc，可惜直到今天也还差的较远，最近一年才实现了 jvm 几年前就做到的并发 gc，并且没有很好的方法解决内存碎片和对象过多带来的性能问题。这些缺陷使得 Go 不太适合做有状态服务，特别不适合做内存管理相关的服务，在这些场景里面还是 C/C++ 更加可靠。 技术的发展前景也是一个重要考虑因素。有些技术设计的很好，比如我个人挺喜欢一个叫做 Io 的语言，但我不会把它用于真实项目，因为这个语言缺乏社区和长期支持，就算设计理念写的再好，里面也必然有各种 bug 和不足，如果没人能够解决就会带来严重的问题。技术的“前景”可以从几个维度来判断，有没有长期规划、有没有持续投入的人或者社区、问题解决的速度如何、业界使用案例及口碑、源码质量。 选择一个技术最低限的标准是，技术的生命周期必须显著长于项目的生命周期。想象一下，如果项目还没做完这个技术就不被维护了，那将是怎样一种窘境。拿去年很火的 Vue.js 来说，尤大在规划、投入和解决问题速度方面都没有问题，这是这个技术能火起来的基本保障，再加上设计优雅、源码确实写的不错，它的成功并不偶然。可以预见，随着尤大全职开发这个框架并且社区贡献者越来越多，Vue.js 能持续几年应该问题不大。 滴滴的 web app，比如微信钱包里面的滴滴入口，就在去年年底全面改用 Vue.js 重构了一版，我们就是看中了 Vue.js 在移动应用开发中的优势再加上对它的前景有信心。在重构前，我们为了确认 Vue.js 真的能承担如此大任，公共前端团队在 2016 年花了半年的时间整体梳理和评估了 Vue.js 1.0 和 2.0 的全部源码，为此还出了一本书，在公司大规模使用前也在滴滴小巴业务和行程分享功能里做了试点，效果非常不错，最终才真正下定决心广泛推广。 技术的发展前景是动态变化的，当一个技术走向了末路，我们也应该勇敢的扬弃。拿 jQuery 为例，最开始它是前端开发的必需品，当时很多前端同学离开了 $ 函数就不会写代码了，它在简化 DOM 操作、抹平浏览器间差异做出了极其重要的贡献。但是随着浏览器越来越标准和趋同，jQuery 的亮点已经不再吸引人，它的插件开发模式逐步被模块化开发给取代，再加上各种历史包袱，它所适用的项目也会变得越来越少，新项目在选型的时候就不推荐优先考虑 jQuery 了。 对于一家大型公司来说，其核心业务的技术选型更需谨慎，看前景时甚至需要考虑技术的独立性。依然把 Go 当做一个例子，当前核心 Go Authors 基本都受雇于 Google，也没有一个独立运作的基金会来负责语言的长期维护，更没有一个公开透明的决策机制来决定语言的未来，假如 Google 出于某种原因停止投入或者改变语言的发展方向，那么这对一家大型公司来说可能会是毁灭性打击。立志于成为一家千亿美元规模的公司，或者是 Google 的潜在竞争对手，在选择使用 Go 时就应该更加谨慎，不要盲从。 角度之二：业务 技术选型必须贴着业务来选择，不同业务阶段会有不同的选型方式。 处于初创期的业务，选型的关键词是“灵活”。只要一个技术够用且开发效率足够高，那么就可以选择它。初创的业务往往带有风险性和不确定性，朝令夕改、反复试错是常态，技术必须适应业务的节奏，然后才是其他方面。MongoDB 是一个很好的例子，相比 MySQL，它的数据结构灵活多变，相比一般的 KV 存储，它又具有类似 SQL 的复杂查询能力，再加上它内置的傻瓜式高可用和水平扩展机制，让它能够很好的适应初创业务对效率的追求。 等业务进入稳定期，选型的关键词是“可靠”。技术始终是业务的基石，当业务稳定了技术不稳，那就会成为业务的一块短板，就必须要修正。当年 Twitter 放弃 RoR 选择 Java 系框架，这就是个很好的例子。RoR 以快速开发著称，但同时 ruby 的性能非常有限，Twitter 工程团队针对 ruby 虚拟机做了非常多性能优化可是依然不能达到预期，再加上当时的 Twitter 为了提升前端体验，全面使用模块化和异步化的方法加载页面，服务端已经基本不怎么负责渲染页面，而专注于提供各种 RESTful API，RoR 的优势也不太明显了。 当业务步入维护期，选型的关键词是“妥协”。代码永远有变乱的趋势，一般经过一两年就有必要对代码来一次大一点的重构。在这种时候，必须得正视各种遗留代码的迁移成本，如果改变技术选型会带来遗留代码重写，这背后带来的代价业务无法承受，那么我们就不得不考虑在现有技术选型之上做一些小修小补或者螺旋式上升的重构。 正因为技术选型和业务相关，我们能够观察到一些很明显的现象：新技术往往被早期创业团队或大公司的新兴业务使用；中大型公司的核心业务则更倾向于用一些稳定了几年的技术；一个公司如果长期使用一种技术，就会倾向于一直使用下去，甚至连版本都不更新的使用下去。这现象背后都是有道理的。 角度之三：人 技术选型过程中最终影响决策的还是人本身，这里要强调一下，我说的“人”是指的个人，而不是团队。 技术选型的决策流程一定得专制。决策者可以在调研的时候体恤民情，并把团队现状当做一个因素考虑进来，但绝对不能采用类似“少数服从多数”、“按着大家习惯来”的方式选型。专制可以使技术选型更加的客观，考虑的更加全面，并且使得权责统一。 并不是每个人都懂得怎么为项目负责，一个基层的开发人员思考的更多的可能是技术是否有挑战、能否做出彩、甚至未来好不好找工作，这些主观因素可能会给选型带来灾难性的后果。专制也使得“螺旋式上升”成为可能，很多时候我们没法一蹴而就的使用某种技术，这时候需要有一个领路人，带着大家坚定的朝一条曲折的路线前进才能获得成功。 技术选型也非常依赖于人的能力。选型是一件很难被标准化的过程，选型的决策质量跟人的眼界、经验、业务敏感度、逻辑性等息息相关。就我自己来说，我在面临一个选型问题时首先考虑的是去学习，看看公司内外类似的问题如何解决的，避免自己闭门造车，然后思考所有的可能性，列举最核心需要考虑的因素，心里列一个方案优劣对比，最后将这些逻辑整理清楚，落地成一个决策。 滴滴在决策客户端动态化方向时就是以这样的方式来进行的，我们将业界所有可能的方案都拿出来，理解他们的优缺点，然后在某次会议上几个核心同学在白板上列了一张表格，以考虑的因素为行，可能的方案为列，分别评估各个方案在每种因素里的优劣势，最终确定了一个结论。我们选择的路是偏向于客户端开发的动态化方案，在保留所有代码和工具链的前提下做到对开发者透明的动态化，这样能让整体迁移和维护代价变得最小，当然，这条路开发难度也相当大，幸好我们当时也找到了最合适的人，我们依然可以在能接受的时间里实现整个方案。 培养技术选型的能力 可以看到，要想做好技术选型还是挺难的，要想做好得有足够的知识积累和实际踩坑的经历才行。如果一个不太懂得如何选型的新人想学着做好这件事，那可以先从小项目开始做尝试，慢慢积累经验。技术选型对人来说最重要的还是“逻辑性”，每一个决策背后都藏着许多假设和事实，我们通过不断挑战这些背后的东西来逐步成长。 比如在需要使用缓存来加快数据访问速度的场景中，我们可能会很自然的选择 redis 作为缓存服务。这看似“直觉”的决策，背后也是由一系列假设和事实组成。可以问自己一连串问题，看看在具体的场景下这个决策是不是真的正确，例如，缓存服务有没有 redis 之外的选项、是否可以在内存里直接缓存、redis 是否稳定、redis 性能是否满足需求、数据库访问速度瓶颈究竟在哪等等问题，很可能最终结果还是“ 使用 redis 做缓存”这个直观方案，但正因为有分析的过程，让我们在下一次做决策可以更迅速、更自信。 如何保持敏感性和广度 技术选型是个很需要经验的活，得有大量的信息积累和输入，再根据具体现实情况输出一个结果。我们在选型的时候最忌讳的是临时抱佛脚、用网上收集一些碎片知识来决策，这是非常危险的，我们得确保自己所有思考都是基于以前的事实，还要弄清楚这些事实背后的假设，这都需要让知识内化形成经验。 我一直在想，“经验”的本质是什么，有什么方法能够确定自己的经验增长了，而不是不断在重复一些很熟悉的东西。我现在的结论是，经验等于“知识索引”的完备程度。 我们一生中会积累很多的知识，如果把我们的大脑比作数据库的话，那我们一定有一部分脑存储贡献给了内容的索引，它能帮助我们将关联知识更快的取出来，并且辅助决策。经验增长等同于我们知识索引的增长，意味着我们能轻易的调动更多的关联知识来做更全面的决策。 要想建立好这个知识索引，我们得保持技术敏感性和广度，也就是要做到持续的信息输入、内化，并发现信息之间的关联性，建立索引，记下来。说起来容易，做起来还是挺有难度的。 首先难在信息输入量大，忘记了怎么办。我们的大脑不是磁盘，不常用的知识就会忘记，忘记了就跟没看过是一回事。我的经验是一定要对知识进行压缩，记住的是最关键的细节，并且反复的去回味这个细节。 比如我学习各种语言的时候就会非常留意一些最有特色的语法特性和应用场景，像 C++，我一直记得很早以前看过的细节，像编译器默认会生成哪些类方法，默认析构、拷贝构造、operator = 等，默认生成的类方法有哪些场景需要显示禁用，什么时候要在构造函数用 explicit 等，我看这些细节已经超过十五年的时间了，依然记忆尤新。 看起来好像有点难度，实际上不难，大家想想自己学过的英文单词，再怎么样最常见的几百个英文单词还是能清楚的记得含义的，而技术的知识点其实压缩之后会远小于英文单词的个数，记忆负担不会有想象中那么大。 然后难在信息更新速度太快，跟不上技术发展怎么办。我学习了非常多技术之后就会发现这确实是个难解的问题，像前端开发，每年都会有新的框架和开发方式出现，ES7 的语法如果不去提前了解，过两年可能连 Javascript 语法都看不懂了。 我在这个问题上也是有些焦虑的，不过多少还是有应对的方式，就是坚持碎片化学习，增量更新过时的内容，只要形成习惯也还是能够慢慢的找到自己的节奏。如果有些技术实在细节太多，比如 Node.js 这种，我以前曾经通读过源码，仔细研究过内部设计，但随着它不断发展现在我也不太敢说对它内部有多熟悉，那我会考虑大胆的放弃追新，等着我可能需要用它的时候再统一更新到最新的知识。 最后难在信息究竟如何存入知识索引，知识太零散形成不了体系，建不了索引怎么办。最入门的做法是看书，看别人是怎么将知识变成一个个章节的信息。要想掌握建立索引背后的方法论，我的经验是先从两个相近的技术开始，找到建索引的感觉，然后再铺开去学习更多知识。有这样困惑的开发者往往在学习方面有些贪心，觉得自己记性好可以囫囵吞枣式的将知识强行内化，这样做短期可以，长期还是会遗忘，也形成不了经验。 其实技术知识之间非常像，有很多共性的点可以挖掘。比如客户端和前端开发，各个框架在 View 生命周期管理、消息派发机制等方面非常像，后端开发则更加的套路化，无论用那种语言，最基本的分布式服务原理、缓存、队列、数据库等基础组件原理，都万变不离其宗。 如果我们更宏观的看每个领域，甚至于都能发现领域之间的知识体系划分也很类似。作为表现层的前端和客户端，知识体系都可以分为语言、API、工程化、框架和设计模式。比如前端的语言包括 HTML、CSS、Javascript 和一些稍小众的 TypeScript、CoffeeScript 等，API 就是各种标准、接口的使用、能够实现的效果、平台限制等，工程化就是各种打包工具、代码转化工具、辅助开发工具等，框架就是像 Vue、React 等，设计模式就是像 PWA、redux 等。 相应的，刚刚说的这些知识都能找到在 iOS 或 Android 里几乎对应的知识，无非换了一些细节，这里我就不继续展开了。服务端也是这样，知识体系最顶层的部分也很少，具体到细节，只是要了解每一个实现背后的优劣。 总结一下，技术选型依赖于经验，经验又来源于知识索引的建设，这依赖于平时的总结和不断的新知识输入，技术是一辈子的事，必须得投入大量时间维持状态。学无止尽，大家一起共勉。]]></content>
      <categories>
        <category>好文</category>
      </categories>
      <tags>
        <tag>技术选型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[许式伟、张宴——系统架构运维思路对话]]></title>
    <url>%2F2018%2F07%2F10%2Fjava%2Fjava_4%2F</url>
    <content type="text"><![CDATA[许式伟：作为系统架构师，您一般会从哪些方面来保证网站的高可用性（降低故障时间）？张宴：很多因素都会导致网站发生故障，从而影响网站的高可用性，比如服务器硬件故障、软件系统故障、IDC机房故障、程序上线前测试未发现的Bug、遭受分布式攻击、突发访问人数剧增等。 一套良好的网站系统架构，应该尽可能地避免只有一台服务器、一个数据库、一套软件节点等单点故障的存在。单点故障一旦发生，将直接导致网站服务不可用，恢复正常服务所需的时间也比较长，甚至还可能无法恢复。负载均衡集群、双节点热备、分布式处理等都可以用来解决单点故障，比如提供相同业务的Web服务器、MySQL数据库从库，都可以构建负载均衡集群。一旦集群中的一台服务器、一个服务出现故障，自动实时摘除，对用户来说是不可感知的，不会影响到整个网站的访问，可以为运维工程师留下足够的时间去排查和解决故障。 对于重要的MySQL数据库主库，我们习惯于从硬件层和软件层来实现热备，避免单点。越是复杂的设备，发生故障的概率越大。在磁盘没有损坏的情况下，应用程序导致服务器宕机的概率，远高于简单的磁盘阵列宕机的概率。所以，从硬件层解决的话，可以在两台服务器上安装相同的数据库版本、进行相同的配置，用SAS或SCSI线连接一台磁盘阵列，将数据库数据文件存放到盘阵上。正常情况下用服务器A挂载盘阵分区，启动MySQL，绑定虚拟IP；如果服务器A宕机，则用服务器B挂载盘阵分区，启动MySQL，接管虚拟IP。从软件层解决的话，则可以借助DRBD等软件做镜像。（主从同步，负载均衡、高可用、缓存） IDC机房发生故障的概率较小，但如果发生的话，影响面也是最大的。如果所有服务器都托管在一个IDC机房，一旦该机房遭遇长时间流量攻击、断电、断网、地方政策性封网等，通常只能联系IDC去处理，除此之外束手无策，解决时间也比较长。如果成本允许，将网站服务器分布在两个以上的IDC机房，当某个IDC发生故障时，可以临时切换DNS域名解析来优先恢复服务。 虽然程序代码上线前，经过了测试人员的严格测试，但测试环境和生产环境毕竟有差异，所以一些会急剧影响性能、正常服务的Bug往往在程序上线之后，才会被发现，这就要求我们在发现Bug后，能够迅速回滚到上一正常版本。我们在SVN的基础上，开发了Web代码发布系统，会将每个发布版本之间的文件变更记录下来，一键实现程序代码在多台Web服务器上的发布和回滚。 遭遇DDOS分布式拒绝服务攻击，使用防火墙来对付半连接、假IP，还算比较容易。而那种专挑复杂动态应用程序URL进行的分布式CC攻击，来源为真实IP、真实HTTP请求，具有模拟正规浏览器User-Agent、单个IP的每秒请求数不高、有成千上万个攻击源等特征，很难与正常访问区分开，比较难对付。但是，正常通过浏览器访问一个URL，会加载该URL中引入的JavaScript脚本、CSS样式、图片等文件。遇到CC攻击，需要及时分析日志，找出访问量异常上涨的URL，然后用事先写好的shell脚本找出哪些IP的请求只访问了该URL，而不加载该URL引入的文件，对这些IP进行自动封锁。 系统架构设计时，需要事先考虑到高于目前访问量多少倍的突发访问。对于网游站点来说，访问量受广告集中时间段投放、线上活动的影响较大，带宽峰值时间不固定，对于静态内容，可以使用商业CDN，按实际使用量计费。对于动态内容，如果遇到突发访问人数剧增，超过现有服务器处理能力，最简单的临时处理办法就是增加服务器。上架新服务器需要时间，但是，同一个IDC机房内，可以借助其他业务的服务器，在不同端口开启一组新进程，加入到原有负载均衡池中。另外，可以临时关闭一些Web中的次要功能，来减少服务器消耗。 许式伟：您在任务切分上，有什么经验分享？您通过哪些手段保证任务的独立性？张宴：相信很多人都遇到过这种情况：在一个老项目上修改、增加一些新功能所花费的时间，不比重新来做一个包含所有功能的新项目时间用得少。一个需要长期维护的项目，不可避免地会面临老员工的离职、新员工的接手，很多时候，项目代码的可维护性将决定一个项目的生存周期。让一个新员工在规定开发时间的压力下，去面对一个文档不够详细、陌生的、功能复杂的庞大项目，短时间弄明白所有功能逻辑不是一件容易的事。所以，任务需要切分，将一个大的任务切分成一个个小模块之后，各模块之间可以做到代码独立，互不影响，可维护性也大大增强。 关于任务切分，我以本人今年负责的两个重要项目架构设计为例来介绍一下。在第一个项目：金山游戏官网的《用户行为分析系统》中，由于数据挖掘计算需要消耗较高的内存、CPU资源，一台服务器的处理能力不够，而商业的分布式数据仓库价格又太贵，所以，只有从程序应用中下手，进行任务切分。我们先按需要挖掘的数据指标，将整个数据挖掘任务切分成多个数据挖掘插件，每个插件可以在不同的服务器上运行，多个插件可以同时在多台服务器上。多个数据挖掘插件之间，如果用到相同的某项数据，那么，就将该项数据以冗余方式，复制几份提供给需要的插件，从而实现插件之间无交互、无关联，保证了超大数据量下插件的运算速度。 在第二个项目：金山游戏新版运营管理系统中，则将整个任务切分成了PHP Web管理界面、PHP Web API功能接口、C/C++中间件引擎三部分。这是一种分层结构切分，最上层的“PHP Web管理界面”调用“PHP Web API功能接口”，“PHP Web API功能接口”调用运行在游戏服务器端的“C/C++中间件引擎”，“C/C++中间件引擎”与“游戏服务器端进程”通过TCP、UDP二进制协议、信号、命令行等多种方式通信。四者之间相对独立，代码无关联，通过一层层API接口实现交互。“PHP Web管理界面”负责通用界面实现。“PHP Web API功能接口”内部，又按接入的游戏模块、子功能模块进行了更细的切分，各功能模块之间通过内部API交互。“C/C++中间件引擎”大而全，不处理具体指令，但兼容TCP、UDP、HTTP、HTTPS/SSL、信号、命令行等大多数通信方式，负责和各种类型的游戏服务端交互。这是一套完全由API接口驱动的系统架构，一款新游戏接入运营管理系统时，只需在“PHP Web API功能接口”中增加一个模块；一个游戏新管理功能的增加，只需要在“PHP Web API功能接口”中增加一个子模块。通过任务切分，将复杂功能简单化，也将原来接入一款新游戏所需要的几个月时间，缩短为1~2周。 许式伟：您通过哪些手段，来保障产品的质量？您倾向于多久更新一次您的网站？张宴：Web产品质量主要体现在架构、功能、性能、安全、代码唯一性、兼容性等方面。 架构方面，我会先设计一套架构方案，然后让和项目相关的人员、专家组成员参与进来，一起探讨和论证架构的利弊，提出改进意见，保证架构的可行性。所有重要项目的技术方案需要经过专家组的评估。 功能、性能方面，则会由专门的测试人员进行功能测试、压力测试、安全扫描，测试环境分为线下测试环境、线上准测试环境。 在代码唯一性方面，我们开发了一个Web配置信息管理平台及相关PHP扩展，提供给系统工程师，用于配置信息的统一管理。在新项目中，PHP程序配置文件中将不再出现MySQL、Memcached等各类IP和端口信息，统一用Web配置信息管理平台给出的变量代替。从“开发环境→线下测试环境→线上测试环境→线上正式环境”，连接的数据库各不相同，导致PHP开发工程师经常搞混淆或忘了修改，通过Web配置信息管理平台，使得PHP代码中的配置文件，在四个环境中无须作任何修改，保证了代码的一致性，降低了出错率，从而确保了产品质量。 在兼容性方面，我们从操作系统到PHP、MySQL版本，都保持开发环境、测试环境、线上环境的统一，所有的Web服务运行在CentOS Linux系统上。由于大多数PHP程序员习惯于在Windows上编写代码，而我们的程序中调用的一些接口、PHP扩展，只能在Linux下运行。为此，我们开发了一个小工具，可以将多名程序员在各自本机Windows上搭建的nginx虚拟主机、编写的程序文件，映射到一台Linux服务器，用Linux上的php-cgi执行Windows上的PHP代码。这样，PHP程序员修改完本机代码，保存一下，即可调试，多人之间互不影响。自己调试通过后，可以在Windows直接点击鼠标右键，将修改的代码提交到SVN版本库。 Web 2.0时代，讲究网站更新的实时性，动态网站不用说，静态网站的内容发布也要保证实时。我们开发了一款名为Sersync的开源软件（http://code.google.com/p/sersync/），使用Linux 2.6内核的inotify监控Linux文件系统事件，被监听目录下如果有文件发生修改，Sersync将通过内核自动捕获到事件，并将该文件利用rsync同步到CDN源站服务器。Sersync仅仅同步发生增、删、改事件的单个文件或目录，不像rsync镜像同步那样需要比对双方服务器整个目录下数千万的文件，并且支持多线程同步，因此效率非常高。金山游戏官网的CMS内容发布系统，无论网站编辑通过Web还是FTP上传图片、视频、附件，还是系统工程师直接去CMS发布服务器上增加、修改、删除文件，干完这些事情后不用做任何处理，Sersync 会自动将发生增、删、改事件的文件同步到CDN源站服务器，并可以在文件同步完成后，自动调用CDN缓存刷新接口，主动刷新发生修改、删除的文件的访问URL。 许式伟：您在面试时，通常关注应聘者的哪些方面？哪些问题经常会问呢？张宴：第一，需要具备岗位要求的基础技能知识，这方面我不再详述。 第二，注重项目经验与积累，不看重学历与工作年限。做一个项目，犹如打一场战役，身经百战，积累下来的成功经验可以让工作更得心应手，失败经验可以避免走很多弯路。 第三，能够在1~2个以上技术领域精通。所谓术业有专攻，能够在某几项技术领域做到精通的人，相信对于新的技术领域或者从未有过相关经验的新项目，也能够轻松胜任，做到尽善尽美。 第四，关注应聘者的知识广度。如今的项目，已经告别个人英雄时代，讲究团队的协作。知识面越广，尽管在非专攻领域的深度可能不够，但是，知己知彼，可以站在一个更高的角度上看问题，这对于团队协作开发、项目融合的益处是显而易见的。 第五，具备良好的领悟能力、思考能力、设计能力、创新能力。基础技能知识不够可以学习，经验不足可以积累，技术不精通可以钻研，知识面不广可以开拓，但要培养这四项能力，是一件非常困难的事。要打造一支优秀的团队，这四项能力不可缺少，它们的重要度甚至超过以上的四方面要求。 我不会经常去问固定的问题，但所问的问题，几乎都跟以上的这些方面相关。 许式伟：您曾尝试开放自己的程序代码吗？您对中国国内开源社区的现状有何看法？张宴：是否开源自己的程序代码，跟所在公司或部门的性质有着密切的关系。如果是在研发驱动型企业或部门，程序代码是公司生存的命脉，需要与竞争对手拼技术和保持技术领先的优势，因此，很难支持开源事业。反之，如果是在运营驱动型企业或部门，技术是用来提高运营质量、运营水平的工具之一。将纯粹的技术代码或产品，从公司的业务产品中提取出来，进行开源，可以按照开源产品的要求，提高公司内部技术产品的规范化、标准化，还可以引用更广大用户的使用、反馈和意见，解决未发现的潜在Bug，改进代码质量，提升技术水平。对于提高运营质量、运营水平来说，益处多多。我也尝试开源自己的一些代码，例如简单消息队列服务HTTPSQS（http://code.google.com/p/httpsqs/）、MySQL HTTP/REST客户端MySQL-UDF-HTTP（http://code.google.com/p/mysql-udf-http/），同时，也鼓励团队成员尝试开源，例如刚才提到的自动同步软件Sersync。 国内的开源社区在不断壮大，很多知名互联网公司都开源了自己的一些产品，但大多数还只停留在开源产品的使用、技术交流、汉化层面，真正参与到开源产品编码中的人还是较少，很多开源产品最终还是由原作者或原公司团队维护。国内开源社区的道路仍然漫长。]]></content>
      <categories>
        <category>转载</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件设计原则]]></title>
    <url>%2F2018%2F07%2F06%2Fjava%2Fjava_3%2F</url>
    <content type="text"><![CDATA[一些软件设计的原则软件设计的原则不单单只是软件开发，可能推广到其他生产活动中。甚至我们生活中遇到问题的思考。 Don’t Repeat Yourself(DRY)DRY是最简单法则。它关注的是我们在两个地方发现一些相似代码后。我们需要把他们共性抽离出来，形成一个唯一的方法。并改变现有地方的代码，以适合的参数调用新的方法。 Keep It Simple,StupidKISS原则在设计上是备受推崇的。在家装，界面，操作设计上。它的哲学是：把一个简单的事情搞复杂是一件简单的事情，但是把一个复杂的事情变简单，是件复杂的事情。 面向接口变成，非面向实现编程注重接口而不是实现，依赖接口而不是实现。这是由于接口的抽象是稳定的，实现则是多样化的。稳定的事物在操作起来更有安全感。 你可能不真正需要它原则只考虑设计必须的功能，避免过度设计。实现目前需要的功能，在以后考虑需要更多功能时候，再进行添加。 如无必要，无增加复杂性。软件开发是一场沟通博弈。 迪米特法则（Law of Demeter)迪米特法则又称之为 &quot;最少知识原则&quot; 它来源于1987年荷兰大学的一个Demeter项目。又被称作&quot;不要和陌生人说话&quot; 如果你想让你的狗跑的话 ，你会对狗狗说还是要对四条腿说？ 如果你去买东西，你是把钱缴费电源，还是把钱包交给店员让他自己拿？ 简言之，在对象调用对象的时候只出现一个&quot;.&quot; dog.run() 而非 dog.getFouLeg().move() 面向对象的S O L I D法则一般来说这是面向对象的五大设计原则。但是，我们可以把这些原则用于所有的软件开发。 Simple Responsiblility Principle(SRP) - 职责单一原则其核心思想是：一个类，只做一件事。并把事做好。它只有一个引起它变化的原因。它可以看做是低耦合高内聚的在面向对象上的引申，将职责定义为引发 变化的原因，提高内聚性来减少引起变化的外因。职责过多，引起变化的原因就变多。一般情况下设计成引起变化的因素只有一类就好。职责与职责之间不 产生依赖。从而降低了耦合度。 正向例子：Unix/Linux 反向例子：Windows Open/Closed Principle（OCP)-开闭原则核心思想是：模块是可以扩展的，不可修改的。也就是说，对扩展是开放的，而对修改是封闭的。 对扩展开放：意味着有新的需求或者变化时，可以对现有代码进行扩展。以适应新的业务需求。 对修改封闭：意味着一旦设计完成，就可以独立完成其工作。而不要对类进行任何修改。 Likov substitution principle(LSP) - 里氏代换原则子类必须能够被替换成他们的基类。 既：子类在任何地方时候都可以被他们的基类替换，代码还能正常工作。不应该在代码里进行if/else对子类的类型进行判断的条件。 LSP是开闭原则的一个重要保证。它也是我们进行类设计的重要思考条件。就像&quot;蜗牛不是牛&quot;，&quot;鲸鱼是鱼&quot;其判断条件方式就是里氏族代换原则来的。 Interface Segregation Principle(ISP) - 接口隔离原则接口隔离是把功能实现在接口中，而不是类中，使用多个专门的接口比使用单一的总接口要好。 例子：电脑有很多使用方式。比如：看电影，聊天，看电影，上网，变成等等。如果把这些都申明在电脑的抽象类里。那么我们的上网本，PC机，服务器 这些都要实现所有的这些接口。就太复杂了。所以，我们把这些功能都隔离开，比如：看电影接口，聊天接口，上网接口。这样不同功能的电脑就可以有 选择地进行继承实现这些接口。 这个原则让我们可以使用&quot;搭积木&quot;的方式进行软件开发。 Java中的Event listener 和Adapter就是用这种原则实现的。 Dependency Inversion Priciple(DIP) - 依赖倒置原则高层不应该依赖低层的实现。而是依赖于高层抽象。 墙面的开关不应该依赖于点灯的开关实现，而是依赖于一个抽象开关标准接口。当我们扩展程序时候，我们的开关同样可以控制其他不同的等，甚至不同的 电器。也就是说点灯和其他电器集成并实现我们的标准开关接口，我们的开关产商可以不需要关于要控制什么样的设备，只需要关心哪个标准开关就行。这 就是依赖倒置原则。 Common Closure Principle(CCP) - 共同封闭原则一个包中所有的类应该对同一种类型的变化关闭。一个变化影响一个包。便影响了包中的所有类。一个简单的说法是:一起修改的类，应该组合在一起（同个包里） 如果有需要改代码，我们希望所有的修改发生在意个包里，而不是分布在很多包里CCP实际上是对包的只能的相似进行聚合。对包的分配有指导作用。]]></content>
      <categories>
        <category>java</category>
        <category>设计</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[solr tlog详解]]></title>
    <url>%2F2018%2F07%2F02%2Fsearch%2Fsolr_4%2F</url>
    <content type="text"></content>
      <categories>
        <category>搜索</category>
      </categories>
      <tags>
        <tag>solr</tag>
        <tag>tlog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux手动修改/etc/shadow和/etc/passwd中的用户密码]]></title>
    <url>%2F2018%2F07%2F02%2Flinux%2Flinux_4%2F</url>
    <content type="text"><![CDATA[前言最近在玩GameShell这小玩意儿，发现没有root权限。于是想办法获取到。发现官方有提供img镜像下载。 img操作1：查看img信息:123456789101112[ 17:15:11-root@hadoop214:img ]#fdisk -lu clockworkos_v0.1.imgDisk clockworkos_v0.1.img: 7948 MB, 7948206080 bytes, 15523840 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x9d1726e4 Device Boot Start End Blocks Id Systemclockworkos_v0.1.img1 8192 93814 42811+ c W95 FAT32 (LBA)clockworkos_v0.1.img2 94208 15523839 7714816 83 Linux 可以看到linxu文件从 94208 开始 扇区大小512k所以94208*512=482344962：挂载img1mount -o loop,offset=48234496 clockworkos_v0.1.img /home/gameshell/img/clockpi 密码修改1.手动修改/etc/shadow中的用户密码/etc/shadow文件说明： 第一字段：用户名（也被称为登录名），在/etc/shadow中，用户名和/etc/passwd 是相同的，这样就把passwd 和shadow中用的用户记录联系在一起；这个字段是非空的； 第二字段：密码（已被加密），这个字段是非空的； 第三字段：上次修改口令的时间；这个时间是从1970年01月01日算起到最近一次修改口令的时间间隔（天数），您可以通过passwd 来修改用户的密码，然后查看/etc/shadow中此字段的变化； 第四字段：两次修改口令间隔最少的天数；如果这个字段的值为空，帐号永久可用； 第五字段：两次修改口令间隔最多的天数；如果这个字段的值为空，帐号永久可用； 第六字段：提前多少天警告用户口令将过期；如果这个字段的值为空，帐号永久可用； 第七字段：在口令过期之后多少天禁用此用户；如果这个字段的值为空，帐号永久可用； 第八字段：用户过期日期；此字段指定了用户作废的天数（从1970年的1月1日开始的天数），如果这个字段的值为空，帐号永久可用； 第九字段：保留字段，目前为空，以备将来发展之用； /etc/shadow中格式如下 #testaccount:$1$acQMceF9$1SaCpG2qiKKA3eGolU4Fp0:13402:0:99999:7:::彩色段为加密后的密码，$1$表示采用的是md5加密，绿色段是简单的字符串，蓝色段为加密后的密码 只要删除 $1$acQMceF9$1SaCpG2qiKKA3eGolU4Fp0 它后，就删除了密码 2.linux忘记登陆密码修改/etc/passwd也可以 很简单的一个技巧，给大家介绍一下在这个界面 按任意键按 e键(编辑命令之前启动)选择第二项 在按e键(修改选定的命令在启动)输入single (注意空格)进入单用户模式选择b 启动输入 vi /etc/passwdroot:x:0:0:root:/root:/bin/bash光标移至x下面按delete 键 删除它输入：x！输入reboot重启重启后你会发现 没让你输密码，破译成功 原理解释：在 /etc/passwd 的文件里 保存着用户的信息文件 root:x:0:0:Administrator:/root:/bin/bash 在这一句中 root就是用户名， x是密码标志，只是说明密码的存放位置，具体呢是放在/etc/passwd的 至于密码别想了 全 是密文保存，看不懂的 0 用户id号 0 组id号 administrator估计是我在装系统的时候，原来的名字没改（虚拟机默认用户名），是用户说 明的意思， root 用户的家目录 /bin/bash 记录着用户登陆后所拥有的权限，即所拥有的shell 那么我们把密码标示删掉之后，自然就不会有问你密码的对话框了 当然 GRUB这个引导装载程序是可以设密码的 不过 设密码 我们可以光启 ，用安装光盘进入安全模式，在把密码清除 光启 是可以设BIOS密码的， BIOS 密码是可以拆机箱 扣电池的 那这么说来 传说中的linux岂不是很不安全，通常所说的安全是基于网络的 ，意思是连接互联网后，对方通过网络途径入侵你的linux计算机是很困难的，这种破译的方法只是以防万一，在万一你忘记密码的时候使用的，至于物理安全，那就看你怎么保护了. 本文转载于：http://blog.chinaunix.net/uid-15797451-id-3041560.html]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[solr 跨数据中心复制 CDCR升级过程]]></title>
    <url>%2F2018%2F06%2F14%2Fsearch%2Fsolr_3%2F</url>
    <content type="text"><![CDATA[前言 公司使用solr作为底层搜索引擎已经运行好多年了。从solr的 4.*版本到现在的 6.4.1经历了若干个大版本的修改和升级。稳定性一直在提高。 SOLR CDCR简介跨数据中心复制。是solr从6.0开始的新功能。其目标是实现两个数据集群间的备份。通过合理的二次开发，可以实现异地容灾的功能。 原有架构升级后架构升级过程注意事项总结]]></content>
      <categories>
        <category>搜索</category>
      </categories>
      <tags>
        <tag>solr</tag>
        <tag>cdcr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[秒杀系统架构优化思路]]></title>
    <url>%2F2018%2F05%2F17%2Fhttp%2Fhttp_2%2F</url>
    <content type="text"><![CDATA[本文曾在“架构师之路”上发布过，近期支援Qcon-AS大会，在微信群里分享了该话题，故对原文进行重新整理与发布。 一、秒杀业务为什么难做1）im系统，例如qq或者微博，每个人都读自己的数据（好友列表、群列表、个人信息）； 2）微博系统，每个人读你关注的人的数据，一个人读多个人的数据； 3）秒杀系统，库存只有一份，所有人会在集中的时间读和写这些数据，多个人读一个数据。 例如：小米手机每周二的秒杀，可能手机只有1万部，但瞬时进入的流量可能是几百几千万。 又例如：12306抢票，票是有限的，库存一份，瞬时流量非常多，都读相同的库存。读写冲突，锁非常严重，这是秒杀业务难的地方。那我们怎么优化秒杀业务的架构呢？ 二、优化方向优化方向有两个（今天就讲这两个点）： （1）将请求尽量拦截在系统上游（不要让锁冲突落到数据库上去）。传统秒杀系统之所以挂，请求都压倒了后端数据层，数据读写锁冲突严重，并发高响应慢，几乎所有请求都超时，流量虽大，下单成功的有效流量甚小。以12306为例，一趟火车其实只有2000张票，200w个人来买，基本没有人能买成功，请求有效率为0。 （2）充分利用缓存，秒杀买票，这是一个典型的读多些少的应用场景，大部分请求是车次查询，票查询，下单和支付才是写请求。一趟火车其实只有2000张票，200w个人来买，最多2000个人下单成功，其他人都是查询库存，写比例只有0.1%，读比例占99.9%，非常适合使用缓存来优化。好，后续讲讲怎么个“将请求尽量拦截在系统上游”法，以及怎么个“缓存”法，讲讲细节。 三、常见秒杀架构常见的站点架构基本是这样的（绝对不画忽悠类的架构图） （1）浏览器端，最上层，会执行到一些JS代码 （2）站点层，这一层会访问后端数据，拼html页面返回给浏览器 （3）服务层，向上游屏蔽底层数据细节，提供数据访问 （4）数据层，最终的库存是存在这里的，mysql是一个典型（当然还有会缓存） 这个图虽然简单，但能形象的说明大流量高并发的秒杀业务架构，大家要记得这一张图。 后面细细解析各个层级怎么优化。 四、各层次优化细节第一层，客户端怎么优化（浏览器层，APP层）问大家一个问题，大家都玩过微信的摇一摇抢红包对吧，每次摇一摇，就会往后端发送请求么？回顾我们下单抢票的场景，点击了“查询”按钮之后，系统那个卡呀，进度条涨的慢呀，作为用户，我会不自觉的再去点击“查询”，对么？继续点，继续点，点点点。。。有用么？平白无故的增加了系统负载，一个用户点5次，80%的请求是这么多出来的，怎么整？ （a）产品层面，用户点击“查询”或者“购票”后，按钮置灰，禁止用户重复提交请求； （b）JS层面，限制用户在x秒之内只能提交一次请求； APP层面，可以做类似的事情，虽然你疯狂的在摇微信，其实x秒才向后端发起一次请求。这就是所谓的“将请求尽量拦截在系统上游”，越上游越好，浏览器层，APP层就给拦住，这样就能挡住80%+的请求，这种办法只能拦住普通用户（但99%的用户是普通用户）对于群内的高端程序员是拦不住的。firebug一抓包，http长啥样都知道，js是万万拦不住程序员写for循环，调用http接口的，这部分请求怎么处理？ 第二层，站点层面的请求拦截怎么拦截？怎么防止程序员写for循环调用，有去重依据么？ip？cookie-id？…想复杂了，这类业务都需要登录，用uid即可。在站点层面，对uid进行请求计数和去重，甚至不需要统一存储计数，直接站点层内存存储（这样计数会不准，但最简单）。一个uid，5秒只准透过1个请求，这样又能拦住99%的for循环请求。 5s只透过一个请求，其余的请求怎么办？缓存，页面缓存，同一个uid，限制访问频度，做页面缓存，x秒内到达站点层的请求，均返回同一页面。同一个item的查询，例如车次，做页面缓存，x秒内到达站点层的请求，均返回同一页面。如此限流，既能保证用户有良好的用户体验（没有返回404）又能保证系统的健壮性（利用页面缓存，把请求拦截在站点层了）。 页面缓存不一定要保证所有站点返回一致的页面，直接放在每个站点的内存也是可以的。优点是简单，坏处是http请求落到不同的站点，返回的车票数据可能不一样，这是站点层的请求拦截与缓存优化。 好，这个方式拦住了写for循环发http请求的程序员，有些高端程序员（黑客）控制了10w个肉鸡，手里有10w个uid，同时发请求（先不考虑实名制的问题，小米抢手机不需要实名制），这下怎么办，站点层按照uid限流拦不住了。 第三层 服务层来拦截（反正就是不要让请求落到数据库上去）服务层怎么拦截？大哥，我是服务层，我清楚的知道小米只有1万部手机，我清楚的知道一列火车只有2000张车票，我透10w个请求去数据库有什么意义呢？没错，请求队列！ 对于写请求，做请求队列，每次只透有限的写请求去数据层（下订单，支付这样的写业务） 1w部手机，只透1w个下单请求去db 3k张火车票，只透3k个下单请求去db 如果均成功再放下一批，如果库存不够则队列里的写请求全部返回“已售完”。 对于读请求，怎么优化？cache抗，不管是memcached还是redis，单机抗个每秒10w应该都是没什么问题的。如此限流，只有非常少的写请求，和非常少的读缓存mis的请求会透到数据层去，又有99.9%的请求被拦住了。 当然，还有业务规则上的一些优化。回想12306所做的，分时分段售票，原来统一10点卖票，现在8点，8点半，9点，…每隔半个小时放出一批：将流量摊匀。 其次，数据粒度的优化：你去购票，对于余票查询这个业务，票剩了58张，还是26张，你真的关注么，其实我们只关心有票和无票？流量大的时候，做一个粗粒度的“有票”“无票”缓存即可。 第三，一些业务逻辑的异步：例如下单业务与 支付业务的分离。这些优化都是结合 业务 来的，我之前分享过一个观点“一切脱离业务的架构设计都是耍流氓”架构的优化也要针对业务。 好了，最后是数据库层 浏览器拦截了80%，站点层拦截了99.9%并做了页面缓存，服务层又做了写请求队列与数据缓存，每次透到数据库层的请求都是可控的。db基本就没什么压力了，闲庭信步，单机也能扛得住，还是那句话，库存是有限的，小米的产能有限，透这么多请求来数据库没有意义。 全部透到数据库，100w个下单，0个成功，请求有效率0%。透3k个到数据，全部成功，请求有效率100%。 五、总结上文应该描述的非常清楚了，没什么总结了，对于秒杀系统，再次重复下我个人经验的两个架构优化思路： （1）尽量将请求拦截在系统上游（越上游越好）； （2）读多写少的常用多使用缓存（缓存抗读压力）； 浏览器和APP：做限速 站点层：按照uid做限速，做页面缓存 服务层：按照业务做写请求队列控制流量，做数据缓存 数据层：闲庭信步 并且：结合业务做优化 六、Q&amp;A问题1、按你的架构，其实压力最大的反而是站点层，假设真实有效的请求数有1000万，不太可能限制请求连接数吧，那么这部分的压力怎么处理？ 答：每秒钟的并发可能没有1kw，假设有1kw，解决方案2个： （1）站点层是可以通过加机器扩容的，最不济1k台机器来呗。 （2）如果机器不够，抛弃请求，抛弃50%（50%直接返回稍后再试），原则是要保护系统，不能让所有用户都失败。 问题2、“控制了10w个肉鸡，手里有10w个uid，同时发请求” 这个问题怎么解决哈？ 答：上面说了，服务层写请求队列控制 问题3：限制访问频次的缓存，是否也可以用于搜索？例如A用户搜索了“手机”，B用户搜索“手机”，优先使用A搜索后生成的缓存页面？ 答：这个是可以的，这个方法也经常用在“动态”运营活动页，例如短时间推送4kw用户app-push运营活动，做页面缓存。 问题4：如果队列处理失败，如何处理？肉鸡把队列被撑爆了怎么办？ 答：处理失败返回下单失败，让用户再试。队列成本很低，爆了很难吧。最坏的情况下，缓存了若干请求之后，后续请求都直接返回“无票”（队列里已经有100w请求了，都等着，再接受请求也没有意义了） 问题5：站点层过滤的话，是把uid请求数单独保存到各个站点的内存中么？如果是这样的话，怎么处理多台服务器集群经过负载均衡器将相同用户的响应分布到不同服务器的情况呢？还是说将站点层的过滤放到负载均衡前？ 答：可以放在内存，这样的话看似一台服务器限制了5s一个请求，全局来说（假设有10台机器），其实是限制了5s 10个请求，解决办法： 1）加大限制（这是建议的方案，最简单） 2）在nginx层做7层均衡，让一个uid的请求尽量落到同一个机器上 问题6：服务层过滤的话，队列是服务层统一的一个队列？还是每个提供服务的服务器各一个队列？如果是统一的一个队列的话，需不需要在各个服务器提交的请求入队列前进行锁控制？ 答：可以不用统一一个队列，这样的话每个服务透过更少量的请求（总票数/服务个数），这样简单。统一一个队列又复杂了。 问题7：秒杀之后的支付完成，以及未支付取消占位，如何对剩余库存做及时的控制更新？ 答：数据库里一个状态，未支付。如果超过时间，例如45分钟，库存会重新会恢复（大家熟知的“回仓”），给我们抢票的启示是，开动秒杀后，45分钟之后再试试看，说不定又有票哟~ 问题8：不同的用户浏览同一个商品 落在不同的缓存实例显示的库存完全不一样 请问老师怎么做缓存数据一致或者是允许脏读？ 答：目前的架构设计，请求落到不同的站点上，数据可能不一致（页面缓存不一样），这个业务场景能接受。但数据库层面真实数据是没问题的。 问题9：就算处于业务把优化考虑“3k张火车票，只透3k个下单请求去db”那这3K个订单就不会发生拥堵了吗？ 答：（1）数据库抗3k个写请求还是ok的；（2）可以数据拆分；（3）如果3k扛不住，服务层可以控制透过去的并发数量，根据压测情况来吧，3k只是举例； 问题10；如果在站点层或者服务层处理后台失败的话，需不需要考虑对这批处理失败的请求做重放？还是就直接丢弃？ 答：别重放了，返回用户查询失败或者下单失败吧，架构设计原则之一是“fail fast”。 问题11.对于大型系统的秒杀，比如12306，同时进行的秒杀活动很多，如何分流？ 答：垂直拆分 问题12、额外又想到一个问题。这套流程做成同步还是异步的？如果是同步的话，应该还存在会有响应反馈慢的情况。但如果是异步的话，如何控制能够将响应结果返回正确的请求方？ 答：用户层面肯定是同步的（用户的http请求是夯住的），服务层面可以同步可以异步。 问题13、秒杀群提问：减库存是在那个阶段减呢？如果是下单锁库存的话，大量恶意用户下单锁库存而不支付如何处理呢？ 答：数据库层面写请求量很低，还好，下单不支付，等时间过完再“回仓”，之前提过了。]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>秒杀，高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站QPS,TPS 预估方法]]></title>
    <url>%2F2018%2F05%2F17%2Fhttp%2Fhttp_tps%2F</url>
    <content type="text"><![CDATA[QPS/TPS是每秒响应的查询数量或处理的事务数量一、TPS：Transactions Per Second（每秒传输的事物处理个数），即服务器每秒处理的事务数。TPS包括一条消息入和一条消息出，加上一次用户数据库访问。（业务TPS = CAPS × 每个呼叫平均TPS） TPS是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。 一般的，评价系统性能均以每秒钟完成的技术交易的数量来衡量。系统整体处理能力取决于处理能力较低模块的TPS值。 二、QPS：每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。 对应fetches/sec，即每秒的响应请求数，也即是较大吞吐能力 ====================================================================================================== QPS = req/sec = 请求数/秒 【QPS计算PV和机器的方式】 QPS统计方式 [一般使用 http_load 进行统计]QPS = 总请求数 / ( 进程总数 * 请求时间 )QPS: 单个进程每秒请求服务器的成功次数 单台服务器每天PV计算公式1：每天总PV = QPS 3600 6公式2：每天总PV = QPS 3600 8 服务器计算服务器数量 = ceil( 每天总PV / 单台服务器每天总PV ) 【峰值QPS和机器计算公式】 原理：每天80%的访问集中在20%的时间里，这20%时间叫做峰值时间公式：( 总PV数 80% ) / ( 每天秒数 20% ) = 峰值时间每秒请求数(QPS)机器：峰值时间每秒QPS / 单台机器的QPS = 需要的机器 问：每天300w PV 的在单台机器上，这台机器需要多少QPS？答：( 3000000 0.8 ) / (86400 0.2 ) = 139 (QPS) 问：如果一台机器的QPS是58，需要几台机器来支持？答：139 / 58 = 3 PS：下面是性能测试的主要概念和计算公式，记录下：一．系统吞度量要素： 一个系统的吞度量（承压能力）与request对CPU的消耗、外部接口、IO等等紧密关联。单个reqeust 对CPU消耗越高，外部系统接口、IO影响速度越慢，系统吞吐能力越低，反之越高。系统吞吐量几个重要参数：QPS（TPS）、并发数、响应时间 QPS（TPS）：每秒钟request/事务 数量 并发数： 系统同时处理的request/事务数 响应时间： 一般取平均响应时间（很多人经常会把并发数和TPS理解混淆）理解了上面三个要素的意义之后，就能推算出它们之间的关系：QPS（TPS）= 并发数/平均响应时间 或者 并发数 = QPS平均响应时间 一个典型的上班签到系统，早上8点上班，7点半到8点的30分钟的时间里用户会登录签到系统进行签到。公司员工为1000人，平均每个员上登录签到系统的时长为5分钟。可以用下面的方法计算。QPS = 1000/(3060) 事务/秒平均响应时间为 = 560 秒并发数= QPS平均响应时间 = 1000/(3060) (5*60)=166.7 一个系统吞吐量通常由QPS（TPS）、并发数两个因素决定，每套系统这两个值都有一个相对极限值，在应用场景访问压力下，只要某一项达到系统较高值，系统的吞吐量就上不去了，如果压力继续增大，系统的吞吐量反而会下降，原因是系统超负荷工作，上下文切换、内存等等其它消耗导致系统性能下降。决定系统响应时间要素我们做项目要排计划，可以多人同时并发做多项任务，也可以一个人或者多个人串行工作，始终会有一条关键路径，这条路径就是项目的工期。系统一次调用的响应时间跟项目计划一样，也有一条关键路径，这个关键路径是就是系统影响时间；关键路径是有CPU运算、IO、外部系统响应等等组成。二．系统吞吐量评估：我们在做系统设计的时候就需要考虑CPU运算、IO、外部系统响应因素造成的影响以及对系统性能的初步预估。而通常境况下，我们面对需求，我们评估出来的出来QPS、并发数之外，还有另外一个维度：日PV。通过观察系统的访问日志发现，在用户量很大的情况下，各个时间周期内的同一时间段的访问流量几乎一样。比如工作日的每天早上。只要能拿到日流量图和QPS我们就可以推算日流量。通常的技术方法： 1. 找出系统的较高TPS和日PV，这两个要素有相对比较稳定的关系（除了放假、季节性因素影响之外） 2. 通过压力测试或者经验预估，得出较高TPS，然后跟进1的关系，计算出系统较高的日吞吐量。B2B中文和淘宝面对的客户群不一样，这两个客户群的网络行为不应用，他们之间的TPS和PV关系比例也不一样。 A)淘宝淘宝流量图： 淘宝的TPS和PV之间的关系通常为 较高TPS：PV大约为 1 : 113600 （相当于按较高TPS访问11个小时，这个是商品详情的场景，不同的应用场景会有一些不同）B) B2B中文站B2B的TPS和PV之间的关系不同的系统不同的应用场景比例变化比较大，粗略估计在1 : 8个小时左右的关系（09年对offerdetail的流量分析数据）。旺铺和offerdetail这两个比例相差很大，可能是因为爬虫暂的比例较高的原因导致。在淘宝环境下，假设我们压力测试出的TPS为100，那么这个系统的日吞吐量=10011*3600=396万这个是在简单（单一url）的情况下，有些页面，一个页面有多个request，系统的实际吞吐量还要小。无论有无思考时间（T_think），测试所得的TPS值和并发虚拟用户数(U_concurrent)、Loadrunner读取的交易响应时间（T_response）之间有以下关系（稳定运行情况下）：TPS=U_concurrent / (T_response+T_think)。并发数、QPS、平均响应时间三者之间关系 上图横坐标是并发用户数。绿线是CPU使用率；紫线是吞吐量，即QPS；蓝线是时延。 开始，系统只有一个用户，CPU工作肯定是不饱合的。一方面该服务器可能有多个cpu，但是只处理单个进程，另一方面，在处理一个进程中，有些阶段可能是IO阶段，这个时候会造成CPU等待，但是有没有其他请 求进程可以被处理）。随着并发用户数的增加，CPU利用率上升，QPS相应也增加（公式为QPS=并发用户数/平均响应时间。）随着并发用户数的增加，平均响应时间也在增加，而且平均响应时间的增加是一个指数增加曲线。而当并发数增加到很大时，每秒钟都会有很多请求需要处理，会造成进程（线程）频繁切换，反正真正用于处理请求的时间变少，每秒能够处 理的请求数反而变少，同时用户的请求等待时间也会变大，甚至超过用户的心理底线。来源：http://www.cnblogs.com/jackei/软件性能测试的基本概念和计算公式一、软件性能的关注点对一个软件做性能测试时需要关注那些性能呢？我们想想在软件设计、部署、使用、维护中一共有哪些角色的参与，然后再考虑这些角色各自关注的性能点是什么，作为一个软件性能测试工程师，我们又该关注什么？首先，开发软件的目的是为了让用户使用，我们先站在用户的角度分析一下，用户需要关注哪些性能。对于用户来说，当点击一个按钮、链接或发出一条指令开始，到系统把结果已用户感知的形式展现出来为止，这个过程所消耗的时间是用户对这个软件性能的直观印象。也就是我们所说的响应时间，当相应时间较小时，用户体验是很好的，当然用户体验的响应时间包括个人主观因素和客观响应时间，在设计软件时，我们就需要考虑到如何更好地结合这两部分达到用户较佳的体验。如：用户在大数据量查询时，我们可以将先提取出来的数据展示给用户，在用户看的过程中继续进行数据检索，这时用户并不知道我们后台在做什么。用户关注的是用户操作的相应时间。其次，我们站在管理员的角度考虑需要关注的性能点。1、 相应时间2、 服务器资源使用情况是否合理3、 应用服务器和数据库资源使用是否合理4、 系统能否实现扩展5、 系统最多支持多少用户访问、系统较大业务处理量是多少6、 系统性能可能存在的瓶颈在哪里7、 更换那些设备可以提高性能8、 系统能否支持7×24小时的业务访问再次，站在开发（设计）人员角度去考虑。1、 架构设计是否合理2、 数据库设计是否合理3、 代码是否存在性能方面的问题4、 系统中是否有不合理的内存使用方式5、 系统中是否存在不合理的线程同步方式6、 系统中是否存在不合理的资源竞争那么站在性能测试工程师的角度，我们要关注什么呢？一句话，我们要关注以上所有的性能点。二、软件性能的几个主要术语1、响应时间：对请求作出响应所需要的时间网络传输时间：N1+N2+N3+N4应用服务器处理时间：A1+A3数据库服务器处理时间：A2响应时间=N1+N2+N3+N4+A1+A3+A22、并发用户数的计算公式系统用户数：系统额定的用户数量，如一个OA系统，可能使用该系统的用户总数是5000个，那么这个数量，就是系统用户数。同时在线用户数：在一定的时间范围内，较大的同时在线用户数量。同时在线用户数=每秒请求数RPS（吞吐量）+并发连接数+平均用户思考时间平均并发用户数的计算：C=nL / T其中C是平均的并发用户数，n是平均每天访问用户数（login session），L是一天内用户从登录到退出的平均时间（login session的平均时间），T是考察时间长度（一天内多长时间有用户使用系统）并发用户数峰值计算：C^约等于C + 3根号C其中C^是并发用户峰值，C是平均并发用户数，该公式遵循泊松分布理论。3、吞吐量的计算公式指单位时间内系统处理用户的请求数从业务角度看，吞吐量可以用：请求数/秒、页面数/秒、人数/天或处理业务数/小时等单位来衡量从网络角度看，吞吐量可以用：字节/秒来衡量对于交互式应用来说，吞吐量指标反映的是服务器承受的压力，他能够说明系统的负载能力以不同方式表达的吞吐量可以说明不同层次的问题，例如，以字节数/秒方式可以表示数要受网络基础设施、服务器架构、应用服务器制约等方面的瓶颈；已请求数/秒的方式表示主要是受应用服务器和应用代码的制约体现出的瓶颈。当没有遇到性能瓶颈的时候，吞吐量与虚拟用户数之间存在一定的联系，可以采用以下公式计算：F=VU R /其中F为吞吐量，VU表示虚拟用户个数，R表示每个虚拟用户发出的请求数，T表示性能测试所用的时间4、性能计数器是描述服务器或操作系统性能的一些数据指标，如使用内存数、进程时间，在性能测试中发挥着“监控和分析”的作用，尤其是在分析统统可扩展性、进行新能瓶颈定位时有着非常关键的作用。资源利用率：指系统各种资源的使用情况，如cpu占用率为68%，内存占用率为55%，一般使用“资源实际使用/总的资源可用量”形成资源利用率。5、思考时间的计算公式Think Time，从业务角度来看，这个时间指用户进行操作时每个请求之间的时间间隔，而在做新能测试时，为了模拟这样的时间间隔，引入了思考时间这个概念，来更加真实的模拟用户的操作。在吞吐量这个公式中F=VU R / T说明吞吐量F是VU数量、每个用户发出的请求数R和时间T的函数，而其中的R又可以用时间T和用户思考时间TS来计算：R = T / TS下面给出一个计算思考时间的一般步骤：A、首先计算出系统的并发用户数C=nL / T F=R×CB、统计出系统平均的吞吐量F=VU R / T R×C = VU R / TC、统计出平均每个用户发出的请求数量R=uC*T/VUD、根据公式计算出思考时间TS=T/R]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>高并发</tag>
        <tag>TPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git使用场景集锦]]></title>
    <url>%2F2018%2F05%2F07%2Ftools%2Ftools_0%2F</url>
    <content type="text"><![CDATA[Git使用安装之后第一步安装 Git 之后，你要做的第一件事情就是去配置你的名字和邮箱，因为每一次提交都需要这些信息： 12git config --global user.name &quot;bukas&quot;git config --global user.email &quot;bukas@gmail.com&quot; 获取Git配置信息，执行以下命令： 1git config --list 创建版本库什么是版本库呢？版本库又名仓库，英文名repository，你可以简单理解成一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改、删除，Git都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻可以“还原”。 12mkdir testgit &amp;&amp; cd testgitgit init 瞬间Git就把仓库建好了，细心的读者可以发现当前目录下多了一个.git的目录，默认是隐藏的，用ls -ah命令就可以看见。 1git-init 把文件添加到版本库12touch readme.mdgit add readme.md 然后用命令git commit告诉Git把文件提交到仓库： 1git commit -m &quot;wrote a readme file&quot; 简单解释一下git commit命令，-m后面输入的是本次提交的说明，可以输入任意内容，当然最好是有意义的，这样你就能从历史记录里方便地找到改动记录。 一次可以add多个不同的文件，以空格分隔： 1git add a.txt b.txt c.txt 仓库状态1git status git status命令可以让我们时刻掌握仓库当前的状态。 但如果能看看具体修改了什么内容就更好了： 1git diff readme.md 版本回退每次提交git都会形成以个commit。我们通过git log可以查看到各个提交的历史。1git log git log –pretty=oneline 参数可以简化显示 1git log --pretty=oneline 在 Git中，用HEAD表示当前版本，也就是最新的提交commit id，上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。 现在我们要把当前版本回退到上一个版本，就可以使用git reset命令： 1git reset --hard HEAD^ 然我们用git log再看看现在版本库的状态，最新的那个版本已经看不到了！好比你从21世纪坐时光穿梭机来到了19世纪，想再回去已经回不去了，肿么办？ git-reset 办法其实还是有的，只要上面的命令行窗口还没有被关掉，你就可以顺着往上找啊找啊，假设找到那个commit id是2e70fdf…，于是就可以指定回到未来的某个版本： 1git reset --hard 2e70fdf 版本号没必要写全，前几位就可以了，Git会自动去找。当然也不能只写前一两位，因为Git可能会找到多个版本号，就无法确定是哪一个了。 现在，你回退到了某个版本，关掉了电脑，第二天早上就后悔了，想恢复到新版本怎么办？找不到新版本的commit id怎么办？ Git提供了一个命令git reflog用来记录你的每一次命令： 1git reflog 终于舒了口气，于是你看到的commit id是2e70fdf，现在，你又可以乘坐时光机回到未来了。 工作区和暂存区Git和其他版本控制系统如SVN的一个不同之处就是有暂存区的概念。 工作区就是你在电脑里能看到的目录，比如我的testgit文件夹就是一个工作区。 工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。 Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向 master的一个指针叫HEAD。 前面讲了我们把文件往 Git 版本库里添加的时候，是分两步执行的： 第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区； 第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。 因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以现在git commit就是往master分支上提交更改。 你可以简单理解为，git add命令实际上就是把要提交的所有修改放到暂存区（Stage），然后执行git commit就可以一次性把暂存区的所有修改提交到分支。 一旦提交后，如果你又没有对工作区做任何修改，那么工作区就是“干净”的。 修改与撤销用git diff HEAD – readme.md命令可以查看工作区和版本库里面最新版本的区别。 git checkout – file可以丢弃工作区的修改： 1git checkout -- readme.md 命令git checkout – readme.md意思就是，把readme.md文件在工作区的修改全部撤销，即让这个文件回到最近一次git commit或git add时的状态。 当然也可以用git reset命令。 删除文件一般情况下，你通常直接在文件管理器中把没用的文件删了，或者用rm命令删了： 1rm readme.md 这个时候，Git 知道你删除了文件，因此，工作区和版本库就不一致了，git status命令会立刻告诉你哪些文件被删除了。 现在你有两个选择，一是确实要从版本库中删除该文件，那就用命令git rm删掉，并且git commit： 12git rm readme.mdgit commit -m &quot;remove readme.md&quot; 现在，文件就从版本库中被删除了。 另一种情况是删错了，因为版本库里还有呢，所以可以很轻松地把误删的文件恢复到最新版本： 1git checkout -- readme.md 生成SSH key创建 SSH Key。在用户主目录下，看看有没有.ssh目录，如果有，再看看这个目录下有没有id_rsa和id_rsa.pub这两个文件，如果已经有了，可直接跳到下一步。如果没有，打开 Shell（Windows下打开Git Bash），创建SSH Key： 1ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 你需要把邮件地址换成你自己的邮件地址，然后一路回车，使用默认值即可。 如果一切顺利的话，可以在用户主目录里找到.ssh目录，里面有id_rsa和id_rsa.pub两个文件，这两个就是SSH Key的秘钥对，id_rsa是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。 然后登录GitHub（或者其它Git代码托管平台），打开Account settings，SSH Keys页面，点Add SSH Key，填上任意Title，在Key文本框里粘贴id_rsa.pub文件的内容。 为什么GitHub需要SSH Key呢？因为GitHub需要识别出你推送的提交确实是你推送的，而不是别人冒充的，而Git支持SSH协议，所以GitHub只要知道了你的公钥，就可以确认只有你自己才能推送。 当然，GitHub允许你添加多个Key。假定你有若干电脑，你一会儿在公司提交，一会儿在家里提交，只要把每台电脑的Key都添加到GitHub，就可以在每台电脑上往GitHub推送了。 远程服务器Git 最强大的功能之一是可以有一个以上的远程服务器（另一个事实，你总是可以运行一个本地仓库）。你不一定总是需要写访问权限，你可以从多个服务器中读取（用于合并），然后写到另一个服务器中。添加一个远程服务器很简单： git remote add origin(别名，根据爱好命名) git@github.com:bukas/bukas.git如果你想查看远程服务器的相关信息，你可以这样做： 12345# shows URLs of each remote servergit remote -v # gives more details about origingit remote show origin(别名) 下一步，就可以把本地库的所有内容推送到远程库上： 1git push -u origin master 把本地库的内容推送到远程，用git push命令，实际上是把当前分支master推送到远程。 由于远程库是空的，我们第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。 从现在起，只要本地作了提交，就可以通过命令把本地master分支的最新修改推送至GitHub： 1git push origin master SSH警告当你第一次使用Git的clone或者push命令连接GitHub时，会得到一个警告： 12345The authenticity of host ‘github.com (xx.xx.xx.xx)’ can’t be established.RSA key fingerprint is xx.xx.xx.xx.xx.Are you sure you want to continue connecting (yes/no)? 这是因为Git使用SSH连接，而SSH连接在第一次验证GitHub服务器的Key时，需要你确认 GitHub的Key的指纹信息是否真的来自GitHub的服务器，输入yes回车即可。 从远程库克隆 当已经有一个远程库的时候，我们可以用命令git clone克隆一个本地库： 1git clone git@github.com:test/testgit.git 你也许还注意到，GitHub给出的地址不止一个，还可以用https://github.com/test/testgit.git这样的地址。实际上Git支持多种协议，默认的git://使用ssh，但也可以使用 https等其他协议。使用https除了速度慢以外，还有个最大的麻烦是每次推送都必须输入口令，但是在某些只开放http端口的公司内部就无法使用ssh协议而只能用https。 创建与合并分支首先我们创建dev分支，然后切换到dev分支： 1git checkout -b dev git checkout命令加上-b参数表示创建并切换，相当于以下两条命令： 12git branch devgit checkout dev 然后用git branch命令查看当前分支： 1git branch 我们在dev分支上进行添加修改操作，然后我们把dev分支的工作成果合并到master分支上： 12git checkout mastergit merge dev git merge命令用于合并指定分支到当前分支。 注意到git merge的信息里面可能有Fast-forward字样，Git告诉我们，这次合并是“快进模式”，也就是直接把master指向dev的当前提交，所以合并速度非常快。 当然也不是每次合并都能Fast-forward。 合并完成后，就可以放心地删除dev分支了： 1git branch -d dev 如果要丢弃一个没有被合并过的分支，可以通过git branch -D 强行删除。 在本地创建和远程分支对应的分支，使用git checkout -b branch-name origin/branch-name，本地和远程分支的名称最好一致； 建立本地分支和远程分支的关联，使用git branch –set-upstream branch-name origin/branch-name； 从远程抓取分支，使用git pull，如果有冲突，要先处理冲突。 解决冲突人生不如意之事十之八九，合并分支往往也不是一帆风顺的。 有时候我们进行合并的时候，会提示有冲突出现CONFLICT (content)，必须手动解决冲突后再提交。git status也可以告诉我们冲突的文件。 打开冲突文件我们会看到Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容，我们修改后提交： 12git add readme.mdgit commit -m &quot;conflict fixed&quot; 用带参数的git log也可以看到分支的合并情况： 1git log --graph --pretty=oneline --abbrev-commit 分支管理策略通常，合并分支时，如果可能，Git会用Fast forward模式，但这种模式下，删除分支后，会丢掉分支信息。 如果要强制禁用Fast forward模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。 下面我们实战一下–no-ff方式的git merge： 首先，仍然创建并切换dev分支： 1git checkout -b dev 修改readme.md文件，并提交一个新的commit： 12git add readme.mdgit commit -m &quot;add merge&quot; 现在，我们切换回master： 1git checkout master 准备合并dev分支，请注意–no-ff参数，表示禁用Fast forward： 1git merge --no-ff -m &quot;merge with no-ff&quot; dev Bug分支软件开发中，bug就像家常便饭一样。有了bug就需要修复，在Git中，由于分支是如此的强大，所以，每个bug都可以通过一个新的临时分支来修复，修复后，合并分支，然后将临时分支删除。 当你接到一个修复一个代号101的bug的任务时，很自然地，你想创建一个分支issue-101来修复它，但是，等等，当前正在dev上进行的工作还没有提交。 并不是你不想提交，而是工作只进行到一半，还没法提交，预计完成还需1天时间。但是，必须在两个小时内修复该bug，怎么办？ 幸好，Git还提供了一个stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作： 1git stash 现在，用git status查看工作区，就是干净的（除非有没有被 Git 管理的文件），因此可以放心地创建分支来修复bug。 首先确定要在哪个分支上修复bug，假定需要在master分支上修复，就从master创建临时分支： 12git checkout mastergit checkout -b issue-101 现在修复bug，然后提交： 12git add readme.mdgit commit -m &quot;fix bug 101&quot; 修复完成后，切换到master分支，并完成合并，最后删除issue-101分支： 123git checkout mastergit merge --no-ff -m &quot;merged bug fix 101&quot; issue-101 太棒了，原计划两个小时的bug修复只花了5分钟！现在，是时候接着回到dev分支干活了！ 12git checkout devgit status 工作区是干净的，刚才的工作现场存到哪去了？用git stash list命令看看： 1git stash list 工作现场还在，Git把stash内容存在某个地方了，但是需要恢复一下，有两个办法： 一是用git stash apply恢复，但是恢复后，stash内容并不删除，你需要用git stash drop来删除； 另一种方式是用git stash pop，恢复的同时把stash内容也删了： 1git stash pop 再用git stash list查看，就看不到任何stash内容了。 你可以多次stash，恢复的时候，先用git stash list查看，然后恢复指定的stash，用命令 1git stash apply stash@&#123;0&#125; 标签管理发布一个版本时，我们通常先在版本库中打一个标签，这样，就唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以，标签也是版本库的一个快照。 命令git tag 用于新建一个标签，默认为HEAD，也可以指定一个commit id。 1git tag -a &lt;tagname&gt; -m &quot;blablabla...&quot;可以指定标签信息。 还可以通过-s用私钥签名一个标签： 1git tag -s v0.5 -m &quot;signed version 0.2 released&quot; fec145a git tag可以查看所有标签。 用命令git show 可以查看某个标签的详细信息。 如果标签打错了，也可以删除： 1git tag -d v0.1 因为创建的标签都只存储在本地，不会自动推送到远程。所以，打错的标签可以在本地安全删除。 如果要推送某个标签到远程，使用命令git push origin ： 1git push origin v1.0 或者，一次性推送全部尚未推送到远程的本地标签：1git push origin --tags 如果标签已经推送到远程，要删除远程标签就麻烦一点，先从本地删除： 1git tag -d v0.9 然后，从远程删除。删除命令也是push，但是格式如下： 1git push origin :refs/tags/v0.9 ####忽略特殊文件 在安装Git一节中，我们已经配置了user.name 和user.email，实际上，Git还有很多可配置项。 比如，让Git显示颜色，会让命令输出看起来更醒目： 1git config --global color.ui true 有些时候，你必须把某些文件放到Git工作目录中，但又不能提交它们，比如保存了数据库密码的配置文件啦，等等，每次git status都会显示Untracked files…，有强迫症的童鞋心里肯定不爽。 好在Git考虑到了大家的感受，这个问题解决起来也很简单，在 Git工作区的根目录下创建一个特殊的.gitignore文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。 不需要从头写.gitignore文件，GitHub已经为我们准备了各种配置文件，只需要组合一下就可以使用了。所有配置文件可以直接在线浏览：https://github.com/github/gitignore 当然也可以配置全局忽略的文件，这样就不用每个项目都加gitignore了： 1git config --global core.excludesfile &apos;~/.gitignore&apos; 配置别名有没有经常敲错命令？比如git status？status这个单词真心不好记。 如果敲git st就表示git status那就简单多了，当然这种偷懒的办法我们是极力赞成的。 我们只需要敲一行命令，告诉Git，以后st就表示status：1git config --global alias.st status 当然还有别的命令可以简写： 123git config --global alias.co checkoutgit config --global alias.ci commitgit config --global alias.br branch –global参数是全局参数，也就是这些命令在这台电脑的所有Git仓库下都有用。 在撤销修改一节中，我们知道，命令git reset HEAD file可以把暂存区的修改撤销掉（unstage），重新放回工作区。既然是一个unstage操作，就可以配置一个unstage别名： 1git config --global alias.unstage &apos;reset HEAD&apos; 配置一个git last，让其显示最后一次提交信息： 1git config --global alias.last &apos;log -1&apos; 甚至还有人把lg配置成了： 1git config --global alias.lg &quot;log --color --graph --pretty=format:&apos;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&apos; --abbrev-commit&quot; ####配置文件 配置Git的时候，加上–global是针对当前用户起作用的，如果不加，那只针对当前的仓库起作用。 配置文件放哪了？每个仓库的Git配置文件都放在.git/config文件中。 而当前用户的Git配置文件放在用户主目录下的一个隐藏文件.gitconfig中。]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[swagger2 注解说明]]></title>
    <url>%2F2018%2F04%2F04%2Fspring%2Fswagger%2Fswagger_1%2F</url>
    <content type="text"><![CDATA[整体说明 swagger2的在线文档功能异常强大。 1234567891011121314151617181920212223242526272829303132@Api：用在请求的类上，表示对类的说明 tags=&quot;说明该类的作用，可以在UI界面上看到的注解&quot; value=&quot;该参数没什么意义，在UI界面上也看到，所以不需要配置&quot;@ApiOperation：用在请求的方法上，说明方法的用途、作用 value=&quot;说明方法的用途、作用&quot; notes=&quot;方法的备注说明&quot;@ApiImplicitParams：用在请求的方法上，表示一组参数说明 @ApiImplicitParam：用在@ApiImplicitParams注解中，指定一个请求参数的各个方面 name：参数名 value：参数的汉字说明、解释 required：参数是否必须传 paramType：参数放在哪个地方 · header --&gt; 请求参数的获取：@RequestHeader · query --&gt; 请求参数的获取：@RequestParam · path（用于restful接口）--&gt; 请求参数的获取：@PathVariable · body（不常用） · form（不常用） dataType：参数类型，默认String，其它值dataType=&quot;Integer&quot; defaultValue：参数的默认值@ApiResponses：用在请求的方法上，表示一组响应 @ApiResponse：用在@ApiResponses中，一般用于表达一个错误的响应信息 code：数字，例如400 message：信息，例如&quot;请求参数没填好&quot; response：抛出异常的类@ApiModel：用于响应类上，表示一个返回响应数据的信息 （这种一般用在post创建的时候，使用@RequestBody这样的场景， 请求参数无法使用@ApiImplicitParam注解进行描述的时候） @ApiModelProperty：用在属性上，描述响应类的属性 详细说明 @Api：用在请求的类上，说明该类的作用 123@Api：用在请求的类上，说明该类的作用 tags=&quot;说明该类的作用&quot; value=&quot;该参数没什么意义，所以不需要配置&quot; @ApiOperation：用在请求的方法上，说明方法的作用 123@ApiOperation：&quot;用在请求的方法上，说明方法的作用&quot; value=&quot;说明方法的作用&quot; notes=&quot;方法的备注说明 示例：1@ApiOperation(value=&quot;用户注册&quot;,notes=&quot;手机号、密码都是必输项，年龄随边填，但必须是数字&quot;) @ApiImplicitParams：用在请求的方法上，包含一组参数说明 12345678910111213@ApiImplicitParams：用在请求的方法上，包含一组参数说明 @ApiImplicitParam：用在 @ApiImplicitParams 注解中，指定一个请求参数的配置信息 name：参数名 value：参数的汉字说明、解释 required：参数是否必须传 paramType：参数放在哪个地方 · header --&gt; 请求参数的获取：@RequestHeader · query --&gt; 请求参数的获取：@RequestParam · path（用于restful接口）--&gt; 请求参数的获取：@PathVariable · body（不常用） · form（不常用） dataType：参数类型，默认String，其它值dataType=&quot;Integer&quot; defaultValue：参数的默认值 示列： 12345@ApiImplicitParams(&#123; @ApiImplicitParam(name=&quot;mobile&quot;,value=&quot;手机号&quot;,required=true,paramType=&quot;form&quot;), @ApiImplicitParam(name=&quot;password&quot;,value=&quot;密码&quot;,required=true,paramType=&quot;form&quot;), @ApiImplicitParam(name=&quot;age&quot;,value=&quot;年龄&quot;,required=true,paramType=&quot;form&quot;,dataType=&quot;Integer&quot;)&#125;) @ApiResponses：用于请求的方法上，表示一组响应 12345@ApiResponses：用于请求的方法上，表示一组响应 @ApiResponse：用在@ApiResponses中，一般用于表达一个错误的响应信息 code：数字，例如400 message：信息，例如&quot;请求参数没填好&quot; response：抛出异常的类 示例： 12345@ApiOperation(value = &quot;select1请求&quot;,notes = &quot;多个参数，多种的查询参数类型&quot;)@ApiResponses(&#123; @ApiResponse(code=400,message=&quot;请求参数没填好&quot;), @ApiResponse(code=404,message=&quot;请求路径没有或页面跳转路径不对&quot;)&#125;) @ApiModel：用于响应类上，表示一个返回响应数据的信息 1234@ApiModel：用于响应类上，表示一个返回响应数据的信息 （这种一般用在post创建的时候，使用@RequestBody这样的场景， 请求参数无法使用@ApiImplicitParam注解进行描述的时候） @ApiModelProperty：用在属性上，描述响应类的属性 示例: 12345678910111213141516171819import io.swagger.annotations.ApiModel;import io.swagger.annotations.ApiModelProperty;import java.io.Serializable;@ApiModel(description= "返回响应数据")public class RestMessage implements Serializable&#123; @ApiModelProperty(value = "是否成功") private boolean success=true; @ApiModelProperty(value = "返回对象") private Object data; @ApiModelProperty(value = "错误编号") private Integer errCode; @ApiModelProperty(value = "错误信息") private String message; /* getter/setter */&#125;]]></content>
      <categories>
        <category>spring</category>
        <category>swagger</category>
      </categories>
      <tags>
        <tag>swagger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Socket,WebSocket,HTML5]]></title>
    <url>%2F2018%2F02%2F06%2Fhttp%2Fhexo%2F</url>
    <content type="text"><![CDATA[背景对Web项目来讲，一般都用http请求来解决。 问题 Socket 和 WebSocket 有哪些区别和联系？ WebSocket 和 HTML5 是什么关系？ 必须在浏览器中才能使用 WebSocket 吗？ WebSocket 能和 Socket 一样传输 raw 数据么？ WebSocket 和 Socket 相比会多耗费流量么？ 概述选择了 WebSocket 技术之后，不可避免的，我要将它和其他协议以及技术做一下比较。最常见的，就是需要比较 WebSocket 与 HTTP、Socket 技术的异同。 WebSocket 是为了满足基于 Web 的日益增长的实时通信需求而产生的。在传统的 Web 中，要实现实时通信，通用的方式是采用 HTTP 协议不断发送请求。但这种方式即浪费带宽（HTTP HEAD 是比较大的），又消耗服务器 CPU 占用（没有信息也要接受请求）。（下图来自 WebSocket.org） Latency comparison between the polling and WebSocket applications 而是用 WebSocket 技术，则会大幅降低上面提到的消耗：（下图来自websocket.org） Comparison of the unnecessary network throughput overhead between the polling and the WebSocket applications 关于更详细的描述，尹立的这篇文章讲得非常好：WebSocket（2）–为什么引入WebSocket协议 。 那么，WebSocket 到底与 HTTP 协议到底是一个什么样的关系呢？它和 Socket 又有什么联系？这就要讲到 OSI 模型和 TCP/IP 协议族。 OSI 模型与 TCP/IP以下是 维基百科 中关于OSI 模型的说明： 开放式系统互联通信参考模型（英语：Open System Interconnection Reference Model，ISO/IEC 7498-1），简称为OSI模型（OSI model），一种概念模型，由国际标准化组织（ISO）提出，一个试图使各种计算机在世界范围内互连为网络的标准框架。 而 TCP/IP 协议可以看做是对 OSI 模型的一种简化（以下内容来自 维基百科）： 它将软件通信过程抽象化为四个抽象层，采取协议堆叠的方式，分别实作出不同通信协议。协议套组下的各种协议，依其功能不同，被分别归属到这四个阶层之中7，常被视为是简化的七层OSI模型。 这里有一张图详细介绍了 TCP/IP 协议族中的各个协议在 OSI模型 中的分布，一图胜千言（下图来自 科来）： TCP/IP 和 OSI 模型 TCP/IP 协议和 OSI 模型的内容，在互联网上有很多。我没有必要再次介绍它们。在这里，我们只需要知道，HTTP、WebSocket 等协议都是处于 OSI 模型的最高层： 应用层 。而 IP 协议工作在网络层（第3层），TCP 协议工作在传输层（第4层）。 至于 OSI 模型的各个层次都有什么系统和它们对应，这里有篇很好的文章可以满足大家的求知欲：OSI七层模型详解 。 WebSocket、HTTP 与 TCP从上面的图中可以看出，HTTP、WebSocket 等应用层协议，都是基于 TCP 协议来传输数据的。我们可以把这些高级协议理解成对 TCP 的封装。 既然大家都使用 TCP 协议，那么大家的连接和断开，都要遵循 TCP 协议中的三次握手和四次握手 ，只是在连接之后发送的内容不同，或者是断开的时间不同。 更详细内容可阅读：wireshark抓包图解 TCP三次握手/四次挥手详解 对于 WebSocket 来说，它必须依赖 HTTP 协议进行一次握手 ，握手成功后，数据就直接从 TCP 通道传输，与 HTTP 无关了。 Socket 与 WebScoketSocket 其实并不是一个协议。它工作在 OSI 模型会话层（第5层），是为了方便大家直接使用更底层协议（一般是 TCP 或 UDP ）而存在的一个抽象层。 最早的一套 Socket API 是 Berkeley sockets ，采用 C 语言实现。它是 Socket 的事实标准，POSIX sockets 是基于它构建的，多种编程语言都遵循这套 API，在 JAVA、Python 中都能看到这套 API 的影子。 下面摘录一段更容易理解的文字（来自 http和socket之长连接和短连接区别）： Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。 Socket是什么 Socket通信过程 主机 A 的应用程序要能和主机 B 的应用程序通信，必须通过 Socket 建立连接，而建立 Socket 连接必须需要底层 TCP/IP 协议来建立 TCP 连接。建立 TCP 连接需要底层 IP 协议来寻址网络中的主机。我们知道网络层使用的 IP 协议可以帮助我们根据 IP 地址来找到目标主机，但是一台主机上可能运行着多个应用程序，如何才能与指定的应用程序通信就要通过 TCP 或 UPD 的地址也就是端口号来指定。这样就可以通过一个 Socket 实例唯一代表一个主机上的一个应用程序的通信链路了。 而 WebSocket 则不同，它是一个完整的 应用层协议，包含一套标准的 API 。 所以，从使用上来说，WebSocket 更易用，而 Socket 更灵活。 HTML5 与 WebSocketWebSocket API 是 HTML5 标准的一部分， 但这并不代表 WebSocket 一定要用在 HTML 中，或者只能在基于浏览器的应用程序中使用。 实际上，许多语言、框架和服务器都提供了 WebSocket 支持，例如： 基于 C 的 libwebsocket.org基于 Node.js 的 Socket.io基于 Python 的 ws4py基于 C++ 的 WebSocket++Apache 对 WebSocket 的支持： Apache Module mod_proxy_wstunnelNginx 对 WebSockets 的支持： NGINX as a WebSockets Proxy 、 NGINX Announces Support for WebSocket Protocol 、WebSocket proxyinglighttpd 对 WebSocket 的支持：mod_websocket 原文链接]]></content>
      <categories>
        <category>http</category>
        <category>WebSocket</category>
      </categories>
      <tags>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Twitter Snowflake 有序ID生成算法]]></title>
    <url>%2F2018%2F01%2F31%2Fjava%2Fjava_2%2F</url>
    <content type="text"><![CDATA[概述分布式系统，各种系统平台建设中，需要用到全局唯一的ID场景，可以统一地进行一些简单的统计和排序。这时候我们需要一个统一的ID生成系统来做这个事情。Twitter Snowflake 可以作为一个满足基础需求的原始样本算法。可以以此为蓝本开发自己的业务ID生成算法。 结构snowflake的结构如下(每部分用-分开):0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000第一位为未使用，接下来的41位为毫秒级时间(41位的长度可以使用69年)，然后是5位datacenterId和5位workerId(10位的长度最多支持部署1024个节点） ，最后12位是毫秒内的计数（12位的计数顺序号支持每个节点每毫秒产生4096个ID序号）一共加起来刚好64位，为一个Long型。(转换成字符串后长度最多19)snowflake生成的ID整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞（由datacenter和workerId作区分），并且效率较高。经测试snowflake每秒能够产生26万个ID。 Java实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144/** * Twitter_Snowflake&lt;br&gt; * SnowFlake的结构如下(每部分用-分开):&lt;br&gt; * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 &lt;br&gt; * 1位标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0&lt;br&gt; * 41位时间截(毫秒级)，注意，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截) * 得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。41位的时间截，可以使用69年，年T = (1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69&lt;br&gt; * 10位的数据机器位，可以部署在1024个节点，包括5位datacenterId和5位workerId&lt;br&gt; * 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号&lt;br&gt; * 加起来刚好64位，为一个Long型。&lt;br&gt; * SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高，经测试，SnowFlake每秒能够产生26万ID左右。 */public class SnowflakeIdWorker &#123; // ==============================Fields=========================================== /** 开始时间截 (2015-01-01) */ private final long twepoch = 1420041600000L; /** 机器id所占的位数 */ private final long workerIdBits = 5L; /** 数据标识id所占的位数 */ private final long datacenterIdBits = 5L; /** 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数) */ private final long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits); /** 支持的最大数据标识id，结果是31 */ private final long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits); /** 序列在id中占的位数 */ private final long sequenceBits = 12L; /** 机器ID向左移12位 */ private final long workerIdShift = sequenceBits; /** 数据标识id向左移17位(12+5) */ private final long datacenterIdShift = sequenceBits + workerIdBits; /** 时间截向左移22位(5+5+12) */ private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; /** 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */ private final long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits); /** 工作机器ID(0~31) */ private long workerId; /** 数据中心ID(0~31) */ private long datacenterId; /** 毫秒内序列(0~4095) */ private long sequence = 0L; /** 上次生成ID的时间截 */ private long lastTimestamp = -1L; //==============================Constructors===================================== /** * 构造函数 * @param workerId 工作ID (0~31) * @param datacenterId 数据中心ID (0~31) */ public SnowflakeIdWorker(long workerId, long datacenterId) &#123; if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format("worker Id can't be greater than %d or less than 0", maxWorkerId)); &#125; if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123; throw new IllegalArgumentException(String.format("datacenter Id can't be greater than %d or less than 0", maxDatacenterId)); &#125; this.workerId = workerId; this.datacenterId = datacenterId; &#125; // ==============================Methods========================================== /** * 获得下一个ID (该方法是线程安全的) * @return SnowflakeId */ public synchronized long nextId() &#123; long timestamp = timeGen(); //如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常 if (timestamp &lt; lastTimestamp) &#123; throw new RuntimeException( String.format("Clock moved backwards. Refusing to generate id for %d milliseconds", lastTimestamp - timestamp)); &#125; //如果是同一时间生成的，则进行毫秒内序列 if (lastTimestamp == timestamp) &#123; sequence = (sequence + 1) &amp; sequenceMask; //毫秒内序列溢出 if (sequence == 0) &#123; //阻塞到下一个毫秒,获得新的时间戳 timestamp = tilNextMillis(lastTimestamp); &#125; &#125; //时间戳改变，毫秒内序列重置 else &#123; sequence = 0L; &#125; //上次生成ID的时间截 lastTimestamp = timestamp; //移位并通过或运算拼到一起组成64位的ID return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) // | (datacenterId &lt;&lt; datacenterIdShift) // | (workerId &lt;&lt; workerIdShift) // | sequence; &#125; /** * 阻塞到下一个毫秒，直到获得新的时间戳 * @param lastTimestamp 上次生成ID的时间截 * @return 当前时间戳 */ protected long tilNextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = timeGen(); &#125; return timestamp; &#125; /** * 返回以毫秒为单位的当前时间 * @return 当前时间(毫秒) */ protected long timeGen() &#123; return System.currentTimeMillis(); &#125; //==============================Test============================================= /** 测试 */ public static void main(String[] args) &#123; SnowflakeIdWorker idWorker = new SnowflakeIdWorker(0, 0); for (int i = 0; i &lt; 1000; i++) &#123; long id = idWorker.nextId(); System.out.println(Long.toBinaryString(id)); System.out.println(id); &#125; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>ID生成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列:观察者模式]]></title>
    <url>%2F2018%2F01%2F23%2Fjava%2Fpatterndesign%2Fpatterndesign_15%2F</url>
    <content type="text"><![CDATA[概念 观察者模式也被称为 Model-View模式。观察者的状态依赖于被观察者的行为。一旦被观察者的行为发生改变观察者的状态也随之发生改变。是一种对象间的信息交互方式。 实现 类图 Observer 1234567891011121314package com.littlehui.design.observer;/** * @Description TODO * @ClassName Observer * @Author littlehui * @Date 2019/10/9 16:32 * @Version 1.0 **/public interface Observer &#123; public void update(String message);&#125; ConcreteObserver 1234567891011121314151617package com.littlehui.design.observer;/** * @Description TODO * @ClassName ConcreteObserver * @Author littlehui * @Date 2019/10/9 16:38 * @Version 1.0 **/public class ConcreteObserver implements Observer &#123; @Override public void update(String message) &#123; System.out.println("观察者1：" + message); &#125;&#125; ConcreteObserver2 12345678910111213141516package com.littlehui.design.observer;/** * @Description TODO * @ClassName ConcreteObserver2 * @Author littlehui * @Date 2019/10/9 16:41 * @Version 1.0 **/public class ConcreteObserver2 implements Observer &#123; @Override public void update(String message) &#123; System.out.println("观察者2：" + message); &#125;&#125; Subject 12345678910111213141516171819package com.littlehui.design.observer;/** * @Description TODO * @ClassName Subject * @Author littlehui * @Date 2019/10/9 16:34 * @Version 1.0 **/public interface Subject &#123; public void register(Observer observer); public void remove(Observer observer); public void notify(String message);&#125; ConcreteSubject 123456789101112131415161718192021222324252627282930313233package com.littlehui.design.observer;import java.util.ArrayList;import java.util.List;/** * @Description TODO * @ClassName ConcreteSubject * @Author littlehui * @Date 2019/10/9 16:38 * @Version 1.0 **/public class ConcreteSubject implements Subject &#123; private List&lt;Observer&gt; observers = new ArrayList&lt;&gt;(); @Override public void register(Observer observer) &#123; observers.add(observer); &#125; @Override public void remove(Observer observer) &#123; observers.remove(observer); &#125; @Override public void notify(String message) &#123; for (Observer observer : observers) &#123; observer.update(message); &#125; &#125;&#125; Client 1234567891011121314151617181920212223package com.littlehui.design.observer;/** * @Description TODO * @ClassName Client * @Author littlehui * @Date 2019/10/9 16:42 * @Version 1.0 **/public class Client &#123; public static void main(String[] args) &#123; Observer observer1 = new ConcreteObserver(); Observer observer2 = new ConcreteObserver2(); Subject subject = new ConcreteSubject(); subject.register(observer1); subject.register(observer2); subject.notify("呼叫司令。"); &#125;&#125; 执行 1234567Connected to the target VM, address: '127.0.0.1:51436', transport: 'socket'观察者1：呼叫司令。观察者2：呼叫司令。Disconnected from the target VM, address: '127.0.0.1:51436', transport: 'socket'Process finished with exit code 0 场景观察者模式功能是用于信息广播。观察者在得到广播信息后进行一系列的状态变更。比如前端菜单面板的应用，面板上的按钮，图标观察面板的状态。一旦面板发生关闭或者取消，面板上的按钮，图标随之也可能发生变更，比如取消或者重新绘制等等。 总结观察者模式提供了一种对象设计,让主题和观察者之间耦合度降得很低,为什么呢?关于观察者的一切,主题只知道观察者实现了Observer接口,并不需要观察者具体的类是谁,做了什么或者其他细节.这样的话,由于松耦合,改变主题或者观察者其中一方,并不会影响另一方,只要他们之间的接口仍被遵守,就可以自由地改变它.降低对象之间的耦合度,也是面设对象设计的一个很重要的原则.]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>观察者</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列:模板方法模式]]></title>
    <url>%2F2018%2F01%2F23%2Fjava%2Fpatterndesign%2Fpatterndesign_14%2F</url>
    <content type="text"><![CDATA[概念 模板方法模式 在意个方法中定义一个算法的骨架，而将这些具体步骤实现延迟到子类中。模板方法使得子类可以在不改变算法结构的情况下，重新定义算法中的某些步骤。 实现 类图： AbstractProjectDesign: 123456789101112131415161718192021222324252627package com.littlehui.design.templatemethod;/** * @Description TODO * @ClassName AbstractProjectDesign * @Author littlehui * @Date 2019/10/9 11:12 * @Version 1.0 **/public abstract class AbstractProjectDesign &#123; public final void tempateMethod() &#123; //需求分析 demandAnalysis(); //架构设计 architecturalDesign(); //代码编写 coding(); &#125; protected abstract void demandAnalysis(); protected abstract void architecturalDesign(); protected abstract void coding();&#125; PaymentProjectDesign: 12345678910111213141516171819202122232425262728package com.littlehui.design.templatemethod;/** * @Description TODO * @ClassName PaymentProjectDesign * @Author littlehui * @Date 2019/10/9 11:27 * @Version 1.0 **/public class PaymentProjectDesign extends AbstractProjectDesign &#123; @Override protected void demandAnalysis() &#123; System.out.println("支付项目需求分析"); &#125; @Override protected void architecturalDesign() &#123; System.out.println("支付项目的架构设计"); &#125; @Override protected void coding() &#123; System.out.println("支付项目的编码"); &#125;&#125; SearchProjectDesign: 123456789101112131415161718192021222324252627package com.littlehui.design.templatemethod;/** * @Description TODO * @ClassName SearchProjectDesign * @Author littlehui * @Date 2019/10/9 11:32 * @Version 1.0 **/public class SearchProjectDesign extends AbstractProjectDesign &#123; @Override protected void demandAnalysis() &#123; System.out.println("搜索项目需求分析"); &#125; @Override protected void architecturalDesign() &#123; System.out.println("搜索项目架构设计"); &#125; @Override protected void coding() &#123; System.out.println("搜索项目编码"); &#125;&#125; Client: 1234567891011121314151617181920package com.littlehui.design.templatemethod;/** * @Description TODO * @ClassName Client * @Author littlehui * @Date 2019/10/9 11:33 * @Version 1.0 **/public class Client &#123; public static void main(String[] args) &#123; AbstractProjectDesign paymentProject = new PaymentProjectDesign(); AbstractProjectDesign searchProject = new SearchProjectDesign(); paymentProject.tempateMethod(); searchProject.tempateMethod(); &#125;&#125; 执行：12345678910Connected to the target VM, address: '127.0.0.1:50695', transport: 'socket'支付项目需求分析支付项目的架构设计支付项目的编码搜索项目需求分析搜索项目架构设计搜索项目编码Disconnected from the target VM, address: '127.0.0.1:50695', transport: 'socket'Process finished with exit code 0 抽象类里的tempateMethod执行的是具体的业务逻辑。以一个个抽象方法呈现。以上展示的逻辑是顺序执行逻辑。此外还可以加上分支，利用模板钩子的方式实现分支逻辑。在具体实现类里面进行取舍。 场景使用模板方法首先将不同业务场景分解成顺序执行的逻辑。将这些具体的逻辑抽出共性，组成抽象方法。如果有具体的分支的话，利用钩子的方法进行扩展。 总结模板方法重点在于定义模板类。注意的点1:模板类由 基本方法，模板方法，钩子方法构成。2：基本方法用final修饰。表明不能修改的。其他的模板方法，钩子等用protected修饰，用于子类的集成修改。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>模板方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列:策略模式]]></title>
    <url>%2F2018%2F01%2F23%2Fjava%2Fpatterndesign%2Fpatterndesign_13%2F</url>
    <content type="text"><![CDATA[概念 策略模式定义了算法族，分别封装起来，让他们之间可以相互替换，此模式让算法的变化独立于使用算法的客户。 实现策略模式涉及到三个角色： 环境(Context)角色：持有一个Strategy的引用。 抽象策略(Strategy)角色：这是一个抽象角色，通常由一个接口或抽象类实现。此角色给出所有的具体策略类所需的接口。 具体策略(ConcreteStrategy)角色：包装了相关的算法或行为。 PriceStrategy:12345678package com.littlehui.design.strategy;/** * Created by littlehui on 2018/2/27. */public interface PriceStrategy &#123; public Double caculaPrice(Double price);&#125; MemberPriceStrategy:12345678910package com.littlehui.design.strategy;/** * Created by littlehui on 2018/2/27. */public class MemberPriceStrategy implements PriceStrategy &#123; public Double caculaPrice(Double price) &#123; return price * 0.9; &#125;&#125; VipPriceStrategy:1234567891011package com.littlehui.design.strategy;/** * Created by littlehui on 2018/2/27. */public class VipPriceStrategy implements PriceStrategy &#123; public Double caculaPrice(Double price) &#123; return price * 0.8; &#125;&#125; Price:1234567891011121314151617package com.littlehui.design.strategy;/** * Created by littlehui on 2018/2/27. */public class Price &#123; private Double price; public Price(Double price) &#123; this.price = price; &#125; public Double cacularPrice(PriceStrategy priceStrategy) &#123; return priceStrategy.caculaPrice(price); &#125;&#125; Client:123456789101112package com.littlehui.design.strategy;/** * Created by littlehui on 2018/2/27. */public class Client &#123; public static void main(String[] args) &#123; Price price = new Price(5D); System.out.println(price.cacularPrice(new VipPriceStrategy())); &#125;&#125; 场景总结策略模式的优点 （1）策略模式提供了管理相关的算法族的办法。策略类的等级结构定义了一个算法或行为族。恰当使用继承可以把公共的代码移到父类里面，从而避免代码重复。 （2）使用策略模式可以避免使用多重条件(if-else)语句。多重条件语句不易维护，它把采取哪一种算法或采取哪一种行为的逻辑与算法或行为的逻辑混合在一起，统统列在一个多重条件语句里面，比使用继承的办法还要原始和落后。 策略模式的缺点 （1）客户端必须知道所有的策略类，并自行决定使用哪一个策略类。这就意味着客户端必须理解这些算法的区别，以便适时选择恰当的算法类。换言之，策略模式只适用于客户端知道算法或行为的情况。 （2）由于策略模式把每个具体的策略实现都单独封装成为类，如果备选的策略很多的话，那么对象的数目就会很可观。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>策略模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux免密码登录]]></title>
    <url>%2F2018%2F01%2F17%2Flinux%2Flinux_3%2F</url>
    <content type="text"><![CDATA[前言有两台机器 A,B。现在要实现A访问B免密码登录。 步骤生成秘钥在A主机上执行12345ssh-keygen -t rsa -f rsa_for_174回车回车回车 -t 类型 -f 指定生成秘钥文件名 追加认证 将生成的秘钥拷贝到B主机，可以手动ftp，也可以用命令。1scp -i ~/.ssh/CY6034_rsa_4096 ./rsa_for_174.pub root@10.5.121.144:~/.ssh/ 1ssh -i CY6034_rsa_4096 root@10.5.121.144 追加1cat ~/.ssh/rsa_for_174 &gt;&gt; ~/.ssh/authorized_keys DONE]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux服务器性能评估]]></title>
    <url>%2F2017%2F11%2F21%2Flinux%2Flinux_2%2F</url>
    <content type="text"><![CDATA[前言 Web服务在部署到Linux系统运行期间，可能会遇到各种问题。程序上的BUG，数据上的问题，这些排查起来较为简单。当排除这些问题后，往往需要深入到服务器层面来寻找影响程序运行的稳定因素。 基本信息查看CPU信息查看 查看CPU个数 1cat /proc/cpuinfo | grep &quot;physical id&quot; | sort | uniq | wc -l 查看CPU中core个数 1cat /proc/cpuinfo | grep &quot;cpu cores&quot; | wc -l 查看CPU逻辑个数 1cat /proc/cpuinfo | grep &quot;processor&quot; | wc -l 逻辑CPU数 = 物理CPU个数*核心数 内存信息查看 内存使用情况12345#free -m total used free shared buffers cachedMem: 64376 37881 26494 0 308 17273-/+ buffers/cache: 20299 44076Swap: 16383 0 16383 total: 总内存数 used: 已用内存数 free: 空闲内存 shared: 多进程共享的内存总数 - buffers/cache: 已用缓存总数 used-buffer-cached + buffers/cache: 可用缓存数 free+buffer+cached Buffer Cache 用于针对磁盘块的写 Page Cache用于针对文件inode的读写，这些cache能够缩短I/O时间 free / used是系统可用/暂用的内存 对于程序来说 -/+ buffers/cache是可用/占用内存，因为 buffers/cache很容易就会被使用到 硬盘查看 查看硬盘分区信息 1fdisk -l 查看文件系统磁盘暂用情况 1df -h 查看硬盘的I/O性能 1234567iostat -d -k 1Linux 2.6.32-358.el6.x86_64 (fzck-10-59-107-216.h.173ops.com) 2017年11月21日 _x86_64_ (32 CPU)Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 13.35 31.70 161.99 2867672698 14655271354sdb 0.86 17.77 29.61 1607620286 2679034433 参数解释： tps：该设备每秒的传输次数（Indicate the number of transfers per second that were issued to the device.）。”一次传输”意思是”一次I/O请求”。多个逻辑请求可能会被合并为”一次I/O请求”。”一次传输”请求的大小是未知的。 kB_read/s：每秒从设备（drive expressed）读取的数据量； kB_wrtn/s：每秒向设备（drive expressed）写入的数据量； kB_read：读取的总数据量； kB_wrtn：写入的总数量数据量；这些单位都为Kilobytes。 指定监控的设备名称为sda，该命令的输出结果和上面命令完全相同。1iostat -d sda 2 默认监控所有的硬盘设备，现在指定只监控sda。 -x 参数123456789101112131415iostat -d -x -k 1 10Linux 2.6.32-358.el6.x86_64 (fzck-10-59-107-216.h.173ops.com) 2017年11月21日 _x86_64_ (32 CPU)Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.01 28.67 1.47 11.89 31.70 161.99 29.01 0.01 0.57 2.76 0.30 0.16 0.21sdb 0.00 0.00 0.47 0.39 17.77 29.61 109.69 0.00 1.61 0.55 2.87 0.38 0.03Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdb 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdb 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 rrqm/s：每秒这个设备相关的读取请求有多少被Merge了（当系统调用需要读取数据的时候，VFS将请求发到各个FS，如果FS发现不同的读取请求读取的是相同Block的数据，FS会将这个请求合并Merge）； wrqm/s：每秒这个设备相关的写入请求有多少被Merge了. rsec/s：每秒读取的扇区数. wsec/：每秒写入的扇区数。 rKB/s：The number of read requests that were issued to the device per second； wKB/s：The number of write requests that were issued to the device per second； avgrq-sz 平均请求扇区的大小 avgqu-sz 是平均请求队列的长度。毫无疑问，队列长度越短越好。 await： 每一个IO请求的处理的平均时间（单位是微秒毫秒）。这里可以理解为IO的响应时间，一般地系统IO响应时间应该低于5ms，如果大于10ms就比较大了。 这个时间包括了队列时间和服务时间，也就是说，一般情况下，await大于svctm，它们的差值越小，则说明队列时间越短，反之差值越大，队列时间越长，说明系统出了问题。 svctm 表示平均每次设备I/O操作的服务时间（以毫秒为单位）。如果svctm的值与await很接近，表示几乎没有I/O等待，磁盘性能很好，如果await的值远高于svctm的值，则表示I/O队列等待太长， 系统上运行的应用程序将变慢。%util： 在统计时间内所有处理IO时间，除以总共统计时间。例如，如果统计间隔1秒，该设备有0.8秒在处理IO，而0.2秒闲置，那么该设备的%util = 0.8/1 = 80%，所以该参数暗示了设备的繁忙程度。一般地，如果该参数是100%表示设备已经接近满负荷运行了（当然如果是多磁盘，即使%util是100%，因为磁盘的并发能力，所以磁盘使用未必就到了瓶颈）。 内存性能指标磁盘性能指标网络IO指标系统评估指标 性能因素 好 坏 糟糕 CPU user% + sys% &lt; 70% user% + sys% =85% user% + sys% &gt;= 90% 内存 Swap In(si) = 0 Swap Out(so) = 0 Per CPU with 10 pages/s More Swap In &amp; Swap Out 磁盘 iowait%&lt; 20% iowat%=35% iowat% &gt;= 50%]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux自动删除N天日志]]></title>
    <url>%2F2017%2F11%2F20%2Flinux%2Flinux_1%2F</url>
    <content type="text"><![CDATA[前言 web在部署到linux环境后，一般都是把日志等级设置加高。只输出Error信息或者直接关闭Log。但是某些系统需要搜集容器的access日志来做数据分析。如果本地存储的话，日子久了，日志就越来越大。占用大量磁盘资源，直接影响到系统的正常运行。所以，这种情况下，对日志做定期清理，是成本最低的方法了。 过程删除文件脚本1find 对应目录 -mtime +天数 -name &quot;文件名&quot; -exec rm -rf &#123;&#125; \; 例如:删除3天前 /opt/logs下 search开头的日志。1find /opt/logs/ -mtime +3 -name &quot;search*.log&quot; exec rm -rf &#123;&#125; \; 说明：find：linux的查找命令，用户查找指定条件的文件/opt/logs/：想要进行清理的任意目录；-mtime：标准语句写法；+3：查找30天前的文件，这里用数字代表天数；“search*.log”：支持范式匹配-exec：执行rm -rf：强制删除命令{} \; ：固定写法，一对大括号+空格++; 计划任务将以上命令放置到可执行shell脚本中再通过cron调度执行。创建shell:12touch ~/bin/auto-del-30-days-ago-log.shchmod +x auto-del-30-days-ago-log.sh 编辑shell脚本1vim auto-del-3-days-ago-log.sh 内容如下：12#!/bin/shfind /opt/logs/ -mtime +3 -name &quot;search*.log&quot; exec rm -rf &#123;&#125; \; 添加计划调度：执行：110 0 * * * ~/auto-del-3-days-ago-log.sh &gt;/dev/null 2&gt;&amp;1 设置是每天凌晨0点10分执行auto-del-3-days-ago-log.sh文件进行数据清理任务了。 总结THE END.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>系统维护</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列:桥接模式]]></title>
    <url>%2F2017%2F11%2F09%2Fjava%2Fpatterndesign%2Fpatterndesign_10%2F</url>
    <content type="text"><![CDATA[概念 类的继承是类本身的垂直维度变化。如果需要水平维度上的变化扩展。继承是不好实现的。这时候我们可以引入桥接方式。桥接模式的做法是把变化部分抽象出来，使变化部分与主类分离开来，从而将多个维度的变化彻底分离。最后，提供一个管理类来组合不同维度上的变化，通过这种组合来满足业务的需要。 实现 Fruit:12345678package com.littlehui.design.bridge;/** * Created by littlehui on 2018/1/17. */public interface Fruit &#123; public void eat();&#125; AbstractFruit:12345678910111213141516171819package com.littlehui.design.bridge;/** * Created by littlehui on 2018/1/17. */public class AbstractFruit implements Fruit &#123; EatHandler eatHandler; public AbstractFruit(EatHandler eatHandler) &#123; this.eatHandler = eatHandler; &#125; @Override public void eat() &#123; eatHandler.handle(); System.out.println("开始吃水果。"); &#125;&#125; Apple:123456789101112131415package com.littlehui.design.bridge;/** * Created by littlehui on 2018/1/17. */public class Apple extends AbstractFruit &#123; public Apple(EatHandler eatHandler) &#123; super(eatHandler); &#125; public void enjoy() &#123; eat(); &#125;&#125; WaterMelon:1234567891011121314151617package com.littlehui.design.bridge;/** * Created by littlehui on 2018/1/17. */public class WaterMelon extends AbstractFruit &#123; public WaterMelon(EatHandler eatHandler) &#123; super(eatHandler); &#125; public void eat() &#123; super.eat(); System.out.println("吃西瓜"); &#125;&#125; EatHandler:1234567891011package com.littlehui.design.bridge;/** * Created by littlehui on 2018/1/17. */public abstract class EatHandler &#123; public void handle() &#123; System.out.println("吃水果前处理。"); &#125;&#125; PeelHandler :123456789101112package com.littlehui.design.bridge;/** * Created by littlehui on 2018/1/17. */public class PeelHandler extends EatHandler &#123; @Override public void handle() &#123; super.handle(); System.out.println("削皮"); &#125;&#125; EatHandlerDivid:1234567891011package com.littlehui.design.bridge;/** * Created by littlehui on 2018/1/17. */public class EatHandlerDivid extends EatHandler &#123; public void handle() &#123; super.handle(); System.out.println("切块。"); &#125;&#125; 123456789101112131415package com.littlehui.design.bridge;/** * Created by littlehui on 2018/1/17. */public class Client &#123; public static void main(String[] args) &#123; EatHandler eatHandler = new PeelHandler(); EatHandler eatHandler1 = new EatHandlerDivid(); Fruit apple = new Apple(eatHandler); Fruit waterMelon = new WaterMelon(eatHandler1); apple.eat(); waterMelon.eat(); &#125;&#125; 如上代码解释： 抽象部分 1：吃水果接口抽象，2.吃水果前处理抽象。 具体实现部分 : apple里的enjoy 这里就分离了水果关于吃水果和水果处理的部分。Apple里的enjoy是具体的实现，可以eat，可以做其他操作。我们可以切换 水果处理 Handle来改变 Appleenjoy具体时动作。 场景略 总结桥接的重点是 将实现解耦，抽象和实现独立开，不影响对方。桥接一般用于跨多个平台的图形和窗口系统上。当需要不同的方式改变借口和实现时，可以用桥接。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列:享元模式]]></title>
    <url>%2F2017%2F11%2F09%2Fjava%2Fpatterndesign%2Fpatterndesign_12%2F</url>
    <content type="text"><![CDATA[概念 一个类的实例有多种 “虚拟实例”。 虚拟实例通过共享数据的方式存在。 实现 类图： Tree:1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.littlehui.design.flyweight;/** * Created by littlehui on 2018/1/23. */public class Tree &#123; private int x; private int y; private int age; public Tree(int x, int y, int age) &#123; this.x = x; this.y = y; this.age = age; &#125; public int getX() &#123; return x; &#125; public void setX(int x) &#123; this.x = x; &#125; public int getY() &#123; return y; &#125; public void setY(int y) &#123; this.y = y; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public void display() &#123; System.out.println("坐标x:" + x + "坐标y:" + y + "年龄age:" + age); &#125;&#125; 123456789101112131415161718192021222324252627282930package com.littlehui.design.flyweight;import java.util.HashMap;import java.util.Map;/** * Created by littlehui on 2018/1/23. */public class TreeManager &#123; Map&lt;String, Tree&gt; allTrees = new HashMap&lt;String, Tree&gt;(); public Tree createTree(int x, int y, int age) &#123; String treeHash = new StringBuffer().append(x).append(y).append(age).toString(); if (allTrees.get(treeHash) != null) &#123; return allTrees.get(treeHash); &#125; else &#123; Tree tree = new Tree(x, y, age); allTrees.put(treeHash, tree); return allTrees.get(treeHash); &#125; &#125; public void displayAllTrees() &#123; for (String key : allTrees.keySet()) &#123; Tree tree = allTrees.get(key); tree.display(); &#125; &#125;&#125; 123456789101112131415161718package com.littlehui.design.flyweight;/** * Created by littlehui on 2018/1/23. */public class Client &#123; public static void main(String[] args) &#123; TreeManager treeManager = new TreeManager(); Tree tree1 = treeManager.createTree(1,2,3); Tree tree2 = treeManager.createTree(1,2,3); Tree tree3 = treeManager.createTree(1,2,4); System.out.println("实例个数：" + "tree1, tree2, tree3"); System.out.println("真实实例个数："); treeManager.displayAllTrees(); &#125;&#125; 场景在java应用中,会出现许多String a=”123”,String b=”123”之类的String类型的变量,如果只是小应用,到还好,假设是一个庞大的系统,有好多处都需要用定义String a=”223”,那开销可想而知,而JDK的开发者自然想到了这点,采用了享元模式解决创建大量相同String变量带来的开销问题 总结 享元模式，其功能是在运行时减少实例的个数，节省内存。当一个类有许多的实例，而这些实例能被统一个方法控制到时候，可以用享元模式。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列:组合模式]]></title>
    <url>%2F2017%2F11%2F09%2Fjava%2Fpatterndesign%2Fpatterndesign_11%2F</url>
    <content type="text"><![CDATA[概念 组合模式是把对象堆起来形成集合的一种方式。它组织对象形成集合，结合迭代器模式，可以对客户隐藏具体对象实现。不至于暴露集合内部信息。形式上经常将组合你模式用于对象的树形结构表示。 实现 背景 村子里面养了 鸡，鸭，本地鸭，外地鸭，猪。这些家畜都会跑。现在要将他们集合起来，进行统一管理。每天数数，防止丢失。 抽象我们可以用组合模式来进行管理这些家畜。首先家畜的集合进行抽象树形结构。第一层：普通家畜第二层：普通家禽下有 猪，禽类第三层：禽类 下面有 鸡，鸭第四层：鸭子下面有 本地鸭，外地鸭。 类图 对象关联图： 部分代码： AnimalType: 1234567891011package com.littlehui.design.composite;import com.littlehui.design.iterate.AnimalIterator;/** * Created by littlehui on 2018/1/18. */public interface AnimalType &#123; public AnimalIterator createIterator();&#125; 123456789101112131415package com.littlehui.design.composite;import com.littlehui.design.iterate.AnimalIterator;/** * Created by littlehui on 2018/1/18. */public interface Animal &#123; public void run(); public void each(); public AnimalIterator iterator();&#125; 12345678910111213141516171819202122232425262728293031323334353637383940package com.littlehui.design.composite;import com.littlehui.design.iterate.AnimalIterator;import com.littlehui.design.iterate.HomeAnimalIterator;import com.littlehui.design.iterate.IteratorComposite;import java.util.ArrayList;import java.util.List;/** * Created by littlehui on 2018/1/18. */public class Bird extends IteratorAnimal implements AnimalType &#123; List&lt;Animal&gt; birds; public Bird() &#123; this.birds = new ArrayList&lt;Animal&gt;(); birds.add(new Chicken()); birds.add(new Duck()); &#125; public void run() &#123; System.out.println("鸟类跑"); &#125; public void each() &#123; for (Animal animal : birds) &#123; animal.each(); &#125; &#125; public AnimalIterator iterator() &#123; return new HomeAnimalIterator(birds); &#125; public AnimalIterator createIterator() &#123; return new IteratorComposite(this.iterator()); &#125;&#125; 12345678910111213141516package com.littlehui.design.composite;/** * Created by littlehui on 2018/1/18. */public class Chicken extends IteratorAnimal &#123; public void run() &#123; System.out.println("小鸡跑"); &#125; public void each() &#123; System.out.println("鸡"); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738package com.littlehui.design.composite;import com.littlehui.design.iterate.AnimalIterator;import com.littlehui.design.iterate.HomeAnimalIterator;import com.littlehui.design.iterate.IteratorComposite;import java.util.ArrayList;import java.util.List;/** * Created by littlehui on 2018/1/18. */public class Duck extends IteratorAnimal implements AnimalType &#123; List&lt;Animal&gt; ducks; public Duck() &#123; ducks = new ArrayList&lt;Animal&gt;(); ducks.add(new LocalDuck()); ducks.add(new ForignDuck()); &#125; public void run() &#123; System.out.println("鸭类跑"); &#125; public void each() &#123; System.out.println("鸭"); &#125; public AnimalIterator iterator() &#123; return new HomeAnimalIterator(ducks); &#125; public AnimalIterator createIterator() &#123; return new IteratorComposite(this.iterator()); &#125;&#125; 1234567891011121314package com.littlehui.design.composite;/** * Created by littlehui on 2018/1/18. */public class ForignDuck extends IteratorAnimal &#123; public void run() &#123; System.out.println("外地鸭跑"); &#125; public void each() &#123; System.out.println("外地鸭"); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637package com.littlehui.design.composite;import com.littlehui.design.iterate.AnimalIterator;import com.littlehui.design.iterate.HomeAnimalIterator;import com.littlehui.design.iterate.IteratorComposite;import java.util.ArrayList;import java.util.List;/** * Created by littlehui on 2018/1/18. */public class HomeAnimal extends IteratorAnimal implements AnimalType &#123; private List&lt;Animal&gt; homeAnimals = new ArrayList&lt;Animal&gt;(); public HomeAnimal() &#123; homeAnimals.add(new Pig()); homeAnimals.add(new Bird()); &#125; public void run() &#123; System.out.println("家养牲畜跑"); &#125; public void each() &#123; System.out.println("家养牲畜跑"); &#125; public AnimalIterator iterator() &#123; return new HomeAnimalIterator(homeAnimals); &#125; public AnimalIterator createIterator() &#123; return new IteratorComposite(this.iterator()); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536package com.littlehui.design.composite;import com.littlehui.design.iterate.AnimalIterator;/** * Created by littlehui on 2018/1/18. */public class IteratorAnimal implements Animal &#123; public IteratorAnimal() &#123; &#125; public void run() &#123; &#125; public void each() &#123; &#125; public AnimalIterator iterator() &#123; final IteratorAnimal baseAnimal = this; return new AnimalIterator() &#123; public boolean hasNext() &#123; if (baseAnimal != null ) &#123; return true; &#125; return false; &#125; public Animal next() &#123; return baseAnimal; &#125; &#125;; &#125;&#125; 123456789101112131415package com.littlehui.design.composite;/** * Created by littlehui on 2018/1/18. */public class LocalDuck extends IteratorAnimal &#123; public void run() &#123; System.out.println("本地鸭跑"); &#125; public void each() &#123; System.out.println("本地鸭"); &#125;&#125; 123456789101112131415package com.littlehui.design.composite;/** * Created by littlehui on 2018/1/18. */public class Pig extends IteratorAnimal &#123; public void run() &#123; System.out.println("猪在跑"); &#125; public void each() &#123; System.out.println("猪"); &#125;&#125; Client:12345678910111213141516171819package com.littlehui.design.composite;import com.littlehui.design.iterate.AnimalIterator;/** * Created by littlehui on 2018/1/18. */public class Client &#123; public static void main(String[] args) &#123; HomeAnimal homeAnimal = new HomeAnimal(); AnimalIterator homeAnimalIterator = homeAnimal.createIterator(); while (homeAnimalIterator.hasNext()) &#123; Animal animal = homeAnimalIterator.next(); animal.run(); &#125; &#125;&#125; 迭代器组合部分 设计模式-组合模式 解析实际上，上面的代码分两个部分理解：1：家畜动物们的关联组合2：对动物们遍历的迭代组合(代码略)组合模式经常会应用到迭代模式，这里也都写上了。 场景HtmlPaser包，解析Html页面。就是典型的组合模式。 总结组合模式关注的重点是对对象的结合方式。结合后暴露统一的接口管理。正如上所表达的，动物们集合后通过组合迭代器的方式统一暴露了一个遍历的方法口。屏蔽了内部实现，调用端只需调用迭代方法就可以实现遍历管理了。有了迭代组合还可以个性化的筛选，等等趋向业务逻辑的实现。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列：外观模式]]></title>
    <url>%2F2017%2F11%2F09%2Fjava%2Fpatterndesign%2Fpatterndesign_9%2F</url>
    <content type="text"><![CDATA[概念 外观模式用于简化系统中一个或者多个复杂的类。外观模式相当直接，容易理解。它提供了一个统一的接口，用来访问子系统中的一群接口。外观定义了一个高层接口，让子同更容易使用。 实现 类图： MyOneDay:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package com.littlehui.design.facade;/** * Created by littlehui on 2018/1/16. * 我的一天 */public class MyOneDay &#123; private Morning morning; private Road road; private Back back; private Office office; private Rest rest; public MyOneDay(Morning morning, Office office, Back back, Road road, Rest rest) &#123; this.morning = morning; this.office = office; this.back = back; this.road = road; this.rest = rest; &#125; /** * 在家起床 */ public void morning() &#123; morning.morningStepA(); morning.morningStepB(); morning.moringStepC(); &#125; /** * 去公司 */ public void goToOffice() &#123; road.onLoadA(); road.onLoadB(); road.onLoadC(); road.onLoadE(); &#125; /** * 工作，coding */ public void work() &#123; office.officeA(); office.officeB(); office.officeC(); &#125; public void backToHome() &#123; back.backStepA(); back.backStepB(); back.backStepC(); back.backStepD(); &#125; public void rest() &#123; rest.restA(); rest.restB(); rest.restC(); rest.restD(); &#125; public void myWholeDay() &#123; morning(); goToOffice(); work(); backToHome(); rest(); &#125;&#125; Morning:12345678910111213141516171819package com.littlehui.design.facade;/** * Created by littlehui on 2018/1/16. */public class Morning &#123; public void morningStepA() &#123; System.out.println("起床刷牙洗脸"); &#125; public void morningStepB() &#123; System.out.println("吃早饭"); &#125; public void moringStepC() &#123; System.out.println("带上背包出门"); &#125;&#125; Office:12345678910111213141516171819package com.littlehui.design.facade;/** * Created by littlehui on 2018/1/16. */public class Office &#123; public void officeA() &#123; System.out.println("放下背包"); &#125; public void officeB() &#123; System.out.println("去除电脑开机"); &#125; public void officeC() &#123; System.out.println("打开IDEA 愉快地codeing"); &#125;&#125; Client:1234567891011package com.littlehui.design.facade;/** * Created by littlehui on 2018/1/16. */public class Client &#123; public static void main(String[] args) &#123; MyOneDay myOneDay = new MyOneDay(new Morning(), new Office(), new Back(), new Road(), new Rest()); myOneDay.myWholeDay(); &#125;&#125; 以上其他类略：详情github链接： 设计模式 场景总结 外观模式体现了设计模式中 最少知识原则。不让太多的类耦合在一起。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列：装饰器模式]]></title>
    <url>%2F2017%2F11%2F09%2Fjava%2Fpatterndesign%2Fpatterndesign_7%2F</url>
    <content type="text"><![CDATA[概念 动态地将责任附加到对象上，若要扩展功能，装饰者提供了比继承更有弹性的替代方案。 实现 类图： Money:1234567891011package com.littlehui.design.decorator;/** * Created by littlehui on 2018/1/15. */public interface Money &#123; public Double totalMoney(); public String getDescription();&#125; Wages:123456789101112131415package com.littlehui.design.decorator;/** * Created by littlehui on 2018/1/15. */public class Wages implements Money &#123; public Double totalMoney() &#123; return 10D; &#125; public String getDescription() &#123; return "基础工资，"; &#125;&#125; Reward:123456789101112131415161718192021package com.littlehui.design.decorator;/** * Created by littlehui on 2018/1/15. */public class Reward implements Money &#123; Money money; public Reward(Money money) &#123; this.money = money; &#125; public Double totalMoney() &#123; return 4d + money.totalMoney(); &#125; public String getDescription() &#123; return "加上额外奖励" + money.getDescription(); &#125;&#125; Bonuses:123456789101112131415161718192021package com.littlehui.design.decorator;/** * Created by littlehui on 2018/1/15. */public class Bonuses implements Money &#123; Money money; public Bonuses(Money money) &#123; this.money = money; &#125; public Double totalMoney() &#123; return 5d + money.totalMoney(); &#125; public String getDescription() &#123; return "加上奖金" + money.getDescription(); &#125;&#125; Client:12345678910111213141516package com.littlehui.design.decorator;/** * Created by littlehui on 2017/11/9. */public class Client &#123; public static void main(String[] args) &#123; Money wages = new Wages(); //奖金装饰它 wages = new Bonuses(wages); //额外奖励装饰它 wages = new Reward(wages); System.out.println("工资：" + wages.getDescription() + wages.totalMoney()); &#125;&#125; 场景Java.io包里就使用了装饰器。BufferedInputStream及LineNumberInputStream都扩展自FilterInputStream，而FilterInputStream是一个抽象的装饰类。 总结 装饰器模式体现了设计模式里的 开放-关闭原则。 装饰者和被装饰者对象有相同的父类 可以使用一个或者多个装饰者包装一个对象。 在任何需要原始对象他们可以相互替换。 装饰者可以在所委托被装饰者的行为之前与/或之后，加上自己的行为，以达到特定的目的。 对象可以在任何时候被装饰，所以可以在运行时动态，不限量地使用。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列：代理模式]]></title>
    <url>%2F2017%2F11%2F09%2Fjava%2Fpatterndesign%2Fpatterndesign_8%2F</url>
    <content type="text"><![CDATA[概念 为另外一个对象提供一个替身或者占位符以控制对这个对象的访问。 实现静态代理 类图： Car：123456789package com.littlehui.design.proxy.statics;/** * Created by littlehui on 2018/1/16. */public interface Car &#123; public void run();&#125; Bus:1234567891011package com.littlehui.design.proxy.statics;/** * Created by littlehui on 2018/1/16. */public class Bus implements Car &#123; public void run() &#123; System.out.println("bus run"); &#125;&#125; BusProxy:12345678910111213package com.littlehui.design.proxy.statics;/** * Created by littlehui on 2018/1/16. */public class BusProxy implements Car &#123; public void run() &#123; System.out.println("car proxy"); Car bus = new Bus(); bus.run(); &#125;&#125; Client:123456789101112package com.littlehui.design.proxy.statics;/** * Created by littlehui on 2018/1/16. */public class Client &#123; public static void main(String[] args) &#123; Car bus = new BusProxy(); bus.run(); &#125;&#125; car为接口 Bus实现car的run方法 BusProxy负责控制Bus访问方法。 动态代理 类图： 动态代理是JDK支持的一种方式 实现例子如下： Car12345678package com.littlehui.design.proxy.dymatic;/** * Created by littlehui on 2018/1/16. */public interface Car &#123; public void run();&#125; Bus:12345678910package com.littlehui.design.proxy.dymatic;/** * Created by littlehui on 2018/1/16. */public class Bus implements Car &#123; public void run() &#123; System.out.println("car run"); &#125;&#125; BusProxyFactory:123456789101112131415161718192021222324252627282930313233package com.littlehui.design.proxy.dymatic;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;/** * Created by littlehui on 2018/1/16. */public class BusProxyFactory &#123; private Object target; public BusProxyFactory(Object car) &#123; this.target = car; &#125; public Object getNewInstance() &#123; return Proxy.newProxyInstance( target.getClass().getClassLoader(), target.getClass().getInterfaces(), new InvocationHandler() &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("开始事务"); //执行目标对象方法 Object returnValue = method.invoke(target, args); System.out.println("提交事务"); return returnValue; &#125; &#125; ); &#125;&#125; Client:123456789101112131415package com.littlehui.design.proxy.dymatic;/** * Created by littlehui on 2018/1/16. */public class Client &#123; public static void main(String[] args) &#123; Car bus = new Bus(); Car newBus = (Car) new BusProxyFactory(bus).getNewInstance(); System.out.println(newBus.getClass()); newBus.run(); &#125;&#125; CGLIB动态代理，引入包spring-core-XX.jarBusProxyFactoryCglib1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.littlehui.design.proxy.dymatic;import org.springframework.cglib.proxy.Enhancer;import org.springframework.cglib.proxy.MethodInterceptor;import org.springframework.cglib.proxy.MethodProxy;import java.lang.reflect.Method;/** * Created by littlehui on 2018/1/16. */public class BusProxyFactoryCglib implements MethodInterceptor &#123; private Object target;//业务类对象，供代理方法中进行真正的业务方法调用 //相当于JDK动态代理中的绑定 public Object getInstance(Object target) &#123; this.target = target; //创建加强器，用来创建动态代理类 Enhancer enhancer = new Enhancer(); //为加强器指定要代理的业务类（即：为下面生成的代理类指定父类） enhancer.setSuperclass(this.target.getClass()); //设置回调：对于代理类上所有方法的调用，都会调用CallBack，而Callback则需要实现intercept()方法进行拦 enhancer.setCallback(this); // 创建动态代理类对象并返回 return enhancer.create(); &#125; //CGLIB的特有方式，不指定 具体对象，只指定类 public Object getInstanceByClass(Class targetClass) &#123; //创建加强器，用来创建动态代理类 Enhancer enhancer = new Enhancer(); //为加强器指定要代理的业务类（即：为下面生成的代理类指定父类） enhancer.setSuperclass(targetClass); //设置回调：对于代理类上所有方法的调用，都会调用CallBack，而Callback则需要实现intercept()方法进行拦 enhancer.setCallback(this); // 创建动态代理类对象并返回 return enhancer.create(); &#125; public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println("预处理"); methodProxy.invokeSuper(o, objects); //调用业务类（父类中）的方法 System.out.println("调用后操作"); return null; &#125;&#125; Client:12345678910111213141516171819package com.littlehui.design.proxy.dymatic;/** * Created by littlehui on 2018/1/16. */public class Client &#123; public static void main(String[] args) &#123; Car bus = new Bus(); Car newBus = (Car) new BusProxyFactory(bus).getNewInstance(); System.out.println(newBus.getClass()); newBus.run(); System.out.println("-----------cglib------------"); Car cglibBus = (Car)new BusProxyFactoryCglib().getInstanceByClass(Bus.class); cglibBus.run(); System.out.println(cglibBus.getClass()); &#125;&#125; result:1234567891011121314/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/bin/java -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:62751,suspend=y,server=n -Dfile.encoding=UTF-8 -classpath &quot;/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/lib/tools.jar:/Users/littlehui/WorkSpaces/Home/pattern/proxy/target/classes:/Users/littlehui/software/repository/org/springframework/spring-core/5.0.0.RC3/spring-core-5.0.0.RC3.jar:/Users/littlehui/software/repository/org/springframework/spring-jcl/5.0.0.RC3/spring-jcl-5.0.0.RC3.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar&quot; com.littlehui.design.proxy.dymatic.ClientConnected to the target VM, address: &apos;127.0.0.1:62751&apos;, transport: &apos;socket&apos;class com.sun.proxy.$Proxy0开始事务car run提交事务-----------cglib------------预处理Disconnected from the target VM, address: &apos;127.0.0.1:62751&apos;, transport: &apos;socket&apos;car run调用后操作class com.littlehui.design.proxy.dymatic.Bus$$EnhancerByCGLIB$$1e8a65c7Process finished with exit code 0 Cglib生成的动态代理类是业务类的子类，重写业务方法进行代理。可以看到CGLIB调用的 class是 class com.littlehui.design.proxy.dymatic.Bus 这个在Spring类的装配和其他涉及获取Class的地方相当有用。 car为接口 Bus实现Car的run方法 Bus对象的访问交给了BusProxyFactory控制。 BusProxyFactory执行中动态地加入了run方法执行前后的标识。场景 Spring AOP 如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP 如果目标对象实现了接口，可以强制使用CGLIB实现AOP 如果目标对象没有实现了接口，必须采用CGLIB库，spring会自动在JDK动态代理和CGLIB之间转换 总结 代理和装饰模式看起来很相似，但是深入理解，本质上是有区别的 主要的区别是：使用代理模式，代理和真实对象之间的的关系通常在编译时就已经确定了，而装饰者能够在运行时递归地被构造。也就是那句话：代理模式可以控制被代理的对象可以控制被代理对象的访问，而装饰模式是被装饰对象的增强。不体现在控制上。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列：适配器模式]]></title>
    <url>%2F2017%2F11%2F09%2Fjava%2Fpatterndesign%2Fpatterndesign_6%2F</url>
    <content type="text"><![CDATA[概念 适配器模式是将一个类的接口，转换成客户期望 的另一个接口。适配器让原来接口不兼容的类可以合作。 实现 类图： 对象适配器 类适配器 Target:12345678package com.littlehui.design.adapter.target;/** * Created by littlehui on 2017/11/9. */public interface Target &#123; public void doTargetThings(String value);&#125; Adapter12345678910111213141516171819package com.littlehui.design.adapter.source;import com.littlehui.design.adapter.target.Target;/** * Created by littlehui on 2017/11/9. */public class Adapter implements Target &#123; Adaptee adaptee; public Adapter(Adaptee adaptee) &#123; this.adaptee = adaptee; &#125; public void doTargetThings(String value) &#123; adaptee.doSourceThings(value); &#125;&#125; Adaptee12345678910package com.littlehui.design.adapter.source;/** * Created by littlehui on 2017/11/9. */public class Adaptee &#123; public void doSourceThings(String value) &#123; System.out.println("value is : " + value + "adaptee"); &#125;&#125; ConcreteTarget1234567891011package com.littlehui.design.adapter.target;/** * Created by littlehui on 2017/11/9. */public class ConcreteTarget implements Target &#123; public void doTargetThings(String value) &#123; System.out.println("value is:" + value); &#125;&#125; Client:12345678910111213141516171819package com.littlehui.design.adapter;import com.littlehui.design.adapter.source.Adaptee;import com.littlehui.design.adapter.source.Adapter;import com.littlehui.design.adapter.target.ConcreteTarget;import com.littlehui.design.adapter.target.Target;/** * Created by littlehui on 2017/11/9. */public class Client &#123; public static void main(String[] args) &#123; Target target = new ConcreteTarget(); Target adaTarget = new Adapter(new Adaptee()); target.doTargetThings("意外"); adaTarget.doTargetThings("意外"); &#125;&#125; 以上利用组合的方式，以修改的接口包装适配者。这种实现方式称之为对象的适配器。它带来的有点是：被适配者的任意子类，都可以搭配适配器使用。 场景以Java举例，早先JDK里使用了枚举器（Enumeration)随着版本的更迭后来被 迭代器(Iterator)取代了。为了兼容之前的接口，枚举器仍然被保留着。并且枚举器添加了删除元素的接口。如果遇到保留着 枚举器的客户端代码，依赖于枚举接口，完全可以使用适配器模式将迭代器转换成枚举。 总结设计模式的原则有一条：组合优于继承。体现在适配器模式上就有两种适配方式。组合的称之为 对象时适配模式，继承的称之为对象适配模式。组合的有点是不仅可以适配某个类，还可以适配这个类的子类属于垂直扩展。类适配器不需要重新实现整个适配者。必要的时候覆盖被适配行为就可以。两种各有优劣。站在java的角度思考，类适配多更需要多继承的方式（虽然也可以用接口）。java不支持多继承。所以 建议使用对象适配。既组合。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列：概况]]></title>
    <url>%2F2017%2F10%2F25%2Fjava%2Fpatterndesign%2Fparterndesign_0%2F</url>
    <content type="text"><![CDATA[概况 设计模式是对于Java变成过程中遇到的特定抽象场景总结出的一套通用方法,常用的用23种几年模式。 分类总体来说设计模式分为三大类： 创建型模式，共五种： 工厂方法模式 定义一个创建对象的接口，让子类决定将哪一个类实例化。使一个类实例化延迟到子类。 抽象工厂模式 提供一个创建一系列产品或相互依赖对象接口无需指定具体的类。 单例模式 保证一个类仅有一个实例，并提供一个访问它的全局访问。 建造者模式 将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 原型模式 用原型实例指定创建对象的种类，并且通过拷贝这个原型来创建新的对象。 结构型模式，共七种： 适配器模式 将一个类的接口转换成客户希望的另一个接口，Adapter使原本由于接口不兼容而不能正常工作的类可以正常工作。 装饰器模式 动态地给一个对象添加一些额外的职责，就扩展功能而言，它比生成子类方式更加灵活。 代理模式 为其他对象提供一个代理以控制对这个对象的访问。 外观模式 为子系统中的一组接口提供一个一致的界面，Facade模式定义一个高层接口，这个接口使得这一子系统更加容易使用。 桥接模式 将抽象部分与实现部分分离，使它们可以独立变化。 组合模式 将对象组合成树形结构以表示 “部分-整体”的层次结构。它使得客户对单个对象和符合对象的使用具有一致性。 享元模式 运用共享技术有效支持大量细粒度对象。 行为型模式，共十一种： 策略模式 定义一系列算法，把他们封装起来，并且使它们可以相互替换，本模式使得算法的变化可以独立与使用它的客户端。 模板方法模式 定义一个操作中的算法骨架，而将一些步骤延迟到子类，Template Method使得子类可以不改变一个算法结构即可重新定义该算法某些特定步骤。 观察者模式 定义对象间的一种一对多的依赖关系，以便当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并自动刷新。 迭代器模式 提供一种方法顺序访问一个聚合对象中各个元素而又不暴露该对象内部表示。 责任链模式 为接触请求的发送者和接受者之间的耦合，而使多个对象都有机会处理这个请求。将这些对象连成一条链，并沿着这条连传递该请求，知道有一个对象处理。 命令模式 将一个请求封装为一个对象，从而使可以用不同的请求对客户进行参数化，对请求排队或记录请求日志，以及支持可取消操作。 备忘录模式 在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，这样以后就可将该对象回复到保存的状态。 状态模式 允许一个对象在其内部状态改变时改变它的行为，对象看起来似乎属于一个新的类。 访问者模式 表示一个作用于某对象结构中的各元素的操作。它使你可以在不改变各元素的类的前提下定义作用于这些元素的新操作。 中介者模式用一个中介对象来封装一系列对象交互，中介者使各对象不需要显示的相互引用，从而使得其耦合松散，而且可以独立的改变他们之间的交互。 解释器模式给定一个语言，定义它的文法的一种表示，并定义一个解释器，该解释器使用该表示来解释语言中句子。原则 开闭原则（Open Close Principle） 开闭原则就是说对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。 里氏代换原则（Liskov Substitution Principle） 子类的能力必须大于等于父类，即父类可以使用的方法，子类都可以使用。 返回值也是同样的道理。假设一个父类方法返回一个List，子类返回一个ArrayList，这当然可以。如果父类方法返回一个ArrayList，子类返回一个List，就说不通了。这里子类返回值的能力是比父类小的。 还有抛出异常的情况。任何子类方法可以声明抛出父类方法声明异常的子类。而不能声明抛出父类没有声明的异常。一句话理解：所有使用父类的地方都可以被子类替换 依赖倒转原则（Dependence Inversion Principle） 面向接口编程，依赖于抽象而不依赖于具体。 接口隔离原则（Interface Segregation Principle） 使用多个隔离的接口，比使用单个接口要好。还是一个降低类之间的耦合度的意思，从这儿我们看出，其实设计模式就是一个软件的设计思想， 从大型软件架构出发，为了升级和维护方便。所以上文中多次出现：降低依赖，降低耦合。 迪米特法则（最少知道原则）（Demeter Principle）一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。 合成复用原则（Composite Reuse Principle） 当聚合和继成都可以实现时候，应该使用聚合。聚合由于继承。 总结 上面提到的23种是经典和常用的模式。在实际生产中按照需求总结提取使用。有利于提高代码和程序功能的扩展维护性。然而也不能一味的以使用模式而是用，这就本末倒置了。随着更深入的理解和学习设计模式，会渐渐意识到：设计模式真正的的模式是 “无模式”。看似无招胜似有招。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列：原型模式]]></title>
    <url>%2F2017%2F10%2F25%2Fjava%2Fpatterndesign%2Fparterndesign_5%2F</url>
    <content type="text"><![CDATA[概念 原型模式是特殊的创建模式，它创建对象不通过直接new的方式产生，而是通过已有的对象复制。 实现浅拷贝 类图： Product123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class Product implements Serializable &#123; private String name; private String value; private ProductB productB; public ProductB getProductB() &#123; return productB; &#125; public void setProductB(ProductB productB) &#123; this.productB = productB; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; public void display() &#123; System.out.println("product name:" + this.name); System.out.println("product value:" + this.value); System.out.println("productB name:" + this.productB.getName()); &#125; public Product deepClone()&#123; try &#123; ByteArrayOutputStream bo = new ByteArrayOutputStream(); ObjectOutputStream oo = new ObjectOutputStream(bo); oo.writeObject(this); ByteArrayInputStream bi = new ByteArrayInputStream(bo.toByteArray()); ObjectInputStream oi = new ObjectInputStream(bi); return (Product)oi.readObject(); &#125; catch (IOException | ClassNotFoundException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); return null; &#125; &#125;&#125; ProductB123456789101112public class ProductB implements Serializable &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; Client12345678910111213141516public class Client &#123; public static void main(String[] args) &#123; Product product = new Product(); ProductB productB = new ProductB(); productB.setName("B"); product.setName("X"); product.setValue("XX"); product.setProductB(productB); Product clone = product.deepClone(); clone.getProductB().setName("newXX"); product.display(); clone.display(); &#125;&#125; 执行结果：Connected to the target VM, address: ‘127.0.0.1:58904’, transport: ‘socket’product name:Xproduct value:XXproductB name:Bproduct name:Xproduct value:XXproductB name:newXXDisconnected from the target VM, address: ‘127.0.0.1:58904’, transport: ‘socket’ 深拷贝 类图： Product1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class Product implements Cloneable &#123; private String name; private String value; private ProductB productB; public ProductB getProductB() &#123; return productB; &#125; public void setProductB(ProductB productB) &#123; this.productB = productB; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; public void display() &#123; System.out.println("product name:" + this.name); System.out.println("product value:" + this.value); System.out.println("productB name:" + this.productB.getName()); &#125; public Product clone() &#123; try &#123; return (Product)super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; ProductB123456789101112public class ProductB &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; Client12345678910111213141516public class Client &#123; public static void main(String[] args) &#123; Product product = new Product(); ProductB productB = new ProductB(); productB.setName("B"); product.setName("X"); product.setValue("XX"); product.setProductB(productB); Product clone = product.clone(); clone.getProductB().setName("newXX"); product.display(); clone.display(); &#125;&#125; 执行结果：Connected to the target VM, address: ‘127.0.0.1:58962’, transport: ‘socket’product name:Xproduct value:XXproductB name:newXXproduct name:Xproduct value:XXproductB name:newXXDisconnected from the target VM, address: ‘127.0.0.1:58962’, transport: ‘socket’ 场景总结 浅拷贝 拷贝后的对象如果有嵌套的复杂对象，那么改变嵌套对象会跟着改变。只拷贝表层的对象信息。深拷贝，是所有的都拷贝，包括嵌套对象。这里的实现是通过序列化的方式实现。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列：建造者模式]]></title>
    <url>%2F2017%2F10%2F25%2Fjava%2Fpatterndesign%2Fparterndesign_4%2F</url>
    <content type="text"><![CDATA[概念 当要创建的对象相对复杂，可以将复杂对象的创建过程分离成若干过程。此时只要改变不同过程中的参数就可以产生不同的实例。 实现 类图 代码Builder12345678910public interface Builder &#123; public void buildProductPartA(); public void buildProductPartB(); public void buildProductPartC(); public Product buildProduct();&#125; Director123456789public class Director &#123; public Product constructProduct(Builder productBuilder)&#123; productBuilder.buildProductPartA(); productBuilder.buildProductPartB(); productBuilder.buildProductPartC(); return productBuilder.buildProduct(); &#125;&#125; ProductBuilder12345678910111213141516171819202122232425public class ProductBuilder implements Builder &#123; private Product product; @Override public void buildProductPartA() &#123; &#125; @Override public void buildProductPartB() &#123; &#125; @Override public void buildProductPartC() &#123; &#125; @Override public Product buildProduct() &#123; return null; &#125;&#125; Product123public class Product &#123;&#125; Client1234567public class Client &#123; public static void main(String[] args) &#123; Director director = new Director(); director.constructProduct(new ProductBuilder()); &#125;&#125; 场景我们看饮料机的工作步骤可以分为 倒入水，倒入饮料剂，制造饮料。定义一个饮料机就可以当做建造饮料的过程。 总结 建造者模式的核心是把类的创建过程分解成一个个过程。每个过程是一个单独的执行流程，可以通过不同参数指定流程的结果。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列：抽象工厂模式]]></title>
    <url>%2F2017%2F10%2F25%2Fjava%2Fpatterndesign%2Fparterndesign_3%2F</url>
    <content type="text"><![CDATA[概念 抽象工厂模式在原有的工厂方法模式上扩展，在工厂方面进行了抽象。从而增加产品规格的需求，可以更高地抽象成增加工厂类型。降低了耦合。 实现类图 代码Factory123456public interface Factory &#123; public Product createSoftProduct(); public Product createHardProduct();&#125; FactoryA123456789101112public class ProductFactoryA implements Factory &#123; public Product createSoftProduct() &#123; System.out.println("工厂A:"); return new SoftProductA(); &#125; public Product createHardProduct() &#123; System.out.println("工厂A:"); return new HardProductA(); &#125;&#125; FactoryB12345678910111213public class ProductFactoryB implements Factory &#123; public Product createSoftProduct() &#123; System.out.println("工厂B:"); return new SoftProductB(); &#125; public Product createHardProduct() &#123; System.out.println("工厂B:"); return new HardProductB(); &#125;&#125; Product123public interface Product &#123; public String getName();&#125; ProductB123456public class ProductB implements Product &#123; public String getName() &#123; return "我是产品B"; &#125;&#125; SoftProductB12345678910public class SoftProductB extends ProductB &#123; public SoftProductB() &#123; System.out.println("创建 产品B:特性:柔软"); &#125; public String getName() &#123; return super.getName() + "柔软"; &#125;&#125; HardProductB123456789public class HardProductB extends ProductB &#123; public HardProductB() &#123; System.out.println("创建 产品B:特性:坚硬"); &#125; public String getName() &#123; return super.getName() + "坚硬"; &#125;&#125; ProductA123456public class ProductA implements Product &#123; public String getName() &#123; return "我是产品A"; &#125;&#125; SoftProductA12345678910public class SoftProductA extends ProductA &#123; public SoftProductA() &#123; System.out.println("创建 产品A:特性:柔软"); &#125; public String getName() &#123; return super.getName() + "柔软"; &#125;&#125; HardProductA12345678910public class HardProductA extends ProductA &#123; public HardProductA() &#123; System.out.println("创建 产品A:特性:坚硬"); &#125; public String getName() &#123; return super.getName() + "坚硬"; &#125;&#125; Client12345678910111213141516public class Client &#123; public static void main(String[] args) &#123; Factory factoryA = new ProductFactoryA(); Factory factoryB = new ProductFactoryB(); Product productAHard = factoryA.createHardProduct(); System.out.println(productAHard.getName()); Product productBHard = factoryB.createHardProduct(); System.out.println(productBHard.getName()); Product productASoft = factoryA.createSoftProduct(); System.out.println(productASoft.getName()); Product productBSoft = factoryB.createSoftProduct(); System.out.println(productBSoft.getName()); &#125;&#125; 场景如上产品 族 A B都有两个子类型，或者说特性。Hard or Soft。如果某个时候业务需求添加产品族C。此时扩展就很方便了，只要实现产品C的工厂类，就可以。不用修改原来的代码，耦合度低。 总结 抽象工厂优点: 扩展产品族（类型）容易缺点: 扩展产品族下的子产品难，需要整体结构调整。]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列：工厂方法模式]]></title>
    <url>%2F2017%2F10%2F25%2Fjava%2Fpatterndesign%2Fparterndesign_2%2F</url>
    <content type="text"><![CDATA[概念 工厂与一类产品的关系。用于调用端从复杂的构造逻辑中解耦。 实现简单工厂模式产品：Product1234public interface Product &#123; public void methodOne(); public void methodTwo();&#125; ProductA12345678public class ProductA implements Product &#123; public void methodOne() &#123; System.out.print("A产品方法1"); &#125; public void methodTwo() &#123; System.out.print("A产品方法2"); &#125;&#125; ProductB12345678public class ProductB implements Product &#123; public void methodOne() &#123; System.out.print("B产品方法1"); &#125; public void methodTwo() &#123; System.out.print("B产品方法2"); &#125; &#125; 工厂：Factory123public interface Factory &#123; public Product createProduct(String type);&#125; SimpleFactory123456789101112public class SimpleFactory implements Factory &#123; public Product createProduct(String type) &#123; switch (type) &#123; case "A": return new ProductA(); case "B": return new ProductB(); default: return null; &#125; &#125;&#125; PS：这里用Java7的写法，switch支持String。 客户端：Client123456789public class Client &#123; public static void main(String[] args) &#123; Factory factory = new SimpleFactory(); Product product = factory.createProduct("A"); product.methodOne(); product.methodTwo(); //业务代码 &#125;&#125; 场景A是一个接口，它的实现由 ClassA1,ClassA2,ClassA3。B是一段业务代码，需要new一个A1并且进行操作。这时候就可以用工厂模式。某天业务的修改，需操作到另外一个ClassA2的方法。在工厂类进行修改就可以了。业务端代码就不用修改。 总结 工厂方法模式有良好的封装性，代码结构清晰。扩展性非常优秀。在增加产品类的情况下，只要适当地修改具体或扩展工厂类即可。调用者它只需要关心产品的接口。 可以对调用端调用复杂的构造逻辑进行解耦。]]></content>
      <categories>
        <category>Java</category>
        <category>设计模式</category>
        <category>工厂方法</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式系列：单例模式]]></title>
    <url>%2F2017%2F10%2F23%2Fjava%2Fpatterndesign%2Fparterndesign_1%2F</url>
    <content type="text"><![CDATA[概念单例模式，顾名思义就是在Java应用中，类的实例保证只有一个在JVM中。他有几个好处 减少创建开销 减少内存使用频率，GC压力 保证流程独立 实现第一种 饿汉法123456789101112public class Singleton &#123; private static Singleton singleton = new Singleton(); private Singleton() &#123; &#125; public static Singleton getSignleton()&#123; return singleton; &#125;&#125; 代码简单，但是无法延迟加载。 第二种 单线程安全1234567891011public class Singleton &#123; private static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 这种方式可以实现基本要求，但是在多线程情况下就会出现可能New出多个实例的情况。由此引入synchronized关键字，我们有如下实现： 第三种 多线程安全123456789101112131415public class Singleton &#123; private static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125; &#125; 第二种方法引入了syncronized 关键字，在调用getInstance方法的时候进行了并发处理。然而在多线程情况下仍然有问题情况如下： a&gt;A、B线程同时进入了第一个if判断 b&gt;A首先进入synchronized块，由于instance为null，所以它执行instance = new Singleton(); c&gt;在new对象的过程中，由于JVM的优化，指令进行重排序，JVM先画出了一些分配给Singleton实例的空白内存，并赋值给instance成员（注意此时JVM没有开始初始化这个实例），然后A离开了synchronized块。 d&gt;B进入synchronized块，由于instance此时不是null，因此它马上离开了synchronized块并将结果返回给调用该方法的程序。 e&gt;此时B线程打算使用Singleton实例，却发现它没有被初始化，于是错误发生了。 这里引入volatile关键字禁止对instance操作的指令重排。 第四种 多线程安全”多重锁检查””123456789101112131415public class Singleton &#123; private volatile static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125; &#125; 这种方法就是有名的DCL的单利模式。基本已经完善多线程下的单例模式。需要提醒的是， volatile屏蔽指令重排的语义在JDK 1.5中才被修复，所以JDK1.5之前的JAVA无法使用这一方式。 第五种 静态内部类方法静态类方法：1234567891011public class Singleton &#123; private static class Holder &#123; private static Singleton singleton = new Singleton(); &#125; private Singleton()&#123;&#125; public static Singleton getSingleton()&#123; return Holder.singleton; &#125;&#125; 类只加载一次，所以这中方式也是线程安全的。不过以上的方法都存在一些问题： 进行序列化时需要额外的工作进行序列化(Serializable,transient,readResolve())等操作。否则每次序列化都是创建一个新的实例。 构造器虽然是私有的，但是还是可以通过反射来强行调用创建实例。一个方法是在构造器里判断已经创建过实例抛异常。如何更优雅地解决以上两个缺陷呢，我们可以使用枚举单例。 第六种 枚举方法12345678910public enum Singleton &#123; INSTANCE; private String name; public String getName()&#123; return name; &#125; public void setName(String name)&#123; this.name = name; &#125;&#125; 枚举不仅线程安全，防止反射强行调用构造器外。还提供了自动化序列机制，繁殖序列化的时候创建新对象。更接近与”完美”的单利模式。 场景程序执行时候只需要一个实例执行的时候就可以用单例来：经典的场景有:线程池，驱动管理，通用的计算模块，工具类代码等等 总结 单例模式既熟悉，又陌生。看起来简单的功能，算法，要写好，无瑕疵，还是需要很大专研精神。避免遇到快很多坑。]]></content>
      <categories>
        <category>Java</category>
        <category>设计模式</category>
        <category>单例</category>
      </categories>
      <tags>
        <tag>设计模式，单例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM系列：JVM内存优化实例]]></title>
    <url>%2F2017%2F10%2F11%2Fjava%2Fjvm%2Fjvm_3%2F</url>
    <content type="text"><![CDATA[优化实例java application项目（非web项目） 改进前：1234567891011-Xms128m-Xmx128m-XX:NewSize=64m-XX:PermSize=64m-XX:+UseConcMarkSweepGC-XX:CMSInitiatingOccupancyFraction=78-XX:ThreadStackSize=128-Xloggc:logs/gc.log-Dsun.rmi.dgc.server.gcInterval=3600000-Dsun.rmi.dgc.client.gcInterval=3600000-Dsun.rmi.server.exceptionTrace=true 问题:permsize 设置较小,很容易达到报警范围(0.8)没有设置MaxPermSize，堆增长会带来额外压力。NewSize较大，old gen 剩余空间64m，一方面可能会带来old区容易增长到报警范围（监控数据显示oldgenused长期在50m左右，接近78%，容易出现full gc）,另一方面也存在promontion fail风险改进后：1234567891011121314151617181920212223-Xms128m-Xmx128m-Xmn24m-XX:PermSize=80m-XX:MaxPermSize=80m-Xss256k-XX:SurvivorRatio=1-XX:MaxTenuringThreshold=20-XX:+UseParNewGC-XX:+UseConcMarkSweepGC-XX:CMSInitiatingOccupancyFraction=75-XX:+UseCMSCompactAtFullCollection-XX:+CMSParallelRemarkEnabled-XX:CMSFullGCsBeforeCompaction=2-XX:SoftRefLRUPolicyMSPerMB=0-XX:+PrintClassHistogram-XX:+PrintGCDetails-XX:+PrintGCTimeStamps-XX:+PrintHeapAtGC-Xloggc:logs/gc.log-Dsun.rmi.dgc.server.gcInterval=3600000-Dsun.rmi.dgc.client.gcInterval=3600000-Dsun.rmi.server.exceptionTrace=true 修改点：PermSize与MaxPermSize都设置为80，一方面避免non heap warn(报警阀值0.8 非对内存一般占用到60M以内），一方面避免堆伸缩带来的压力通过设置Xmn=24M及SurvivorRatio=1 使得Eden区=from space=to space=8M,降低了Eden区大小，降低YGC的时间(降低到3-4ms左右),同时通过设MaxTenuringThreshold=20，使得old gen的增长很缓慢。带来的问题是YGC的次数明显提高了很多。其他参数优化 修改后带来的好处见JVM参数设置再次改进后1234567891011121314151617181920212223-Xms128m-Xmx128m-Xmn36m-XX:PermSize=80m-XX:MaxPermSize=80m-Xss256k-XX:SurvivorRatio=1-XX:MaxTenuringThreshold=20-XX:+UseParNewGC-XX:+UseConcMarkSweepGC-XX:CMSInitiatingOccupancyFraction=73-XX:+UseCMSCompactAtFullCollection-XX:+CMSParallelRemarkEnabled-XX:CMSFullGCsBeforeCompaction=2-XX:SoftRefLRUPolicyMSPerMB=0-XX:+PrintClassHistogram-XX:+PrintGCDetails-XX:+PrintGCTimeStamps-XX:+PrintHeapAtGC-Xloggc:logs/gc.log-Dsun.rmi.dgc.server.gcInterval=3600000-Dsun.rmi.dgc.client.gcInterval=3600000-Dsun.rmi.server.exceptionTrace=true 修改点： 在上面的基础上调整Xmn大小到36M，设置CMSInitiatingOccupancyFraction=73。 Dden区与Survivor区大小都增加到12M，通过CMSInitiatingOccupancyFraction计算公式,计算得出value为73是，可以避免promotion faild问题，同时满足堆内存监控报警值在80%：内存大小128M*80%=102.4M 102.4M-36M=66.4M(老生代达到此值报警） 老生代达到67.15M（92M*0.73）将发生Full GC，所以在老生代大小达到66.4M时也就是WARN报警时将很有可能出现Full GC。 增大了Eden和Survivor区的值，会减小YGC的次数，但由于空间变大理论上也会相应的增加YGC的时间，不过由于新生代本身就很小（才36M）这点儿变化可以忽略掉。实际的监控值显示YGC的时间在4-5ms之间。是可以接受范围。 SurvivorRatio 这个值还得在仔细考虑下,有待优化中 网上某个牛人的配置 :每天几百万pv一点问题都没有，网站没有停顿12345678910111213141516171819202122232425262728$JAVA_ARGS.=&quot;-Dresin.home=$SERVER_ROOT-server-Xms6000M-Xmx6000M-Xmn500M-XX:PermSize=500M-XX:MaxPermSize=500M-XX:SurvivorRatio=65536-XX:MaxTenuringThreshold=0-Xnoclassgc-XX:+DisableExplicitGC-XX:+UseParNewGC-XX:+UseConcMarkSweepGC-XX:+UseCMSCompactAtFullCollection-XX:CMSFullGCsBeforeCompaction=0-XX:+CMSClassUnloadingEnabled-XX:-CMSParallelRemarkEnabled-XX:CMSInitiatingOccupancyFraction=90-XX:SoftRefLRUPolicyMSPerMB=0-XX:+PrintClassHistogram-XX:+PrintGCDetails-XX:+PrintGCTimeStamps-XX:+PrintHeapAtGC-Xloggc:log/gc.log&quot;; 说明一下， -XX:SurvivorRatio=65536 -XX:MaxTenuringThreshold=0就是去掉了救助空间；-Xnoclassgc禁用类垃圾回收，性能会高一点；-XX:+DisableExplicitGC禁止System.gc()，免得程序员误调用gc方法影响性能；-XX:+UseParNewGC，对年轻代采用多线程并行回收，这样收得快；带CMS参数的都是和并发回收相关的，不明白的可以上网搜索；CMSInitiatingOccupancyFraction，这个参数设置有很大技巧，基本上满足(Xmx-Xmn)(100-CMSInitiatingOccupancyFraction)/100&gt;=Xmn就不会出现promotion failed。在我的应用中Xmx是6000，Xmn是500，那么Xmx-Xmn是5500兆，也就是年老代有5500兆，CMSInitiatingOccupancyFraction=90说明年老代到90%满的时候开始执行对年老代的并发垃圾回收（CMS），这时还剩10%的空间是550010%=550兆，所以即使Xmn（也就是年轻代共500兆）里所有对象都搬到年老代里，550兆的空间也足够了，所以只要满足上面的公式，就不会出现垃圾回收时的promotion failed；SoftRefLRUPolicyMSPerMB这个参数我认为可能有点用，官方解释是softly reachable objects will remain alive for some amount of time after the last time they were referenced. The default value is one second of lifetime per free megabyte in the heap，我觉得没必要等1秒；123456789101112131415161718192021222324-Xmx4000M-Xms4000M-Xmn600M-XX:PermSize=500M-XX:MaxPermSize=500M-Xss256K-XX:+DisableExplicitGC-XX:SurvivorRatio=1-XX:+UseConcMarkSweepGC-XX:+UseParNewGC-XX:+CMSParallelRemarkEnabled-XX:+UseCMSCompactAtFullCollection-XX:CMSFullGCsBeforeCompaction=0-XX:+CMSClassUnloadingEnabled-XX:LargePageSizeInBytes=128M-XX:+UseFastAccessorMethods-XX:+UseCMSInitiatingOccupancyOnly-XX:CMSInitiatingOccupancyFraction=80-XX:SoftRefLRUPolicyMSPerMB=0-XX:+PrintClassHistogram-XX:+PrintGCDetails-XX:+PrintGCTimeStamps-XX:+PrintHeapAtGC-Xloggc:log/gc.log 改进方案：上面方法不太好，因为没有用到救助空间，所以年老代容易满，CMS执行会比较频繁。我改善了一下，还是用救助空间，但是把救助空间加大，这样也不会有promotion failed。具体操作上，32位Linux和64位Linux好像不一样，64位系统似乎只要配置MaxTenuringThreshold参数，CMS还是有暂停。为了解决暂停问题和promotion failed问题，最后我设置-XX:SurvivorRatio=1 ，并把MaxTenuringThreshold去掉，这样即没有暂停又不会有promotoin failed，而且更重要的是，年老代和永久代上升非常慢（因为好多对象到不了年老代就被回收了），所以CMS执行频率非常低，好几个小时才执行一次，这样，服务器都不用重启了。某网友:123456789101112131415161718192021222324252627282930$JAVA_ARGS.=&quot;-Dresin.home=$SERVER_ROOT-server-Xmx3000M-Xms3000M-Xmn600M-XX:PermSize=500M-XX:MaxPermSize=500M-Xss256K-XX:+DisableExplicitGC-XX:SurvivorRatio=1-XX:+UseConcMarkSweepGC-XX:+UseParNewGC-XX:+CMSParallelRemarkEnabled-XX:+UseCMSCompactAtFullCollection-XX:CMSFullGCsBeforeCompaction=0-XX:+CMSClassUnloadingEnabled-XX:LargePageSizeInBytes=128M-XX:+UseFastAccessorMethods-XX:+UseCMSInitiatingOccupancyOnly-XX:CMSInitiatingOccupancyFraction=70-XX:SoftRefLRUPolicyMSPerMB=0-XX:+PrintClassHistogram-XX:+PrintGCDetails-XX:+PrintGCTimeStamps-XX:+PrintHeapAtGC-Xloggc:log/gc.log&quot;; 64位jdk参考设置，年老代涨得很慢，CMS执行频率变小，CMS没有停滞，也不会有promotion failed问题，内存回收得很干净 总结 打印并分析进行垃圾回收的时间，内容，具体数值。如果有OOM导出OOM时内存使用情况。 分析垃圾回收时候的数据信息，（年轻区，年老区，方法区）查看OOM时内存使用情况。 优化的权重顺序可以按照，FullGc&gt;频繁YGC]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM系列：JVM内存优化建议]]></title>
    <url>%2F2017%2F10%2F09%2Fjava%2Fjvm%2Fjvm_2%2F</url>
    <content type="text"><![CDATA[优化原则JAVA程序在运行时 加快GC速度 减少FullGC 减少停顿 杜绝GC出错 GC优化的策略本质上JVM运行中通过参数的变换调和达到运行平衡的过程。it is an art. 经验配置 垃圾搜集器新生代收集器：有Serial收集器、ParNew收集器、Parallel Scavenge收集器老生代收集器：Serial Old收集器、Parallel Old收集器、CMS收集器、G1收集器以上所有的垃圾收集器都会发生STW，只不过FGC的STW时间更长。 常用搜集器： CMSGC CMS(Concurrent Mark-Sweep)是以牺牲吞吐量为代价来获得最短回收停顿时间的垃圾回收器。对于要求服务器响应速度的应用上，这种垃圾回收器非常适合，因此我们又叫它低延迟垃圾收集器。在启动JVM参数加上-XX:+UseConcMarkSweepGC ，这个参数表示对于老年代的回收采用CMS，注意此时新生代默认使用的是ParNew。CMS采用的基础算法是：标记—清除。 MSCGC vs CMSGC 和普通序列化整理（MSC）区别在于有三个mark阶段（实际上还有个预清理过程，但对于解释清楚CMSGC没有帮助就忽略了）。CMSGC的精髓在于因为做到了不STW的情况下进行mark，我们得到了更短的总STW时间，代价是因为并行mark产生了『脏数据』即在mark的同时又生成了需要mark的对象，我们必须再进行一次STW，并收尾（remark）。同时，我们要注意到得到更短的STW的同时，我们牺牲了系统吞吐量，CMSGC总吞吐量比ParOld要更低。 G1GC 作为最新的垃圾收集器，有可能在jdk9中成为默认的垃圾收集器。主要思路是将新生代老生代进一步分为多个region，每次gc可以针对部分region而不是整个堆内存。由此可以降低stw的单次最长时间，代价是可能在总时间上会更高。G1GC让系统在整体吞吐量略降的情况下变得更加平滑稳定。 响应时间优先的应用 年轻代选择尽可能设大,直到接近系统的最低响应时间限制(根据实际情况选择).在此种情况下,年轻代收集发生的频率也是最小的.同时,减少到达年老代的对象. 年老代选择年老代使用并发收集器,所以其大小需要小心设置,一般要考虑并发会话率和会话持续时间等一些参数.如果堆设置小了,可以会造成内存碎片,高回收频率以及应用暂停而使用传统的标记清除方式;如果堆大了,则需要较长的收集时间.最优化的方案,一般需要参考以下数据获得: 并发垃圾收集信息. 持久代并发收集次数. 传统GC信息. 花在年轻代和年老代回收上的时间比例。吞吐量优先的应用 年轻代选择尽可能的设置大,可能到达Gbit的程度.因为对响应时间没有要求,垃圾收集可以并行进行,一般适合8CPU以上的应用.避免设置过小.当新生代设置过小时会导致: YGC次数更加频繁 可能导致YGC对象直接进入旧生代,如果此时旧生代满了,会触发FGC. 年老代选择一般吞吐量优先的应用都有一个很大的年轻代和一个较小的年老代.这样可以尽可能回收掉大部分短期对象,减少中期的对象,而年老代尽存放长期存活对象. 碎片问题因为年老代的并发收集器使用标记,清除算法,所以不会对堆进行压缩.当收集器回收时,他会把相邻的空间进行合并,这样可以分配给较大的对象.但是,当堆空间较小时,运行一段时间以后,就会出现”碎片”,如果并发收集器找不到足够的空间,那么并发收集器将会停止,然后使用传统的标记,清除方式进行回收.如果出现”碎片”,可能需要进行如下配置: -XX:+UseCMSCompactAtFullCollection:使用并发收集器时,开启对年老代的压缩.-XX:CMSFullGCsBeforeCompaction=0:上面配置开启的情况下,这里设置多少次Full GC后,对年老代进行压缩 promotion failed问题可能是两种原因产生： 1. 第一个原因是救助空间不够，救助空间里的对象还不应该被移动到年老代，但年轻代又有很多对象需要放入救助空间。 2. 第二个原因是年老代没有足够的空间接纳来自年轻代的对象；这两种情况都会转向Full GC，网站停顿时间较长。 用64位操作系统，Linux下64位的jdk比32位jdk要慢一些，但是吃得内存更多，吞吐量更大XMX和XMS设置一样大，MaxPermSize和MinPermSize设置一样大，这样可以减轻伸缩堆大小带来的压力 使用CMS的好处是用尽量少的新生代，经验值是128M－256M， 老生代利用CMS并行收集，这样能保证系统低延迟的吞吐效率。 cms的收集停顿时间非常的短，2G的内存， 大约20－80ms的应用程序停顿时间系统停顿的时候可能是GC的问题也可能是程序的问题，多用jmap和jstack查看，或者killall -3 java，然后查看java控制台日志，能看出很多问题。 如果用了缓存，那么年老代应该大一些，缓存的HashMap不应该无限制长，建议采用LRU算法的Map做缓存，LRUMap的最大长度也要根据实际情况设定。 采用并发回收时，年轻代小一点，年老代要大，因为年老大用的是并发回收，即使时间长点也不会影响其他程序继续运行，网站不会停顿JVM参数的设置(特别是 –Xmx –Xms –Xmn -XX:SurvivorRatio -XX:MaxTenuringThreshold等参数的设置没有一个固定的公式，需要根据PV old区实际数据 YGC次数等多方面来衡量。为了避免promotion faild可能会导致xmn设置偏小，也意味着YGC的次数会增多，处理并发访问的能力下降等问题。每个参数的调整都需要经过详细的性能测试，才能找到特定应用的最佳配置。 解决方方案一： 第一个原因最终解决办法是去掉救助空间，设置-XX:SurvivorRatio=65536 -XX:MaxTenuringThreshold=0即可， 第二个原因我的解决办法是设置CMSInitiatingOccupancyFraction为某个值（假设70），这样年老代空间到70%时就开始执行CMS，年老代有足够的空间接纳来自年轻代的对象。解决方案一的改进方案： 又有改进了，上面方法不太好，因为没有用到救助空间，所以年老代容易满，CMS执行会比较频繁。我改善了一下，还是用救助空间，但是把救助空间加大，这样也不会有promotion failed。具体操作上，32位Linux和64位Linux好像不一样，64位系统似乎只要配置MaxTenuringThreshold参数，CMS还是有暂停。为了解决暂停问题和promotion failed问题，最后我设置-XX:SurvivorRatio=1 ，并把MaxTenuringThreshold去掉，这样即没有暂停又不会有promotoin failed，而且更重要的是，年老代和永久代上升非常慢（因为好多对象到不了年老代就被回收了），所以CMS执行频率非常低，好几个小时才执行一次，这样，服务器都不用重启了。 -Xmx4000M -Xms4000M -Xmn600M -XX:PermSize=500M -XX:MaxPermSize=500M -Xss256K -XX:+DisableExplicitGC -XX:SurvivorRatio=1 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=0 -XX:+CMSClassUnloadingEnabled -XX:LargePageSizeInBytes=128M -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=80 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:+PrintClassHistogram -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC -Xloggc:log/gc.log CMSInitiatingOccupancyFraction值与Xmn的关系公式 上面介绍了promontion faild产生的原因是EDEN空间不足的情况下将EDEN与From survivor中的存活对象存入To survivor区时,To survivor区的空间不足，再次晋升到old gen区，而old gen区内存也不够的情况下产生了promontion faild从而导致full gc.那可以推断出：eden+from survivor &lt; old gen区剩余内存时，不会出现promontion faild的情况，即：(Xmx-Xmn)*(1-CMSInitiatingOccupancyFraction/100)&gt;=(Xmn-Xmn/(SurvivorRatior+2)) 进而推断出： CMSInitiatingOccupancyFraction &lt;=((Xmx-Xmn)-(Xmn-Xmn/(SurvivorRatior+2)))/(Xmx-Xmn)*100 例如： 当xmx=128 xmn=36 SurvivorRatior=1时 CMSInitiatingOccupancyFraction&lt;=((128.0-36)-(36-36/(1+2)))/(128-36)*100 =73.913 当xmx=128 xmn=24 SurvivorRatior=1时 CMSInitiatingOccupancyFraction&lt;=((128.0-24)-(24-24/(1+2)))/(128-24)*100=84.615… 当xmx=3000 xmn=600 SurvivorRatior=1时 CMSInitiatingOccupancyFraction&lt;=((3000.0-600)-(600-600/(1+2)))/(3000-600)*100=83.33 CMSInitiatingOccupancyFraction低于70% 需要调整xmn或SurvivorRatior值。 令： 网上一童鞋推断出的公式是：:(Xmx-Xmn)*(100-CMSInitiatingOccupancyFraction)/100&gt;=Xmn 这个公式个人认为不是很严谨，在内存小的时候会影响xmn的计算。 参考：http://www.cnblogs.com/redcreen/archive/2011/05/05/2038331.htmlhttp://www.jianshu.com/p/c9ac99b87d56]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM系列：基础概念]]></title>
    <url>%2F2017%2F09%2F28%2Fjava%2Fjvm%2Fjvm_1%2F</url>
    <content type="text"><![CDATA[jvm内存区域分三种：栈，堆，方法区。设计上Java还可以使用到直接内存，在Java NIO包里使用DirectBuffer可以显示地调用申请堆外内存。 栈 栈是基于线程执行而言的，它描述的是一个线程执行的流程路线。并且在整个业务执行流程中需要用到的各种局部变量（简单类型保存值，对象保存地址），以及基本类型。 这个路线可以认为是通过方法区的程序执行流程，按照帧（Stack Frame)的方式一压入内存，在JVM内存 看起来就是Stack的存储。 栈的配置 JVM通过 -XSS指定配置每个线程所拥有栈大小。默认值随着虚拟机版本以及操作系统影响，官网上指定： In Java SE 6, the default on Sparc is 512k in the 32-bit VM, and 1024k in the 64-bit VM. On x86 Solaris/Linux it is 320k in the 32-bit VM and 1024k in the 64-bit VM. 。 栈的大小直接影响可以创建的线程数量。 线程数 = （系统空闲内存-堆内存（-Xms, -Xmx）- perm方法区内存(-XX:MaxPermSize)) / 线程栈大小(-Xss) 如上我们可知栈设置越小，可以创建的线程数就越多，但是也是有限制的。限制有两个方便： 操作系统配置也可以限制数量。例如ubuntu里/proc/sys/kernel/threads-max设置最大线程数。 异常 调用链太长，栈不够时会抛出StackOverFlow。一般是发生了递归而产生。 堆 堆是JVM最大的内存部分，它负责存放对象实例，JVM所有对象实例都在这里。（变量，对象属性但是不包括方法里的简单类型变量）。它保存了执行所需要的 各种东西。 堆的配置 参数名称 含义 默认值 其他 -Xms 初始堆大小 物理内存的1/64(&lt;1GB) 默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制. -Xmx 最大堆大小 物理内存的1/4(&lt;1GB) 默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制 -Xmn 年轻代大小 (1.4or lator) 注意：此处的大小是（eden+ 2 survivor space).与jmap -heap中显示的New gen是不同的。整个堆大小=年轻代大小 + 年老代大小 + 持久代大小.增大年轻代后,将会减小年老代大小.此值对系统性能影响较大,Sun官方推荐配置为整个堆的3/8 -XX:NewSize 设置年轻代大小(for 1.3/1.4) -XX:MaxNewSize 年轻代最大值(for 1.3/1.4) -XX:PermSize 设置持久代(perm gen)初始值 物理内存的1/64 -XX:MaxPermSize 设置持久代最大值 物理内存的1/4 -Xss 每个线程的堆栈大小 JDK5.0以后每个线程堆栈大小为1M,以前每个线程堆栈大小为256K.更具应用的线程所需内存大小进行 调整.在相同物理内存下,减小这个值能生成更多的线程.但是操作系统对一个进程内的线程数还是有限制的,不能无限生成,经验值在3000~5000左右 一般小的应用，如果栈不很深， 应该是128k够用的大的应用建议使用256k。这个选项对性能影响比较大，需要严格的测试。（校长）和threadstacksize选项解释很类似,官方文档似乎没有解释,在论坛中有这样一句话:”-Xss is translated in a VM flag named ThreadStackSize”一般设置这个值就可以了 -XX:ThreadStackSize Thread Stack Size (0 means use default stack size) [Sparc: 512; Solaris x86: 320 (was 256 prior in 5.0 and earlier); Sparc 64 bit: 1024; Linux amd64: 1024 (was 0 in 5.0 and earlier); all others 0.] -XX:NewRatio 年轻代(包括Eden和两个Survivor区)与年老代的比值(除去持久代) -XX:NewRatio=4表示年轻代与年老代所占比值为1:4,年轻代占整个堆栈的1/5 Xms=Xmx并且设置了Xmn的情况下，该参数不需要进行设置。 -XX:SurvivorRatio Eden区与Survivor区的大小比值 设置为8,则两个Survivor区与一个Eden区的比值为2:8,一个Survivor区占整个年轻代的1/10 -XX:LargePageSizeInBytes 内存页的大小 不可设置过大， 会影响Perm的大小 =128m -XX:+UseFastAccessorMethods 原始类型的快速优化 -XX:+DisableExplicitGC 关闭System.gc() 这个参数需要严格的测试 -XX:MaxTenuringThreshold 垃圾最大年龄 如果设置为0的话,则年轻代对象不经过Survivor区,直接进入年老代. 对于年老代比较多的应用,可以提高效率.如果将此值设置为一个较大值,则年轻代对象会在Survivor区进行多次复制,这样可以增加对象再年轻代的存活 时间,增加在年轻代即被回收的概率该参数只有在串行GC时才有效. -XX:+AggressiveOpts 加快编译 -XX:+UseBiasedLocking 锁机制的性能改善 -Xnoclassgc 禁用垃圾回收 -XX:SoftRefLRUPolicyMSPerMB 每兆堆空闲空间中SoftReference的存活时间 1s softly reachable objects will remain alive for some amount of time after the last time they were referenced. The default value is one second of lifetime per free megabyte in the heap -XX:PretenureSizeThreshold 对象超过多大是直接在旧生代分配 0 单位字节 新生代采用Parallel Scavenge GC时无效另一种直接在旧生代分配的情况是大的数组对象,且数组中无外部引用对象. -XX:TLABWasteTargetPercent TLAB占eden区的百分比 1% -XX:+CollectGen0First FullGC时是否先YGC false 并行收集器相关参数 参数名称 含义 默认值 其他 -XX:+UseParallelGC Full GC采用parallel MSC 选择垃圾收集器为并行收集器.此配置仅对年轻代有效.即上述配置下,年轻代使用并发收集,而年老代仍旧使用串行收集.(此项待验证) -XX:+UseParNewGC 设置年轻代为并行收集 可与CMS收集同时使用 JDK5.0以上,JVM会根据系统配置自行设置,所以无需再设置此值 -XX:ParallelGCThreads 并行收集器的线程数 此值最好配置与处理器数目相等 同样适用于CMS -XX:+UseParallelOldGC 年老代垃圾收集方式为并行收集(Parallel Compacting) 这个是JAVA 6出现的参数选项 -XX:MaxGCPauseMillis 每次年轻代垃圾回收的最长时间(最大暂停时间) 如果无法满足此时间,JVM会自动调整年轻代大小,以满足此值. -XX:+UseAdaptiveSizePolicy 自动选择年轻代区大小和相应的Survivor区比例 设置此选项后,并行收集器会自动选择年轻代区大小和相应的Survivor区比例,以达到目标系统规定的最低相应时间或者收集频率等,此值建议使用并行收集器时,一直打开. -XX:GCTimeRatio 设置垃圾回收时间占程序运行时间的百分比 公式为1/(1+n) -XX:+ScavengeBeforeFullGC Full GC前调用YGC true Do young generation GC prior to a full GC. (Introduced in 1.4.1.) CMS相关参数 参数名称 含义 默认值 其他 -XX:+UseConcMarkSweepGC 使用CMS内存收集 测试中配置这个以后,-XX:NewRatio=4的配置失效了,原因不明.所以,此时年轻代大小最好用-Xmn设置.??? -XX:+AggressiveHeap 试图是使用大量的物理内存 长时间大内存使用的优化，能检查计算资源（内存， 处理器数量）至少需要256MB内存大量的CPU／内存， （在1.4.1在4CPU的机器上已经显示有提升） -XX:CMSFullGCsBeforeCompaction 多少次后进行内存压缩 由于并发收集器不对内存空间进行压缩,整理,所以运行一段时间以后会产生”碎片”,使得运行效率降低.此值设置运行多少次GC以后对内存空间进行压缩,整理. -XX:+CMSParallelRemarkEnabled 降低标记停顿 -XX+UseCMSCompactAtFullCollection 在FULL GC的时候， 对年老代的压缩 CMS是不会移动内存的， 因此， 这个非常容易产生碎片， 导致内存不够用， 因此， 内存的压缩这个时候就会被启用。 增加这个参数是个好习惯。 可能会影响性能,但是可以消除碎片 -XX:+UseCMSInitiatingOccupancyOnly 使用手动定义初始化定义开始CMS收集 禁止hostspot自行触发CMS GC -XX:CMSInitiatingOccupancyFraction=70 使用cms作为垃圾回收 使用70％后开始CMS收集 92 为了保证不出现promotion failed(见下面介绍)错误,该值的设置需要满足以下公式CMSInitiatingOccupancyFraction计算公式 -XX:CMSInitiatingPermOccupancyFraction 设置Perm Gen使用到达多少比率时触发 92 -XX:+CMSIncrementalMode 设置为增量模式 用于单CPU情况 -XX:+CMSClassUnloadingEnabled 辅助信息 参数名称 含义 默认值 其他 -XX:+PrintGC 输出形式:[GC 118250K-&gt;113543K(130112K), 0.0094143secs][Full GC 121376K-&gt;10414K(130112K), 0.0650971 secs] -XX:+PrintGCDetails 输出形式:[GC [DefNew: 8614K-&gt;781K(9088K), 0.0123035 secs] 118250K-&gt;113543K(130112K), 0.0124633 secs][GC [DefNew: 8614K-&gt;8614K(9088K), 0.0000665 secs][Tenured: 112761K-&gt;10414K(121024K), 0.0433488 secs] 121376K-&gt;10414K(130112K), 0.0436268 secs] -XX:+PrintGCTimeStamps -XX:+PrintGC:PrintGCTimeStamps 可与-XX:+PrintGC -XX:+PrintGCDetails混合使用 输出形式:11.851: [GC 98328K-&gt;93620K(130112K), 0.0082960 secs] -XX:+PrintGCApplicationStoppedTime 打印垃圾回收期间程序暂停的时间.可与上面混合使用 输出形式:Total time for which application threads were stopped: 0.0468229 seconds -XX:+PrintGCApplicationConcurrentTime 打印每次垃圾回收前,程序未中断的执行时间.可与上面混合使用 输出形式:Application time: 0.5291524 seconds -XX:+PrintHeapAtGC 打印GC前后的详细堆栈信息 -Xloggc:filename 把相关日志信息记录到文件以便分析.与上面几个配合使用 -XX:+PrintClassHistogram garbage collects before printing the histogram. -XX:+PrintTLAB 查看TLAB空间的使用情况 XX:+PrintTenuringDistribution 查看每次minor GC后新的存活周期的阈值 Desired survivor size 1048576 bytes, new threshold 7 (max 15) new threshold 7即标识新的存活周期的阈值为7。 方法区 又叫静态区，跟堆一样，被所有的线程共享。方法区包含所有的class和static变量；方法区中包含的都是在程序中永远的唯一的元素。特别说明的是枚举 是存放在方法区，而单例是某个类在内存中唯一的对象实例，是存放在堆中的。 配置方法 -XX:PermSize=10M -XX:MaxPermSize=10M 值得一提的是 JAVA8 将方法区 改成了 MateSpace (元数据区。) 同时 PerSize MaxPermSize参数也移除了。带来了几个新的参数： -XX:MetaspaceSize，class metadata的初始空间配额，以bytes为单位，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整：如果释放了大量的空间，就适当的降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize（如果设置了的话），适当的提高该值。 -XX:MaxMetaspaceSize，可以为class metadata分配的最大空间。默认是没有限制的。 -XX:MinMetaspaceFreeRatio,在GC之后，最小的Metaspace剩余空间容量的百分比，减少为class metadata分配空间导致的垃圾收集 -XX:MaxMetaspaceFreeRatio,在GC之后，最大的Metaspace剩余空间容量的百分比，减少为class metadata释放空间导致的垃圾收集XX:MaxMetaspaceSize总结图]]></content>
      <categories>
        <category>java</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis简介]]></title>
    <url>%2F2017%2F09%2F26%2Fredis%2Fredis_2%2F</url>
    <content type="text"><![CDATA[Redis简介 Redis 是一个非常快速的非关系内存型数据库。Redis非常有区分度的是它提供的5种不同类型的数据结构，其数据结构是有针对地为解决问题而生的数据结构，区分于其他数据库的一个显著特点。可以说，Redis核心问题和功能都围绕着五种数据结构展开的，另外，它方便的扩展功能，可以支持到数百GB级数据。 与其他数据库和软件的对比 Redis的特点决定了它在存储工具里的定位，它经常被用来与其他数据库进行对比。这里，我们介于内存键值存储 Memcached 与MongoDB对Redis进行一次比较。 名称 类型 存储 查询 附加功能 Redis 内存存储（in-memmory)的非关系数据库 字符串,列表，集合，散列表，有序集合 每种数据类型都有自己的专属命令，还有批操作和不完整的事务支持 发布与订阅，主从复制，持久化，脚本 Memcached 使用内存存储的键值缓存 键值之间的映射 创建，读取，更新删除等命令 多线程服务支持 MongoDB 硬盘存储的非关系文档存储 每个数据库可以包含多个个表，每个表包含多个schema 的BSON文档 更新，读取，删除，条件查询等命令 支持map-reduce操作，主从复制，分片，空间索引（spatial index） 使用Redis的理由Redis之于缓存界：使用memcached 时，没有原生的列表结构，只能用Append命令将数据添加到已有字符串末尾。可以认为那个字符串就是一个列表。但是删除这些就比较困难了。memcached采用的办法是通过黑名单来隐藏列表里的元素，从而避免对元素进行读取，更新，写入。相反地，Redis的LIST和SET允许用户直接添加或者删除元素。 Redis之于数据库：当数据库用于存储长期数据报告，报表。并将这些数据作为固定时间范围内聚合。数据库的做法是：将各个行插入一个报表中，通过扫描这些行进行聚合数据。这样就要频繁地对表里数据进行 读，写。Redis可以使用原子的INCR命令来进行聚合计算。并且Redis存储在内存里。并且查询不通过数据库的分析器，查询优化器等，所以对Redis存储的数据行随机写的速度是非常迅速的。Redis之于NoSql数据库：避免写入不必要的临时数据。免去了临时数据进行扫描删除的麻烦。可以改上程序的性能。]]></content>
  </entry>
  <entry>
    <title><![CDATA[HttpURLConnection Post请求自动重传机制]]></title>
    <url>%2F2017%2F09%2F26%2Fjava%2Fjava_1%2F</url>
    <content type="text"><![CDATA[背景故事 之前负责的一个商城项目，需要从供应商库进行订单下单同步，服务器间通讯通过http请求。 加密方式采用DES加密方式。在运行初期一切正常，几个月后供应商发现有重复订单存在，而客户端这边接收到异常生成订单异常信息，订单生成不同步。供应商的处理逻辑我们无从得知，只能从自身角度思考为什么会有这种问题，在排除了一系列原因后，定位到一个问题。那就是 HttpURLConnection的post请求重发机制。 场景再现Http请求是通过HttpUrlConnection封装的一套Java请求客户端 部分源码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273 //请求的header如下 protected Map&lt;String, Object&gt; getDefaultHeaders() &#123; Map&lt;String, Object&gt; defaultHeaders = new HashMap&lt;&gt;(); defaultHeaders.put("Accept", "*/*"); defaultHeaders.put("Connection", "Keep-Alive"); defaultHeaders.put("User-Agent", "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1)"); defaultHeaders.put("Accept-Charset", "utf-8"); defaultHeaders.put("Content-Type", "application/x-www-form-urlencoded;charset=utf-8"); headers = defaultHeaders; return headers; &#125;//初始化 httpConnectionprotected void initConnection() throws IOException &#123; if ("POST".equals(method)) &#123; this.url = new URL(getUrl); this.postJson = JsonUtil.toJson(param); &#125; else &#123; this.url = new URL(getUrl + urlParams); &#125; httpConnection = (HttpURLConnection) url.openConnection(); for (String keyset : headers.keySet()) &#123; httpConnection.setRequestProperty(keyset, headers.get(keyset).toString()); &#125; /** * 然后把连接设为输出模式。URLConnection通常作为输入来使用，比如下载一个Web页。 * 通过把URLConnection设为输出，你可以把数据向你个Web页传送。： */ httpConnection.setRequestMethod(method); httpConnection.setUseCaches(false); if ("POST".equals(method)) &#123; httpConnection.setDoOutput(true); &#125; else &#123; httpConnection.setDoOutput(true); &#125; httpConnection.setDoInput(true); &#125; //执行Http请求 public String doRequest() &#123; this.toUrlParams(); OutputStreamWriter out = null; try &#123; this.initConnection(); // 一旦发送成功，用以下方法就可以得到服务器的回应： String sTotalString; InputStream urlStream; out = new OutputStreamWriter(httpConnection.getOutputStream(), charSet); if (method.equals("POST")) &#123; out.write(this.postJson); //向页面传递数据。post的关键所在！ &#125; // remember to clean up out.flush(); urlStream = httpConnection.getInputStream(); logger.debug("连接状态:" + urlStream.available()); //new InputStreamReader(l_urlStream,) sTotalString = IOUtil.in2Str(urlStream, charSet); return sTotalString; &#125; catch (Exception e) &#123; e.printStackTrace(); throw new SystemException(e); &#125; finally &#123; if (out != null) &#123; try &#123; out.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new SystemException(e); &#125; &#125; httpConnection.disconnect(); &#125; &#125; Java代码调用doRequest通过HttpUrlConnection模拟一个Post请求。结果服务端会收到两次请求。 原因分析HttpURLConnection 采用 Sun 私有的一个 HTTP 协议实现类： HttpClient.java 123456789101112131415161718192021222324252627282930313233343536public boolean parseHTTP(MessageHeader var1, ProgressSource var2, HttpURLConnection var3) throws IOException &#123; try &#123; this.serverInput = this.serverSocket.getInputStream(); if(this.capture != null) &#123; this.serverInput = new HttpCaptureInputStream(this.serverInput, this.capture); &#125; this.serverInput = new BufferedInputStream(this.serverInput); return this.parseHTTPHeader(var1, var2, var3); &#125; catch (SocketTimeoutException var6) &#123; if(this.ignoreContinue) &#123; this.closeServer(); &#125; throw var6; &#125; catch (IOException var7) &#123; this.closeServer(); this.cachedHttpClient = false; if(!this.failedOnce &amp;&amp; this.requests != null) &#123; this.failedOnce = true; if(!this.getRequestMethod().equals("CONNECT") &amp;&amp; !this.streaming &amp;&amp; (!var3.getRequestMethod().equals("POST") || retryPostProp)) &#123; this.openServer(); if(this.needsTunneling()) &#123; MessageHeader var5 = this.requests; var3.doTunneling(); this.requests = var5; &#125; this.afterConnect(); this.writeRequests(this.requests, this.poster); return this.parseHTTP(var1, var2, var3); &#125; &#125; throw var7; &#125; &#125; 当发生IOException就会执行判断是否进行重试。failedOnce 默认是 false，表示是否已经失败过一次了。这也就限制了最多发送 2 次请求。var3 是请求信息retryPostProp 默认是 true ，可以通过命令行参数( -Dsun.net.http.retryPost=false )来指定值。streaming：默认 false 。 true if we are in streaming mode (fixed length or chunked) 。 bug链接：http://bugs.java.com/bugdatabase/view_bug.do?bug_id=6427251这个Bug很早就有了，归根结底原因就是sun提供的实现与Http对于Post请求的规范有不同。Http协议里Post不是幂等的，不能进行重试。 解决方案 使用Apache Client请求 修改JVM启动参数 添加：-Dsun.net.http.retryPost=false http://bugs.java.com/bugdatabase/view_bug.do?bug_id=6427251 总结心得 http协议方面：http规定的部分是规范，实现有千种方法。有的符合协议，有的又有所区别，在对接过程中，指定接入方式，形成书面文档规范。有利于后续问题职责归属。 在寻找问题方面，无法完整获取所有信息时，从已掌握的信息出发，避免任何一点得出结论的依据。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[solr 的edismax插件扩展方式]]></title>
    <url>%2F2017%2F09%2F19%2Fsearch%2Fsolr_2%2F</url>
    <content type="text"><![CDATA[前言 solr 通过插件的方式实现对edismax的支持。在熟悉了solr插件的执行流程后我，我们也可以对solr插件功能进行定制。实现更加强大的功能。 类图 ExtendedDismaxQParserPlugin NamedListInitializedPlugin 作用NameList作为solr存储map的方式，可以看成是一个key value容器。NameListInitializedPlugin是可以通过NameList初始化的插件。只有一个init方法。接收NameList参数。 SolrInfoMBean 作用提供Solr后台基础信息的Bean接口。3：QparserPlugin所有插件的父类，定义了默认方法，保存声明了所有solr已经实现的plugin。 ExtendedDismaxQparser ExtendDismaxQparser描述edismax支持的配置和方法，集合了edismax所需功能的各种操作。并创建 ExtendedSolrDismaxQueryParser,为其提供职责更为简明的操作环境。是edismax语法支持类。 ExtendSolrQueryParser QueryBuilderlucene 提供用于创建查询器的工厂类 可以被当做自定义解析器的子类，使得查询解析器更容易地集成到分析链中。生成查询可以定制化。所有默认lucene提供的query在这里创建 SolrQueryParserBaseSolr继承自QueryBuilder的类。作为Solr标准查询解析器的父类。Solr对lucene的扩展，加入了 MagicFieldName RawQuery等支持。初始化时读入 schema配置。可以修改这个类来扩展schema标签功能。 QueryParser默认的query解析器 SolrQueryParserSolr’s 的默认查询解析器schema驱动的经典lucene查询解析方式。 ExtendedSolrQueryParser作为ExtendedSolrQParser的内部类存在。实施最终的查询解析。 请求过程SolrDispatchFilter（doFilter,execute） -&gt;SolrCore.execute -&gt;RequestHandlerBase.handleRequest -&gt;SearchHandler.handleRequestBody//有可能执行多个Component//query,facet,group等等，这里每个查询特性对应每个SearchComponent-&gt;QueryComponent.process -&gt;SolrIndexSearcher(search,getDocListC) 描述edismax请求到 SearchHandler 分析调用的SearchComponent链，其中QueryComponent 通过defType选择 插件ExtendedDismaxQParserPlugin 创建queryParser初始化插件paraer QueryComponent prepare调用QParser rqparser = QParser.getParser(rankQueryString, defType, req);先解析出参数语法包含的解析器信息 QueryComponent 源码部分 关键方法: 123456789101112131415161718192021222324252627282930313233343536public static QParser getParser(String qstr, String defaultParser, SolrQueryRequest req) throws SyntaxError &#123; ... //存在字符 &#123;！需要分析参数需要什么样的查询解析器选定信息 if (qstr != null &amp;&amp; qstr.startsWith(QueryParsing.LOCALPARAM_START)) &#123; localParams = new ModifiableSolrParams(); localParamsEnd = QueryParsing.parseLocalParams(qstr, 0, localParams, globalParams); String val = localParams.get(QueryParsing.V); if (val != null) &#123; // val was directly specified in localParams via v=&lt;something&gt; or v=$arg valFollowedParams = false; &#125; else &#123; // use the remainder of the string as the value valFollowedParams = true; val = qstr.substring(localParamsEnd); localParams.set(QueryParsing.V, val); &#125; &#125; ... //localParams 语法解析出来的localParams是否需要特殊的解析器来解析查询。 if (localParams == null) &#123; parserName = defaultParser; &#125; else &#123; //显示的defType与解析出来的信息一起判断优先级来选定解析器名称 parserName = localParams.get(QueryParsing.TYPE,defaultParser); qstr = localParams.get("v"); &#125; parserName = parserName==null ? QParserPlugin.DEFAULT_QTYPE : parserName; //确定后通过名称获取解析插件 QParserPlugin qplug = req.getCore().getQueryPlugin(parserName); QParser parser = qplug.createParser(qstr, localParams, req.getParams(), req); ... return parser; &#125; 对edisMax查询操作，QueryComponet返回了 ExtendDismaxQparser 作为查询解析器作为后续的查询支持 。默认解析器 lucene 扩展功能扩展步骤：1:新建 XXPlugin 继承 QParserPlugin 实现方法： 123456//定义插件名称，用于配置指定public static String NAME = "XXXqueryPlus";@Overridepublic QParser createParser(String qstr, SolrParams localParams, SolrParams params, SolrQueryRequest req) &#123; return new XXXQParser(qstr, localParams, params, req);&#125; 2:创建XXXQParser继承QParser, XXXSolrQueryParser继承SolrQueryParser可以采用组合方式，也可以采用内部类的方式。在XXXQParser里重写 parser()方法12345678@Overridepublic Query parse() throws SyntaxError &#123; //返回具体的 查询Query //可以结合XXXSolrQueryParser方法返回. //this.parser() --&gt; XXSolrQueryParser.parser()。 //提交给 SolrQuerybase执行，只要根据需要重写 SolrQueryBase里的 // protected Query getFieldQuery(String field, String queryText, //boolean quoted, boolean raw)方法即可。&#125; 3:solrConfig里配置123456&lt;requestHandler name="standard" class="solr.SearchHandler" default="true"&gt; &lt;lst name="defaults"&gt; &lt;str name="defType"&gt;XXXqueryPlus&lt;/str&gt; &lt;/lst&gt;&lt;/requestHandler&gt;]]></content>
      <categories>
        <category>搜索</category>
      </categories>
      <tags>
        <tag>solr</tag>
        <tag>edismax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据结构介绍]]></title>
    <url>%2F2017%2F09%2F18%2Fredis%2FRedisshujujiegou%2F</url>
    <content type="text"><![CDATA[Redis数据结构介绍 Redis数据结构分为 STRING,LIST,SET,HASH,ZSET五种。与其他数据库或者缓存有相互对应关系。又有他自己的特点。 结构类型 值类型 读写能力 STRING 字符串，整数，浮点数，基本类型 对整个字符串或者字符串其中的一部分进行操作，对整数和浮点数进行自增或者自减 LIST 一个链表，链表上的每个节点都包含了一个字符串 从链表的两端推入或者弹出元素，根据偏移量对链表进行修剪，读取单个或者多个元素；根据值查找或者移除元素 SET 包含字符串的无序搜集器（unordered collection)，并且被包含的每个字符串都是独一无二，各不相同的 添加，获取，移除单个元素；检查一个元素是否存在于集合中；计算交集，并集，差集；从集合里随机获取元素 HASH 包含键值对的无序散列表 添加、获取、移除单个键值对；获取所有键值对 ZSET(有序集合) 字符串成员（member）与浮点数值（score）之间的有序映射，元素的排列顺序由分值的大小决定 添加、获取、删除、单个元素；根据分值范围（染个）或者成员来获取元素 字符串（STRING)基本操作： 命令 行为 GET 获取存储在给定键值中的值 SET 设置存储在给定键中的值 DEL 删除存储在给定键中的值（所有类型适用） 列表（List)基本操作： 命令 行为 RPUSH 给定的值推入列表的右端 LRANGE 获取列表在给定范围上的所有值 LINDEX 获取在列表给定位置上的单个元素 LPOP 从列表的左端弹出一个值，并返回被弹出的值 集合（SET） 和集合一样可以存储多个字符串，不同的是 列表中可以村粗多个相同的字符串。而集合则通过使用散列来保证自己存储的每个字符串都是各自不同的（这些散列只有键没有键值） 基本操作： 命令 行为 SADD 将给定元素添加到集合 SMEMBERS 返回集合包含的所有元素 SISMEMBER 检查给定元素是存在于集合中 SREM 如果给定的元素存在于集合中，那么移除这个元素 另外的操作SINTER,SUNION, SDIFF 分别执行交集计算、并集计算和差集计算。 散列（HASH） Redis的散列可以存储多个键值间的映射。其值，可以是字符串有可以是数字值。也可以对散列存储的值进行自增或自减。 散列在很多方面就是一个缩小版的Redis，不少字符串都有相应的散列版本。 基本操作： 命令 行为 HSET 在散列里面关联起给定的键值对 HGET 获取指定散列键的值 HGETALL 获取散列包含所有键值对 HDEL 如果给定键存在于散列里，那么移除这个键 Redis的散列可以看做文档数据库里的文档，在开发过程中可以很好的对应。在关系书库里可以看做关系数据库里的行。散列、文档、数据行这三者都允许用户同时访问或者修改一个火多个域。 有序集（ZSET） 和散列一样，有序集都用于存储键值对：有序集合的键称为 成员（member）每个成员都各不相同；有序集的值被称为分值（score）必须为浮点数。是唯一一个可以根据成员访问元素，又可以根据分值以及分值的排序来访问元素的结构。 基本操作： 命令 行为 ZADD 将一个带有给定成分值的成员添加到有序集合里 ZRANGE 根据元素在有序排列中所处处的位置，从有序集合中获取多个元素 ZRANGEBYSCORE 获取有序集合给定分值范围内的所有属性 ZREM 如果给定成员存在，移除这个成员]]></content>
      <categories>
        <category>缓存</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql缓存与Memcached,Redis区别]]></title>
    <url>%2F2017%2F09%2F18%2Fmysql%2FMysql_1%2F</url>
    <content type="text"><![CDATA[前言 我们在做Web开发的时候从至上而下的技术分层里，缓存始终贯穿其中。浏览器层–》业务层–》数据库层。每个层面上的缓存都有各自的功能与场景。我们今天探讨下业务层到数据库层上缓存的功能和区别。 业务层缓存MemcachedMemcached 严格上讲还不能说是完整的分布式缓存系统。它有很多第三方工具支撑其分布式功能。Memcached 通过内部固定的大小的chunk预申请内存数据。使得分配和回收内存的效率很高。读写性能也很高。64k对象的情况下，单机QPS可以达到15W以上。Memcached 的集群架构中，单个节点对其他节点是相互独立的，没有数据方面的通信。不具备failover能力。Memcached 支持多语言，有相当的稳定性。 RedisRedis 显著的特点是不仅支持普通的K，V 类型存储，还支持其独特的 五种数据结构 详见Redis数据结构Redis 也支持集群，Redis支持的集群是Master-Slave模式。其有点是可以在宕机时切换到备份机。可用性方面有一定的提升。Redis 单纯当做缓存存储在内存时速度和Memcached不相上下。存储到硬盘时，性能和速度会下降很多，介于 Memcahced 和mysql之间。Redis 有特殊的订阅功能，使得它经常被用于当做内存队列使用。Redis 扩展方面不如Memcached，无法做到持续的线性扩容。目前支持通过复制的方式，产生一主多备架构并升级容量。 数据库层缓存mysql缓存MySQL将缓存分为Buffer缓存和Cache缓存。Buffer缓存:由于硬盘的写入速度过慢，或者频繁的I/O，对于硬盘来说是极大的效率浪费。那么可以等到缓存中储存一定量的数据之后，一次性的写入到硬盘中。Buffer 缓存主要用于写数据，提升I/O性能。Cache 缓存:Cache 是在开启缓存功能前提下，在通过的每次sql进行hash计算，生成此条sql的唯一hash作为存储的Key值。SO select是区分大小写的。生成缓存之后，如果涉及的table有任何数据的变动（整个talbe),所有的cache就会被删除。如果Cache缓存已经存储满，则启用LRU算法，进行数据淘汰。淘汰掉最远未使用的数据，从而开辟新的存储空间。不过对于特大型的网站，依靠这种策略很难缓解高频率的读请求，一般会把访问非常频繁的数据静态化，直接由nginx返还给用户。程序和数据库I/O设备交互的越少，则效率越高。 问题既然有Memcached,Redis 为什么还要用Mysql缓存呢？ 解答 从整体架构上看，Memcached和Redis支持扩展分布式缓存。适用于大型Web项目。单从单节点功能上看，Mysql由于自身的cache 删除方式。使得其缓存有相对的局限性。并且无法简单的管控。需要更好的使用的话，需要对业务上进行更详尽细致的分析。在数据库的逻辑设计层面细分出能够说回合mysql缓存的场景。单节点，数据简单，无太多修改的数据面前，但根据场景来，mysql缓存还是有一定价值的。比Memcached Redis简单易用，效率更好。 参考：https://dev.mysql.com/doc/refman/5.7/en/query-cache.html]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux expect ssh自动登录详解]]></title>
    <url>%2F2017%2F09%2F14%2Flinux%2Flinux%20expect%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[简介 Expect是用于自动化交互式应用程序的工具，如telnet，ftp，passwd，fsck，rlogin，tip等。使用起来很简单。 使用方法 首行加上/usr/bin/expect spawn: 后面加上需要执行的shell 命令，比如说spawn sudo touch testfile expect: 只有spawn 执行的命令结果才会被expect 捕捉到，因为spawn 会启动一个进程，只有这个进程的相关信息才会被捕捉到，主要包括：标准输入的提示信息，eof 和timeout。 send 和send_user：send 会将expect 脚本中需要的信息发送给spawn 启动的那个进程，而send_user 只是回显用户发出的信息，类似于shell 中的echo 而已。 实例1:远程拷贝文件1234567891011121314151617181920set timeout 10set host [lindex $argv 0]set username [lindex $argv 1]set password [lindex $argv 2]set src_file [lindex $argv 3]set dest_file [lindex $argv 4]spawn scp $src_file $username@$host:$dest_file expect &#123; &quot;(yes/no)?&quot; &#123; send &quot;yes\n&quot; expect &quot;*assword:&quot; &#123; send &quot;$password\n&quot;&#125; &#125; &quot;*assword:&quot; &#123; send &quot;$password\n&quot; &#125; &#125; expect &quot;100%&quot; expect eof 2:执行远程命令1234567891011121314151617181920set timeout 10set host [lindex $argv 0]set username [lindex $argv 1]set password [lindex $argv 2]set cmd [lindex $argv 3]spawn ssh -t -p $port $username@$host &apos;cmd&apos; expect &#123; &quot;(yes/no)?&quot; &#123; send &quot;yes\n&quot; expect &quot;*assword:&quot; &#123; send &quot;$password\n&quot;&#125; &#125; &quot;*assword:&quot; &#123; send &quot;$password\n&quot; &#125; &#125; expect &quot;100%&quot; expect eof 3：与SSH合用 123/usr/bin/expect &lt;&lt;-EOF//TODO这里写expect脚本 EOF]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[alfred结合七牛实现快速插入markdown格式图片]]></title>
    <url>%2F2017%2F09%2F13%2Fblog%2Falfred%E7%BB%93%E5%90%88%E4%B8%83%E7%89%9B%E5%AE%9E%E7%8E%B0%E5%BF%AB%E9%80%9F%E6%8F%92%E5%85%A5markdown%E6%A0%BC%E5%BC%8F%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[详细过程可以访问：https://github.com/tiann/markdown-img-upload 问题修复 由于retina截屏的图片会放大，所以在markdown脚本里做了处理：有遇到缩放的会进行指定宽度大小。所以会插入&lt;img 标签。但是这不符合markdown的图片方式，这里做了一下改进。将 计算后的size插入七牛的样式图片里就可以解决。 打开workflow的脚本修改保存1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# coding: utf-8from clipboard import get_paste_img_filefrom upload import upload_qiniuimport utilimport osimport subprocessimport sysimport timeif not os.path.exists(util.CONFIG_FILE): util.generate_config_file()config = util.read_config()if not config: util.notice('请先设置你的七牛图床信息') util.open_with_editor(util.CONFIG_FILE) sys.exit(0)url = '%s/%s' % (config['url'], config['prefix'])styleprefix = 'imageView2/2/w/'stylesubfix = '/h/640/format/jpg/q/100|watermark/2/text/d3d3LmxpbGh1aS5jb20=/font/5b6u6L2v6ZuF6buR/fontsize/400/fill/Izk2OEM4Qw==/dissolve/100/gravity/SouthEast/dx/10/dy/10|imageslim'mkdprefix='![图片]('mkdsubfix=')'img_file, need_format, format = get_paste_img_file()if img_file: # has image # use time to generate a unique upload_file name, we can not use the tmp file name upload_name = "%s.%s" % (int(time.time() * 1000), format) if need_format: size_str = subprocess.check_output('sips -g pixelWidth %s | tail -n1 | cut -d" " -f4' % img_file.name, shell=True) size = int(size_str.strip()) / 2 #markdown_url = '&lt;img src="%s/%s-1960" width="%d"/&gt;' % (url, upload_name, size) markdown_url = '%s%s/%s?%s%d%s%s' % (mkdprefix, url, upload_name, styleprefix, size, stylesubfix, mkdsubfix) else: markdown_url = '%s%s/%s-960%s' % (mkdprefix, url, upload_name, mkdsubfix) # make it to clipboard os.system("echo '%s' | pbcopy" % markdown_url) os.system('osascript -e \'tell application "System Events" to keystroke "v" using command down\'') upload_file = util.try_compress_png(img_file, format!='gif') if not upload_qiniu(upload_file.name, upload_name): util.notice("上传图片到图床失败，请检查网络后重试")else: util.notice("剪切版里没有图片！") 上面是我修改后的脚本信息，修改的地方是：1markdown_url = &apos;%s%s/%s?%s%d%s%s&apos; % (mkdprefix, url, upload_name, styleprefix, size, stylesubfix, mkdsubfix) 注意这两个变量12styleprefix = &apos;imageView2/2/w/&apos; stylesubfix =&apos;/h/640/format/jpg/q/100|watermark/2/text/d3d3LmxpbGh1aS5jb20=/font/5b6u6L2v6ZuF6buR/fontsize/400/fill/Izk2OEM4Qw==/dissolve/100/gravity/SouthEast/dx/10/dy/10|imageslim&apos; 根据自己的七牛图片拼装 markdown_url即可。我这里用的是通过改变七牛提供的链接图片 size 进行替换。中间拼装计算好的原始图片size即变成正常大小。既： styleprefix + size + stylesubfix]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>alfred</tag>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[solr高级查询edismax函数详解]]></title>
    <url>%2F2017%2F09%2F11%2Fsearch%2Fsolr%E9%AB%98%E7%BA%A7%E6%9F%A5%E8%AF%A2edismax%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[前言 最近遇到solr查询中加入字段权重的需求，自然而然地想到了edismax这个功能。通过系统的学习和文档阅读，大概了解solr 对于函数式查询的支持方式。为了便于记忆，这里对常用公式进行整理说明。 使用方式详细见官方文档介绍，这里不做说明，我们重点讲solr edismax所涉及到的函数。 bf函数列表 constant 支持小数点的常量例如，1.5，查询表达式就是：_val_:1.5 fieldvalue 返回numberic field的名字.域必须是index的，非multivalue。格式为该域的名字。如果这个域没值，就返回0 ord ord，返回你要查询的那个特定的值在这个顺序中的排名。 非multiValued的，当没有值存在的时候，将返回0 例如：某个特定的域只能去三个值，“apple”、“banana”、“pear”，那么ord（“apple”）=1，ord（“banana”）=2，ord（“pear”）=3 需要注意的是，ord（）这个函数，依赖于值在索引中的位置，所以当有文档被删除、或者添加的时候，ord（）的值就会发生变化。当你使用MultiSearcher的时候，这个值也就是不定的了。 rord 函数将会返回与ord相对应的倒排序的排名。 格式: rord(myIndexedField). sum 就是表示多个数值的“和”。 格式： sum(x,1) sum(x,y) sum(sqrt(x),log(y),z,0.5) product 多个参数的乘积，参数可以是数值，也可以是函数，当为函数时，表示为此函数的计算值乘积。 格式： product(x,2) product(x,y) div 两个参数做除法。支持函数参数 格式： div(x,y) div(sum(x,100),max(y,1)) pow 幂值计算，pow(x,y)=x^y 。支持函数参数。 格式： pow(x,0.5) 标识开方 pow(x, log(y)) abs 返回表达式的绝对值，支持函数参数。 格式： abx(-5) abc(x) log返回对数操作，支持函数参数。格式：log(x)log(sum(x,100)) sqrt返回平方根。与pow(x，0.5)一样。格式：sqrt(2)sqrt(sum(x,100)) map区间检测如果 min&lt;=x&lt;=max，那么map(x,min,max,target)=target，如果x不在[min,max]这个区间内，那么map(x,min,max,target)=x. scala限制参数区间例如：scale(x,minTarget,maxTarget) 这个函数将会把x的值限制在[minTarget,maxTarget]范围内。 query计算subquery查询分数例如：query(subquery,default)表示返回给定的subquery的分数，如果subquery与文档不匹配，那么将会返回默认值。任何的查询类型都是受支持的。可以通过引用的方式，也可以直接指定查询串。q=product(popularity, query({!dismax v=’solr rocks’})) 将会返回popularity和通过dismax 查询得到的分数的乘积q=product(popularity, query($qq)&amp;qq={!dismax}solr rocks) 跟上一个例子的效果是一样的。不过这里使用的是引用的方式q=product(popularity, query($qq,0.1)&amp;qq={!dismax}solr rocks) 在前一个例子的基础上又加了一个默认值。 linear线性函数计算例如：liner(x,m,c)其中 x为变量或者函数，m,c为常量。整个函数取值为： xm+c的值。liner(x,2,4)=2x+4 reciprecip(x,m,a,b) 函数表达式 a/(m*x+b)其中，m、a、b是常量，x是变量或者一个函数。当a=b，并且x&gt;=0的时候，这个函数的最大值是1，值的大小随着x的增大而减小。 max比较大小例如：max(x,c) x可以为变量或者函数，c为常数，返回两个之间最大值。 场景应用 某地的新闻网页库中原本的逻辑是对仓库里的数据字段 subject，message进行搜索。默认是通过score检索字段匹配得分进行排序输出。随着时间的推移，大量的搜索可能会展示两年前，三年前匹配度更高的数据，这些搜索结果明显不合适的。那么我们需要对其进行改造，加入发布时间权重排序。 原本的参数： 1subject:武则天 OR message:武则天 搜索得出结果： 文档得分： 上面我们可以看到，tid为666811的文档排在第一位，得分27.811375 它的dateline时间是：1239781944明显早于第二位 tid：10364925的 1503334472，得分：26.519054。第三位是 tid:9759987 得分：26.511488。这样的搜索结果显然不是很令人满意的。 开启edismax 加入 1bf=sqrt(log(dateline))^100 搜索得出结果： 文档得分： 经过调整，我们得出的结果中排在第一位的是 tid:9759987 其时间dateline是1473820016 得分：330.85 是原本的第三位。原来的排第一的 tid:666811排在了第三位，得分 329.40 原来的第二tid:10364925 得分：329.50 调整后的排序大致满足我们的需求。那么为什么调整后会变成这样的排序呢？ 首先我们要清楚solr的打分机制默认是通过匹配度计算文档相似度得来的。也就是第一次搜索的默认得分，引入edismax的bf函数后我们来分析下最终的结果是怎样，以第一次搜索排名前三的数据为例子： tid | dateline | 初始得分 | 引入bf重新计算 —|—|—|— 666811 | 1239781944 | 27.811382 | 329.40198 10364925 | 1503334472 | 26.519054 |329.50174 9759987 | 1473820016 | 26.511488 | 330.85834 根据bf=sqrt(log(dateline))^100 分别计算上面三个的新得分 1234567891011121314151617sqrt(log(1239781944)) = 3.0155174194591075 权重乘100 得: 301.55174194591075再加 27.811382 =329.36312394591073sqrt(log(1503334472)) = 3.029365546794402权重乘100 得:302.9365546794402再加 26.519054=329.45560867944016sqrt(log(1473820016)) = 3.0279439311841663权重乘100 得:302.79439311841663再加 26.511488=329.3058811184166 纳尼。很奇怪为什么 9759987 计算最小 不对劲 于是翻看原来前面查询的debug列表分析仔细看原来是原图： 添加edismax后： 对比以上靓图，原来是我们的Qparser不一样。在普通查询的时候我么使用的是定制化的 SWMCLuceneQparser 查询解析器。而 用edimax后，解析器变成了 ExtendDismaxQparser 这两个差别在于 定制化的 SWMCLuceneQparser会将查询字段通过IK分词转换后进行查询。其parsedquery_tostring 变成1&quot;parsedquery&quot;:&quot;PhraseQuery(subject:\&quot;武 则 天\&quot;) PhraseQuery(message:\&quot;武 则 天\&quot;)&quot;, ExtendDismaxQparser的 parsedquery_tostringshi :1&quot;parsedquery_toString&quot;:&quot;+((subject:武 subject:则 subject:天) (message:武 message:则 message:天)) (sqrt(log(long(dateline))))^10.0&quot;, 两者稍有不同，所以在计算最终权重的时候有些差异。]]></content>
      <categories>
        <category>搜索</category>
      </categories>
      <tags>
        <tag>solr</tag>
        <tag>edismax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo技术博客搭建日记]]></title>
    <url>%2F2017%2F09%2F02%2Fblog%2Fhexo%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%97%A5%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[9月2号听说Hexo 案例1 案例2 9月3号了解Hexo搭建博客方式 hexo搭建参考1 hexo搭建参考2 hexo主题 9月5号搭建完成 9月6号添加域名解析 9月7号添加Gitment评论功能 Gitment的github地址 9月9号配置结合alfred + 七牛 快捷插入markdown图片工具 Github地址 9月11号第一篇文章登陆 9月12号完善主题配置 9月13日添加站点收录 npm install hexo-generator-sitemap –save npm install hexo-generator-baidu-sitemap –save 搜索引擎站点收录 七牛后面需要域名绑定并且实名认证。所以改用自建图床，zimg。]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>IntelliJ IDEA</tag>
        <tag>Git</tag>
        <tag>Github</tag>
      </tags>
  </entry>
</search>
